{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-22T08:28:23.922815Z",
     "start_time": "2024-10-22T08:28:20.666004Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import time\n",
    "import os\n",
    "from stable_baselines3 import PPO  #PPO"
   ],
   "id": "e53a1203651f7767",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-22T08:28:23.953802Z",
     "start_time": "2024-10-22T08:28:23.930154Z"
    }
   },
   "cell_type": "code",
   "source": "from carla_park_env import CarlaParkingEnv",
   "id": "387456739ce827c6",
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-10-22T08:28:24.061639Z",
     "start_time": "2024-10-22T08:28:24.048269Z"
    }
   },
   "source": [
    "print('setting folders for logs and models')\n",
    "models_dir = f\"models/{int(time.time())}/\"\n",
    "logdir = f\"logs/{int(time.time())}/\"\n",
    "\n",
    "if not os.path.exists(models_dir):\n",
    "    os.makedirs(models_dir)\n",
    "\n",
    "if not os.path.exists(logdir):\n",
    "    os.makedirs(logdir)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setting folders for logs and models\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-22T08:28:29.584056Z",
     "start_time": "2024-10-22T08:28:24.092733Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print('connecting to env..')\n",
    "env = CarlaParkingEnv()"
   ],
   "id": "d00ce18c7e25a28d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "connecting to env..\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-22T08:28:33.833773Z",
     "start_time": "2024-10-22T08:28:29.601569Z"
    }
   },
   "cell_type": "code",
   "source": [
    "env.reset()\n",
    "print('Env has been reset as part of launch')"
   ],
   "id": "8626f06463a603fd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Env has been reset as part of launch\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-22T08:28:33.926951Z",
     "start_time": "2024-10-22T08:28:33.908062Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = (\n",
    "    PPO(\n",
    "        'MlpPolicy',\n",
    "        env,\n",
    "        verbose=2,\n",
    "        learning_rate=1e-5,\n",
    "        clip_range=0.5,  #clip_range en PPO para permitir más exploración:\n",
    "        tensorboard_log=logdir,\n",
    "        device='cuda'\n",
    "    )\n",
    ")"
   ],
   "id": "20ba0bca8a04a837",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ruben\\anaconda3\\envs\\carla-sim\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:50: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  \"You provided an OpenAI Gym environment. \"\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-22T08:28:34.114308Z",
     "start_time": "2024-10-22T08:28:34.096537Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from stable_baselines3.common.callbacks import BaseCallback\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ],
   "id": "aa04d3f3e666a8c0",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-22T08:28:34.191563Z",
     "start_time": "2024-10-22T08:28:34.168738Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class ProgressCallback(BaseCallback):\n",
    "    def __init__(self, check_freq: int, log_dir: str):\n",
    "        super(ProgressCallback, self).__init__()\n",
    "        self.check_freq = check_freq\n",
    "        self.log_dir = log_dir\n",
    "        self.rewards = []  # Para almacenar las recompensas por episodio\n",
    "        self.episode_rewards = []  # Para almacenar la recompensa promedio por episodio\n",
    "        self.episodes = 0  # Contador de episodios\n",
    "\n",
    "    def _on_step(self) -> bool:\n",
    "        if self.n_calls % self.check_freq == 0:\n",
    "            # Usar la recompensa registrada en 'rewards' directamente\n",
    "            mean_reward = np.mean(self.locals['rewards'])  # Promedio de recompensas recientes\n",
    "\n",
    "            self.rewards.append(mean_reward)\n",
    "            self.episodes += 1  # Aumenta el número de episodios\n",
    "            print(f\"Step: {self.n_calls}, Mean Reward (últimos {self.check_freq} pasos): {mean_reward}\")\n",
    "        \n",
    "        return True\n",
    "\n",
    "    def _on_training_end(self) -> None:\n",
    "        # Al finalizar el entrenamiento, graficar recompensas vs episodios\n",
    "        self.plot_rewards()\n",
    "        \n",
    "    def plot_rewards(self):\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(range(self.episodes), self.rewards, label=\"Recompensa Promedio\")\n",
    "        plt.xlabel(\"Episodios\")\n",
    "        plt.ylabel(\"Recompensa Promedio\")\n",
    "        plt.title(\"Recompensa Promedio por Episodio\")\n",
    "        plt.legend()\n",
    "        plt.grid()\n",
    "        plt.show()"
   ],
   "id": "63b921ffa5f70848",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-22T08:35:45.412612Z",
     "start_time": "2024-10-22T08:32:48.083908Z"
    }
   },
   "cell_type": "code",
   "source": [
    "total_timesteps = 10000 # how many timesteps you want to train for\n",
    "progress_callback = ProgressCallback(check_freq=10, log_dir=logdir)\n",
    "model.learn(total_timesteps=total_timesteps, callback=progress_callback)\n",
    "model.save(\"ppo_carla_parking\")"
   ],
   "id": "318a1383c45db0c2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to logs/1729585704/PPO_2\n",
      "Recompensa por acortar distancias: +  0.9156947947468153\n",
      "Penalización por parar muy lejos: -  0.16592873017928675\n",
      "Penalización por duración del episodio: -  0.26915503235680127\n",
      "Recompensa por acortar distancias: +  0.9156947947468153\n",
      "Penalización por duración del episodio: -  0.26945210791562124\n",
      "Recompensa por acortar distancias: +  0.9156948315576056\n",
      "Penalización por parar muy lejos: -  0.165928796171837\n",
      "Penalización por duración del episodio: -  0.2697533494953414\n",
      "Recompensa por acortar distancias: +  0.9156948904548395\n",
      "Penalización por parar muy lejos: -  0.1659289017599611\n",
      "Penalización por duración del episodio: -  0.2700616228709736\n",
      "Recompensa por acortar distancias: +  0.9156950082491956\n",
      "Penalización por parar muy lejos: -  0.1659291129363708\n",
      "Penalización por duración del episodio: -  0.27036160524201436\n",
      "Recompensa por acortar distancias: +  0.9156950082491956\n",
      "Penalización por duración del episodio: -  0.27067567219394545\n",
      "Recompensa por acortar distancias: +  0.9156950082491956\n",
      "Penalización por parar muy lejos: -  0.1659291129363708\n",
      "Penalización por duración del episodio: -  0.2707571045870313\n",
      "Recompensa por acortar distancias: +  0.9156949567141831\n",
      "Penalización por parar muy lejos: -  0.16592902054666508\n",
      "Penalización por duración del episodio: -  0.2708665824578071\n",
      "Recompensa por acortar distancias: +  0.9156949567141831\n",
      "Penalización por parar muy lejos: -  0.16592902054666508\n",
      "Penalización por duración del episodio: -  0.2709920738853657\n",
      "Recompensa por acortar distancias: +  0.9156949346277407\n",
      "Penalización por duración del episodio: -  0.27131180936598054\n",
      "Step: 10, Mean Reward (últimos 10 pasos): 0.6443831324577332\n",
      "Recompensa por acortar distancias: +  0.9156949346277407\n",
      "Penalización por parar muy lejos: -  0.16592898095108952\n",
      "Penalización por duración del episodio: -  0.271621356945686\n",
      "Recompensa por acortar distancias: +  0.9156952659238281\n",
      "Penalización por duración del episodio: -  0.2717019959823985\n",
      "Recompensa por acortar distancias: +  0.9156953542692517\n",
      "Penalización por duración del episodio: -  0.2719346567149935\n",
      "Recompensa por acortar distancias: +  0.9156955604082467\n",
      "Penalización por duración del episodio: -  0.27223785675606876\n",
      "Recompensa por acortar distancias: +  0.9156957002880186\n",
      "Penalización por duración del episodio: -  0.27254906784137484\n",
      "Recompensa por acortar distancias: +  0.9156957002880186\n",
      "Penalización por parar muy lejos: -  0.16593035360212585\n",
      "Penalización por duración del episodio: -  0.2728503783499996\n",
      "Recompensa por acortar distancias: +  0.9156958696158813\n",
      "Penalización por parar muy lejos: -  0.16593065717041022\n",
      "Penalización por duración del episodio: -  0.2731650563841259\n",
      "Recompensa por acortar distancias: +  0.9156958696158813\n",
      "Penalización por duración del episodio: -  0.27325403538123294\n",
      "Recompensa por acortar distancias: +  0.9156958548917316\n",
      "Penalización por parar muy lejos: -  0.16593063077315043\n",
      "Penalización por duración del episodio: -  0.2734700130311367\n",
      "Recompensa por acortar distancias: +  0.9156958917021016\n",
      "Penalización por duración del episodio: -  0.27353116722257104\n",
      "steer input from model: 0.05 , throttle:  1.0\n",
      "reward: 0.6421647244795305\n",
      "Step: 20, Mean Reward (últimos 10 pasos): 0.6421647071838379\n",
      "Recompensa por acortar distancias: +  0.9156959653227976\n",
      "Penalización por duración del episodio: -  0.27378343955990025\n",
      "Recompensa por acortar distancias: +  0.9156961346501771\n",
      "Penalización por duración del episodio: -  0.27408918200356275\n",
      "Recompensa por acortar distancias: +  0.9156962818911256\n",
      "Penalización por duración del episodio: -  0.27441889136023273\n",
      "Recompensa por acortar distancias: +  0.9156962818911256\n",
      "Penalización por parar muy lejos: -  0.16593139629504988\n",
      "Penalización por duración del episodio: -  0.2747368944318423\n",
      "Recompensa por acortar distancias: +  0.9156962598049982\n",
      "Penalización por parar muy lejos: -  0.16593135669902018\n",
      "Penalización por duración del episodio: -  0.27505678073399314\n",
      "Recompensa por acortar distancias: +  0.9156962892531669\n",
      "Penalización por parar muy lejos: -  0.16593140949372814\n",
      "Penalización por duración del episodio: -  0.27536783510762614\n",
      "Recompensa por acortar distancias: +  0.9156963481494764\n",
      "Penalización por duración del episodio: -  0.27567630816747163\n",
      "Recompensa por acortar distancias: +  0.9156966720785101\n",
      "Penalización por parar muy lejos: -  0.16593209582615595\n",
      "Penalización por duración del episodio: -  0.27598327536934775\n",
      "Recompensa por acortar distancias: +  0.9156968855765736\n",
      "Penalización por parar muy lejos: -  0.1659324785894592\n",
      "Penalización por duración del episodio: -  0.27630409815057794\n",
      "Recompensa por acortar distancias: +  0.9156968855765736\n",
      "Penalización por parar muy lejos: -  0.1659324785894592\n",
      "Penalización por duración del episodio: -  0.27661581971463184\n",
      "Step: 30, Mean Reward (últimos 10 pasos): 0.4731485843658447\n",
      "Recompensa por acortar distancias: +  0.9156969591964816\n",
      "Penalización por parar muy lejos: -  0.16593261057696915\n",
      "Penalización por duración del episodio: -  0.27693330588214066\n",
      "Recompensa por acortar distancias: +  0.9156969812824427\n",
      "Penalización por duración del episodio: -  0.2772454462523245\n",
      "Recompensa por acortar distancias: +  0.9156969812824427\n",
      "Penalización por parar muy lejos: -  0.16593265017323852\n",
      "Penalización por duración del episodio: -  0.27755553254056325\n",
      "Recompensa por acortar distancias: +  0.9156971653319136\n",
      "Penalización por parar muy lejos: -  0.16593298014244443\n",
      "Penalización por duración del episodio: -  0.2778786106133923\n",
      "Recompensa por acortar distancias: +  0.9156973641049325\n",
      "Penalización por parar muy lejos: -  0.16593333650977715\n",
      "Penalización por duración del episodio: -  0.2781848046648425\n",
      "Recompensa por acortar distancias: +  0.9156974671722563\n",
      "Penalización por duración del episodio: -  0.27850616260584465\n",
      "Recompensa por acortar distancias: +  0.9156974671722563\n",
      "Penalización por duración del episodio: -  0.2788208447975555\n",
      "Recompensa por acortar distancias: +  0.9156974230005601\n",
      "Penalización por duración del episodio: -  0.27912875038086465\n",
      "Recompensa por acortar distancias: +  0.9156974230005601\n",
      "Penalización por parar muy lejos: -  0.1659334421002157\n",
      "Penalización por duración del episodio: -  0.2794267734815423\n",
      "Recompensa por acortar distancias: +  0.9156975260678185\n",
      "Penalización por duración del episodio: -  0.27951890912290434\n",
      "steer input from model: 0.05 , throttle:  1.0\n",
      "reward: 0.6361786169449142\n",
      "Step: 40, Mean Reward (últimos 10 pasos): 0.6361786127090454\n",
      "Recompensa por acortar distancias: +  0.9156975702394657\n",
      "Penalización por duración del episodio: -  0.27973841765447816\n",
      "Recompensa por acortar distancias: +  0.9156976144110918\n",
      "Penalización por parar muy lejos: -  0.16593378526951275\n",
      "Penalización por duración del episodio: -  0.2800501108788266\n",
      "Recompensa por acortar distancias: +  0.9156977101162097\n",
      "Penalización por duración del episodio: -  0.28035795151888404\n",
      "Recompensa por acortar distancias: +  0.9156977101162097\n",
      "Penalización por duración del episodio: -  0.28068495937570015\n",
      "Recompensa por acortar distancias: +  0.9156975407917033\n",
      "Penalización por duración del episodio: -  0.2810041648385586\n",
      "Recompensa por acortar distancias: +  0.9156975260678185\n",
      "Penalización por parar muy lejos: -  0.1659336268836127\n",
      "Penalización por duración del episodio: -  0.2813062046218683\n",
      "Recompensa por acortar distancias: +  0.9156973420190626\n",
      "Penalización por duración del episodio: -  0.2816234909342561\n",
      "Recompensa por acortar distancias: +  0.9156974303625111\n",
      "Penalización por parar muy lejos: -  0.1659334552990243\n",
      "Penalización por duración del episodio: -  0.28195211095635253\n",
      "Recompensa por acortar distancias: +  0.9156975260678185\n",
      "Penalización por duración del episodio: -  0.2820313272433547\n",
      "Recompensa por acortar distancias: +  0.915697562877526\n",
      "Penalización por duración del episodio: -  0.28227225476962226\n",
      "Step: 50, Mean Reward (últimos 10 pasos): 0.6334252953529358\n",
      "Recompensa por acortar distancias: +  0.915697562877526\n",
      "Penalización por duración del episodio: -  0.2825821206649761\n",
      "Recompensa por acortar distancias: +  0.915697562877526\n",
      "Penalización por duración del episodio: -  0.2829040232632743\n",
      "Recompensa por acortar distancias: +  0.9156974082766567\n",
      "Penalización por duración del episodio: -  0.28301106866843356\n",
      "Recompensa por acortar distancias: +  0.9156974082766567\n",
      "Penalización por parar muy lejos: -  0.16593341570260103\n",
      "Penalización por duración del episodio: -  0.28321125499628585\n",
      "Recompensa por acortar distancias: +  0.9156974082766567\n",
      "Penalización por parar muy lejos: -  0.16593341570260103\n",
      "Penalización por duración del episodio: -  0.2835155791818344\n",
      "Recompensa por acortar distancias: +  0.9156974671722563\n",
      "Penalización por parar muy lejos: -  0.16593352129307995\n",
      "Penalización por duración del episodio: -  0.2836091863410429\n",
      "Recompensa por acortar distancias: +  0.9156975039819871\n",
      "Penalización por parar muy lejos: -  0.16593358728715663\n",
      "Penalización por duración del episodio: -  0.2837017753319884\n",
      "Recompensa por acortar distancias: +  0.9156975923252814\n",
      "Penalización por parar muy lejos: -  0.16593374567302638\n",
      "Penalización por duración del episodio: -  0.2838316399460803\n",
      "Recompensa por acortar distancias: +  0.9156975996872189\n",
      "Penalización por duración del episodio: -  0.283920118644338\n",
      "Recompensa por acortar distancias: +  0.9156976438588309\n",
      "Penalización por duración del episodio: -  0.2841448435176963\n",
      "steer input from model: -0.25 , throttle:  0.7\n",
      "reward: 0.6315528003411346\n",
      "Step: 60, Mean Reward (últimos 10 pasos): 0.6315528154373169\n",
      "Recompensa por acortar distancias: +  0.9156976733065607\n",
      "Penalización por parar muy lejos: -  0.16593389086018007\n",
      "Penalización por duración del episodio: -  0.28445231562136175\n",
      "Recompensa por acortar distancias: +  0.9156976733065607\n",
      "Penalización por parar muy lejos: -  0.16593389086018007\n",
      "Penalización por duración del episodio: -  0.2847620130089063\n",
      "Recompensa por acortar distancias: +  0.9156975113439315\n",
      "Penalización por duración del episodio: -  0.2850974534258748\n",
      "Recompensa por acortar distancias: +  0.9156975039819871\n",
      "Penalización por duración del episodio: -  0.28541071912584093\n",
      "Recompensa por acortar distancias: +  0.9156972904853456\n",
      "Penalización por parar muy lejos: -  0.16593320452180466\n",
      "Penalización por duración del episodio: -  0.28572297989075696\n",
      "Recompensa por acortar distancias: +  0.9156973199331874\n",
      "Penalización por parar muy lejos: -  0.16593325731698358\n",
      "Penalización por duración del episodio: -  0.28583863391757475\n",
      "Recompensa por acortar distancias: +  0.9156973199331874\n",
      "Penalización por duración del episodio: -  0.28593148987091965\n",
      "Recompensa por acortar distancias: +  0.9156973199331874\n",
      "Penalización por parar muy lejos: -  0.16593325731698358\n",
      "Penalización por duración del episodio: -  0.2860240328260913\n",
      "Recompensa por acortar distancias: +  0.9156972683994581\n",
      "Penalización por duración del episodio: -  0.2861371398271559\n",
      "Recompensa por acortar distancias: +  0.9156972683994581\n",
      "Penalización por parar muy lejos: -  0.16593316492542934\n",
      "Penalización por duración del episodio: -  0.28633600877077503\n",
      "Step: 70, Mean Reward (últimos 10 pasos): 0.4634280800819397\n",
      "Recompensa por acortar distancias: +  0.9156971506079694\n",
      "Penalización por duración del episodio: -  0.28666091771552143\n",
      "Recompensa por acortar distancias: +  0.9156971506079694\n",
      "Penalización por duración del episodio: -  0.2869808269636336\n",
      "Recompensa por acortar distancias: +  0.9156969665584692\n",
      "Penalización por parar muy lejos: -  0.1659326237757248\n",
      "Penalización por duración del episodio: -  0.2870648582422683\n",
      "Recompensa por acortar distancias: +  0.9156969960064137\n",
      "Penalización por parar muy lejos: -  0.16593267657075564\n",
      "Penalización por duración del episodio: -  0.28730467429304485\n",
      "Recompensa por acortar distancias: +  0.9156969960064137\n",
      "Penalización por duración del episodio: -  0.28762739623441774\n",
      "Recompensa por acortar distancias: +  0.9156970769882131\n",
      "Penalización por duración del episodio: -  0.2879404743877536\n",
      "Recompensa por acortar distancias: +  0.9156971579699418\n",
      "Penalización por parar muy lejos: -  0.1659329669436661\n",
      "Penalización por duración del episodio: -  0.28825834854994686\n",
      "Recompensa por acortar distancias: +  0.9156972683994581\n",
      "Penalización por duración del episodio: -  0.2885733722147087\n",
      "Recompensa por acortar distancias: +  0.9156972683994581\n",
      "Penalización por parar muy lejos: -  0.16593316492542934\n",
      "Penalización por duración del episodio: -  0.2888919358840312\n",
      "Recompensa por acortar distancias: +  0.9156971285220487\n",
      "Penalización por duración del episodio: -  0.28921636418748004\n",
      "steer input from model: 0.05 , throttle:  0.7\n",
      "reward: 0.6264807643345687\n",
      "Step: 80, Mean Reward (últimos 10 pasos): 0.626480758190155\n",
      "Recompensa por acortar distancias: +  0.9156971506079694\n",
      "Penalización por duración del episodio: -  0.28953112613927856\n",
      "Recompensa por acortar distancias: +  0.9156969960064137\n",
      "Penalización por duración del episodio: -  0.2898512144164085\n",
      "Recompensa por acortar distancias: +  0.9156972095037325\n",
      "Penalización por duración del episodio: -  0.290174271887539\n",
      "Recompensa por acortar distancias: +  0.9156972904853456\n",
      "Penalización por parar muy lejos: -  0.16593320452180466\n",
      "Penalización por duración del episodio: -  0.2904885299145295\n",
      "Recompensa por acortar distancias: +  0.9156973125712279\n",
      "Penalización por duración del episodio: -  0.29081304926619955\n",
      "Recompensa por acortar distancias: +  0.9156973125712279\n",
      "Penalización por parar muy lejos: -  0.16593324411818758\n",
      "Penalización por duración del episodio: -  0.2909131827329689\n",
      "Recompensa por acortar distancias: +  0.9156971211600738\n",
      "Penalización por parar muy lejos: -  0.16593290094978708\n",
      "Penalización por duración del episodio: -  0.2911391797888341\n",
      "Recompensa por acortar distancias: +  0.9156970917121691\n",
      "Penalización por duración del episodio: -  0.2914533250505832\n",
      "Recompensa por acortar distancias: +  0.9156970917121691\n",
      "Penalización por parar muy lejos: -  0.16593284815469897\n",
      "Penalización por duración del episodio: -  0.2915308424261436\n",
      "Recompensa por acortar distancias: +  0.9156971726938848\n",
      "Penalización por duración del episodio: -  0.2917733157515306\n",
      "Step: 90, Mean Reward (últimos 10 pasos): 0.6239238381385803\n",
      "Recompensa por acortar distancias: +  0.9156972389515999\n",
      "Penalización por parar muy lejos: -  0.16593311213027395\n",
      "Penalización por duración del episodio: -  0.291870894122252\n",
      "Recompensa por acortar distancias: +  0.9156972610374945\n",
      "Penalización por duración del episodio: -  0.29210568501072187\n",
      "Recompensa por acortar distancias: +  0.9156972831233836\n",
      "Penalización por duración del episodio: -  0.29244661884932516\n",
      "Recompensa por acortar distancias: +  0.9156973861907973\n",
      "Penalización por duración del episodio: -  0.2927637297330574\n",
      "Recompensa por acortar distancias: +  0.9156973861907973\n",
      "Penalización por duración del episodio: -  0.29308067156646955\n",
      "Recompensa por acortar distancias: +  0.9156972831233836\n",
      "Penalización por parar muy lejos: -  0.16593319132301204\n",
      "Penalización por duración del episodio: -  0.2934043683533375\n",
      "Recompensa por acortar distancias: +  0.9156973052092677\n",
      "Penalización por duración del episodio: -  0.29373792886757466\n",
      "Recompensa por acortar distancias: +  0.9156971653319136\n",
      "Penalización por duración del episodio: -  0.29381686054424333\n",
      "Recompensa por acortar distancias: +  0.9156971653319136\n",
      "Penalización por parar muy lejos: -  0.16593298014244443\n",
      "Penalización por duración del episodio: -  0.2940614061951784\n",
      "Recompensa por acortar distancias: +  0.9156971653319136\n",
      "Penalización por parar muy lejos: -  0.16593298014244443\n",
      "Penalización por duración del episodio: -  0.2941760255502207\n",
      "steer input from model: 0.1 , throttle:  0.0\n",
      "reward: 0.4555881596392485\n",
      "Step: 100, Mean Reward (últimos 10 pasos): 0.455588161945343\n",
      "Recompensa por acortar distancias: +  0.9156971653319136\n",
      "Penalización por parar muy lejos: -  0.16593298014244443\n",
      "Penalización por duración del episodio: -  0.29438127291138694\n",
      "Recompensa por acortar distancias: +  0.9156971432459964\n",
      "Penalización por parar muy lejos: -  0.16593294054611193\n",
      "Penalización por duración del episodio: -  0.2944737535797525\n",
      "Recompensa por acortar distancias: +  0.9156970696262342\n",
      "Penalización por duración del episodio: -  0.29470845859005584\n",
      "Recompensa por acortar distancias: +  0.9156970696262342\n",
      "Penalización por duración del episodio: -  0.29503406571992324\n",
      "Recompensa por acortar distancias: +  0.9156970696262342\n",
      "Penalización por parar muy lejos: -  0.16593280855839176\n",
      "Penalización por duración del episodio: -  0.29513962567857505\n",
      "Recompensa por acortar distancias: +  0.9156970696262342\n",
      "Penalización por parar muy lejos: -  0.16593280855839176\n",
      "Penalización por duración del episodio: -  0.2953556443901927\n",
      "Recompensa por acortar distancias: +  0.915696811956607\n",
      "Penalización por duración del episodio: -  0.2954221194703202\n",
      "Recompensa por acortar distancias: +  0.915696811956607\n",
      "Penalización por parar muy lejos: -  0.16593234660203335\n",
      "Penalización por duración del episodio: -  0.29569648305239565\n",
      "Recompensa por acortar distancias: +  0.915696811956607\n",
      "Penalización por duración del episodio: -  0.2960251432841975\n",
      "Recompensa por acortar distancias: +  0.915696811956607\n",
      "Penalización por duración del episodio: -  0.2963478502319227\n",
      "Step: 110, Mean Reward (últimos 10 pasos): 0.61934894323349\n",
      "Recompensa por acortar distancias: +  0.9156967898706059\n",
      "Penalización por duración del episodio: -  0.29643574149947255\n",
      "Recompensa por acortar distancias: +  0.9156968634905899\n",
      "Penalización por parar muy lejos: -  0.16593243899322263\n",
      "Penalización por duración del episodio: -  0.2966757603936358\n",
      "Recompensa por acortar distancias: +  0.9156968634905899\n",
      "Penalización por duración del episodio: -  0.29701143690502135\n",
      "Recompensa por acortar distancias: +  0.9156968634905899\n",
      "Penalización por parar muy lejos: -  0.16593243899322263\n",
      "Penalización por duración del episodio: -  0.29734372120156033\n",
      "Recompensa por acortar distancias: +  0.9156968855765736\n",
      "Penalización por duración del episodio: -  0.29769053551327185\n",
      "Recompensa por acortar distancias: +  0.9156969960064137\n",
      "Penalización por parar muy lejos: -  0.16593267657075564\n",
      "Penalización por duración del episodio: -  0.29802398071009023\n",
      "Recompensa por acortar distancias: +  0.9156971211600738\n",
      "Penalización por parar muy lejos: -  0.16593290094978708\n",
      "Penalización por duración del episodio: -  0.29835953234833484\n",
      "Recompensa por acortar distancias: +  0.9156972610374945\n",
      "Penalización por parar muy lejos: -  0.16593315172663922\n",
      "Penalización por duración del episodio: -  0.29869660954311344\n",
      "Recompensa por acortar distancias: +  0.9156972831233836\n",
      "Penalización por parar muy lejos: -  0.16593319132301204\n",
      "Penalización por duración del episodio: -  0.299014680016978\n",
      "Recompensa por acortar distancias: +  0.9156972831233836\n",
      "Penalización por parar muy lejos: -  0.16593319132301204\n",
      "Penalización por duración del episodio: -  0.2993696439824945\n",
      "steer input from model: 0.1 , throttle:  0.0\n",
      "reward: 0.45039444781787713\n",
      "Step: 120, Mean Reward (últimos 10 pasos): 0.4503944516181946\n",
      "Recompensa por acortar distancias: +  0.9156971211600738\n",
      "Penalización por parar muy lejos: -  0.16593290094978708\n",
      "Penalización por duración del episodio: -  0.29944419576334225\n",
      "Recompensa por acortar distancias: +  0.9156971211600738\n",
      "Penalización por duración del episodio: -  0.29968522768208633\n",
      "Recompensa por acortar distancias: +  0.9156970549022747\n",
      "Penalización por duración del episodio: -  0.3000136539453298\n",
      "Recompensa por acortar distancias: +  0.9156971653319136\n",
      "Penalización por duración del episodio: -  0.30011170861340714\n",
      "Recompensa por acortar distancias: +  0.9156971726938848\n",
      "Penalización por parar muy lejos: -  0.1659329933412236\n",
      "Penalización por duración del episodio: -  0.3003441044245594\n",
      "Recompensa por acortar distancias: +  0.9156972683994581\n",
      "Penalización por parar muy lejos: -  0.16593316492542934\n",
      "Penalización por duración del episodio: -  0.3004348646383969\n",
      "Recompensa por acortar distancias: +  0.9156972683994581\n",
      "Penalización por parar muy lejos: -  0.16593316492542934\n",
      "Penalización por duración del episodio: -  0.3006740606861545\n",
      "Recompensa por acortar distancias: +  0.9156973714668881\n",
      "Penalización por parar muy lejos: -  0.16593334970857904\n",
      "Penalización por duración del episodio: -  0.30100702763031467\n",
      "Recompensa por acortar distancias: +  0.9156973714668881\n",
      "Penalización por duración del episodio: -  0.3013429250087541\n",
      "Recompensa por acortar distancias: +  0.9156973714668881\n",
      "Penalización por parar muy lejos: -  0.16593334970857904\n",
      "Penalización por duración del episodio: -  0.3016623602250592\n",
      "Step: 130, Mean Reward (últimos 10 pasos): 0.448101669549942\n",
      "Recompensa por acortar distancias: +  0.915697194779795\n",
      "Penalización por parar muy lejos: -  0.16593303293756617\n",
      "Penalización por duración del episodio: -  0.30199851714456816\n",
      "Recompensa por acortar distancias: +  0.915697018092366\n",
      "Penalización por parar muy lejos: -  0.16593271616703767\n",
      "Penalización por duración del episodio: -  0.30207299398049087\n",
      "Recompensa por acortar distancias: +  0.9156970549022747\n",
      "Penalización por parar muy lejos: -  0.1659327821608578\n",
      "Penalización por duración del episodio: -  0.3023372551143023\n",
      "Recompensa por acortar distancias: +  0.9156971211600738\n",
      "Penalización por duración del episodio: -  0.30243187313254916\n",
      "Recompensa por acortar distancias: +  0.9156971211600738\n",
      "Penalización por parar muy lejos: -  0.16593290094978708\n",
      "Penalización por duración del episodio: -  0.3026755943526539\n",
      "Recompensa por acortar distancias: +  0.9156971211600738\n",
      "Penalización por parar muy lejos: -  0.16593290094978708\n",
      "Penalización por duración del episodio: -  0.30300624237852225\n",
      "Recompensa por acortar distancias: +  0.9156971211600738\n",
      "Penalización por parar muy lejos: -  0.16593290094978708\n",
      "Penalización por duración del episodio: -  0.3033427374663031\n",
      "Recompensa por acortar distancias: +  0.9156971211600738\n",
      "Penalización por parar muy lejos: -  0.16593290094978708\n",
      "Penalización por duración del episodio: -  0.30343364801471345\n",
      "Recompensa por acortar distancias: +  0.9156971211600738\n",
      "Penalización por duración del episodio: -  0.3036737414539203\n",
      "Recompensa por acortar distancias: +  0.9156967456985874\n",
      "Penalización por duración del episodio: -  0.3040048279448854\n",
      "steer input from model: 0.25 , throttle:  1.0\n",
      "reward: 0.6116919177537019\n",
      "Step: 140, Mean Reward (últimos 10 pasos): 0.6116918921470642\n",
      "Recompensa por acortar distancias: +  0.9156967456985874\n",
      "Penalización por parar muy lejos: -  0.16593222781342198\n",
      "Penalización por duración del episodio: -  0.3041068545460915\n",
      "Recompensa por acortar distancias: +  0.9156967898706059\n",
      "Penalización por parar muy lejos: -  0.16593230700582204\n",
      "Penalización por duración del episodio: -  0.30434612731301297\n",
      "Recompensa por acortar distancias: +  0.9156968266806051\n",
      "Penalización por duración del episodio: -  0.30445467572968316\n",
      "Recompensa por acortar distancias: +  0.9156968782145795\n",
      "Penalización por duración del episodio: -  0.30452819124927444\n",
      "Recompensa por acortar distancias: +  0.9156968782145795\n",
      "Penalización por duración del episodio: -  0.3046773079208885\n",
      "Recompensa por acortar distancias: +  0.9156969076625522\n",
      "Penalización por parar muy lejos: -  0.16593251818570337\n",
      "Penalización por duración del episodio: -  0.30502340317386095\n",
      "Recompensa por acortar distancias: +  0.9156969591964816\n",
      "Penalización por duración del episodio: -  0.30535449155611233\n",
      "Recompensa por acortar distancias: +  0.9156969591964816\n",
      "Penalización por duración del episodio: -  0.30569511747384903\n",
      "Recompensa por acortar distancias: +  0.9156968855765736\n",
      "Penalización por parar muy lejos: -  0.1659324785894592\n",
      "Penalización por duración del episodio: -  0.30603711043703397\n",
      "Recompensa por acortar distancias: +  0.9156969076625522\n",
      "Penalización por duración del episodio: -  0.32986148256976733\n",
      "Step: 150, Mean Reward (últimos 10 pasos): 0.5858353972434998\n",
      "Recompensa por acortar distancias: +  0.8062930224321185\n",
      "Penalización por duración del episodio: -  0.3299501932375585\n",
      "Recompensa por acortar distancias: +  0.8004766627892315\n",
      "Penalización por parar muy lejos: -  0.06845143372661268\n",
      "Penalización por duración del episodio: -  0.33015462013000724\n",
      "Recompensa por acortar distancias: +  0.7984574703828717\n",
      "Penalización por parar muy lejos: -  0.06765266213971625\n",
      "Penalización por duración del episodio: -  0.33051244384842243\n",
      "Recompensa por acortar distancias: +  0.7923927770167404\n",
      "Penalización por parar muy lejos: -  0.06533924740567132\n",
      "Penalización por duración del episodio: -  0.330860271166932\n",
      "Recompensa por acortar distancias: +  0.7873062676188444\n",
      "Penalización por duración del episodio: -  0.33120234740727106\n",
      "Recompensa por acortar distancias: +  0.7873062676188444\n",
      "Penalización por parar muy lejos: -  0.0634924891745281\n",
      "Penalización por duración del episodio: -  0.3315387052781834\n",
      "Recompensa por acortar distancias: +  0.7873062676188444\n",
      "Penalización por parar muy lejos: -  0.0634924891745281\n",
      "Penalización por duración del episodio: -  0.3316434395491574\n",
      "Recompensa por acortar distancias: +  0.7763588294030309\n",
      "Penalización por parar muy lejos: -  0.05978082654622837\n",
      "Penalización por duración del episodio: -  0.3318797869718738\n",
      "Recompensa por acortar distancias: +  0.7739580799998965\n",
      "Penalización por duración del episodio: -  0.3322330731966091\n",
      "Recompensa por acortar distancias: +  0.7670387552497593\n",
      "Penalización por parar muy lejos: -  0.05687543837702622\n",
      "Penalización por duración del episodio: -  0.33258013941286857\n",
      "steer input from model: 0.05 , throttle:  0.0\n",
      "reward: 0.37758317745986447\n",
      "Step: 160, Mean Reward (últimos 10 pasos): 0.37758317589759827\n",
      "Recompensa por acortar distancias: +  0.7612607739879731\n",
      "Penalización por parar muy lejos: -  0.05517989492821986\n",
      "Penalización por duración del episodio: -  0.33293493279064346\n",
      "Recompensa por acortar distancias: +  0.7540694308397182\n",
      "Penalización por duración del episodio: -  0.3332915526880178\n",
      "Recompensa por acortar distancias: +  0.7523371860526247\n",
      "Penalización por parar muy lejos: -  0.05270583060993404\n",
      "Penalización por duración del episodio: -  0.3336445470266866\n",
      "Recompensa por acortar distancias: +  0.7523371860526247\n",
      "Penalización por duración del episodio: -  0.33399021827780423\n",
      "Recompensa por acortar distancias: +  0.7377537913294431\n",
      "Penalización por duración del episodio: -  0.3343447170289731\n",
      "Recompensa por acortar distancias: +  0.7299767172468397\n",
      "Penalización por duración del episodio: -  0.33469999756468216\n",
      "Recompensa por acortar distancias: +  0.7242766534778954\n",
      "Penalización por duración del episodio: -  0.3350386592547871\n",
      "Recompensa por acortar distancias: +  0.7197457942962084\n",
      "Penalización por duración del episodio: -  0.3351232742103012\n",
      "Recompensa por acortar distancias: +  0.7172566608458827\n",
      "Penalización por duración del episodio: -  0.3353916643590799\n",
      "Recompensa por acortar distancias: +  0.7120747915764115\n",
      "Penalización por duración del episodio: -  0.335489744280179\n",
      "Step: 170, Mean Reward (últimos 10 pasos): 0.3765850365161896\n",
      "Recompensa por acortar distancias: +  0.7120747915764115\n",
      "Penalización por duración del episodio: -  0.3357498730765456\n",
      "Recompensa por acortar distancias: +  0.7120747915764115\n",
      "Penalización por duración del episodio: -  0.33608195306377725\n",
      "Recompensa por acortar distancias: +  0.7120747915764115\n",
      "Penalización por duración del episodio: -  0.3362101736323981\n",
      "Recompensa por acortar distancias: +  0.698376513104052\n",
      "Penalización por duración del episodio: -  0.33644346392912167\n",
      "Recompensa por acortar distancias: +  0.6947849016395206\n",
      "Penalización por duración del episodio: -  0.33680368590194437\n",
      "Recompensa por acortar distancias: +  0.6866839715900211\n",
      "Penalización por duración del episodio: -  0.33715630767648685\n",
      "Recompensa por acortar distancias: +  0.6797581973400941\n",
      "Penalización por duración del episodio: -  0.3372730909781572\n",
      "Recompensa por acortar distancias: +  0.6797581973400941\n",
      "Penalización por duración del episodio: -  0.33751353546381613\n",
      "Recompensa por acortar distancias: +  0.6731298801573217\n",
      "Penalización por duración del episodio: -  0.33785813723958596\n",
      "Recompensa por acortar distancias: +  0.6731298801573217\n",
      "Penalización por duración del episodio: -  0.3382026764403206\n",
      "steer input from model: -0.25 , throttle:  0.7\n",
      "reward: 0.3349272037170011\n",
      "Step: 180, Mean Reward (últimos 10 pasos): 0.33492720127105713\n",
      "Recompensa por acortar distancias: +  0.6731298801573217\n",
      "Penalización por duración del episodio: -  0.3385624808108616\n",
      "Recompensa por acortar distancias: +  0.655925771587928\n",
      "Penalización por duración del episodio: -  0.3389087541609574\n",
      "Recompensa por acortar distancias: +  0.6478429251854271\n",
      "Penalización por duración del episodio: -  0.3392548205666972\n",
      "Recompensa por acortar distancias: +  0.6408821984266888\n",
      "Penalización por duración del episodio: -  0.33934250654164666\n",
      "Recompensa por acortar distancias: +  0.6408821984266888\n",
      "Penalización por duración del episodio: -  0.3396146886222847\n",
      "Recompensa por acortar distancias: +  0.6340389338292561\n",
      "Penalización por duración del episodio: -  0.3399650908076728\n",
      "Recompensa por acortar distancias: +  0.6290325955049284\n",
      "Penalización por duración del episodio: -  0.3403207424235455\n",
      "Recompensa por acortar distancias: +  0.6290325955049284\n",
      "Penalización por duración del episodio: -  0.340665858260324\n",
      "Recompensa por acortar distancias: +  0.6150441365873077\n",
      "Penalización por duración del episodio: -  0.3410099215815285\n",
      "Recompensa por acortar distancias: +  0.6118969837306739\n",
      "Penalización por duración del episodio: -  0.34136004895566907\n",
      "Step: 190, Mean Reward (últimos 10 pasos): 0.2705369293689728\n",
      "Recompensa por acortar distancias: +  0.6007237615606401\n",
      "Penalización por duración del episodio: -  0.3414658613197297\n",
      "Recompensa por acortar distancias: +  0.6007237615606401\n",
      "Penalización por duración del episodio: -  0.3417152834723438\n",
      "Recompensa por acortar distancias: +  0.5960320293180746\n",
      "Penalización por duración del episodio: -  0.3418149803123966\n",
      "Recompensa por acortar distancias: +  0.5937411528582057\n",
      "Penalización por duración del episodio: -  0.3420611499589292\n",
      "Recompensa por acortar distancias: +  0.589291645132286\n",
      "Penalización por duración del episodio: -  0.342407141478775\n",
      "Recompensa por acortar distancias: +  0.589291645132286\n",
      "Penalización por duración del episodio: -  0.34274837551691373\n",
      "Recompensa por acortar distancias: +  0.5752540983375262\n",
      "Penalización por duración del episodio: -  0.34311206702084074\n",
      "Recompensa por acortar distancias: +  0.5723402487559465\n",
      "Penalización por duración del episodio: -  0.34346237299755317\n",
      "Recompensa por acortar distancias: +  0.5642193962876061\n",
      "Penalización por duración del episodio: -  0.343804157252796\n",
      "Recompensa por acortar distancias: +  0.5574365678513049\n",
      "Penalización por duración del episodio: -  0.3441523026649317\n",
      "steer input from model: -0.25 , throttle:  1.0\n",
      "reward: 0.21328426518637322\n",
      "Step: 200, Mean Reward (últimos 10 pasos): 0.21328426897525787\n",
      "Recompensa por acortar distancias: +  0.5512025543445342\n",
      "Penalización por duración del episodio: -  0.3442532105946553\n",
      "Recompensa por acortar distancias: +  0.5489006221952594\n",
      "Penalización por duración del episodio: -  0.3445017623213229\n",
      "Recompensa por acortar distancias: +  0.5462848635761879\n",
      "Penalización por duración del episodio: -  0.34486153321586865\n",
      "Recompensa por acortar distancias: +  0.5462848635761879\n",
      "Penalización por duración del episodio: -  0.34522083523837543\n",
      "Recompensa por acortar distancias: +  0.5332038307691254\n",
      "Penalización por duración del episodio: -  0.34531759565806874\n",
      "Recompensa por acortar distancias: +  0.5307422099046163\n",
      "Penalización por duración del episodio: -  0.34558112832704524\n",
      "Recompensa por acortar distancias: +  0.5307422099046163\n",
      "Penalización por duración del episodio: -  0.34594429607942184\n",
      "Recompensa por acortar distancias: +  0.5204002019093763\n",
      "Penalización por duración del episodio: -  0.34630085915906983\n",
      "Recompensa por acortar distancias: +  0.5146218081928212\n",
      "Penalización por duración del episodio: -  0.34664869066458115\n",
      "Recompensa por acortar distancias: +  0.508688618219856\n",
      "Penalización por duración del episodio: -  0.34700631849729374\n",
      "Step: 210, Mean Reward (últimos 10 pasos): 0.16168229281902313\n",
      "Recompensa por acortar distancias: +  0.508688618219856\n",
      "Penalización por duración del episodio: -  0.3473593194965496\n",
      "Recompensa por acortar distancias: +  0.49727688143948084\n",
      "Penalización por duración del episodio: -  0.3477080325817269\n",
      "Recompensa por acortar distancias: +  0.4947461452665526\n",
      "Penalización por duración del episodio: -  0.34806380686957517\n",
      "Recompensa por acortar distancias: +  0.4861321799486\n",
      "Penalización por duración del episodio: -  0.34842429738929576\n",
      "Recompensa por acortar distancias: +  0.48100360505924344\n",
      "Penalización por duración del episodio: -  0.3487737302806766\n",
      "Recompensa por acortar distancias: +  0.47576750881771424\n",
      "Penalización por duración del episodio: -  0.3491388423931822\n",
      "Recompensa por acortar distancias: +  0.4740607114052965\n",
      "Penalización por duración del episodio: -  0.3494842766706358\n",
      "Recompensa por acortar distancias: +  0.4740607114052965\n",
      "Penalización por duración del episodio: -  0.34959854581801847\n",
      "Recompensa por acortar distancias: +  0.4740607114052965\n",
      "Penalización por duración del episodio: -  0.3498365228315674\n",
      "Recompensa por acortar distancias: +  0.4611919014582732\n",
      "Penalización por duración del episodio: -  0.3501911410309773\n",
      "steer input from model: -0.9 , throttle:  0.3\n",
      "reward: 0.1110007604272959\n",
      "Step: 220, Mean Reward (últimos 10 pasos): 0.11100076138973236\n",
      "Recompensa por acortar distancias: +  0.4611919014582732\n",
      "Penalización por duración del episodio: -  0.35055513069276134\n",
      "Recompensa por acortar distancias: +  0.45154946145445535\n",
      "Penalización por duración del episodio: -  0.3506490732086424\n",
      "Recompensa por acortar distancias: +  0.44995936410137377\n",
      "Penalización por duración del episodio: -  0.3509145209111055\n",
      "Recompensa por acortar distancias: +  0.447513871959139\n",
      "Penalización por duración del episodio: -  0.35127098343098156\n",
      "Recompensa por acortar distancias: +  0.44409452890817697\n",
      "Penalización por duración del episodio: -  0.3516264160591204\n",
      "Recompensa por acortar distancias: +  0.44409452890817697\n",
      "Penalización por duración del episodio: -  0.35198979516664236\n",
      "Recompensa por acortar distancias: +  0.43362209768653537\n",
      "Penalización por duración del episodio: -  0.352352921346703\n",
      "Recompensa por acortar distancias: +  0.43362209768653537\n",
      "Penalización por duración del episodio: -  0.3527275947638814\n",
      "Recompensa por acortar distancias: +  0.42604911592454064\n",
      "Penalización por duración del episodio: -  0.3531019047755394\n",
      "Recompensa por acortar distancias: +  0.4216893249765411\n",
      "Penalización por duración del episodio: -  0.35346607550214065\n",
      "Step: 230, Mean Reward (últimos 10 pasos): 0.0682232528924942\n",
      "Recompensa por acortar distancias: +  0.4192573067423205\n",
      "Penalización por duración del episodio: -  0.353818772983561\n",
      "Recompensa por acortar distancias: +  0.4192573067423205\n",
      "Penalización por duración del episodio: -  0.3541803388087506\n",
      "Recompensa por acortar distancias: +  0.4120276680325176\n",
      "Penalización por duración del episodio: -  0.35454287888255215\n",
      "Recompensa por acortar distancias: +  0.41054055414926593\n",
      "Penalización por duración del episodio: -  0.35490327170365743\n",
      "Recompensa por acortar distancias: +  0.4057714684415763\n",
      "Penalización por duración del episodio: -  0.3550083279210833\n",
      "Recompensa por acortar distancias: +  0.404737241420217\n",
      "Penalización por duración del episodio: -  0.35525510804055216\n",
      "Recompensa por acortar distancias: +  0.4026925209557162\n",
      "Penalización por duración del episodio: -  0.35560657641681065\n",
      "Recompensa por acortar distancias: +  0.40017399569138834\n",
      "Penalización por duración del episodio: -  0.35596917592803495\n",
      "Recompensa por acortar distancias: +  0.40017399569138834\n",
      "Penalización por duración del episodio: -  0.3563358724765551\n",
      "Recompensa por acortar distancias: +  0.39544110944792277\n",
      "Penalización por duración del episodio: -  0.35669979421815207\n",
      "steer input from model: 0.9 , throttle:  0.0\n",
      "reward: 0.0387413152297707\n",
      "Step: 240, Mean Reward (últimos 10 pasos): 0.03874131664633751\n",
      "Recompensa por acortar distancias: +  0.3944006452332421\n",
      "Penalización por duración del episodio: -  0.3570651129569485\n",
      "Recompensa por acortar distancias: +  0.39095502693903256\n",
      "Penalización por duración del episodio: -  0.3574252261637253\n",
      "Recompensa por acortar distancias: +  0.3891289758831381\n",
      "Penalización por duración del episodio: -  0.3577823723659125\n",
      "Recompensa por acortar distancias: +  0.38741789669456295\n",
      "Penalización por duración del episodio: -  0.3581325626663442\n",
      "Recompensa por acortar distancias: +  0.38627409972305454\n",
      "Penalización por duración del episodio: -  0.35849171011541187\n",
      "Recompensa por acortar distancias: +  0.38627409972305454\n",
      "Penalización por duración del episodio: -  0.3588643187255151\n",
      "Recompensa por acortar distancias: +  0.3827637196604691\n",
      "Penalización por duración del episodio: -  0.3592287120354988\n",
      "Recompensa por acortar distancias: +  0.38220722321955575\n",
      "Penalización por duración del episodio: -  0.35959752293298675\n",
      "Recompensa por acortar distancias: +  0.3795082094929728\n",
      "Penalización por duración del episodio: -  0.35994483589379284\n",
      "Recompensa por acortar distancias: +  0.37853238744335893\n",
      "Penalización por duración del episodio: -  0.3601366172311521\n",
      "Step: 250, Mean Reward (últimos 10 pasos): 0.018395770341157913\n",
      "Recompensa por acortar distancias: +  0.3781737387876889\n",
      "Penalización por duración del episodio: -  0.3603161117434789\n",
      "Recompensa por acortar distancias: +  0.3781737387876889\n",
      "Penalización por duración del episodio: -  0.36041735734893104\n",
      "Recompensa por acortar distancias: +  0.3781737387876889\n",
      "Penalización por duración del episodio: -  0.360673260739292\n",
      "Recompensa por acortar distancias: +  0.3781737387876889\n",
      "Penalización por duración del episodio: -  0.361041085547698\n",
      "Recompensa por acortar distancias: +  0.3781737387876889\n",
      "Penalización por duración del episodio: -  0.3613964892456384\n",
      "Recompensa por acortar distancias: +  0.3781737387876889\n",
      "Penalización por duración del episodio: -  0.3617464078419951\n",
      "Recompensa por acortar distancias: +  0.3781737387876889\n",
      "Penalización por duración del episodio: -  0.3624668217522231\n",
      "Recompensa por acortar distancias: +  0.3781737387876889\n",
      "Penalización por duración del episodio: -  0.3628290768970827\n",
      "Recompensa por acortar distancias: +  0.3781737387876889\n",
      "Penalización por duración del episodio: -  0.3631916753193681\n",
      "Recompensa por acortar distancias: +  0.3781737387876889\n",
      "Penalización por duración del episodio: -  0.3635654957053404\n",
      "steer input from model: 0.05 , throttle:  0.0\n",
      "reward: 0.014608243082348482\n",
      "Step: 260, Mean Reward (últimos 10 pasos): 0.014608243480324745\n",
      "Recompensa por acortar distancias: +  0.3781737387876889\n",
      "Penalización por duración del episodio: -  0.3639217869310274\n",
      "Recompensa por acortar distancias: +  0.3781737387876889\n",
      "Penalización por duración del episodio: -  0.36428566467511825\n",
      "Recompensa por acortar distancias: +  0.3781737387876889\n",
      "Penalización por duración del episodio: -  0.36463856751469154\n",
      "Recompensa por acortar distancias: +  0.3781737387876889\n",
      "Penalización por duración del episodio: -  0.36499641243227277\n",
      "Recompensa por acortar distancias: +  0.3781737387876889\n",
      "Penalización por duración del episodio: -  0.3653529913640589\n",
      "Recompensa por acortar distancias: +  0.3781737387876889\n",
      "Penalización por duración del episodio: -  0.3657178368442954\n",
      "Recompensa por acortar distancias: +  0.3781737387876889\n",
      "Penalización por duración del episodio: -  0.36607571017007967\n",
      "Recompensa por acortar distancias: +  0.3781737387876889\n",
      "Penalización por duración del episodio: -  0.36644491794275924\n",
      "Recompensa por acortar distancias: +  0.3781737387876889\n",
      "Penalización por duración del episodio: -  0.3665368569109989\n",
      "Recompensa por acortar distancias: +  0.3781737387876889\n",
      "Penalización por duración del episodio: -  0.3668189452428764\n",
      "Step: 270, Mean Reward (últimos 10 pasos): 0.011354793794453144\n",
      "Recompensa por acortar distancias: +  0.3781737387876889\n",
      "Penalización por duración del episodio: -  0.3671774772888959\n",
      "Recompensa por acortar distancias: +  0.3781737387876889\n",
      "Penalización por duración del episodio: -  0.3675350811848935\n",
      "Recompensa por acortar distancias: +  0.3781737387876889\n",
      "Penalización por duración del episodio: -  0.36790776200017017\n",
      "Recompensa por acortar distancias: +  0.3781737387876889\n",
      "Penalización por duración del episodio: -  0.3682324334969306\n",
      "Recompensa por acortar distancias: +  0.3781737387876889\n",
      "Penalización por duración del episodio: -  0.36860852222341906\n",
      "Recompensa por acortar distancias: +  0.3781737387876889\n",
      "Penalización por duración del episodio: -  0.3689599071580054\n",
      "Recompensa por acortar distancias: +  0.3781737387876889\n",
      "Penalización por duración del episodio: -  0.36933322793334933\n",
      "Recompensa por acortar distancias: +  0.3781737387876889\n",
      "Penalización por duración del episodio: -  0.36970584955979147\n",
      "Recompensa por acortar distancias: +  0.3781737387876889\n",
      "Penalización por duración del episodio: -  0.37007933794974424\n",
      "Recompensa por acortar distancias: +  0.3781737387876889\n",
      "Penalización por duración del episodio: -  0.3704419001972934\n",
      "steer input from model: -0.25 , throttle:  0.0\n",
      "reward: 0.007731838590395501\n",
      "Step: 280, Mean Reward (últimos 10 pasos): 0.007731838617473841\n",
      "Recompensa por acortar distancias: +  0.3781737387876889\n",
      "Penalización por duración del episodio: -  0.3707479394881708\n",
      "Recompensa por acortar distancias: +  0.3781737387876889\n",
      "Penalización por duración del episodio: -  0.37098485739936254\n",
      "Recompensa por acortar distancias: +  0.3781737387876889\n",
      "Penalización por duración del episodio: -  0.37110950217753413\n",
      "Recompensa por acortar distancias: +  0.3781737387876889\n",
      "Penalización por duración del episodio: -  0.3712246254992854\n",
      "Recompensa por acortar distancias: +  0.3781737387876889\n",
      "Penalización por duración del episodio: -  0.37132094010857725\n",
      "Recompensa por acortar distancias: +  0.3781737387876889\n",
      "Penalización por duración del episodio: -  0.3715405551650714\n",
      "Recompensa por acortar distancias: +  0.3781737387876889\n",
      "Penalización por duración del episodio: -  0.3718986858916044\n",
      "Recompensa por acortar distancias: +  0.3781737387876889\n",
      "Penalización por duración del episodio: -  0.37226647892978476\n",
      "Recompensa por acortar distancias: +  0.3781737387876889\n",
      "Penalización por duración del episodio: -  0.37262386337752584\n",
      "Recompensa por acortar distancias: +  0.3781737387876889\n",
      "Penalización por duración del episodio: -  0.37301415666147636\n",
      "Step: 290, Mean Reward (últimos 10 pasos): 0.005159582011401653\n",
      "Recompensa por acortar distancias: +  0.3781737387876889\n",
      "Penalización por duración del episodio: -  0.37336917117942836\n",
      "Recompensa por acortar distancias: +  0.3781737387876889\n",
      "Penalización por duración del episodio: -  0.37374052749292075\n",
      "Recompensa por acortar distancias: +  0.3781737387876889\n",
      "Penalización por duración del episodio: -  0.3738344948712635\n",
      "Recompensa por acortar distancias: +  0.3781737387876889\n",
      "Penalización por duración del episodio: -  0.37410424492048044\n",
      "Recompensa por acortar distancias: +  0.3781737387876889\n",
      "Penalización por duración del episodio: -  0.3744699643874216\n",
      "Recompensa por acortar distancias: +  0.3781737387876889\n",
      "Penalización por duración del episodio: -  0.3748252176943789\n",
      "Recompensa por acortar distancias: +  0.3781737387876889\n",
      "Penalización por duración del episodio: -  0.3752010004076842\n",
      "Recompensa por acortar distancias: +  0.3781737387876889\n",
      "Penalización por duración del episodio: -  0.3755760109585878\n",
      "Recompensa por acortar distancias: +  0.3781737387876889\n",
      "Penalización por duración del episodio: -  0.3759305754452003\n",
      "Recompensa por acortar distancias: +  0.3781737387876889\n",
      "Penalización por duración del episodio: -  0.3762908573311546\n",
      "steer input from model: 0.0 , throttle:  0.0\n",
      "reward: 0.0018828814565343133\n",
      "Step: 300, Mean Reward (últimos 10 pasos): 0.0018828815082088113\n",
      "Recompensa por acortar distancias: +  0.3781737387876889\n",
      "Penalización por duración del episodio: -  0.376662398828758\n",
      "Recompensa por acortar distancias: +  0.3781737387876889\n",
      "Penalización por duración del episodio: -  0.3770231039550564\n",
      "Recompensa por acortar distancias: +  0.3781737387876889\n",
      "Penalización por duración del episodio: -  0.3773890544232742\n",
      "Recompensa por acortar distancias: +  0.3781737387876889\n",
      "Penalización por duración del episodio: -  0.3777584063458929\n",
      "Recompensa por acortar distancias: +  0.3781737387876889\n",
      "Penalización por duración del episodio: -  0.378127216240638\n",
      "Recompensa por acortar distancias: +  0.3781737387876889\n",
      "Penalización por duración del episodio: -  0.3784924319415276\n",
      "Recompensa por acortar distancias: +  0.3781737387876889\n",
      "Penalización por duración del episodio: -  0.37884908352532404\n",
      "Recompensa por acortar distancias: +  0.3781737387876889\n",
      "Penalización por duración del episodio: -  0.37920506353121136\n",
      "Recompensa por acortar distancias: +  0.3781737387876889\n",
      "Penalización por duración del episodio: -  0.3795787756452346\n",
      "Recompensa por acortar distancias: +  0.3724733261962988\n",
      "Penalización por duración del episodio: -  0.37967944165497836\n",
      "Step: 310, Mean Reward (últimos 10 pasos): -0.007206115406006575\n",
      "Recompensa por acortar distancias: +  0.3724733261962988\n",
      "Penalización por duración del episodio: -  0.3799403915589154\n",
      "Recompensa por acortar distancias: +  0.3724733261962988\n",
      "Penalización por duración del episodio: -  0.38031917736065046\n",
      "Recompensa por acortar distancias: +  0.3719772654140815\n",
      "Penalización por duración del episodio: -  0.3804251117976381\n",
      "Recompensa por acortar distancias: +  0.3719772654140815\n",
      "Penalización por duración del episodio: -  0.38068124008937704\n",
      "Recompensa por acortar distancias: +  0.37195210742288365\n",
      "Penalización por duración del episodio: -  0.38079756850412805\n",
      "Recompensa por acortar distancias: +  0.37195210742288365\n",
      "Penalización por duración del episodio: -  0.38105119544398147\n",
      "Recompensa por acortar distancias: +  0.37205742806727254\n",
      "Penalización por duración del episodio: -  0.3814139648870431\n",
      "Recompensa por acortar distancias: +  0.37225644477772\n",
      "Penalización por duración del episodio: -  0.3817775419370167\n",
      "Recompensa por acortar distancias: +  0.3726398765790877\n",
      "Penalización por duración del episodio: -  0.3821556963083734\n",
      "Recompensa por acortar distancias: +  0.3726398765790877\n",
      "Penalización por duración del episodio: -  0.38223348027625126\n",
      "steer input from model: 0.9 , throttle:  0.7\n",
      "reward: -0.009593603697163555\n",
      "Step: 320, Mean Reward (últimos 10 pasos): -0.009593604132533073\n",
      "Recompensa por acortar distancias: +  0.3732647094655833\n",
      "Penalización por duración del episodio: -  0.38252153670264183\n",
      "Recompensa por acortar distancias: +  0.3732647094655833\n",
      "Penalización por duración del episodio: -  0.38288971296825125\n",
      "Recompensa por acortar distancias: +  0.3732647094655833\n",
      "Penalización por duración del episodio: -  0.3832419568802638\n",
      "Recompensa por acortar distancias: +  0.3732647094655833\n",
      "Penalización por duración del episodio: -  0.3836190549913891\n",
      "Recompensa por acortar distancias: +  0.375531560688422\n",
      "Penalización por duración del episodio: -  0.383697019493284\n",
      "Recompensa por acortar distancias: +  0.375531560688422\n",
      "Penalización por duración del episodio: -  0.38399588144342384\n",
      "Recompensa por acortar distancias: +  0.375531560688422\n",
      "Penalización por duración del episodio: -  0.3840956964225786\n",
      "Recompensa por acortar distancias: +  0.37657279381395287\n",
      "Penalización por duración del episodio: -  0.3843583876288154\n",
      "Recompensa por acortar distancias: +  0.3769405426509335\n",
      "Penalización por duración del episodio: -  0.38473657624901514\n",
      "Recompensa por acortar distancias: +  0.3769405426509335\n",
      "Penalización por duración del episodio: -  0.38511418154826743\n",
      "Step: 330, Mean Reward (últimos 10 pasos): -0.008173638954758644\n",
      "Recompensa por acortar distancias: +  0.3784991621183194\n",
      "Penalización por duración del episodio: -  0.385249175380475\n",
      "Recompensa por acortar distancias: +  0.3784991621183194\n",
      "Penalización por duración del episodio: -  0.3854869269181206\n",
      "Recompensa por acortar distancias: +  0.3788663528734041\n",
      "Penalización por duración del episodio: -  0.3858540890294647\n",
      "Recompensa por acortar distancias: +  0.37979414097834935\n",
      "Penalización por duración del episodio: -  0.386247125406318\n",
      "Recompensa por acortar distancias: +  0.38058998690335566\n",
      "Penalización por duración del episodio: -  0.3866207584418581\n",
      "Recompensa por acortar distancias: +  0.38137908372752605\n",
      "Penalización por duración del episodio: -  0.38698007969213744\n",
      "Recompensa por acortar distancias: +  0.38137908372752605\n",
      "Penalización por duración del episodio: -  0.3873421662292767\n",
      "Recompensa por acortar distancias: +  0.38137908372752605\n",
      "Penalización por duración del episodio: -  0.3874589850618884\n",
      "Recompensa por acortar distancias: +  0.3833763372696182\n",
      "Penalización por duración del episodio: -  0.3877284430820465\n",
      "Recompensa por acortar distancias: +  0.3838479760756191\n",
      "Penalización por duración del episodio: -  0.38809576900815473\n",
      "steer input from model: 0.25 , throttle:  0.0\n",
      "reward: -0.004247792932535632\n",
      "Step: 340, Mean Reward (últimos 10 pasos): -0.00424779299646616\n",
      "Recompensa por acortar distancias: +  0.38521451197146633\n",
      "Penalización por duración del episodio: -  0.3884679344830378\n",
      "Recompensa por acortar distancias: +  0.3865561863197826\n",
      "Penalización por duración del episodio: -  0.38884196381390734\n",
      "Recompensa por acortar distancias: +  0.38780261353923057\n",
      "Penalización por duración del episodio: -  0.3889504594325751\n",
      "Recompensa por acortar distancias: +  0.38831961896876926\n",
      "Penalización por duración del episodio: -  0.3892060353365462\n",
      "Recompensa por acortar distancias: +  0.38831961896876926\n",
      "Penalización por duración del episodio: -  0.38956843315229117\n",
      "Recompensa por acortar distancias: +  0.38831961896876926\n",
      "Penalización por duración del episodio: -  0.38967339593612016\n",
      "Recompensa por acortar distancias: +  0.38831961896876926\n",
      "Penalización por duración del episodio: -  0.38975702420854624\n",
      "Recompensa por acortar distancias: +  0.39124428390366595\n",
      "Penalización por duración del episodio: -  0.3899343105866126\n",
      "Recompensa por acortar distancias: +  0.39124428390366595\n",
      "Penalización por duración del episodio: -  0.3903083286955658\n",
      "Recompensa por acortar distancias: +  0.39200013799358135\n",
      "Penalización por duración del episodio: -  0.39066414395244764\n",
      "Step: 350, Mean Reward (últimos 10 pasos): 0.0013359939912334085\n",
      "Recompensa por acortar distancias: +  0.3946971591001881\n",
      "Penalización por duración del episodio: -  0.39077399784822336\n",
      "Recompensa por acortar distancias: +  0.3951783982841536\n",
      "Penalización por duración del episodio: -  0.39104266577276536\n",
      "Recompensa por acortar distancias: +  0.3963379121755212\n",
      "Penalización por duración del episodio: -  0.39115309151240824\n",
      "Recompensa por acortar distancias: +  0.3968254842707857\n",
      "Penalización por duración del episodio: -  0.3912756976370565\n",
      "Recompensa por acortar distancias: +  0.39747289770444616\n",
      "Penalización por duración del episodio: -  0.39143144514509826\n",
      "Recompensa por acortar distancias: +  0.3981891310914846\n",
      "Penalización por duración del episodio: -  0.39180390899470247\n",
      "Recompensa por acortar distancias: +  0.3981891310914846\n",
      "Penalización por duración del episodio: -  0.39218826332049944\n",
      "Recompensa por acortar distancias: +  0.4017746352909173\n",
      "Penalización por duración del episodio: -  0.39256513870987647\n",
      "Recompensa por acortar distancias: +  0.4025153798035367\n",
      "Penalización por duración del episodio: -  0.39293133080590975\n",
      "Recompensa por acortar distancias: +  0.40543372959490975\n",
      "Penalización por duración del episodio: -  0.39329280766918234\n",
      "steer input from model: 0.0 , throttle:  0.0\n",
      "reward: 0.01214092192572741\n",
      "Step: 360, Mean Reward (últimos 10 pasos): 0.012140922248363495\n",
      "Recompensa por acortar distancias: +  0.4071291796707861\n",
      "Penalización por duración del episodio: -  0.39339061138879045\n",
      "Recompensa por acortar distancias: +  0.4077690953653315\n",
      "Penalización por duración del episodio: -  0.3934917579923267\n",
      "Recompensa por acortar distancias: +  0.4083985231825737\n",
      "Penalización por duración del episodio: -  0.39365492499288945\n",
      "Recompensa por acortar distancias: +  0.4090977685160048\n",
      "Penalización por duración del episodio: -  0.3940322448602307\n",
      "Recompensa por acortar distancias: +  0.4098431510584981\n",
      "Penalización por duración del episodio: -  0.3944096797499842\n",
      "Recompensa por acortar distancias: +  0.4098431510584981\n",
      "Penalización por duración del episodio: -  0.39478943950292217\n",
      "Recompensa por acortar distancias: +  0.41441512606027586\n",
      "Penalización por duración del episodio: -  0.3951521740867697\n",
      "Recompensa por acortar distancias: +  0.41441512606027586\n",
      "Penalización por duración del episodio: -  0.3955149158440897\n",
      "Recompensa por acortar distancias: +  0.41819100841186757\n",
      "Penalización por duración del episodio: -  0.395634124210589\n",
      "Recompensa por acortar distancias: +  0.41883544756397995\n",
      "Penalización por duración del episodio: -  0.3957544168410751\n",
      "Step: 370, Mean Reward (últimos 10 pasos): 0.023081030696630478\n",
      "Recompensa por acortar distancias: +  0.41967933044000777\n",
      "Penalización por duración del episodio: -  0.3959048003709368\n",
      "Recompensa por acortar distancias: +  0.42034197883827296\n",
      "Penalización por duración del episodio: -  0.39602087285688603\n",
      "Recompensa por acortar distancias: +  0.4211671097117903\n",
      "Penalización por duración del episodio: -  0.3962866034620255\n",
      "Recompensa por acortar distancias: +  0.42196234258682225\n",
      "Penalización por duración del episodio: -  0.3966627129833928\n",
      "Recompensa por acortar distancias: +  0.42196234258682225\n",
      "Penalización por duración del episodio: -  0.397047580514464\n",
      "Recompensa por acortar distancias: +  0.4270312645370965\n",
      "Penalización por duración del episodio: -  0.39741875251411435\n",
      "Recompensa por acortar distancias: +  0.4270312645370965\n",
      "Penalización por duración del episodio: -  0.39779597101857\n",
      "Recompensa por acortar distancias: +  0.4270312645370965\n",
      "Penalización por duración del episodio: -  0.3981811324527202\n",
      "Recompensa por acortar distancias: +  0.4337690803338325\n",
      "Penalización por duración del episodio: -  0.39856138494780746\n",
      "Recompensa por acortar distancias: +  0.4362365709690117\n",
      "Penalización por duración del episodio: -  0.3989280677851896\n",
      "steer input from model: -0.9 , throttle:  0.7\n",
      "reward: 0.03730850318382212\n",
      "Step: 380, Mean Reward (últimos 10 pasos): 0.037308502942323685\n",
      "Recompensa por acortar distancias: +  0.4362365709690117\n",
      "Penalización por duración del episodio: -  0.399291043940839\n",
      "Recompensa por acortar distancias: +  0.4416609530241801\n",
      "Penalización por duración del episodio: -  0.3996752048838125\n",
      "Recompensa por acortar distancias: +  0.44308848012088026\n",
      "Penalización por duración del episodio: -  0.40004051418775155\n",
      "Recompensa por acortar distancias: +  0.4471939248018517\n",
      "Penalización por duración del episodio: -  0.40042361045827213\n",
      "Recompensa por acortar distancias: +  0.45028494827796345\n",
      "Penalización por duración del episodio: -  0.40052470734671625\n",
      "Recompensa por acortar distancias: +  0.4512984323145869\n",
      "Penalización por duración del episodio: -  0.40080113127397454\n",
      "Recompensa por acortar distancias: +  0.4535204705305476\n",
      "Penalización por duración del episodio: -  0.4011764043545667\n",
      "Recompensa por acortar distancias: +  0.45472775241799895\n",
      "Penalización por duración del episodio: -  0.40153375735546504\n",
      "Recompensa por acortar distancias: +  0.45472775241799895\n",
      "Penalización por duración del episodio: -  0.40189645889641556\n",
      "Recompensa por acortar distancias: +  0.4620790243824771\n",
      "Penalización por duración del episodio: -  0.40228590224872024\n",
      "Step: 390, Mean Reward (últimos 10 pasos): 0.05979312211275101\n",
      "Recompensa por acortar distancias: +  0.46591239621353026\n",
      "Penalización por duración del episodio: -  0.40265968729838286\n",
      "Recompensa por acortar distancias: +  0.468823044098742\n",
      "Penalización por duración del episodio: -  0.40303379197420774\n",
      "Recompensa por acortar distancias: +  0.47194632722233726\n",
      "Penalización por duración del episodio: -  0.40340111241299\n",
      "Recompensa por acortar distancias: +  0.47515810398080166\n",
      "Penalización por duración del episodio: -  0.40377143973506785\n",
      "Penalización por duración del episodio\n",
      "Recompensa por acortar distancias: +  0.9156963113392873\n",
      "Penalización por parar muy lejos: -  0.16593144908976795\n",
      "Penalización por duración del episodio: -  0.26902285735328657\n",
      "Recompensa por acortar distancias: +  0.9156963113392873\n",
      "Penalización por parar muy lejos: -  0.16593144908976795\n",
      "Penalización por duración del episodio: -  0.2692372831904737\n",
      "Recompensa por acortar distancias: +  0.9156963113392873\n",
      "Penalización por duración del episodio: -  0.2695344348281751\n",
      "Recompensa por acortar distancias: +  0.915695943236595\n",
      "Penalización por duración del episodio: -  0.2698402346114256\n",
      "Recompensa por acortar distancias: +  0.9156959726848639\n",
      "Penalización por parar muy lejos: -  0.16593084195132288\n",
      "Penalización por duración del episodio: -  0.2701450919252539\n",
      "Step: 400, Mean Reward (últimos 10 pasos): 0.4796200394630432\n",
      "Recompensa por acortar distancias: +  0.9156959726848639\n",
      "Penalización por parar muy lejos: -  0.16593084195132288\n",
      "Penalización por duración del episodio: -  0.2704525840317774\n",
      "Recompensa por acortar distancias: +  0.9156959726848639\n",
      "Penalización por parar muy lejos: -  0.16593084195132288\n",
      "Penalización por duración del episodio: -  0.270760051504563\n",
      "Recompensa por acortar distancias: +  0.915695943236595\n",
      "Penalización por parar muy lejos: -  0.1659307891567596\n",
      "Penalización por duración del episodio: -  0.27107077248763334\n",
      "Recompensa por acortar distancias: +  0.915695943236595\n",
      "Penalización por parar muy lejos: -  0.1659307891567596\n",
      "Penalización por duración del episodio: -  0.27136996938013624\n",
      "Recompensa por acortar distancias: +  0.9156961493742826\n",
      "Penalización por parar muy lejos: -  0.16593115871898523\n",
      "Penalización por duración del episodio: -  0.2716811814279942\n",
      "Recompensa por acortar distancias: +  0.9156963260633646\n",
      "Penalización por duración del episodio: -  0.27199236221648493\n",
      "Recompensa por acortar distancias: +  0.9156963702355827\n",
      "Penalización por parar muy lejos: -  0.16593155467924436\n",
      "Penalización por duración del episodio: -  0.272305372457367\n",
      "Recompensa por acortar distancias: +  0.9156963702355827\n",
      "Penalización por parar muy lejos: -  0.16593155467924436\n",
      "Penalización por duración del episodio: -  0.2726197095974689\n",
      "Recompensa por acortar distancias: +  0.9156963702355827\n",
      "Penalización por parar muy lejos: -  0.16593155467924436\n",
      "Penalización por duración del episodio: -  0.2729221381242344\n",
      "Recompensa por acortar distancias: +  0.9156963702355827\n",
      "Penalización por parar muy lejos: -  0.16593155467924436\n",
      "Penalización por duración del episodio: -  0.2732292785148144\n",
      "Step: 410, Mean Reward (últimos 10 pasos): 0.47653552889823914\n",
      "Recompensa por acortar distancias: +  0.9156966205444212\n",
      "Penalización por parar muy lejos: -  0.16593200343511977\n",
      "Penalización por duración del episodio: -  0.27332335163548294\n",
      "Recompensa por acortar distancias: +  0.9156966794405205\n",
      "Penalización por parar muy lejos: -  0.1659321090248788\n",
      "Penalización por duración del episodio: -  0.27353217160766546\n",
      "Recompensa por acortar distancias: +  0.9156967825086042\n",
      "Penalización por parar muy lejos: -  0.16593229380708657\n",
      "Penalización por duración del episodio: -  0.2738388059784473\n",
      "Recompensa por acortar distancias: +  0.9156968266806051\n",
      "Penalización por parar muy lejos: -  0.16593237299951183\n",
      "Penalización por duración del episodio: -  0.273912828388872\n",
      "Recompensa por acortar distancias: +  0.9156968266806051\n",
      "Penalización por duración del episodio: -  0.2741485199329455\n",
      "steer input from model: -0.9 , throttle:  0.7\n",
      "reward: 0.6415483067476597\n",
      "Recompensa por acortar distancias: +  0.9156968266806051\n",
      "Penalización por duración del episodio: -  0.2744546441804492\n",
      "Recompensa por acortar distancias: +  0.9156968266806051\n",
      "Penalización por parar muy lejos: -  0.16593237299951183\n",
      "Penalización por duración del episodio: -  0.27454745076334924\n",
      "Recompensa por acortar distancias: +  0.9156967088885559\n",
      "Penalización por duración del episodio: -  0.27476675324948485\n",
      "Recompensa por acortar distancias: +  0.9156967236125705\n",
      "Penalización por parar muy lejos: -  0.16593218821723335\n",
      "Penalización por duración del episodio: -  0.27508548679574174\n",
      "Recompensa por acortar distancias: +  0.9156965616482846\n",
      "Penalización por parar muy lejos: -  0.16593189784541454\n",
      "Penalización por duración del episodio: -  0.2753898339330541\n",
      "Step: 420, Mean Reward (últimos 10 pasos): 0.47437483072280884\n",
      "Recompensa por acortar distancias: +  0.9156967972326069\n",
      "Penalización por parar muy lejos: -  0.16593232020455828\n",
      "Penalización por duración del episodio: -  0.27570266902987844\n",
      "Recompensa por acortar distancias: +  0.9156970475402941\n",
      "Penalización por parar muy lejos: -  0.16593276896209214\n",
      "Penalización por duración del episodio: -  0.27600508071558827\n",
      "Recompensa por acortar distancias: +  0.9156970475402941\n",
      "Penalización por duración del episodio: -  0.27632293462915625\n",
      "Recompensa por acortar distancias: +  0.9156970475402941\n",
      "Penalización por duración del episodio: -  0.27663162069759534\n",
      "Recompensa por acortar distancias: +  0.9156969444725047\n",
      "Penalización por duración del episodio: -  0.27694733725021276\n",
      "Recompensa por acortar distancias: +  0.9156969444725047\n",
      "Penalización por parar muy lejos: -  0.1659325841794604\n",
      "Penalización por duración del episodio: -  0.2772842168587475\n",
      "Recompensa por acortar distancias: +  0.9156971358840228\n",
      "Penalización por duración del episodio: -  0.2775873829064455\n",
      "Recompensa por acortar distancias: +  0.9156971800558555\n",
      "Penalización por parar muy lejos: -  0.1659330065400036\n",
      "Penalización por duración del episodio: -  0.2779067231946812\n",
      "Recompensa por acortar distancias: +  0.9156971653319136\n",
      "Penalización por duración del episodio: -  0.27822080732831134\n",
      "Recompensa por acortar distancias: +  0.9156971653319136\n",
      "Penalización por parar muy lejos: -  0.16593298014244443\n",
      "Penalización por duración del episodio: -  0.2785296333146538\n",
      "Step: 430, Mean Reward (últimos 10 pasos): 0.4712345600128174\n",
      "Recompensa por acortar distancias: +  0.9156969886444285\n",
      "Penalización por duración del episodio: -  0.2788346424715754\n",
      "Recompensa por acortar distancias: +  0.9156969886444285\n",
      "Penalización por duración del episodio: -  0.27915011832651243\n",
      "Recompensa por acortar distancias: +  0.9156970475402941\n",
      "Penalización por duración del episodio: -  0.27923294657653913\n",
      "Recompensa por acortar distancias: +  0.9156970917121691\n",
      "Penalización por duración del episodio: -  0.27947037848151846\n",
      "Recompensa por acortar distancias: +  0.9156971653319136\n",
      "Penalización por duración del episodio: -  0.2795379425314849\n",
      "steer input from model: 0.05 , throttle:  0.3\n",
      "reward: 0.6361592228004287\n",
      "Recompensa por acortar distancias: +  0.9156972095037325\n",
      "Penalización por duración del episodio: -  0.27978772623618203\n",
      "Recompensa por acortar distancias: +  0.9156972389515999\n",
      "Penalización por parar muy lejos: -  0.16593311213027395\n",
      "Penalización por duración del episodio: -  0.28009794827153345\n",
      "Recompensa por acortar distancias: +  0.9156972389515999\n",
      "Penalización por duración del episodio: -  0.28040354071529305\n",
      "Recompensa por acortar distancias: +  0.9156971653319136\n",
      "Penalización por duración del episodio: -  0.2807191282358339\n",
      "Recompensa por acortar distancias: +  0.9156971653319136\n",
      "Penalización por duración del episodio: -  0.2810344119528525\n",
      "Step: 440, Mean Reward (últimos 10 pasos): 0.6346627473831177\n",
      "Recompensa por acortar distancias: +  0.9156969444725047\n",
      "Penalización por parar muy lejos: -  0.1659325841794604\n",
      "Penalización por duración del episodio: -  0.28135285186209674\n",
      "Recompensa por acortar distancias: +  0.9156971653319136\n",
      "Penalización por parar muy lejos: -  0.16593298014244443\n",
      "Penalización por duración del episodio: -  0.2816633346487\n",
      "Recompensa por acortar distancias: +  0.9156972536755301\n",
      "Penalización por duración del episodio: -  0.2819737166910465\n",
      "Recompensa por acortar distancias: +  0.9156973125712279\n",
      "Penalización por parar muy lejos: -  0.16593324411818758\n",
      "Penalización por duración del episodio: -  0.28228391509664613\n",
      "Recompensa por acortar distancias: +  0.9156973125712279\n",
      "Penalización por parar muy lejos: -  0.16593324411818758\n",
      "Penalización por duración del episodio: -  0.282591541148579\n",
      "Recompensa por acortar distancias: +  0.9156971358840228\n",
      "Penalización por duración del episodio: -  0.2826821160723993\n",
      "Recompensa por acortar distancias: +  0.9156971653319136\n",
      "Penalización por parar muy lejos: -  0.16593298014244443\n",
      "Penalización por duración del episodio: -  0.28290902935936335\n",
      "Recompensa por acortar distancias: +  0.9156971653319136\n",
      "Penalización por duración del episodio: -  0.28298016041243257\n",
      "Recompensa por acortar distancias: +  0.9156971653319136\n",
      "Penalización por parar muy lejos: -  0.16593298014244443\n",
      "Penalización por duración del episodio: -  0.28322937131740794\n",
      "Recompensa por acortar distancias: +  0.9156972536755301\n",
      "Penalización por duración del episodio: -  0.28331097847124465\n",
      "Step: 450, Mean Reward (últimos 10 pasos): 0.6323862671852112\n",
      "Recompensa por acortar distancias: +  0.9156973125712279\n",
      "Penalización por parar muy lejos: -  0.16593324411818758\n",
      "Penalización por duración del episodio: -  0.28353962580829717\n",
      "Recompensa por acortar distancias: +  0.9156973714668881\n",
      "Penalización por duración del episodio: -  0.28385562036677436\n",
      "Recompensa por acortar distancias: +  0.9156974745342036\n",
      "Penalización por parar muy lejos: -  0.16593353449189358\n",
      "Penalización por duración del episodio: -  0.2841683840160557\n",
      "Recompensa por acortar distancias: +  0.9156974745342036\n",
      "Penalización por parar muy lejos: -  0.16593353449189358\n",
      "Penalización por duración del episodio: -  0.2844833791124312\n",
      "Recompensa por acortar distancias: +  0.9156973567429766\n",
      "Penalización por parar muy lejos: -  0.16593332331097613\n",
      "Penalización por duración del episodio: -  0.2848109924880549\n",
      "steer input from model: -0.9 , throttle:  0.0\n",
      "reward: 0.4649530409439456\n",
      "Recompensa por acortar distancias: +  0.9156973567429766\n",
      "Penalización por parar muy lejos: -  0.16593332331097613\n",
      "Penalización por duración del episodio: -  0.28512160026734495\n",
      "Recompensa por acortar distancias: +  0.9156971653319136\n",
      "Penalización por duración del episodio: -  0.2854495970532088\n",
      "Recompensa por acortar distancias: +  0.9156972536755301\n",
      "Penalización por parar muy lejos: -  0.16593313852784994\n",
      "Penalización por duración del episodio: -  0.28577547475486825\n",
      "Recompensa por acortar distancias: +  0.9156972536755301\n",
      "Penalización por duración del episodio: -  0.2860931608669173\n",
      "Recompensa por acortar distancias: +  0.9156972536755301\n",
      "Penalización por duración del episodio: -  0.2864117455826793\n",
      "Step: 460, Mean Reward (últimos 10 pasos): 0.6292855143547058\n",
      "Recompensa por acortar distancias: +  0.9156972536755301\n",
      "Penalización por parar muy lejos: -  0.16593313852784994\n",
      "Penalización por duración del episodio: -  0.28647714303125527\n",
      "Recompensa por acortar distancias: +  0.9156969591964816\n",
      "Penalización por duración del episodio: -  0.2867262906857753\n",
      "Recompensa por acortar distancias: +  0.9156969297485253\n",
      "Penalización por duración del episodio: -  0.2870408275919415\n",
      "Recompensa por acortar distancias: +  0.9156969297485253\n",
      "Penalización por duración del episodio: -  0.28736329454077786\n",
      "Recompensa por acortar distancias: +  0.9156969444725047\n",
      "Penalización por duración del episodio: -  0.2874585072322681\n",
      "Recompensa por acortar distancias: +  0.9156969444725047\n",
      "Penalización por parar muy lejos: -  0.1659325841794604\n",
      "Penalización por duración del episodio: -  0.28769217762024385\n",
      "Recompensa por acortar distancias: +  0.9156970475402941\n",
      "Penalización por parar muy lejos: -  0.16593276896209214\n",
      "Penalización por duración del episodio: -  0.2880251425138006\n",
      "Recompensa por acortar distancias: +  0.9156970917121691\n",
      "Penalización por duración del episodio: -  0.2883542074838075\n",
      "Recompensa por acortar distancias: +  0.9156970917121691\n",
      "Penalización por parar muy lejos: -  0.16593284815469897\n",
      "Penalización por duración del episodio: -  0.28868579700748964\n",
      "Recompensa por acortar distancias: +  0.9156969297485253\n",
      "Penalización por duración del episodio: -  0.289000995250571\n",
      "Step: 470, Mean Reward (últimos 10 pasos): 0.6266959309577942\n",
      "Recompensa por acortar distancias: +  0.9156969739204561\n",
      "Penalización por parar muy lejos: -  0.16593263697448127\n",
      "Penalización por duración del episodio: -  0.289329702366735\n",
      "Recompensa por acortar distancias: +  0.9156968266806051\n",
      "Penalización por duración del episodio: -  0.2894098323924262\n",
      "Recompensa por acortar distancias: +  0.9156969003005598\n",
      "Penalización por parar muy lejos: -  0.1659325049869545\n",
      "Penalización por duración del episodio: -  0.2896466418565399\n",
      "Recompensa por acortar distancias: +  0.915697018092366\n",
      "Penalización por parar muy lejos: -  0.16593271616703767\n",
      "Penalización por duración del episodio: -  0.28995804375709017\n",
      "Recompensa por acortar distancias: +  0.9156971800558555\n",
      "Penalización por duración del episodio: -  0.2900636984265345\n",
      "steer input from model: -0.9 , throttle:  1.0\n",
      "reward: 0.625633481629321\n",
      "Recompensa por acortar distancias: +  0.9156971800558555\n",
      "Penalización por parar muy lejos: -  0.1659330065400036\n",
      "Penalización por duración del episodio: -  0.2902898214737583\n",
      "Recompensa por acortar distancias: +  0.9156971800558555\n",
      "Penalización por duración del episodio: -  0.29061057254390477\n",
      "Recompensa por acortar distancias: +  0.9156971064361227\n",
      "Penalización por duración del episodio: -  0.2909316606170034\n",
      "Recompensa por acortar distancias: +  0.9156971064361227\n",
      "Penalización por duración del episodio: -  0.29124881387211743\n",
      "Recompensa por acortar distancias: +  0.9156971800558555\n",
      "Penalización por parar muy lejos: -  0.1659330065400036\n",
      "Penalización por duración del episodio: -  0.29132111116522813\n",
      "Step: 480, Mean Reward (últimos 10 pasos): 0.4584430754184723\n",
      "Recompensa por acortar distancias: +  0.9156972095037325\n",
      "Penalización por duración del episodio: -  0.29157570001382227\n",
      "Recompensa por acortar distancias: +  0.9156972831233836\n",
      "Penalización por parar muy lejos: -  0.16593319132301204\n",
      "Penalización por duración del episodio: -  0.29165817686923756\n",
      "Recompensa por acortar distancias: +  0.9156973272951463\n",
      "Penalización por duración del episodio: -  0.2919032750253239\n",
      "Recompensa por acortar distancias: +  0.9156973714668881\n",
      "Penalización por duración del episodio: -  0.2920091744800332\n",
      "Recompensa por acortar distancias: +  0.9156973714668881\n",
      "Penalización por duración del episodio: -  0.29222104109252833\n",
      "Recompensa por acortar distancias: +  0.9156973714668881\n",
      "Penalización por duración del episodio: -  0.29255061579930486\n",
      "Recompensa por acortar distancias: +  0.9156973714668881\n",
      "Penalización por duración del episodio: -  0.29287979612527193\n",
      "Recompensa por acortar distancias: +  0.9156972242276673\n",
      "Penalización por duración del episodio: -  0.2932067920477733\n",
      "Recompensa por acortar distancias: +  0.9156972242276673\n",
      "Penalización por duración del episodio: -  0.2935395982897499\n",
      "Recompensa por acortar distancias: +  0.9156973567429766\n",
      "Penalización por duración del episodio: -  0.2938659907220321\n",
      "Step: 490, Mean Reward (últimos 10 pasos): 0.6218313574790955\n",
      "Recompensa por acortar distancias: +  0.915697378828843\n",
      "Penalización por duración del episodio: -  0.29418789684438174\n",
      "Recompensa por acortar distancias: +  0.9156973714668881\n",
      "Penalización por duración del episodio: -  0.2945088196290193\n",
      "Recompensa por acortar distancias: +  0.9156973714668881\n",
      "Penalización por duración del episodio: -  0.29483803094602073\n",
      "Recompensa por acortar distancias: +  0.9156970475402941\n",
      "Penalización por duración del episodio: -  0.29515920268179524\n",
      "Recompensa por acortar distancias: +  0.9156970475402941\n",
      "Penalización por parar muy lejos: -  0.16593276896209214\n",
      "Penalización por duración del episodio: -  0.2954855905352952\n",
      "steer input from model: 0.25 , throttle:  0.0\n",
      "reward: 0.4542786880429067\n",
      "Recompensa por acortar distancias: +  0.9156970475402941\n",
      "Penalización por duración del episodio: -  0.2955807747443962\n",
      "Recompensa por acortar distancias: +  0.9156970917121691\n",
      "Penalización por parar muy lejos: -  0.16593284815469897\n",
      "Penalización por duración del episodio: -  0.29580660062828884\n",
      "Recompensa por acortar distancias: +  0.9156971064361227\n",
      "Penalización por parar muy lejos: -  0.16593287455224134\n",
      "Penalización por duración del episodio: -  0.2958870424529611\n",
      "Recompensa por acortar distancias: +  0.9156971358840228\n",
      "Penalización por duración del episodio: -  0.2961344720550072\n",
      "Recompensa por acortar distancias: +  0.915697194779795\n",
      "Penalización por parar muy lejos: -  0.16593303293756617\n",
      "Penalización por duración del episodio: -  0.296455323562408\n",
      "Step: 500, Mean Reward (últimos 10 pasos): 0.4533088505268097\n",
      "Recompensa por acortar distancias: +  0.915697194779795\n",
      "Penalización por duración del episodio: -  0.2967797696332266\n",
      "Recompensa por acortar distancias: +  0.915697194779795\n",
      "Penalización por duración del episodio: -  0.2971085534013815\n",
      "Recompensa por acortar distancias: +  0.9156968266806051\n",
      "Penalización por parar muy lejos: -  0.16593237299951183\n",
      "Penalización por duración del episodio: -  0.2974290876484825\n",
      "Recompensa por acortar distancias: +  0.9156968266806051\n",
      "Penalización por parar muy lejos: -  0.16593237299951183\n",
      "Penalización por duración del episodio: -  0.29775766301116147\n",
      "Recompensa por acortar distancias: +  0.9156970475402941\n",
      "Penalización por parar muy lejos: -  0.16593276896209214\n",
      "Penalización por duración del episodio: -  0.2980855095222515\n",
      "Recompensa por acortar distancias: +  0.915697194779795\n",
      "Penalización por duración del episodio: -  0.2981803285774202\n",
      "Recompensa por acortar distancias: +  0.9156972242276673\n",
      "Penalización por parar muy lejos: -  0.16593308573270132\n",
      "Penalización por duración del episodio: -  0.2984069847266674\n",
      "Recompensa por acortar distancias: +  0.9156972389515999\n",
      "Penalización por duración del episodio: -  0.29872679608611624\n",
      "Recompensa por acortar distancias: +  0.9156972389515999\n",
      "Penalización por parar muy lejos: -  0.16593311213027395\n",
      "Penalización por duración del episodio: -  0.2990568245433785\n",
      "Recompensa por acortar distancias: +  0.9156970769882131\n",
      "Penalización por parar muy lejos: -  0.16593282175715998\n",
      "Penalización por duración del episodio: -  0.29912870248463397\n",
      "Step: 510, Mean Reward (últimos 10 pasos): 0.45063555240631104\n",
      "Recompensa por acortar distancias: +  0.915697062264255\n",
      "Penalización por duración del episodio: -  0.2993957336461535\n",
      "Recompensa por acortar distancias: +  0.915697062264255\n",
      "Penalización por duración del episodio: -  0.2994717296477691\n",
      "Recompensa por acortar distancias: +  0.915697062264255\n",
      "Penalización por duración del episodio: -  0.29957748223663805\n",
      "Recompensa por acortar distancias: +  0.915697062264255\n",
      "Penalización por parar muy lejos: -  0.16593279535962438\n",
      "Penalización por duración del episodio: -  0.29964368289534793\n",
      "Recompensa por acortar distancias: +  0.9156971211600738\n",
      "Penalización por parar muy lejos: -  0.16593290094978708\n",
      "Penalización por duración del episodio: -  0.300064181209635\n",
      "steer input from model: 0.25 , throttle:  0.0\n",
      "reward: 0.44970003900065175\n",
      "Recompensa por acortar distancias: +  0.9156972242276673\n",
      "Penalización por duración del episodio: -  0.3001487930897803\n",
      "Recompensa por acortar distancias: +  0.9156972536755301\n",
      "Penalización por parar muy lejos: -  0.16593313852784994\n",
      "Penalización por duración del episodio: -  0.30039172227414224\n",
      "Recompensa por acortar distancias: +  0.9156973272951463\n",
      "Penalización por parar muy lejos: -  0.1659332705157804\n",
      "Penalización por duración del episodio: -  0.300486354490381\n",
      "Recompensa por acortar distancias: +  0.9156973272951463\n",
      "Penalización por duración del episodio: -  0.30071455893229465\n",
      "Recompensa por acortar distancias: +  0.9156973272951463\n",
      "Penalización por parar muy lejos: -  0.1659332705157804\n",
      "Penalización por duración del episodio: -  0.3010453089336924\n",
      "Step: 520, Mean Reward (últimos 10 pasos): 0.44871875643730164\n",
      "Recompensa por acortar distancias: +  0.9156973272951463\n",
      "Penalización por parar muy lejos: -  0.1659332705157804\n",
      "Penalización por duración del episodio: -  0.3011450409532196\n",
      "Recompensa por acortar distancias: +  0.9156971506079694\n",
      "Penalización por parar muy lejos: -  0.16593295374488862\n",
      "Penalización por duración del episodio: -  0.30136860065096827\n",
      "Recompensa por acortar distancias: +  0.9156971358840228\n",
      "Penalización por parar muy lejos: -  0.16593292734733617\n",
      "Penalización por duración del episodio: -  0.30169119060400196\n",
      "Recompensa por acortar distancias: +  0.9156969739204561\n",
      "Penalización por duración del episodio: -  0.30201075499690966\n",
      "Recompensa por acortar distancias: +  0.9156971653319136\n",
      "Penalización por parar muy lejos: -  0.16593298014244443\n",
      "Penalización por duración del episodio: -  0.30233834136854765\n",
      "Recompensa por acortar distancias: +  0.915697194779795\n",
      "Penalización por duración del episodio: -  0.3024289055344238\n",
      "Recompensa por acortar distancias: +  0.915697194779795\n",
      "Penalización por duración del episodio: -  0.3026716843973228\n",
      "Recompensa por acortar distancias: +  0.9156971800558555\n",
      "Penalización por parar muy lejos: -  0.1659330065400036\n",
      "Penalización por duración del episodio: -  0.30301635828007456\n",
      "Recompensa por acortar distancias: +  0.9156971800558555\n",
      "Penalización por parar muy lejos: -  0.1659330065400036\n",
      "Penalización por duración del episodio: -  0.30334106471924926\n",
      "Recompensa por acortar distancias: +  0.9156968561285941\n",
      "Penalización por parar muy lejos: -  0.16593242579447878\n",
      "Penalización por duración del episodio: -  0.3036692696585175\n",
      "Step: 530, Mean Reward (últimos 10 pasos): 0.44609516859054565\n",
      "Recompensa por acortar distancias: +  0.9156968414046006\n",
      "Penalización por duración del episodio: -  0.3040101752482044\n",
      "Recompensa por acortar distancias: +  0.9156966941645394\n",
      "Penalización por duración del episodio: -  0.30434858054340475\n",
      "Recompensa por acortar distancias: +  0.9156968561285941\n",
      "Penalización por duración del episodio: -  0.3044565286425043\n",
      "Recompensa por acortar distancias: +  0.9156969297485253\n",
      "Penalización por parar muy lejos: -  0.16593255778195506\n",
      "Penalización por duración del episodio: -  0.304688914955508\n",
      "Recompensa por acortar distancias: +  0.9156969739204561\n",
      "Penalización por parar muy lejos: -  0.16593263697448127\n",
      "Penalización por duración del episodio: -  0.3047771476500177\n",
      "steer input from model: -0.9 , throttle:  0.0\n",
      "reward: 0.4449871892959572\n",
      "Recompensa por acortar distancias: +  0.9156969739204561\n",
      "Penalización por parar muy lejos: -  0.16593263697448127\n",
      "Penalización por duración del episodio: -  0.30501384090941486\n",
      "Recompensa por acortar distancias: +  0.9156969739204561\n",
      "Penalización por duración del episodio: -  0.3053397349309335\n",
      "Recompensa por acortar distancias: +  0.9156968266806051\n",
      "Penalización por parar muy lejos: -  0.16593237299951183\n",
      "Penalización por duración del episodio: -  0.3054288926774338\n",
      "Recompensa por acortar distancias: +  0.9156968266806051\n",
      "Penalización por duración del episodio: -  0.30565953945438024\n",
      "Recompensa por acortar distancias: +  0.9156968561285941\n",
      "Penalización por parar muy lejos: -  0.16593242579447878\n",
      "Penalización por duración del episodio: -  0.3060016367364181\n",
      "Step: 540, Mean Reward (últimos 10 pasos): 0.44376277923583984\n",
      "Recompensa por acortar distancias: +  0.9156969886444285\n",
      "Penalización por duración del episodio: -  0.3063241187085149\n",
      "Recompensa por acortar distancias: +  0.9156971800558555\n",
      "Penalización por duración del episodio: -  0.3066575775710782\n",
      "Recompensa por acortar distancias: +  0.9156973125712279\n",
      "Penalización por duración del episodio: -  0.30700033349006883\n",
      "Recompensa por acortar distancias: +  0.9156973420190626\n",
      "Penalización por parar muy lejos: -  0.1659332969133766\n",
      "Penalización por duración del episodio: -  0.307328583833868\n",
      "Recompensa por acortar distancias: +  0.9156973420190626\n",
      "Penalización por parar muy lejos: -  0.1659332969133766\n",
      "Penalización por duración del episodio: -  0.30743140071100733\n",
      "Recompensa por acortar distancias: +  0.915697194779795\n",
      "Penalización por parar muy lejos: -  0.16593303293756617\n",
      "Penalización por duración del episodio: -  0.30767734336965497\n",
      "Recompensa por acortar distancias: +  0.915697194779795\n",
      "Penalización por duración del episodio: -  0.3080023930057406\n",
      "Recompensa por acortar distancias: +  0.915697194779795\n",
      "Penalización por duración del episodio: -  0.30807137974236515\n",
      "Recompensa por acortar distancias: +  0.9156972536755301\n",
      "Penalización por duración del episodio: -  0.3083400446471204\n",
      "Recompensa por acortar distancias: +  0.9156972831233836\n",
      "Penalización por parar muy lejos: -  0.16593319132301204\n",
      "Penalización por duración del episodio: -  0.30866563997777025\n",
      "Step: 550, Mean Reward (últimos 10 pasos): 0.4410984516143799\n",
      "Recompensa por acortar distancias: +  0.9156974009147041\n",
      "Penalización por parar muy lejos: -  0.16593340250379493\n",
      "Penalización por duración del episodio: -  0.3087427230771677\n",
      "Recompensa por acortar distancias: +  0.9156974009147041\n",
      "Penalización por duración del episodio: -  0.30900602050247705\n",
      "Recompensa por acortar distancias: +  0.9156974303625111\n",
      "Penalización por parar muy lejos: -  0.1659334552990243\n",
      "Penalización por duración del episodio: -  0.30933618142340796\n",
      "Recompensa por acortar distancias: +  0.9156974303625111\n",
      "Penalización por duración del episodio: -  0.30967700074288146\n",
      "Recompensa por acortar distancias: +  0.9156972831233836\n",
      "Penalización por duración del episodio: -  0.31000317619564594\n",
      "steer input from model: 0.25 , throttle:  0.3\n",
      "reward: 0.6056941069277377\n",
      "Recompensa por acortar distancias: +  0.9156972536755301\n",
      "Penalización por duración del episodio: -  0.31033059703123284\n",
      "Recompensa por acortar distancias: +  0.9156973125712279\n",
      "Penalización por duración del episodio: -  0.3104141661144247\n",
      "Recompensa por acortar distancias: +  0.9156973272951463\n",
      "Penalización por parar muy lejos: -  0.1659332705157804\n",
      "Penalización por duración del episodio: -  0.3106573808591554\n",
      "Recompensa por acortar distancias: +  0.9156974303625111\n",
      "Penalización por parar muy lejos: -  0.1659334552990243\n",
      "Penalización por duración del episodio: -  0.31099997615476827\n",
      "Recompensa por acortar distancias: +  0.9156974892580966\n",
      "Penalización por parar muy lejos: -  0.16593356088952343\n",
      "Penalización por duración del episodio: -  0.311339466126635\n",
      "Step: 560, Mean Reward (últimos 10 pasos): 0.4384244680404663\n",
      "Recompensa por acortar distancias: +  0.9156974892580966\n",
      "Penalización por parar muy lejos: -  0.16593356088952343\n",
      "Penalización por duración del episodio: -  0.31166494997834665\n",
      "Recompensa por acortar distancias: +  0.9156972095037325\n",
      "Penalización por duración del episodio: -  0.3120008349927242\n",
      "Recompensa por acortar distancias: +  0.9156972095037325\n",
      "Penalización por duración del episodio: -  0.31234563855524616\n",
      "Recompensa por acortar distancias: +  0.9156969444725047\n",
      "Penalización por duración del episodio: -  0.3126760878258677\n",
      "Recompensa por acortar distancias: +  0.9156970475402941\n",
      "Penalización por parar muy lejos: -  0.16593276896209214\n",
      "Penalización por duración del episodio: -  0.31275276108306566\n",
      "Recompensa por acortar distancias: +  0.9156970917121691\n",
      "Penalización por duración del episodio: -  0.3130147305548563\n",
      "Recompensa por acortar distancias: +  0.9156971653319136\n",
      "Penalización por duración del episodio: -  0.31334234362357527\n",
      "Recompensa por acortar distancias: +  0.9156971653319136\n",
      "Penalización por duración del episodio: -  0.3136783964696368\n",
      "Recompensa por acortar distancias: +  0.9156971653319136\n",
      "Penalización por parar muy lejos: -  0.16593298014244443\n",
      "Penalización por duración del episodio: -  0.31376919729105923\n",
      "Recompensa por acortar distancias: +  0.9156971653319136\n",
      "Penalización por duración del episodio: -  0.3140155744802277\n",
      "Step: 570, Mean Reward (últimos 10 pasos): 0.6016815900802612\n",
      "Recompensa por acortar distancias: +  0.9156970475402941\n",
      "Penalización por duración del episodio: -  0.31434643815187663\n",
      "Recompensa por acortar distancias: +  0.9156970475402941\n",
      "Penalización por duración del episodio: -  0.3146726522677226\n",
      "Recompensa por acortar distancias: +  0.9156971211600738\n",
      "Penalización por duración del episodio: -  0.31501411258627265\n",
      "Recompensa por acortar distancias: +  0.9156972389515999\n",
      "Penalización por parar muy lejos: -  0.16593311213027395\n",
      "Penalización por duración del episodio: -  0.31534896782939503\n",
      "Recompensa por acortar distancias: +  0.9156973567429766\n",
      "Penalización por parar muy lejos: -  0.16593332331097613\n",
      "Penalización por duración del episodio: -  0.31569288935482887\n",
      "steer input from model: 0.05 , throttle:  0.0\n",
      "reward: 0.4340711440771716\n",
      "Recompensa por acortar distancias: +  0.9156973567429766\n",
      "Penalización por duración del episodio: -  0.31605227282931014\n",
      "Recompensa por acortar distancias: +  0.9156972536755301\n",
      "Penalización por parar muy lejos: -  0.16593313852784994\n",
      "Penalización por duración del episodio: -  0.31639005788104696\n",
      "Recompensa por acortar distancias: +  0.9156972831233836\n",
      "Penalización por duración del episodio: -  0.31673391363465064\n",
      "Recompensa por acortar distancias: +  0.9156973272951463\n",
      "Penalización por duración del episodio: -  0.31707692173038043\n",
      "Recompensa por acortar distancias: +  0.9156974303625111\n",
      "Penalización por duración del episodio: -  0.3171608163151314\n",
      "Step: 580, Mean Reward (últimos 10 pasos): 0.5985366106033325\n",
      "Recompensa por acortar distancias: +  0.9156974450864109\n",
      "Penalización por duración del episodio: -  0.31741918856633966\n",
      "Recompensa por acortar distancias: +  0.9156974745342036\n",
      "Penalización por duración del episodio: -  0.31774968763232364\n",
      "Recompensa por acortar distancias: +  0.9156974745342036\n",
      "Penalización por duración del episodio: -  0.3180909202569651\n",
      "Recompensa por acortar distancias: +  0.9156974745342036\n",
      "Penalización por parar muy lejos: -  0.16593353449189358\n",
      "Penalización por duración del episodio: -  0.3184316963124915\n",
      "Recompensa por acortar distancias: +  0.9156971064361227\n",
      "Penalización por duración del episodio: -  0.318767287469972\n",
      "Recompensa por acortar distancias: +  0.9156971064361227\n",
      "Penalización por duración del episodio: -  0.3191129611141856\n",
      "Recompensa por acortar distancias: +  0.915697062264255\n",
      "Penalización por parar muy lejos: -  0.16593279535962438\n",
      "Penalización por duración del episodio: -  0.31945085672403883\n",
      "Recompensa por acortar distancias: +  0.9156972683994581\n",
      "Penalización por parar muy lejos: -  0.16593316492542934\n",
      "Penalización por duración del episodio: -  0.3197809139325086\n",
      "Recompensa por acortar distancias: +  0.9156973272951463\n",
      "Penalización por parar muy lejos: -  0.1659332705157804\n",
      "Penalización por duración del episodio: -  0.3201155675582694\n",
      "Recompensa por acortar distancias: +  0.9156973272951463\n",
      "Penalización por duración del episodio: -  0.32045144478552495\n",
      "Step: 590, Mean Reward (últimos 10 pasos): 0.595245897769928\n",
      "Recompensa por acortar distancias: +  0.9156973714668881\n",
      "Penalización por duración del episodio: -  0.32079159641741734\n",
      "Recompensa por acortar distancias: +  0.9156973714668881\n",
      "Penalización por duración del episodio: -  0.32090574137055516\n",
      "Recompensa por acortar distancias: +  0.9156974450864109\n",
      "Penalización por duración del episodio: -  0.32113370049973194\n",
      "Recompensa por acortar distancias: +  0.9156790604790275\n",
      "Penalización por duración del episodio: -  0.3214840629272347\n",
      "Recompensa por acortar distancias: +  0.9154970504161586\n",
      "Penalización por duración del episodio: -  0.32157634544617036\n",
      "steer input from model: -0.25 , throttle:  0.3\n",
      "reward: 0.5939207049699882\n",
      "Recompensa por acortar distancias: +  0.9154970504161586\n",
      "Penalización por duración del episodio: -  0.3216758522493564\n",
      "Recompensa por acortar distancias: +  0.9153741653383465\n",
      "Penalización por parar muy lejos: -  0.16535570637800115\n",
      "Penalización por duración del episodio: -  0.32181981176380403\n",
      "Recompensa por acortar distancias: +  0.9152301369501554\n",
      "Penalización por duración del episodio: -  0.3221522929413258\n",
      "Recompensa por acortar distancias: +  0.9152301369501554\n",
      "Penalización por duración del episodio: -  0.322247409929795\n",
      "Recompensa por acortar distancias: +  0.9152301369501554\n",
      "Penalización por parar muy lejos: -  0.16509945754394953\n",
      "Penalización por duración del episodio: -  0.32248954878188774\n",
      "Step: 600, Mean Reward (últimos 10 pasos): 0.4276411235332489\n",
      "Recompensa por acortar distancias: +  0.9142465955570462\n",
      "Penalización por duración del episodio: -  0.32260141106926016\n",
      "Recompensa por acortar distancias: +  0.9142465955570462\n",
      "Penalización por duración del episodio: -  0.3228368299920041\n",
      "Recompensa por acortar distancias: +  0.9139198132196481\n",
      "Penalización por duración del episodio: -  0.3231742469834954\n",
      "Recompensa por acortar distancias: +  0.9130159086316302\n",
      "Penalización por duración del episodio: -  0.3235241519318259\n",
      "Recompensa por acortar distancias: +  0.9123746590881681\n",
      "Penalización por parar muy lejos: -  0.1601624967852641\n",
      "Penalización por duración del episodio: -  0.3238842681763527\n",
      "Recompensa por acortar distancias: +  0.911327207616854\n",
      "Penalización por duración del episodio: -  0.3242230079817446\n",
      "Recompensa por acortar distancias: +  0.9109910871203147\n",
      "Penalización por duración del episodio: -  0.3245604371778162\n",
      "Recompensa por acortar distancias: +  0.9109910871203147\n",
      "Penalización por parar muy lejos: -  0.1578645613762111\n",
      "Penalización por duración del episodio: -  0.32490543274735495\n",
      "Recompensa por acortar distancias: +  0.9086609010813009\n",
      "Penalización por duración del episodio: -  0.3252488708271669\n",
      "Recompensa por acortar distancias: +  0.9086609010813009\n",
      "Penalización por duración del episodio: -  0.3255935072522903\n",
      "Step: 610, Mean Reward (últimos 10 pasos): 0.5830674171447754\n",
      "Recompensa por acortar distancias: +  0.9065681893501254\n",
      "Penalización por duración del episodio: -  0.32571013328549087\n",
      "Recompensa por acortar distancias: +  0.9062264625664858\n",
      "Penalización por parar muy lejos: -  0.1503838714672162\n",
      "Penalización por duración del episodio: -  0.3258086762032566\n",
      "Recompensa por acortar distancias: +  0.9057872327090307\n",
      "Penalización por duración del episodio: -  0.32590203335281437\n",
      "Recompensa por acortar distancias: +  0.9053249916089398\n",
      "Penalización por parar muy lejos: -  0.1490392797782072\n",
      "Penalización por duración del episodio: -  0.32630012276259074\n",
      "Recompensa por acortar distancias: +  0.9044980275531205\n",
      "Penalización por parar muy lejos: -  0.14782449435274314\n",
      "Penalización por duración del episodio: -  0.32664160540574394\n",
      "steer input from model: -0.1 , throttle:  0.0\n",
      "reward: 0.4300319277946334\n",
      "Recompensa por acortar distancias: +  0.9044980275531205\n",
      "Penalización por parar muy lejos: -  0.14782449435274314\n",
      "Penalización por duración del episodio: -  0.3267434666657525\n",
      "Recompensa por acortar distancias: +  0.9044980275531205\n",
      "Penalización por parar muy lejos: -  0.14782449435274314\n",
      "Penalización por duración del episodio: -  0.3269786023661969\n",
      "Recompensa por acortar distancias: +  0.9018553273489729\n",
      "Penalización por parar muy lejos: -  0.14405776512645949\n",
      "Penalización por duración del episodio: -  0.3270945655575896\n",
      "Recompensa por acortar distancias: +  0.9018553273489729\n",
      "Penalización por duración del episodio: -  0.3272037896714776\n",
      "Recompensa por acortar distancias: +  0.9011497793342117\n",
      "Penalización por duración del episodio: -  0.32732982057969856\n",
      "Step: 620, Mean Reward (últimos 10 pasos): 0.5738199353218079\n",
      "Recompensa por acortar distancias: +  0.9011497793342117\n",
      "Penalización por parar muy lejos: -  0.14308077851201823\n",
      "Penalización por duración del episodio: -  0.32768473580369434\n",
      "Recompensa por acortar distancias: +  0.9011497793342117\n",
      "Penalización por duración del episodio: -  0.3280249806797962\n",
      "Recompensa por acortar distancias: +  0.8981661788232526\n",
      "Penalización por duración del episodio: -  0.32837529163669577\n",
      "Recompensa por acortar distancias: +  0.8971406530776233\n",
      "Penalización por parar muy lejos: -  0.13774465121117108\n",
      "Penalización por duración del episodio: -  0.3287158661349078\n",
      "Recompensa por acortar distancias: +  0.8971406530776233\n",
      "Penalización por duración del episodio: -  0.32904138763957186\n",
      "Recompensa por acortar distancias: +  0.8971406530776233\n",
      "Penalización por duración del episodio: -  0.3293831936651046\n",
      "Recompensa por acortar distancias: +  0.8940014444062577\n",
      "Penalización por duración del episodio: -  0.3297245848486798\n",
      "Recompensa por acortar distancias: +  0.8922709049613281\n",
      "Penalización por parar muy lejos: -  0.1317183851937674\n",
      "Penalización por duración del episodio: -  0.3300776750751919\n",
      "Recompensa por acortar distancias: +  0.8910111784012623\n",
      "Penalización por duración del episodio: -  0.330174936112297\n",
      "Recompensa por acortar distancias: +  0.8905576254687928\n",
      "Penalización por duración del episodio: -  0.3304324920173039\n",
      "Step: 630, Mean Reward (últimos 10 pasos): 0.5601251125335693\n",
      "Recompensa por acortar distancias: +  0.8896420545050782\n",
      "Penalización por parar muy lejos: -  0.12865428869229611\n",
      "Penalización por duración del episodio: -  0.33078191814838365\n",
      "Recompensa por acortar distancias: +  0.8886121405761309\n",
      "Penalización por parar muy lejos: -  0.12748763051365056\n",
      "Penalización por duración del episodio: -  0.3308978491090041\n",
      "Recompensa por acortar distancias: +  0.8886121405761309\n",
      "Penalización por parar muy lejos: -  0.12748763051365056\n",
      "Penalización por duración del episodio: -  0.33112859505669545\n",
      "Recompensa por acortar distancias: +  0.8886121405761309\n",
      "Penalización por duración del episodio: -  0.33120633468523814\n",
      "Recompensa por acortar distancias: +  0.8886121405761309\n",
      "Penalización por duración del episodio: -  0.3314792065185782\n",
      "steer input from model: -0.05 , throttle:  0.7\n",
      "reward: 0.5571329340575527\n",
      "Recompensa por acortar distancias: +  0.8856328889436271\n",
      "Penalización por parar muy lejos: -  0.12421452821897096\n",
      "Penalización por duración del episodio: -  0.33155907484084796\n",
      "Recompensa por acortar distancias: +  0.8856328889436271\n",
      "Penalización por parar muy lejos: -  0.12421452821897096\n",
      "Penalización por duración del episodio: -  0.33181887771228047\n",
      "Recompensa por acortar distancias: +  0.8848661445855633\n",
      "Penalización por parar muy lejos: -  0.12339574341415734\n",
      "Penalización por duración del episodio: -  0.3321760028429939\n",
      "Recompensa por acortar distancias: +  0.8829839335790717\n",
      "Penalización por duración del episodio: -  0.3322589019276921\n",
      "Recompensa por acortar distancias: +  0.8829839335790717\n",
      "Penalización por duración del episodio: -  0.33252959032936424\n",
      "Step: 640, Mean Reward (últimos 10 pasos): 0.550454318523407\n",
      "Recompensa por acortar distancias: +  0.881261371420221\n",
      "Penalización por parar muy lejos: -  0.11966878442147055\n",
      "Penalización por duración del episodio: -  0.33287880794161656\n",
      "Recompensa por acortar distancias: +  0.8802138747223262\n",
      "Penalización por duración del episodio: -  0.33295611321072344\n",
      "Recompensa por acortar distancias: +  0.8802138747223262\n",
      "Penalización por parar muy lejos: -  0.11862217555270557\n",
      "Penalización por duración del episodio: -  0.3332338668030926\n",
      "Recompensa por acortar distancias: +  0.8802138747223262\n",
      "Penalización por parar muy lejos: -  0.11862217555270557\n",
      "Penalización por duración del episodio: -  0.3335964876560669\n",
      "Recompensa por acortar distancias: +  0.8770988560044622\n",
      "Penalización por parar muy lejos: -  0.11560131625573199\n",
      "Penalización por duración del episodio: -  0.33395166896648754\n",
      "Recompensa por acortar distancias: +  0.8764220875354666\n",
      "Penalización por duración del episodio: -  0.3343064763052294\n",
      "Recompensa por acortar distancias: +  0.8740591166882579\n",
      "Penalización por parar muy lejos: -  0.11277893496334429\n",
      "Penalización por duración del episodio: -  0.3346443614654543\n",
      "Recompensa por acortar distancias: +  0.8726042714319093\n",
      "Penalización por parar muy lejos: -  0.11146968863266324\n",
      "Penalización por duración del episodio: -  0.33499289011102296\n",
      "Recompensa por acortar distancias: +  0.8711020025131044\n",
      "Penalización por duración del episodio: -  0.33533327703926546\n",
      "Recompensa por acortar distancias: +  0.8711020025131044\n",
      "Penalización por parar muy lejos: -  0.11014485825001463\n",
      "Penalización por duración del episodio: -  0.33567395221911195\n",
      "Step: 650, Mean Reward (últimos 10 pasos): 0.42528319358825684\n",
      "Recompensa por acortar distancias: +  0.8711020025131044\n",
      "Penalización por parar muy lejos: -  0.11014485825001463\n",
      "Penalización por duración del episodio: -  0.33577342893080414\n",
      "Recompensa por acortar distancias: +  0.8679735783913684\n",
      "Penalización por duración del episodio: -  0.33601383041577126\n",
      "Recompensa por acortar distancias: +  0.8671520815399845\n",
      "Penalización por duración del episodio: -  0.33635217015614655\n",
      "Recompensa por acortar distancias: +  0.8671520815399845\n",
      "Penalización por duración del episodio: -  0.33644255907461046\n",
      "Recompensa por acortar distancias: +  0.8651777349488056\n",
      "Penalización por parar muy lejos: -  0.10517313119581913\n",
      "Penalización por duración del episodio: -  0.33670963900373463\n",
      "steer input from model: -0.1 , throttle:  0.0\n",
      "reward: 0.42329496474925177\n",
      "Recompensa por acortar distancias: +  0.8640577828464706\n",
      "Penalización por parar muy lejos: -  0.10427607687275782\n",
      "Penalización por duración del episodio: -  0.33680526757234047\n",
      "Recompensa por acortar distancias: +  0.8635414462901262\n",
      "Penalización por duración del episodio: -  0.3370622389950666\n",
      "Recompensa por acortar distancias: +  0.8625072180297713\n",
      "Penalización por duración del episodio: -  0.33741273905916147\n",
      "Recompensa por acortar distancias: +  0.8614024275389619\n",
      "Penalización por duración del episodio: -  0.33777216395991055\n",
      "Recompensa por acortar distancias: +  0.8614024275389619\n",
      "Penalización por parar muy lejos: -  0.1022002631022609\n",
      "Penalización por duración del episodio: -  0.33811704976013207\n",
      "Step: 660, Mean Reward (últimos 10 pasos): 0.4210851192474365\n",
      "Recompensa por acortar distancias: +  0.8583133146410759\n",
      "Penalización por duración del episodio: -  0.3384660580980034\n",
      "Recompensa por acortar distancias: +  0.8576369279339267\n",
      "Penalización por duración del episodio: -  0.33882609001340674\n",
      "Recompensa por acortar distancias: +  0.8546987504095244\n",
      "Penalización por parar muy lejos: -  0.09725883009930059\n",
      "Penalización por duración del episodio: -  0.3391689731798657\n",
      "Recompensa por acortar distancias: +  0.8533092865738865\n",
      "Penalización por duración del episodio: -  0.3392763214773449\n",
      "Recompensa por acortar distancias: +  0.8527789223821886\n",
      "Penalización por duración del episodio: -  0.33951602426368577\n",
      "Recompensa por acortar distancias: +  0.8517585548449076\n",
      "Penalización por duración del episodio: -  0.3398714747453161\n",
      "Recompensa por acortar distancias: +  0.8517585548449076\n",
      "Penalización por parar muy lejos: -  0.09521677672445913\n",
      "Penalización por duración del episodio: -  0.34021628967329154\n",
      "Recompensa por acortar distancias: +  0.8517585548449076\n",
      "Penalización por parar muy lejos: -  0.09521677672445913\n",
      "Penalización por duración del episodio: -  0.3402958641763834\n",
      "Recompensa por acortar distancias: +  0.8517585548449076\n",
      "Penalización por parar muy lejos: -  0.09521677672445913\n",
      "Penalización por duración del episodio: -  0.34039213846069516\n",
      "Recompensa por acortar distancias: +  0.8479156956405848\n",
      "Penalización por parar muy lejos: -  0.09265382715644778\n",
      "Penalización por duración del episodio: -  0.34056847564171594\n",
      "Step: 670, Mean Reward (últimos 10 pasos): 0.4146933853626251\n",
      "Recompensa por acortar distancias: +  0.8470506116907086\n",
      "Penalización por duración del episodio: -  0.34091829317771033\n",
      "Recompensa por acortar distancias: +  0.8470506116907086\n",
      "Penalización por duración del episodio: -  0.3412628117933125\n",
      "Recompensa por acortar distancias: +  0.8443430637429608\n",
      "Penalización por parar muy lejos: -  0.09037246580625276\n",
      "Penalización por duración del episodio: -  0.3413700676985021\n",
      "Recompensa por acortar distancias: +  0.8438746483464522\n",
      "Penalización por parar muy lejos: -  0.09008026728920707\n",
      "Penalización por duración del episodio: -  0.3414575246322583\n",
      "Recompensa por acortar distancias: +  0.8433066890967285\n",
      "Penalización por parar muy lejos: -  0.08972806708961693\n",
      "Penalización por duración del episodio: -  0.3416059055073134\n",
      "steer input from model: 0.9 , throttle:  0.0\n",
      "reward: 0.41197271649979816\n",
      "Recompensa por acortar distancias: +  0.8426379954761049\n",
      "Penalización por duración del episodio: -  0.3417000738003174\n",
      "Recompensa por acortar distancias: +  0.8426379954761049\n",
      "Penalización por duración del episodio: -  0.341958253288206\n",
      "Recompensa por acortar distancias: +  0.8420592578144391\n",
      "Penalización por parar muy lejos: -  0.08896246785158494\n",
      "Penalización por duración del episodio: -  0.3423216289450553\n",
      "Recompensa por acortar distancias: +  0.8420592578144391\n",
      "Penalización por parar muy lejos: -  0.08896246785158494\n",
      "Penalización por duración del episodio: -  0.34267319221677045\n",
      "Recompensa por acortar distancias: +  0.8382183605184995\n",
      "Penalización por parar muy lejos: -  0.08667162880051331\n",
      "Penalización por duración del episodio: -  0.34302937706349235\n",
      "Step: 680, Mean Reward (últimos 10 pasos): 0.40851736068725586\n",
      "Recompensa por acortar distancias: +  0.8382183605184995\n",
      "Penalización por duración del episodio: -  0.3433932700868328\n",
      "Recompensa por acortar distancias: +  0.8351638379903032\n",
      "Penalización por duración del episodio: -  0.34373994271891267\n",
      "Recompensa por acortar distancias: +  0.8333745930831032\n",
      "Penalización por duración del episodio: -  0.3440838116821947\n",
      "Recompensa por acortar distancias: +  0.8323692425067045\n",
      "Penalización por duración del episodio: -  0.34444353157805757\n",
      "Recompensa por acortar distancias: +  0.8323692425067045\n",
      "Penalización por duración del episodio: -  0.3447879500458556\n",
      "Recompensa por acortar distancias: +  0.8290806655414305\n",
      "Penalización por parar muy lejos: -  0.08159471691464981\n",
      "Penalización por duración del episodio: -  0.3448672915567749\n",
      "Recompensa por acortar distancias: +  0.8284436019286281\n",
      "Penalización por duración del episodio: -  0.3451441118789673\n",
      "Recompensa por acortar distancias: +  0.8284436019286281\n",
      "Penalización por duración del episodio: -  0.3454788070338953\n",
      "Recompensa por acortar distancias: +  0.8257487369133768\n",
      "Penalización por duración del episodio: -  0.3455869300891914\n",
      "Recompensa por acortar distancias: +  0.825157907369268\n",
      "Penalización por duración del episodio: -  0.3458229864518758\n",
      "Step: 690, Mean Reward (últimos 10 pasos): 0.47933492064476013\n",
      "Recompensa por acortar distancias: +  0.8245229849647696\n",
      "Penalización por duración del episodio: -  0.3461611379245366\n",
      "Recompensa por acortar distancias: +  0.8229453510425279\n",
      "Penalización por parar muy lejos: -  0.07845194593496095\n",
      "Penalización por duración del episodio: -  0.3462524583184445\n",
      "Recompensa por acortar distancias: +  0.8223770139241965\n",
      "Penalización por duración del episodio: -  0.3464980412523761\n",
      "Recompensa por acortar distancias: +  0.8223770139241965\n",
      "Penalización por duración del episodio: -  0.34685641177134247\n",
      "Recompensa por acortar distancias: +  0.8223770139241965\n",
      "Penalización por duración del episodio: -  0.34720232716073385\n",
      "steer input from model: -0.9 , throttle:  0.3\n",
      "reward: 0.47517468676346264\n",
      "Recompensa por acortar distancias: +  0.8182126498794718\n",
      "Penalización por duración del episodio: -  0.3475605250816345\n",
      "Recompensa por acortar distancias: +  0.8182126498794718\n",
      "Penalización por duración del episodio: -  0.3479196907195798\n",
      "Recompensa por acortar distancias: +  0.8142923282513028\n",
      "Penalización por duración del episodio: -  0.34826991082520736\n",
      "Recompensa por acortar distancias: +  0.8126612786094677\n",
      "Penalización por parar muy lejos: -  0.07360389673229917\n",
      "Penalización por duración del episodio: -  0.3486299375810237\n",
      "Recompensa por acortar distancias: +  0.8113395271595742\n",
      "Penalización por duración del episodio: -  0.34899125849445783\n",
      "Step: 700, Mean Reward (últimos 10 pasos): 0.4623482823371887\n",
      "Recompensa por acortar distancias: +  0.8113395271595742\n",
      "Penalización por duración del episodio: -  0.3493560805468426\n",
      "Recompensa por acortar distancias: +  0.8073068477599891\n",
      "Penalización por duración del episodio: -  0.3497133256409852\n",
      "Recompensa por acortar distancias: +  0.8063696080661867\n",
      "Penalización por parar muy lejos: -  0.07086950707828034\n",
      "Penalización por duración del episodio: -  0.35008037894415467\n",
      "Recompensa por acortar distancias: +  0.8031582673854426\n",
      "Penalización por parar muy lejos: -  0.06953538883461255\n",
      "Penalización por duración del episodio: -  0.35043396054817705\n",
      "Recompensa por acortar distancias: +  0.8011957182508099\n",
      "Penalización por duración del episodio: -  0.3507900412688396\n",
      "Recompensa por acortar distancias: +  0.7997026777486811\n",
      "Penalización por parar muy lejos: -  0.06814351200180141\n",
      "Penalización por duración del episodio: -  0.3511561314059939\n",
      "Recompensa por acortar distancias: +  0.7989783363287464\n",
      "Penalización por duración del episodio: -  0.35149285342004394\n",
      "Recompensa por acortar distancias: +  0.7989783363287464\n",
      "Penalización por parar muy lejos: -  0.06785730594541063\n",
      "Penalización por duración del episodio: -  0.35157190443471986\n",
      "Recompensa por acortar distancias: +  0.7944380965398335\n",
      "Penalización por duración del episodio: -  0.35186570090468267\n",
      "Recompensa por acortar distancias: +  0.7933484406068032\n",
      "Penalización por duración del episodio: -  0.35223133626179876\n",
      "Step: 710, Mean Reward (últimos 10 pasos): 0.4411171078681946\n",
      "Recompensa por acortar distancias: +  0.7904979588268922\n",
      "Penalización por parar muy lejos: -  0.06464167238042584\n",
      "Penalización por duración del episodio: -  0.352596616949918\n",
      "Recompensa por acortar distancias: +  0.7881982150689734\n",
      "Penalización por duración del episodio: -  0.35295509502668904\n",
      "Recompensa por acortar distancias: +  0.7862453726199953\n",
      "Penalización por duración del episodio: -  0.3533012967569538\n",
      "Recompensa por acortar distancias: +  0.7854833143822654\n",
      "Penalización por parar muy lejos: -  0.06285024216341698\n",
      "Penalización por duración del episodio: -  0.35365671552840794\n",
      "Recompensa por acortar distancias: +  0.7854833143822654\n",
      "Penalización por duración del episodio: -  0.3540219304600911\n",
      "steer input from model: -0.9 , throttle:  0.3\n",
      "reward: 0.43146138392217426\n",
      "Recompensa por acortar distancias: +  0.7801668726463441\n",
      "Penalización por duración del episodio: -  0.3543900323193612\n",
      "Recompensa por acortar distancias: +  0.7781035252022346\n",
      "Penalización por parar muy lejos: -  0.06034972529235364\n",
      "Penalización por duración del episodio: -  0.3547698330862661\n",
      "Recompensa por acortar distancias: +  0.7750001316198062\n",
      "Penalización por parar muy lejos: -  0.059343434266819414\n",
      "Penalización por duración del episodio: -  0.35490650315435146\n",
      "Recompensa por acortar distancias: +  0.7734738202531033\n",
      "Penalización por duración del episodio: -  0.3550146606729897\n",
      "Recompensa por acortar distancias: +  0.7734738202531033\n",
      "Penalización por parar muy lejos: -  0.058857865376661454\n",
      "Penalización por duración del episodio: -  0.3551317711409256\n",
      "Step: 720, Mean Reward (últimos 10 pasos): 0.3594841957092285\n",
      "Recompensa por acortar distancias: +  0.7723636527176742\n",
      "Penalización por duración del episodio: -  0.35523267476895054\n",
      "Recompensa por acortar distancias: +  0.7723636527176742\n",
      "Penalización por parar muy lejos: -  0.058508465922079624\n",
      "Penalización por duración del episodio: -  0.3553726746795114\n",
      "Recompensa por acortar distancias: +  0.771095684525695\n",
      "Penalización por parar muy lejos: -  0.05811323587321594\n",
      "Penalización por duración del episodio: -  0.35581208599434144\n",
      "Recompensa por acortar distancias: +  0.7697036178664981\n",
      "Penalización por parar muy lejos: -  0.057683960191893945\n",
      "Penalización por duración del episodio: -  0.3561794920401611\n",
      "Recompensa por acortar distancias: +  0.7697036178664981\n",
      "Penalización por duración del episodio: -  0.3562986227188973\n",
      "Recompensa por acortar distancias: +  0.7646600390243576\n",
      "Penalización por parar muy lejos: -  0.056168064405650184\n",
      "Penalización por duración del episodio: -  0.3565251665892657\n",
      "Recompensa por acortar distancias: +  0.7633859337540845\n",
      "Penalización por duración del episodio: -  0.3568919707453208\n",
      "Recompensa por acortar distancias: +  0.7601735124221066\n",
      "Penalización por parar muy lejos: -  0.05486931300812179\n",
      "Penalización por duración del episodio: -  0.35724544777001255\n",
      "Recompensa por acortar distancias: +  0.7582557294119836\n",
      "Penalización por duración del episodio: -  0.3576039602405476\n",
      "Recompensa por acortar distancias: +  0.7556178968454056\n",
      "Penalización por duración del episodio: -  0.3579585608926452\n",
      "Step: 730, Mean Reward (últimos 10 pasos): 0.3976593315601349\n",
      "Recompensa por acortar distancias: +  0.754716438255624\n",
      "Penalización por duración del episodio: -  0.35806402500195067\n",
      "Recompensa por acortar distancias: +  0.754716438255624\n",
      "Penalización por duración del episodio: -  0.35831258795664334\n",
      "Recompensa por acortar distancias: +  0.754716438255624\n",
      "Penalización por duración del episodio: -  0.3586719576496486\n",
      "Recompensa por acortar distancias: +  0.7488437511572993\n",
      "Penalización por parar muy lejos: -  0.05178184956122958\n",
      "Penalización por duración del episodio: -  0.35890694257747074\n",
      "Recompensa por acortar distancias: +  0.7474585780530378\n",
      "Penalización por duración del episodio: -  0.359071814173862\n",
      "steer input from model: 0.05 , throttle:  1.0\n",
      "reward: 0.3883867638791758\n",
      "Recompensa por acortar distancias: +  0.7474585780530378\n",
      "Penalización por duración del episodio: -  0.35917241257224924\n",
      "Recompensa por acortar distancias: +  0.7474585780530378\n",
      "Penalización por duración del episodio: -  0.359400268471434\n",
      "Recompensa por acortar distancias: +  0.7432601945431611\n",
      "Penalización por parar muy lejos: -  0.050353725508828814\n",
      "Penalización por duración del episodio: -  0.359502883615276\n",
      "Recompensa por acortar distancias: +  0.7432601945431611\n",
      "Penalización por parar muy lejos: -  0.050353725508828814\n",
      "Penalización por duración del episodio: -  0.3597509026618256\n",
      "Recompensa por acortar distancias: +  0.7409714059302253\n",
      "Penalización por duración del episodio: -  0.3598548303763312\n",
      "Step: 740, Mean Reward (últimos 10 pasos): 0.3811165690422058\n",
      "Recompensa por acortar distancias: +  0.7409714059302253\n",
      "Penalización por duración del episodio: -  0.36011916823173784\n",
      "Recompensa por acortar distancias: +  0.7386352639576\n",
      "Penalización por parar muy lejos: -  0.049213917308364434\n",
      "Penalización por duración del episodio: -  0.36048375654249376\n",
      "Recompensa por acortar distancias: +  0.7386352639576\n",
      "Penalización por parar muy lejos: -  0.049213917308364434\n",
      "Penalización por duración del episodio: -  0.3605973746900533\n",
      "Recompensa por acortar distancias: +  0.7386352639576\n",
      "Penalización por duración del episodio: -  0.360832779360977\n",
      "Recompensa por acortar distancias: +  0.7386352639576\n",
      "Penalización por duración del episodio: -  0.36097004394895016\n",
      "Recompensa por acortar distancias: +  0.732804667981709\n",
      "Penalización por duración del episodio: -  0.3612023197847015\n",
      "Recompensa por acortar distancias: +  0.7312519916369074\n",
      "Penalización por duración del episodio: -  0.361560081850242\n",
      "Recompensa por acortar distancias: +  0.7312519916369074\n",
      "Penalización por duración del episodio: -  0.36164496697029086\n",
      "Recompensa por acortar distancias: +  0.727135184543984\n",
      "Penalización por duración del episodio: -  0.3618258341497767\n",
      "Recompensa por acortar distancias: +  0.727135184543984\n",
      "Penalización por duración del episodio: -  0.36194469594688133\n",
      "Step: 750, Mean Reward (últimos 10 pasos): 0.3651904761791229\n",
      "Recompensa por acortar distancias: +  0.7251948097605512\n",
      "Penalización por duración del episodio: -  0.3622605333442867\n",
      "Recompensa por acortar distancias: +  0.7228839512328089\n",
      "Penalización por duración del episodio: -  0.3626286399366442\n",
      "Recompensa por acortar distancias: +  0.7228839512328089\n",
      "Penalización por duración del episodio: -  0.3629780866476152\n",
      "Recompensa por acortar distancias: +  0.7228839512328089\n",
      "Penalización por duración del episodio: -  0.36334502887345393\n",
      "Recompensa por acortar distancias: +  0.7143748315844504\n",
      "Penalización por duración del episodio: -  0.3634556053803319\n",
      "steer input from model: 0.0 , throttle:  0.0\n",
      "reward: 0.3509192262041185\n",
      "Recompensa por acortar distancias: +  0.7143748315844504\n",
      "Penalización por duración del episodio: -  0.3637154960054792\n",
      "Recompensa por acortar distancias: +  0.7143748315844504\n",
      "Penalización por duración del episodio: -  0.3640869639002926\n",
      "Recompensa por acortar distancias: +  0.7089549486192195\n",
      "Penalización por duración del episodio: -  0.36419235919920456\n",
      "Recompensa por acortar distancias: +  0.7079838754948982\n",
      "Penalización por duración del episodio: -  0.3644417615963747\n",
      "Recompensa por acortar distancias: +  0.7068937897357296\n",
      "Penalización por duración del episodio: -  0.36480117614116386\n",
      "Step: 760, Mean Reward (últimos 10 pasos): 0.3420926034450531\n",
      "Recompensa por acortar distancias: +  0.7048086947562514\n",
      "Penalización por duración del episodio: -  0.3651729562033446\n",
      "Recompensa por acortar distancias: +  0.7048086947562514\n",
      "Penalización por duración del episodio: -  0.36554208815794176\n",
      "Recompensa por acortar distancias: +  0.6978925133525582\n",
      "Penalización por duración del episodio: -  0.36588770242100527\n",
      "Recompensa por acortar distancias: +  0.6978925133525582\n",
      "Penalización por duración del episodio: -  0.3662501008129561\n",
      "Recompensa por acortar distancias: +  0.6923524316718075\n",
      "Penalización por duración del episodio: -  0.36661122780525607\n",
      "Recompensa por acortar distancias: +  0.6897003197806848\n",
      "Penalización por duración del episodio: -  0.3669687827891181\n",
      "Recompensa por acortar distancias: +  0.6870042436775442\n",
      "Penalización por duración del episodio: -  0.36733646328446196\n",
      "Recompensa por acortar distancias: +  0.6870042436775442\n",
      "Penalización por duración del episodio: -  0.36771074492998707\n",
      "Recompensa por acortar distancias: +  0.6813501082797371\n",
      "Penalización por duración del episodio: -  0.36807794910642017\n",
      "Recompensa por acortar distancias: +  0.6800643646799769\n",
      "Penalización por duración del episodio: -  0.36845153654865764\n",
      "Step: 770, Mean Reward (últimos 10 pasos): 0.3116128146648407\n",
      "Recompensa por acortar distancias: +  0.6800643646799769\n",
      "Penalización por duración del episodio: -  0.36881666795675166\n",
      "Recompensa por acortar distancias: +  0.6733620705869131\n",
      "Penalización por duración del episodio: -  0.36892462529671155\n",
      "Recompensa por acortar distancias: +  0.672130805199042\n",
      "Penalización por duración del episodio: -  0.3691743983857333\n",
      "Recompensa por acortar distancias: +  0.6700690299281775\n",
      "Penalización por duración del episodio: -  0.3695463204269521\n",
      "Recompensa por acortar distancias: +  0.6700690299281775\n",
      "Penalización por duración del episodio: -  0.36992136489817384\n",
      "steer input from model: 0.1 , throttle:  1.0\n",
      "reward: 0.3001476650300037\n",
      "Recompensa por acortar distancias: +  0.6700690299281775\n",
      "Penalización por duración del episodio: -  0.3700284889860786\n",
      "Recompensa por acortar distancias: +  0.6638570680317488\n",
      "Penalización por duración del episodio: -  0.370287538057308\n",
      "Recompensa por acortar distancias: +  0.6623083542668297\n",
      "Penalización por duración del episodio: -  0.3706404126543649\n",
      "Recompensa por acortar distancias: +  0.6623083542668297\n",
      "Penalización por duración del episodio: -  0.37101618111656687\n",
      "Recompensa por acortar distancias: +  0.656448644687302\n",
      "Penalización por duración del episodio: -  0.37139728223979596\n",
      "Step: 780, Mean Reward (últimos 10 pasos): 0.2850513756275177\n",
      "Recompensa por acortar distancias: +  0.6530819730066487\n",
      "Penalización por duración del episodio: -  0.37176044603790004\n",
      "Recompensa por acortar distancias: +  0.6522212825793454\n",
      "Penalización por duración del episodio: -  0.37211638486042703\n",
      "Recompensa por acortar distancias: +  0.6522212825793454\n",
      "Penalización por duración del episodio: -  0.3722282594836248\n",
      "Recompensa por acortar distancias: +  0.6522212825793454\n",
      "Penalización por duración del episodio: -  0.3723355676948925\n",
      "Recompensa por acortar distancias: +  0.6466033029606375\n",
      "Penalización por duración del episodio: -  0.3724909250247891\n",
      "Recompensa por acortar distancias: +  0.6466033029606375\n",
      "Penalización por duración del episodio: -  0.37286167671057296\n",
      "Recompensa por acortar distancias: +  0.6450316928043078\n",
      "Penalización por duración del episodio: -  0.37321817738510465\n",
      "Recompensa por acortar distancias: +  0.640760970457566\n",
      "Penalización por duración del episodio: -  0.37358433436674354\n",
      "Recompensa por acortar distancias: +  0.6392855608545936\n",
      "Penalización por duración del episodio: -  0.37369644903590477\n",
      "Recompensa por acortar distancias: +  0.6384854915589174\n",
      "Penalización por duración del episodio: -  0.3737960149770635\n",
      "Step: 790, Mean Reward (últimos 10 pasos): 0.26468947529792786\n",
      "Recompensa por acortar distancias: +  0.6376404411056976\n",
      "Penalización por duración del episodio: -  0.3739590590091271\n",
      "Recompensa por acortar distancias: +  0.6368422971560961\n",
      "Penalización por duración del episodio: -  0.374075746300591\n",
      "Recompensa por acortar distancias: +  0.6368422971560961\n",
      "Penalización por duración del episodio: -  0.37433581111891373\n",
      "Recompensa por acortar distancias: +  0.6368422971560961\n",
      "Penalización por duración del episodio: -  0.3746821315474874\n",
      "Recompensa por acortar distancias: +  0.6368422971560961\n",
      "Penalización por duración del episodio: -  0.37475553497320485\n",
      "steer input from model: -0.1 , throttle:  0.3\n",
      "reward: 0.26208676218289123\n",
      "Recompensa por acortar distancias: +  0.6368422971560961\n",
      "Penalización por duración del episodio: -  0.37504949683938493\n",
      "Recompensa por acortar distancias: +  0.6335493697139138\n",
      "Penalización por duración del episodio: -  0.37541403757080777\n",
      "Recompensa por acortar distancias: +  0.6331809052425361\n",
      "Penalización por duración del episodio: -  0.3757803861595535\n",
      "Recompensa por acortar distancias: +  0.6315297946341926\n",
      "Penalización por duración del episodio: -  0.3761384736882553\n",
      "Recompensa por acortar distancias: +  0.6303626997377599\n",
      "Penalización por duración del episodio: -  0.37650324491604037\n",
      "Step: 800, Mean Reward (últimos 10 pasos): 0.2538594603538513\n",
      "Recompensa por acortar distancias: +  0.6300136430513047\n",
      "Penalización por duración del episodio: -  0.37686791543977827\n",
      "Recompensa por acortar distancias: +  0.6300136430513047\n",
      "Penalización por duración del episodio: -  0.37722489513134855\n",
      "Recompensa por acortar distancias: +  0.6274336714831209\n",
      "Penalización por duración del episodio: -  0.3775953661118344\n",
      "Recompensa por acortar distancias: +  0.6274336714831209\n",
      "Penalización por duración del episodio: -  0.3779689061403357\n",
      "Recompensa por acortar distancias: +  0.6262936685097256\n",
      "Penalización por duración del episodio: -  0.37834745847357476\n",
      "Recompensa por acortar distancias: +  0.6262844109370955\n",
      "Penalización por duración del episodio: -  0.37871920856985813\n",
      "Recompensa por acortar distancias: +  0.6262650473005104\n",
      "Penalización por duración del episodio: -  0.3790754328312239\n",
      "Recompensa por acortar distancias: +  0.6262650473005104\n",
      "Penalización por duración del episodio: -  0.37944326236878817\n",
      "Recompensa por acortar distancias: +  0.6260502065751538\n",
      "Penalización por duración del episodio: -  0.37980293561553014\n",
      "Recompensa por acortar distancias: +  0.6260012932932122\n",
      "Penalización por duración del episodio: -  0.3801782132273759\n",
      "Step: 810, Mean Reward (últimos 10 pasos): 0.24582308530807495\n",
      "Recompensa por acortar distancias: +  0.625733650829388\n",
      "Penalización por duración del episodio: -  0.3805427307920215\n",
      "Recompensa por acortar distancias: +  0.6256224533843296\n",
      "Penalización por duración del episodio: -  0.38091676113900014\n",
      "Recompensa por acortar distancias: +  0.6256253906773702\n",
      "Penalización por duración del episodio: -  0.3812893748484283\n",
      "Recompensa por acortar distancias: +  0.6256253906773702\n",
      "Penalización por duración del episodio: -  0.3816619876773288\n",
      "Recompensa por acortar distancias: +  0.6256323485627392\n",
      "Penalización por duración del episodio: -  0.3820171671955651\n",
      "steer input from model: -0.25 , throttle:  1.0\n",
      "reward: 0.24361518136717408\n",
      "Recompensa por acortar distancias: +  0.6256342974314331\n",
      "Penalización por duración del episodio: -  0.38237932529275453\n",
      "Recompensa por acortar distancias: +  0.6256384520261643\n",
      "Penalización por duración del episodio: -  0.38274924635227986\n",
      "Recompensa por acortar distancias: +  0.6256439467843027\n",
      "Penalización por duración del episodio: -  0.3831259410565655\n",
      "Recompensa por acortar distancias: +  0.6256486374058645\n",
      "Penalización por duración del episodio: -  0.38324140460712147\n",
      "Recompensa por acortar distancias: +  0.6256503014540316\n",
      "Penalización por duración del episodio: -  0.38349281017907205\n",
      "Step: 820, Mean Reward (últimos 10 pasos): 0.2421574890613556\n",
      "Recompensa por acortar distancias: +  0.6256519766673059\n",
      "Penalización por duración del episodio: -  0.3838493575842702\n",
      "Recompensa por acortar distancias: +  0.6256519766673059\n",
      "Penalización por duración del episodio: -  0.38422148577095966\n",
      "Recompensa por acortar distancias: +  0.6256604085283989\n",
      "Penalización por duración del episodio: -  0.38458270639420805\n",
      "Recompensa por acortar distancias: +  0.6256604085283989\n",
      "Penalización por duración del episodio: -  0.38495888344602397\n",
      "Recompensa por acortar distancias: +  0.625616601107489\n",
      "Penalización por duración del episodio: -  0.38505292099189115\n",
      "Recompensa por acortar distancias: +  0.625616601107489\n",
      "Penalización por duración del episodio: -  0.3853282748746818\n",
      "Recompensa por acortar distancias: +  0.6255642640368668\n",
      "Penalización por duración del episodio: -  0.3854341493834452\n",
      "Recompensa por acortar distancias: +  0.6255461922108202\n",
      "Penalización por duración del episodio: -  0.3857031141709964\n",
      "Recompensa por acortar distancias: +  0.6255082491724484\n",
      "Penalización por duración del episodio: -  0.38606100611997807\n",
      "Recompensa por acortar distancias: +  0.6255082491724484\n",
      "Penalización por duración del episodio: -  0.3864272575508795\n",
      "Step: 830, Mean Reward (últimos 10 pasos): 0.2390809953212738\n",
      "Recompensa por acortar distancias: +  0.6255082491724484\n",
      "Penalización por duración del episodio: -  0.38677939855572774\n",
      "Recompensa por acortar distancias: +  0.6253121762620579\n",
      "Penalización por duración del episodio: -  0.3871569665337034\n",
      "Recompensa por acortar distancias: +  0.6253121762620579\n",
      "Penalización por duración del episodio: -  0.38753474372582203\n",
      "Recompensa por acortar distancias: +  0.6253198123918529\n",
      "Penalización por duración del episodio: -  0.3879227327088426\n",
      "Recompensa por acortar distancias: +  0.6253209854567404\n",
      "Penalización por duración del episodio: -  0.38806597082872785\n",
      "steer input from model: -0.05 , throttle:  0.3\n",
      "reward: 0.23725501462801257\n",
      "Recompensa por acortar distancias: +  0.6253256609435939\n",
      "Penalización por duración del episodio: -  0.3882983429272227\n",
      "Recompensa por acortar distancias: +  0.6252953676190792\n",
      "Penalización por duración del episodio: -  0.3886588585276025\n",
      "Recompensa por acortar distancias: +  0.6252953676190792\n",
      "Penalización por duración del episodio: -  0.3887605426709084\n",
      "Recompensa por acortar distancias: +  0.6252953676190792\n",
      "Penalización por duración del episodio: -  0.38902184204156554\n",
      "Recompensa por acortar distancias: +  0.6252953676190792\n",
      "Penalización por duración del episodio: -  0.38938578194145146\n",
      "Step: 840, Mean Reward (últimos 10 pasos): 0.2359095811843872\n",
      "Recompensa por acortar distancias: +  0.6252711680051959\n",
      "Penalización por duración del episodio: -  0.389494514012707\n",
      "Recompensa por acortar distancias: +  0.6252711680051959\n",
      "Penalización por duración del episodio: -  0.3897515123001574\n",
      "Recompensa por acortar distancias: +  0.6252711680051959\n",
      "Penalización por duración del episodio: -  0.38987443681247136\n",
      "Recompensa por acortar distancias: +  0.6252408617422562\n",
      "Penalización por duración del episodio: -  0.3901047339118044\n",
      "Recompensa por acortar distancias: +  0.6252410293371937\n",
      "Penalización por duración del episodio: -  0.3902093857482334\n",
      "Recompensa por acortar distancias: +  0.6252415935732626\n",
      "Penalización por duración del episodio: -  0.39047498058909685\n",
      "Recompensa por acortar distancias: +  0.6252425879686743\n",
      "Penalización por duración del episodio: -  0.3908398927966546\n",
      "Recompensa por acortar distancias: +  0.6252425879686743\n",
      "Penalización por duración del episodio: -  0.39122036645931485\n",
      "Recompensa por acortar distancias: +  0.6252425879686743\n",
      "Penalización por duración del episodio: -  0.39158800432150437\n",
      "Recompensa por acortar distancias: +  0.6252438393411734\n",
      "Penalización por duración del episodio: -  0.3919634872916204\n",
      "Step: 850, Mean Reward (últimos 10 pasos): 0.23328034579753876\n",
      "Recompensa por acortar distancias: +  0.6252438393411734\n",
      "Penalización por duración del episodio: -  0.39234010990053003\n",
      "Recompensa por acortar distancias: +  0.6252458169532276\n",
      "Penalización por duración del episodio: -  0.39270383399022657\n",
      "Recompensa por acortar distancias: +  0.6252184093356937\n",
      "Penalización por duración del episodio: -  0.39306647702433345\n",
      "Recompensa por acortar distancias: +  0.6252224317024399\n",
      "Penalización por duración del episodio: -  0.3934421138222823\n",
      "Recompensa por acortar distancias: +  0.6252224317024399\n",
      "Penalización por duración del episodio: -  0.3938044899754196\n",
      "steer input from model: 0.9 , throttle:  0.0\n",
      "reward: 0.23141794172702024\n",
      "Recompensa por acortar distancias: +  0.6252217166162822\n",
      "Penalización por duración del episodio: -  0.39417897909949284\n",
      "Recompensa por acortar distancias: +  0.625221694269831\n",
      "Penalización por duración del episodio: -  0.39454899070851923\n",
      "Recompensa por acortar distancias: +  0.6252226160605012\n",
      "Penalización por duración del episodio: -  0.3946600041166279\n",
      "Recompensa por acortar distancias: +  0.6252228060051326\n",
      "Penalización por duración del episodio: -  0.3947762406670201\n",
      "Recompensa por acortar distancias: +  0.6252300462188006\n",
      "Penalización por duración del episodio: -  0.39493182806411053\n",
      "Step: 860, Mean Reward (últimos 10 pasos): 0.2302982211112976\n",
      "Recompensa por acortar distancias: +  0.6252081410488356\n",
      "Penalización por duración del episodio: -  0.39529526911871954\n",
      "Recompensa por acortar distancias: +  0.6252189847586632\n",
      "Penalización por duración del episodio: -  0.39565850667760355\n",
      "Recompensa por acortar distancias: +  0.6252189847586632\n",
      "Penalización por duración del episodio: -  0.396030881129175\n",
      "Recompensa por acortar distancias: +  0.6251803356607248\n",
      "Penalización por duración del episodio: -  0.3964096569329546\n",
      "Recompensa por acortar distancias: +  0.6251697038061658\n",
      "Penalización por duración del episodio: -  0.39679009776012175\n",
      "Recompensa por acortar distancias: +  0.6251695138507561\n",
      "Penalización por duración del episodio: -  0.3971751901929688\n",
      "Recompensa por acortar distancias: +  0.6251701060645531\n",
      "Penalización por duración del episodio: -  0.3972658428892529\n",
      "Recompensa por acortar distancias: +  0.6251702792590833\n",
      "Penalización por duración del episodio: -  0.39756107243473254\n",
      "Recompensa por acortar distancias: +  0.6251705865396227\n",
      "Penalización por duración del episodio: -  0.3979561930193132\n",
      "Recompensa por acortar distancias: +  0.6251704859750935\n",
      "Penalización por duración del episodio: -  0.3983282589650494\n",
      "Step: 870, Mean Reward (últimos 10 pasos): 0.2268422245979309\n",
      "Recompensa por acortar distancias: +  0.6251704859750935\n",
      "Penalización por duración del episodio: -  0.39870456350766026\n",
      "Recompensa por acortar distancias: +  0.6251626139737156\n",
      "Penalización por duración del episodio: -  0.39907073606058713\n",
      "Recompensa por acortar distancias: +  0.6251626139737156\n",
      "Penalización por duración del episodio: -  0.3994436445398607\n",
      "Recompensa por acortar distancias: +  0.6251354553401905\n",
      "Penalización por duración del episodio: -  0.3998125160755885\n",
      "Recompensa por acortar distancias: +  0.6251079774433465\n",
      "Penalización por duración del episodio: -  0.3999403734604029\n",
      "steer input from model: -0.05 , throttle:  0.0\n",
      "reward: 0.22516760398294355\n",
      "Recompensa por acortar distancias: +  0.6250995573570964\n",
      "Penalización por duración del episodio: -  0.4002005300934243\n",
      "Recompensa por acortar distancias: +  0.6250884273060988\n",
      "Penalización por duración del episodio: -  0.4005993061497378\n",
      "Recompensa por acortar distancias: +  0.6250884273060988\n",
      "Penalización por duración del episodio: -  0.4009905400448016\n",
      "Recompensa por acortar distancias: +  0.6250735367449191\n",
      "Penalización por duración del episodio: -  0.40134512317558346\n",
      "Recompensa por acortar distancias: +  0.6250624957857802\n",
      "Penalización por duración del episodio: -  0.4017420582134597\n",
      "Step: 880, Mean Reward (últimos 10 pasos): 0.22332043945789337\n",
      "Recompensa por acortar distancias: +  0.6251137993830713\n",
      "Penalización por duración del episodio: -  0.4021120036778897\n",
      "Recompensa por acortar distancias: +  0.6250971045108331\n",
      "Penalización por duración del episodio: -  0.40248137830859393\n",
      "Recompensa por acortar distancias: +  0.6251056084287231\n",
      "Penalización por duración del episodio: -  0.40285588788420534\n",
      "Recompensa por acortar distancias: +  0.6251056084287231\n",
      "Penalización por duración del episodio: -  0.40323454403063413\n",
      "Recompensa por acortar distancias: +  0.6250573775642301\n",
      "Penalización por duración del episodio: -  0.40334555845341563\n",
      "Recompensa por acortar distancias: +  0.6250573775642301\n",
      "Penalización por duración del episodio: -  0.40348903296476196\n",
      "Recompensa por acortar distancias: +  0.6250124298852564\n",
      "Penalización por duración del episodio: -  0.403613545083964\n",
      "Recompensa por acortar distancias: +  0.6250124298852564\n",
      "Penalización por duración del episodio: -  0.403987127181352\n",
      "Recompensa por acortar distancias: +  0.6250124298852564\n",
      "Penalización por duración del episodio: -  0.4043690609669186\n",
      "Recompensa por acortar distancias: +  0.6249664909515567\n",
      "Penalización por duración del episodio: -  0.4044792973626595\n",
      "Step: 890, Mean Reward (últimos 10 pasos): 0.22048719227313995\n",
      "Recompensa por acortar distancias: +  0.6249322294691592\n",
      "Penalización por duración del episodio: -  0.4047557289404927\n",
      "Recompensa por acortar distancias: +  0.6249081210637306\n",
      "Penalización por duración del episodio: -  0.4051229503968093\n",
      "Recompensa por acortar distancias: +  0.6249081210637306\n",
      "Penalización por duración del episodio: -  0.4055110324778377\n",
      "Recompensa por acortar distancias: +  0.6249081210637306\n",
      "Penalización por duración del episodio: -  0.4056472233885138\n",
      "Recompensa por acortar distancias: +  0.6249277699638123\n",
      "Penalización por duración del episodio: -  0.4058893783162493\n",
      "steer input from model: -0.9 , throttle:  1.0\n",
      "reward: 0.21903839164756295\n",
      "Recompensa por acortar distancias: +  0.6249279320264078\n",
      "Penalización por duración del episodio: -  0.40625961201922905\n",
      "Recompensa por acortar distancias: +  0.6249279320264078\n",
      "Penalización por duración del episodio: -  0.40664168767354403\n",
      "Recompensa por acortar distancias: +  0.6248638983566537\n",
      "Penalización por duración del episodio: -  0.40701013498459004\n",
      "Recompensa por acortar distancias: +  0.6247686445230058\n",
      "Penalización por duración del episodio: -  0.40712681443833915\n",
      "Recompensa por acortar distancias: +  0.6247686445230058\n",
      "Penalización por duración del episodio: -  0.40739285811509585\n",
      "Step: 900, Mean Reward (últimos 10 pasos): 0.21737578511238098\n",
      "Recompensa por acortar distancias: +  0.6246870593666376\n",
      "Penalización por duración del episodio: -  0.4077689571816724\n",
      "Recompensa por acortar distancias: +  0.6246870593666376\n",
      "Penalización por duración del episodio: -  0.40813613952738365\n",
      "Recompensa por acortar distancias: +  0.6246870593666376\n",
      "Penalización por duración del episodio: -  0.40852584594015334\n",
      "Recompensa por acortar distancias: +  0.6243713057673764\n",
      "Penalización por duración del episodio: -  0.4089066949362918\n",
      "Recompensa por acortar distancias: +  0.6241720869642708\n",
      "Penalización por duración del episodio: -  0.4092957578915273\n",
      "Recompensa por acortar distancias: +  0.6240404891359181\n",
      "Penalización por duración del episodio: -  0.4094154130703583\n",
      "Recompensa por acortar distancias: +  0.6239601220020744\n",
      "Penalización por duración del episodio: -  0.40966955664729254\n",
      "Recompensa por acortar distancias: +  0.6238078493317223\n",
      "Penalización por duración del episodio: -  0.41004998290508554\n",
      "Recompensa por acortar distancias: +  0.6238078493317223\n",
      "Penalización por duración del episodio: -  0.4104254918661667\n",
      "Recompensa por acortar distancias: +  0.6238078493317223\n",
      "Penalización por duración del episodio: -  0.41051251101600184\n",
      "Step: 910, Mean Reward (últimos 10 pasos): 0.2132953405380249\n",
      "Recompensa por acortar distancias: +  0.6238078493317223\n",
      "Penalización por duración del episodio: -  0.41066970545790915\n",
      "Recompensa por acortar distancias: +  0.623058404658992\n",
      "Penalización por duración del episodio: -  0.4107528220944597\n",
      "Recompensa por acortar distancias: +  0.623058404658992\n",
      "Penalización por duración del episodio: -  0.41087957265396696\n",
      "Recompensa por acortar distancias: +  0.6228105366371917\n",
      "Penalización por duración del episodio: -  0.41117972615463794\n",
      "Recompensa por acortar distancias: +  0.6228105366371917\n",
      "Penalización por duración del episodio: -  0.4115628751400644\n",
      "steer input from model: 0.25 , throttle:  0.7\n",
      "reward: 0.21124766149712726\n",
      "Recompensa por acortar distancias: +  0.621964269314424\n",
      "Penalización por duración del episodio: -  0.411672868373946\n",
      "Recompensa por acortar distancias: +  0.6217913145655102\n",
      "Penalización por duración del episodio: -  0.41194903073029626\n",
      "Recompensa por acortar distancias: +  0.6216113246357521\n",
      "Penalización por duración del episodio: -  0.4120785550851886\n",
      "Recompensa por acortar distancias: +  0.6216019426408852\n",
      "Penalización por duración del episodio: -  0.4123065128542254\n",
      "Recompensa por acortar distancias: +  0.6216019426408852\n",
      "Penalización por duración del episodio: -  0.4126882711910245\n",
      "Step: 920, Mean Reward (últimos 10 pasos): 0.2089136689901352\n",
      "Recompensa por acortar distancias: +  0.6216019426408852\n",
      "Penalización por duración del episodio: -  0.41307238309367034\n",
      "Recompensa por acortar distancias: +  0.6212402880173411\n",
      "Penalización por duración del episodio: -  0.4131994342151793\n",
      "Recompensa por acortar distancias: +  0.6212402880173411\n",
      "Penalización por duración del episodio: -  0.4134619259622787\n",
      "Recompensa por acortar distancias: +  0.6211042189563961\n",
      "Penalización por duración del episodio: -  0.4138293281287394\n",
      "Recompensa por acortar distancias: +  0.620635784442227\n",
      "Penalización por duración del episodio: -  0.4139264410424227\n",
      "Recompensa por acortar distancias: +  0.620635784442227\n",
      "Penalización por duración del episodio: -  0.41420269215980815\n",
      "Recompensa por acortar distancias: +  0.6204920178870381\n",
      "Penalización por duración del episodio: -  0.41431748199938057\n",
      "Recompensa por acortar distancias: +  0.6204896879412101\n",
      "Penalización por duración del episodio: -  0.4145953776341528\n",
      "Recompensa por acortar distancias: +  0.6204871221872085\n",
      "Penalización por duración del episodio: -  0.41469626994336045\n",
      "Recompensa por acortar distancias: +  0.6204871221872085\n",
      "Penalización por duración del episodio: -  0.41496510603342757\n",
      "Step: 930, Mean Reward (últimos 10 pasos): 0.20552201569080353\n",
      "Recompensa por acortar distancias: +  0.6204871221872085\n",
      "Penalización por duración del episodio: -  0.41533311229960573\n",
      "Recompensa por acortar distancias: +  0.6204138409605852\n",
      "Penalización por duración del episodio: -  0.41571268511932\n",
      "Recompensa por acortar distancias: +  0.6204126674730298\n",
      "Penalización por duración del episodio: -  0.4161039895564794\n",
      "Recompensa por acortar distancias: +  0.6204121396839094\n",
      "Penalización por duración del episodio: -  0.4164887364363792\n",
      "Recompensa por acortar distancias: +  0.6204130717368442\n",
      "Penalización por duración del episodio: -  0.4168683979210324\n",
      "steer input from model: -0.9 , throttle:  0.0\n",
      "reward: 0.20354467381581182\n",
      "Recompensa por acortar distancias: +  0.6204136051402326\n",
      "Penalización por duración del episodio: -  0.41724067385488156\n",
      "Recompensa por acortar distancias: +  0.6204136051402326\n",
      "Penalización por duración del episodio: -  0.41762283808115624\n",
      "Recompensa por acortar distancias: +  0.6204136051402326\n",
      "Penalización por duración del episodio: -  0.417999144503225\n",
      "Recompensa por acortar distancias: +  0.6204127236207918\n",
      "Penalización por duración del episodio: -  0.41807672931753825\n",
      "Recompensa por acortar distancias: +  0.6204127236207918\n",
      "Penalización por duración del episodio: -  0.41837168254014784\n",
      "Step: 940, Mean Reward (últimos 10 pasos): 0.20204104483127594\n",
      "Recompensa por acortar distancias: +  0.6204127236207918\n",
      "Penalización por duración del episodio: -  0.4187514166607836\n",
      "Recompensa por acortar distancias: +  0.620356366490036\n",
      "Penalización por duración del episodio: -  0.4188555680931304\n",
      "Recompensa por acortar distancias: +  0.620356366490036\n",
      "Penalización por duración del episodio: -  0.41897331370847407\n",
      "Recompensa por acortar distancias: +  0.6202897803743013\n",
      "Penalización por duración del episodio: -  0.4191185235670093\n",
      "Recompensa por acortar distancias: +  0.6202761683523141\n",
      "Penalización por duración del episodio: -  0.4192160944931488\n",
      "Recompensa por acortar distancias: +  0.6202761683523141\n",
      "Penalización por duración del episodio: -  0.41948094178465023\n",
      "Recompensa por acortar distancias: +  0.6202414916574566\n",
      "Penalización por duración del episodio: -  0.4198611069206056\n",
      "Recompensa por acortar distancias: +  0.6202414916574566\n",
      "Penalización por duración del episodio: -  0.42022965669258383\n",
      "Recompensa por acortar distancias: +  0.6202414916574566\n",
      "Penalización por duración del episodio: -  0.4206179454852772\n",
      "Recompensa por acortar distancias: +  0.6202613263156559\n",
      "Penalización por duración del episodio: -  0.4210068439538397\n",
      "Step: 950, Mean Reward (últimos 10 pasos): 0.19925448298454285\n",
      "Recompensa por acortar distancias: +  0.6202623764406656\n",
      "Penalización por duración del episodio: -  0.4214101350840496\n",
      "Recompensa por acortar distancias: +  0.6202628930792946\n",
      "Penalización por duración del episodio: -  0.42179186560678955\n",
      "Recompensa por acortar distancias: +  0.6202637971962393\n",
      "Penalización por duración del episodio: -  0.42217193897788136\n",
      "Recompensa por acortar distancias: +  0.6202637971962393\n",
      "Penalización por duración del episodio: -  0.4225419647517471\n",
      "Recompensa por acortar distancias: +  0.6202637971962393\n",
      "Penalización por duración del episodio: -  0.4229235637956385\n",
      "steer input from model: 0.0 , throttle:  1.0\n",
      "reward: 0.19734023340060075\n",
      "Recompensa por acortar distancias: +  0.6202140021338391\n",
      "Penalización por duración del episodio: -  0.42330289764770374\n",
      "Recompensa por acortar distancias: +  0.6202140021338391\n",
      "Penalización por duración del episodio: -  0.4234183749213861\n",
      "Recompensa por acortar distancias: +  0.6202130923550083\n",
      "Penalización por duración del episodio: -  0.4236913221582596\n",
      "Recompensa por acortar distancias: +  0.6202176580883999\n",
      "Penalización por duración del episodio: -  0.4238468546379856\n",
      "Recompensa por acortar distancias: +  0.6201883651414293\n",
      "Penalización por duración del episodio: -  0.42409729274670005\n",
      "Step: 960, Mean Reward (últimos 10 pasos): 0.19609107077121735\n",
      "Recompensa por acortar distancias: +  0.6201990412191173\n",
      "Penalización por duración del episodio: -  0.42448511751786155\n",
      "Recompensa por acortar distancias: +  0.620185804213335\n",
      "Penalización por duración del episodio: -  0.4248824965851299\n",
      "Recompensa por acortar distancias: +  0.620185804213335\n",
      "Penalización por duración del episodio: -  0.4252587438512003\n",
      "Recompensa por acortar distancias: +  0.6202121938071856\n",
      "Penalización por duración del episodio: -  0.42564175149441885\n",
      "Recompensa por acortar distancias: +  0.6202121938071856\n",
      "Penalización por duración del episodio: -  0.426014698407231\n",
      "Recompensa por acortar distancias: +  0.620130905516166\n",
      "Penalización por duración del episodio: -  0.4263945521075857\n",
      "Recompensa por acortar distancias: +  0.6200844680853742\n",
      "Penalización por duración del episodio: -  0.42650749646532843\n",
      "Recompensa por acortar distancias: +  0.6200844680853742\n",
      "Penalización por duración del episodio: -  0.426596455457667\n",
      "Recompensa por acortar distancias: +  0.6200842658856573\n",
      "Penalización por duración del episodio: -  0.4267793804203177\n",
      "Recompensa por acortar distancias: +  0.6200857149827073\n",
      "Penalización por duración del episodio: -  0.42715912266765255\n",
      "Step: 970, Mean Reward (últimos 10 pasos): 0.1929265856742859\n",
      "Recompensa por acortar distancias: +  0.6200857149827073\n",
      "Penalización por duración del episodio: -  0.42754409751325423\n",
      "Recompensa por acortar distancias: +  0.6200857149827073\n",
      "Penalización por duración del episodio: -  0.42762636554884725\n",
      "Recompensa por acortar distancias: +  0.6200195205166416\n",
      "Penalización por duración del episodio: -  0.4279202826451803\n",
      "Recompensa por acortar distancias: +  0.6200193576227575\n",
      "Penalización por duración del episodio: -  0.4283029494636674\n",
      "Recompensa por acortar distancias: +  0.6200193576227575\n",
      "Penalización por duración del episodio: -  0.42867544843133637\n",
      "steer input from model: -0.1 , throttle:  0.0\n",
      "reward: 0.19134390919142114\n",
      "Recompensa por acortar distancias: +  0.6199990518458393\n",
      "Penalización por duración del episodio: -  0.4287982623787779\n",
      "Recompensa por acortar distancias: +  0.619999006908661\n",
      "Penalización por duración del episodio: -  0.42904765444633475\n",
      "Recompensa por acortar distancias: +  0.6199993776403199\n",
      "Penalización por duración del episodio: -  0.4294123290189107\n",
      "Recompensa por acortar distancias: +  0.6199993776403199\n",
      "Penalización por duración del episodio: -  0.42979088704643076\n",
      "Recompensa por acortar distancias: +  0.6199993776403199\n",
      "Penalización por duración del episodio: -  0.43017574544660486\n",
      "Step: 980, Mean Reward (últimos 10 pasos): 0.18982362747192383\n",
      "Recompensa por acortar distancias: +  0.6199045275614379\n",
      "Penalización por duración del episodio: -  0.43055758428802626\n",
      "Recompensa por acortar distancias: +  0.6199045275614379\n",
      "Penalización por duración del episodio: -  0.43095128698748714\n",
      "Recompensa por acortar distancias: +  0.6198168596333365\n",
      "Penalización por duración del episodio: -  0.43133051531775496\n",
      "Recompensa por acortar distancias: +  0.6197843691104569\n",
      "Penalización por duración del episodio: -  0.431712824870621\n",
      "Recompensa por acortar distancias: +  0.6197327629875085\n",
      "Penalización por duración del episodio: -  0.4320929692041714\n",
      "Recompensa por acortar distancias: +  0.6197327629875085\n",
      "Penalización por duración del episodio: -  0.43246499525418913\n",
      "Recompensa por acortar distancias: +  0.6197327629875085\n",
      "Penalización por duración del episodio: -  0.4328702135920374\n",
      "Recompensa por acortar distancias: +  0.6194440278331462\n",
      "Penalización por duración del episodio: -  0.43295850272651043\n",
      "Recompensa por acortar distancias: +  0.6194440278331462\n",
      "Penalización por duración del episodio: -  0.433255096153271\n",
      "Recompensa por acortar distancias: +  0.6193009635733376\n",
      "Penalización por duración del episodio: -  0.4333324031722596\n",
      "Step: 990, Mean Reward (últimos 10 pasos): 0.1859685629606247\n",
      "Recompensa por acortar distancias: +  0.6193009635733376\n",
      "Penalización por duración del episodio: -  0.4334667980673841\n",
      "Recompensa por acortar distancias: +  0.6191988448509693\n",
      "Penalización por duración del episodio: -  0.4336063086229663\n",
      "Recompensa por acortar distancias: +  0.6191544548275677\n",
      "Penalización por duración del episodio: -  0.4340412962907487\n",
      "Recompensa por acortar distancias: +  0.6190638246359275\n",
      "Penalización por duración del episodio: -  0.4344302184505308\n",
      "Recompensa por acortar distancias: +  0.6190638246359275\n",
      "Penalización por duración del episodio: -  0.4348028391879824\n",
      "steer input from model: 0.0 , throttle:  1.0\n",
      "reward: 0.18426098544794506\n",
      "Recompensa por acortar distancias: +  0.6190638246359275\n",
      "Penalización por duración del episodio: -  0.4348977944874646\n",
      "Recompensa por acortar distancias: +  0.6190638246359275\n",
      "Penalización por duración del episodio: -  0.4350445609714308\n",
      "Recompensa por acortar distancias: +  0.6189567275150454\n",
      "Penalización por duración del episodio: -  0.43518990306272864\n",
      "Recompensa por acortar distancias: +  0.6189567275150454\n",
      "Penalización por duración del episodio: -  0.43533130614036025\n",
      "Recompensa por acortar distancias: +  0.618956783745898\n",
      "Penalización por duración del episodio: -  0.43557960744197927\n",
      "Step: 1000, Mean Reward (últimos 10 pasos): 0.18337717652320862\n",
      "Recompensa por acortar distancias: +  0.618956783745898\n",
      "Penalización por duración del episodio: -  0.4359550102410726\n",
      "Recompensa por acortar distancias: +  0.6189558221978781\n",
      "Penalización por duración del episodio: -  0.43634627191673947\n",
      "Recompensa por acortar distancias: +  0.6189561933217859\n",
      "Penalización por duración del episodio: -  0.436722563198038\n",
      "Recompensa por acortar distancias: +  0.6189563957529497\n",
      "Penalización por duración del episodio: -  0.43708460229379625\n",
      "Recompensa por acortar distancias: +  0.6189563957529497\n",
      "Penalización por duración del episodio: -  0.437469942578652\n",
      "Recompensa por acortar distancias: +  0.6189551586729699\n",
      "Penalización por duración del episodio: -  0.43758646946503776\n",
      "Recompensa por acortar distancias: +  0.6189544895245193\n",
      "Penalización por duración del episodio: -  0.43785302858898006\n",
      "Recompensa por acortar distancias: +  0.6189544895245193\n",
      "Penalización por duración del episodio: -  0.4379572303082272\n",
      "Recompensa por acortar distancias: +  0.6189544895245193\n",
      "Penalización por duración del episodio: -  0.43824536866147534\n",
      "Recompensa por acortar distancias: +  0.6189549674877444\n",
      "Penalización por duración del episodio: -  0.43835694587480184\n",
      "Step: 1010, Mean Reward (últimos 10 pasos): 0.18059802055358887\n",
      "Recompensa por acortar distancias: +  0.6189551924115353\n",
      "Penalización por duración del episodio: -  0.4386242247215002\n",
      "Recompensa por acortar distancias: +  0.6189558896749626\n",
      "Penalización por duración del episodio: -  0.4387343670556811\n",
      "Recompensa por acortar distancias: +  0.6189558896749626\n",
      "Penalización por duración del episodio: -  0.4388478209691067\n",
      "Recompensa por acortar distancias: +  0.618955855936421\n",
      "Penalización por duración del episodio: -  0.4389609054909353\n",
      "Recompensa por acortar distancias: +  0.6189562720450211\n",
      "Penalización por duración del episodio: -  0.4394028824042985\n",
      "steer input from model: 0.25 , throttle:  0.0\n",
      "reward: 0.17955338964072265\n",
      "Recompensa por acortar distancias: +  0.6189562720450211\n",
      "Penalización por duración del episodio: -  0.43979221177903294\n",
      "Recompensa por acortar distancias: +  0.6189562720450211\n",
      "Penalización por duración del episodio: -  0.43989977411939335\n",
      "Recompensa por acortar distancias: +  0.6189559965136704\n",
      "Penalización por duración del episodio: -  0.440184599830857\n",
      "Recompensa por acortar distancias: +  0.6189557041129694\n",
      "Penalización por duración del episodio: -  0.4405810585162131\n",
      "Recompensa por acortar distancias: +  0.6189427428029518\n",
      "Penalización por duración del episodio: -  0.4409618709948523\n",
      "Step: 1020, Mean Reward (últimos 10 pasos): 0.17798087000846863\n",
      "Recompensa por acortar distancias: +  0.6189151158096692\n",
      "Penalización por duración del episodio: -  0.44134853733288154\n",
      "Recompensa por acortar distancias: +  0.6188794014523263\n",
      "Penalización por duración del episodio: -  0.44173358151200287\n",
      "Recompensa por acortar distancias: +  0.6188794351934691\n",
      "Penalización por duración del episodio: -  0.4421154026364922\n",
      "Recompensa por acortar distancias: +  0.6188794351934691\n",
      "Penalización por duración del episodio: -  0.44250493833360816\n",
      "Recompensa por acortar distancias: +  0.6188772588874064\n",
      "Penalización por duración del episodio: -  0.44287663197821076\n",
      "Recompensa por acortar distancias: +  0.6188772588874064\n",
      "Penalización por duración del episodio: -  0.44324558897641525\n",
      "Recompensa por acortar distancias: +  0.6188780011938868\n",
      "Penalización por duración del episodio: -  0.44339574537318566\n",
      "Recompensa por acortar distancias: +  0.6188782823704388\n",
      "Penalización por duración del episodio: -  0.4434946530182986\n",
      "Recompensa por acortar distancias: +  0.6188782823704388\n",
      "Penalización por duración del episodio: -  0.4436294085788765\n",
      "Recompensa por acortar distancias: +  0.6188827474434044\n",
      "Penalización por duración del episodio: -  0.44401587932124864\n",
      "Step: 1030, Mean Reward (últimos 10 pasos): 0.17486687004566193\n",
      "Recompensa por acortar distancias: +  0.6188465932714478\n",
      "Penalización por duración del episodio: -  0.4443930578789366\n",
      "Recompensa por acortar distancias: +  0.6188465932714478\n",
      "Penalización por duración del episodio: -  0.4447812517485697\n",
      "Recompensa por acortar distancias: +  0.6188465932714478\n",
      "Penalización por duración del episodio: -  0.44491880601233125\n",
      "Recompensa por acortar distancias: +  0.6188442031918825\n",
      "Penalización por duración del episodio: -  0.4451676168325902\n",
      "Recompensa por acortar distancias: +  0.6188440007378195\n",
      "Penalización por duración del episodio: -  0.44527434764075124\n",
      "steer input from model: 0.05 , throttle:  0.0\n",
      "reward: 0.1735696530970683\n",
      "Recompensa por acortar distancias: +  0.6188440007378195\n",
      "Penalización por duración del episodio: -  0.44554221565280605\n",
      "Recompensa por acortar distancias: +  0.6188440007378195\n",
      "Penalización por duración del episodio: -  0.445620150267154\n",
      "Recompensa por acortar distancias: +  0.618853426055394\n",
      "Penalización por duración del episodio: -  0.44593537331012534\n",
      "Recompensa por acortar distancias: +  0.6188149650232685\n",
      "Penalización por duración del episodio: -  0.4463182114316267\n",
      "Recompensa por acortar distancias: +  0.6187947469361884\n",
      "Penalización por duración del episodio: -  0.44670933951365127\n",
      "Step: 1040, Mean Reward (últimos 10 pasos): 0.17208540439605713\n",
      "Recompensa por acortar distancias: +  0.6187685387335153\n",
      "Penalización por duración del episodio: -  0.4470876734563948\n",
      "Recompensa por acortar distancias: +  0.6187685387335153\n",
      "Penalización por duración del episodio: -  0.4474715212565936\n",
      "Recompensa por acortar distancias: +  0.6187372960775054\n",
      "Penalización por duración del episodio: -  0.4478488521520924\n",
      "Recompensa por acortar distancias: +  0.6187372960775054\n",
      "Penalización por duración del episodio: -  0.44822289387077124\n",
      "Recompensa por acortar distancias: +  0.6187078241566093\n",
      "Penalización por duración del episodio: -  0.4483403736754486\n",
      "Recompensa por acortar distancias: +  0.6187080603854049\n",
      "Penalización por duración del episodio: -  0.4485972359749259\n",
      "Recompensa por acortar distancias: +  0.6187082347447181\n",
      "Penalización por duración del episodio: -  0.4486861065675424\n",
      "Recompensa por acortar distancias: +  0.6187082347447181\n",
      "Penalización por duración del episodio: -  0.44897959915894176\n",
      "Recompensa por acortar distancias: +  0.6187082572426917\n",
      "Penalización por duración del episodio: -  0.4490572351708315\n",
      "Recompensa por acortar distancias: +  0.6187082572426917\n",
      "Penalización por duración del episodio: -  0.44935855385143714\n",
      "Step: 1050, Mean Reward (últimos 10 pasos): 0.16934970021247864\n",
      "Recompensa por acortar distancias: +  0.6187082572426917\n",
      "Penalización por duración del episodio: -  0.4497483588845464\n",
      "Recompensa por acortar distancias: +  0.6187082572426917\n",
      "Penalización por duración del episodio: -  0.45014664074549615\n",
      "Recompensa por acortar distancias: +  0.618706401158152\n",
      "Penalización por duración del episodio: -  0.45054678077212945\n",
      "Recompensa por acortar distancias: +  0.618707042351385\n",
      "Penalización por duración del episodio: -  0.4506409986658171\n",
      "Recompensa por acortar distancias: +  0.618707042351385\n",
      "Penalización por duración del episodio: -  0.4507738115934902\n",
      "steer input from model: -0.9 , throttle:  0.3\n",
      "reward: 0.16793323075789474\n",
      "Recompensa por acortar distancias: +  0.6187068117468488\n",
      "Penalización por duración del episodio: -  0.45094022574308307\n",
      "Recompensa por acortar distancias: +  0.6187069467348765\n",
      "Penalización por duración del episodio: -  0.45107575820293394\n",
      "Recompensa por acortar distancias: +  0.618714044829496\n",
      "Penalización por duración del episodio: -  0.4513235476944828\n",
      "Recompensa por acortar distancias: +  0.6186822998668543\n",
      "Penalización por duración del episodio: -  0.45170502015147646\n",
      "Recompensa por acortar distancias: +  0.6186822998668543\n",
      "Penalización por duración del episodio: -  0.4520850847491481\n",
      "Step: 1060, Mean Reward (últimos 10 pasos): 0.16659721732139587\n",
      "Recompensa por acortar distancias: +  0.6186490464373673\n",
      "Penalización por duración del episodio: -  0.45247551816918347\n",
      "Recompensa por acortar distancias: +  0.6186217318953356\n",
      "Penalización por duración del episodio: -  0.45287048796935586\n",
      "Recompensa por acortar distancias: +  0.6185637141291593\n",
      "Penalización por duración del episodio: -  0.4532484537449298\n",
      "Recompensa por acortar distancias: +  0.6185173154821072\n",
      "Penalización por duración del episodio: -  0.4533855015362383\n",
      "Recompensa por acortar distancias: +  0.6184929058203047\n",
      "Penalización por duración del episodio: -  0.4536401355180591\n",
      "Recompensa por acortar distancias: +  0.6184218055437524\n",
      "Penalización por duración del episodio: -  0.45377693161041865\n",
      "Recompensa por acortar distancias: +  0.618420882860819\n",
      "Penalización por duración del episodio: -  0.45402300366824944\n",
      "Recompensa por acortar distancias: +  0.618420882860819\n",
      "Penalización por duración del episodio: -  0.4544128892543173\n",
      "Recompensa por acortar distancias: +  0.618420882860819\n",
      "Penalización por duración del episodio: -  0.45479193539761253\n",
      "Recompensa por acortar distancias: +  0.6184279492400334\n",
      "Penalización por duración del episodio: -  0.45491920622696763\n",
      "Step: 1070, Mean Reward (últimos 10 pasos): 0.16350874304771423\n",
      "Recompensa por acortar distancias: +  0.6183950586443224\n",
      "Penalización por duración del episodio: -  0.4551787793916285\n",
      "Recompensa por acortar distancias: +  0.6183950586443224\n",
      "Penalización por duración del episodio: -  0.45558201032068973\n",
      "Recompensa por acortar distancias: +  0.6183357054198094\n",
      "Penalización por duración del episodio: -  0.45570375266317004\n",
      "Recompensa por acortar distancias: +  0.6182955757093922\n",
      "Penalización por duración del episodio: -  0.4558082434763226\n",
      "Recompensa por acortar distancias: +  0.6182923571601536\n",
      "Penalización por duración del episodio: -  0.45597253651671243\n",
      "steer input from model: 0.1 , throttle:  0.3\n",
      "reward: 0.1623198206434412\n",
      "Recompensa por acortar distancias: +  0.6182655673989861\n",
      "Penalización por duración del episodio: -  0.4560830227670586\n",
      "Recompensa por acortar distancias: +  0.618265556144997\n",
      "Penalización por duración del episodio: -  0.4562080694827882\n",
      "Recompensa por acortar distancias: +  0.618265556144997\n",
      "Penalización por duración del episodio: -  0.45636544147891095\n",
      "Recompensa por acortar distancias: +  0.6182337406105434\n",
      "Penalización por duración del episodio: -  0.4564437640014504\n",
      "Recompensa por acortar distancias: +  0.6182337406105434\n",
      "Penalización por duración del episodio: -  0.4567445162041928\n",
      "Step: 1080, Mean Reward (últimos 10 pasos): 0.16148921847343445\n",
      "Recompensa por acortar distancias: +  0.6182337406105434\n",
      "Penalización por duración del episodio: -  0.457124919029981\n",
      "Recompensa por acortar distancias: +  0.6182486074934243\n",
      "Penalización por duración del episodio: -  0.4575021823815787\n",
      "Recompensa por acortar distancias: +  0.6182487594248465\n",
      "Penalización por duración del episodio: -  0.4579021256332451\n",
      "Recompensa por acortar distancias: +  0.618218063180768\n",
      "Penalización por duración del episodio: -  0.4583001284410569\n",
      "Recompensa por acortar distancias: +  0.6182010124302602\n",
      "Penalización por duración del episodio: -  0.4585387804874785\n",
      "Recompensa por acortar distancias: +  0.618163876801304\n",
      "Penalización por duración del episodio: -  0.4586796437323956\n",
      "Recompensa por acortar distancias: +  0.6181667356016173\n",
      "Penalización por duración del episodio: -  0.458785863818299\n",
      "Recompensa por acortar distancias: +  0.6181325251294898\n",
      "Penalización por duración del episodio: -  0.45889787758660194\n",
      "Recompensa por acortar distancias: +  0.6181325251294898\n",
      "Penalización por duración del episodio: -  0.4590634934152347\n",
      "Recompensa por acortar distancias: +  0.6181325251294898\n",
      "Penalización por duración del episodio: -  0.4594637225508836\n",
      "Step: 1090, Mean Reward (últimos 10 pasos): 0.15866880118846893\n",
      "Recompensa por acortar distancias: +  0.6181325251294898\n",
      "Penalización por duración del episodio: -  0.4598456871127909\n",
      "Recompensa por acortar distancias: +  0.6181325251294898\n",
      "Penalización por duración del episodio: -  0.4600049521618044\n",
      "Recompensa por acortar distancias: +  0.6180819754511093\n",
      "Penalización por duración del episodio: -  0.46010857092133084\n",
      "Recompensa por acortar distancias: +  0.6180819754511093\n",
      "Penalización por duración del episodio: -  0.4606058359892742\n",
      "Recompensa por acortar distancias: +  0.6180484318352643\n",
      "Penalización por duración del episodio: -  0.46099005521289294\n",
      "steer input from model: -0.05 , throttle:  0.0\n",
      "reward: 0.15705837662237132\n",
      "Recompensa por acortar distancias: +  0.6180474806659899\n",
      "Penalización por duración del episodio: -  0.4613826512062626\n",
      "Recompensa por acortar distancias: +  0.6180476269997833\n",
      "Penalización por duración del episodio: -  0.4617648778703046\n",
      "Recompensa por acortar distancias: +  0.6180476269997833\n",
      "Penalización por duración del episodio: -  0.4621536625042582\n",
      "Recompensa por acortar distancias: +  0.6180466983426541\n",
      "Penalización por duración del episodio: -  0.4625549280683873\n",
      "Recompensa por acortar distancias: +  0.6180468503047888\n",
      "Penalización por duración del episodio: -  0.4629466569895037\n",
      "Step: 1100, Mean Reward (últimos 10 pasos): 0.15510019659996033\n",
      "Recompensa por acortar distancias: +  0.6180468503047888\n",
      "Penalización por duración del episodio: -  0.4633231719372525\n",
      "Recompensa por acortar distancias: +  0.6180468503047888\n",
      "Penalización por duración del episodio: -  0.46372734039716385\n",
      "Recompensa por acortar distancias: +  0.617977845863893\n",
      "Penalización por duración del episodio: -  0.4638143984125175\n",
      "Recompensa por acortar distancias: +  0.6179466572216226\n",
      "Penalización por duración del episodio: -  0.4641205627004135\n",
      "Recompensa por acortar distancias: +  0.6179466572216226\n",
      "Penalización por duración del episodio: -  0.4645162314504639\n",
      "Recompensa por acortar distancias: +  0.6179466572216226\n",
      "Penalización por duración del episodio: -  0.4646009014390948\n",
      "Recompensa por acortar distancias: +  0.6179466572216226\n",
      "Penalización por duración del episodio: -  0.4649010197817173\n",
      "Recompensa por acortar distancias: +  0.617860330368206\n",
      "Penalización por duración del episodio: -  0.46530777958316977\n",
      "Recompensa por acortar distancias: +  0.6178582193875344\n",
      "Penalización por duración del episodio: -  0.4657041147925402\n",
      "Recompensa por acortar distancias: +  0.6178053533517057\n",
      "Penalización por duración del episodio: -  0.4658185945345445\n",
      "Step: 1110, Mean Reward (últimos 10 pasos): 0.151986762881279\n",
      "Recompensa por acortar distancias: +  0.6178053533517057\n",
      "Penalización por duración del episodio: -  0.46608938069264516\n",
      "Recompensa por acortar distancias: +  0.6178058994212786\n",
      "Penalización por duración del episodio: -  0.4664863348574257\n",
      "Recompensa por acortar distancias: +  0.6178059557170938\n",
      "Penalización por duración del episodio: -  0.4668767147066962\n",
      "Recompensa por acortar distancias: +  0.6178059557170938\n",
      "Penalización por duración del episodio: -  0.46727102843023505\n",
      "Recompensa por acortar distancias: +  0.617803940324935\n",
      "Penalización por duración del episodio: -  0.4676546990916076\n",
      "steer input from model: -0.1 , throttle:  0.3\n",
      "reward: 0.1501492412333274\n",
      "Recompensa por acortar distancias: +  0.6178042218045304\n",
      "Penalización por duración del episodio: -  0.46805575335658817\n",
      "Recompensa por acortar distancias: +  0.617804852318537\n",
      "Penalización por duración del episodio: -  0.4684332741645528\n",
      "Recompensa por acortar distancias: +  0.6178103861878426\n",
      "Penalización por duración del episodio: -  0.46880908555404277\n",
      "Recompensa por acortar distancias: +  0.6177747392022389\n",
      "Penalización por duración del episodio: -  0.4691948069413766\n",
      "Recompensa por acortar distancias: +  0.6177747392022389\n",
      "Penalización por duración del episodio: -  0.4695721623066857\n",
      "Step: 1120, Mean Reward (últimos 10 pasos): 0.148202583193779\n",
      "Recompensa por acortar distancias: +  0.6177747392022389\n",
      "Penalización por duración del episodio: -  0.46971549380345495\n",
      "Recompensa por acortar distancias: +  0.6177747392022389\n",
      "Penalización por duración del episodio: -  0.46985905003179257\n",
      "Recompensa por acortar distancias: +  0.6176491708774753\n",
      "Penalización por duración del episodio: -  0.46997826731485814\n",
      "Recompensa por acortar distancias: +  0.6176491708774753\n",
      "Penalización por duración del episodio: -  0.4701056959318158\n",
      "Recompensa por acortar distancias: +  0.6176114854911334\n",
      "Penalización por duración del episodio: -  0.47021400381835166\n",
      "Recompensa por acortar distancias: +  0.6176114854911334\n",
      "Penalización por duración del episodio: -  0.47072697188711954\n",
      "Recompensa por acortar distancias: +  0.6176114854911334\n",
      "Penalización por duración del episodio: -  0.47088729048298045\n",
      "Recompensa por acortar distancias: +  0.6176114854911334\n",
      "Penalización por duración del episodio: -  0.4710363578920016\n",
      "Recompensa por acortar distancias: +  0.617629976450637\n",
      "Penalización por duración del episodio: -  0.47118632750849043\n",
      "Recompensa por acortar distancias: +  0.617629976450637\n",
      "Penalización por duración del episodio: -  0.47134812468576504\n",
      "Step: 1130, Mean Reward (últimos 10 pasos): 0.14628185331821442\n",
      "Recompensa por acortar distancias: +  0.617629976450637\n",
      "Penalización por duración del episodio: -  0.47153500539089327\n",
      "Recompensa por acortar distancias: +  0.6176290361451423\n",
      "Penalización por duración del episodio: -  0.47166615221974056\n",
      "Recompensa por acortar distancias: +  0.6176290361451423\n",
      "Penalización por duración del episodio: -  0.4718297436735907\n",
      "Recompensa por acortar distancias: +  0.6176290361451423\n",
      "Penalización por duración del episodio: -  0.4719793067546339\n",
      "Recompensa por acortar distancias: +  0.6176297681195555\n",
      "Penalización por duración del episodio: -  0.47211634332342056\n",
      "steer input from model: 0.05 , throttle:  0.0\n",
      "reward: 0.14551342479613494\n",
      "Recompensa por acortar distancias: +  0.6176297681195555\n",
      "Penalización por duración del episodio: -  0.4722405966935613\n",
      "Recompensa por acortar distancias: +  0.6176297681195555\n",
      "Penalización por duración del episodio: -  0.47270163746789623\n",
      "Recompensa por acortar distancias: +  0.6176297681195555\n",
      "Penalización por duración del episodio: -  0.4728386127541823\n",
      "Recompensa por acortar distancias: +  0.6176297681195555\n",
      "Penalización por duración del episodio: -  0.4729522122209551\n",
      "Recompensa por acortar distancias: +  0.6176297681195555\n",
      "Penalización por duración del episodio: -  0.47345979786716036\n",
      "Step: 1140, Mean Reward (últimos 10 pasos): 0.14416997134685516\n",
      "Recompensa por acortar distancias: +  0.6174281396824464\n",
      "Penalización por duración del episodio: -  0.4735834218984022\n",
      "Recompensa por acortar distancias: +  0.6174281396824464\n",
      "Penalización por duración del episodio: -  0.47369048331926394\n",
      "Recompensa por acortar distancias: +  0.6173511063361369\n",
      "Penalización por duración del episodio: -  0.47385918188360915\n",
      "Recompensa por acortar distancias: +  0.6173511063361369\n",
      "Penalización por duración del episodio: -  0.4739810092491546\n",
      "Recompensa por acortar distancias: +  0.6173511063361369\n",
      "Penalización por duración del episodio: -  0.4742455686603591\n",
      "Recompensa por acortar distancias: +  0.6173511063361369\n",
      "Penalización por duración del episodio: -  0.47462114239197495\n",
      "Recompensa por acortar distancias: +  0.6172383898110908\n",
      "Penalización por duración del episodio: -  0.4750090997262146\n",
      "Recompensa por acortar distancias: +  0.6172383898110908\n",
      "Penalización por duración del episodio: -  0.47540143378131283\n",
      "Recompensa por acortar distancias: +  0.6172383898110908\n",
      "Penalización por duración del episodio: -  0.4755009298105959\n",
      "Recompensa por acortar distancias: +  0.6172383898110908\n",
      "Penalización por duración del episodio: -  0.4757948150537999\n",
      "Step: 1150, Mean Reward (últimos 10 pasos): 0.14144358038902283\n",
      "Recompensa por acortar distancias: +  0.6172139545934663\n",
      "Penalización por duración del episodio: -  0.4759010919203274\n",
      "Recompensa por acortar distancias: +  0.6172139545934663\n",
      "Penalización por duración del episodio: -  0.4760257999494291\n",
      "Recompensa por acortar distancias: +  0.6171986949557982\n",
      "Penalización por duración del episodio: -  0.47612951249498214\n",
      "Recompensa por acortar distancias: +  0.6171986949557982\n",
      "Penalización por duración del episodio: -  0.4762658702683241\n",
      "Recompensa por acortar distancias: +  0.6171986949557982\n",
      "Penalización por duración del episodio: -  0.47656669767073223\n",
      "steer input from model: -0.1 , throttle:  1.0\n",
      "reward: 0.14063199728506592\n",
      "Recompensa por acortar distancias: +  0.6171986949557982\n",
      "Penalización por duración del episodio: -  0.4769587092907165\n",
      "Recompensa por acortar distancias: +  0.6172194522874476\n",
      "Penalización por duración del episodio: -  0.47734307608329757\n",
      "Recompensa por acortar distancias: +  0.6172194522874476\n",
      "Penalización por duración del episodio: -  0.4777436797713633\n",
      "Recompensa por acortar distancias: +  0.6172194522874476\n",
      "Penalización por duración del episodio: -  0.4781309504834924\n",
      "Recompensa por acortar distancias: +  0.6172191424796702\n",
      "Penalización por duración del episodio: -  0.4785126668938792\n",
      "Step: 1160, Mean Reward (últimos 10 pasos): 0.13870647549629211\n",
      "Recompensa por acortar distancias: +  0.6172192326055789\n",
      "Penalización por duración del episodio: -  0.47889118953432364\n",
      "Recompensa por acortar distancias: +  0.6172192326055789\n",
      "Penalización por duración del episodio: -  0.47927499641071003\n",
      "Recompensa por acortar distancias: +  0.6172176385023795\n",
      "Penalización por duración del episodio: -  0.4793886170039646\n",
      "Recompensa por acortar distancias: +  0.6172176779325244\n",
      "Penalización por duración del episodio: -  0.479662100584963\n",
      "Recompensa por acortar distancias: +  0.6172176779325244\n",
      "Penalización por duración del episodio: -  0.4800466583616683\n",
      "Recompensa por acortar distancias: +  0.6172176779325244\n",
      "Penalización por duración del episodio: -  0.4804355128434779\n",
      "Recompensa por acortar distancias: +  0.6172171371761171\n",
      "Penalización por duración del episodio: -  0.48058138181486726\n",
      "Recompensa por acortar distancias: +  0.6172171371761171\n",
      "Penalización por duración del episodio: -  0.4808195761077648\n",
      "Recompensa por acortar distancias: +  0.6172170076198514\n",
      "Penalización por duración del episodio: -  0.48092641583011214\n",
      "Recompensa por acortar distancias: +  0.6172170076198514\n",
      "Penalización por duración del episodio: -  0.48104852390636377\n",
      "Step: 1170, Mean Reward (últimos 10 pasos): 0.1361684799194336\n",
      "Recompensa por acortar distancias: +  0.6172170076198514\n",
      "Penalización por duración del episodio: -  0.4811538257874364\n",
      "Recompensa por acortar distancias: +  0.6172170076198514\n",
      "Penalización por duración del episodio: -  0.4812285297145799\n",
      "Recompensa por acortar distancias: +  0.6172170076198514\n",
      "Penalización por duración del episodio: -  0.48139708237479034\n",
      "Recompensa por acortar distancias: +  0.6172170076198514\n",
      "Penalización por duración del episodio: -  0.48151052657005433\n",
      "Recompensa por acortar distancias: +  0.6171383920604793\n",
      "Penalización por duración del episodio: -  0.48197515623596815\n",
      "steer input from model: -0.9 , throttle:  1.0\n",
      "reward: 0.13516323582451112\n",
      "Recompensa por acortar distancias: +  0.6171576184008902\n",
      "Penalización por duración del episodio: -  0.4823657845518944\n",
      "Recompensa por acortar distancias: +  0.6171576184008902\n",
      "Penalización por duración del episodio: -  0.48276384637840125\n",
      "Recompensa por acortar distancias: +  0.6170798038233892\n",
      "Penalización por duración del episodio: -  0.4831638650354159\n",
      "Recompensa por acortar distancias: +  0.6170605196623525\n",
      "Penalización por duración del episodio: -  0.4835598922593987\n",
      "Recompensa por acortar distancias: +  0.6170152964934942\n",
      "Penalización por duración del episodio: -  0.4836844513884729\n",
      "Step: 1180, Mean Reward (últimos 10 pasos): 0.13333085179328918\n",
      "Recompensa por acortar distancias: +  0.6170151218392329\n",
      "Penalización por duración del episodio: -  0.48380418367847094\n",
      "Recompensa por acortar distancias: +  0.6170151218392329\n",
      "Penalización por duración del episodio: -  0.48395003939807646\n",
      "Recompensa por acortar distancias: +  0.6170151218392329\n",
      "Penalización por duración del episodio: -  0.48434176621223113\n",
      "Recompensa por acortar distancias: +  0.6170151218392329\n",
      "Penalización por duración del episodio: -  0.48447225084118645\n",
      "Recompensa por acortar distancias: +  0.6170151218392329\n",
      "Penalización por duración del episodio: -  0.4846026839939421\n",
      "Recompensa por acortar distancias: +  0.6170151218392329\n",
      "Penalización por duración del episodio: -  0.48511672543813245\n",
      "Recompensa por acortar distancias: +  0.616733207423219\n",
      "Penalización por duración del episodio: -  0.4852244375267262\n",
      "Recompensa por acortar distancias: +  0.616733207423219\n",
      "Penalización por duración del episodio: -  0.4853804608023655\n",
      "Recompensa por acortar distancias: +  0.616733207423219\n",
      "Penalización por duración del episodio: -  0.4855244806944641\n",
      "Recompensa por acortar distancias: +  0.616733207423219\n",
      "Penalización por duración del episodio: -  0.48568281423117804\n",
      "Step: 1190, Mean Reward (últimos 10 pasos): 0.13105039298534393\n",
      "Recompensa por acortar distancias: +  0.616733207423219\n",
      "Penalización por duración del episodio: -  0.4859037689339045\n",
      "Recompensa por acortar distancias: +  0.6161656810233178\n",
      "Penalización por duración del episodio: -  0.4862865100102295\n",
      "Recompensa por acortar distancias: +  0.616033974297615\n",
      "Penalización por duración del episodio: -  0.48639854865192494\n",
      "Recompensa por acortar distancias: +  0.616026834715633\n",
      "Penalización por duración del episodio: -  0.4865386897061321\n",
      "Recompensa por acortar distancias: +  0.616026834715633\n",
      "Penalización por duración del episodio: -  0.48669205572493185\n",
      "steer input from model: 0.1 , throttle:  0.7\n",
      "reward: 0.12933477899070117\n",
      "Recompensa por acortar distancias: +  0.616026834715633\n",
      "Penalización por duración del episodio: -  0.48704390343547727\n",
      "Recompensa por acortar distancias: +  0.616026834715633\n",
      "Penalización por duración del episodio: -  0.48715695775220735\n",
      "Recompensa por acortar distancias: +  0.616026834715633\n",
      "Penalización por duración del episodio: -  0.48726930454754885\n",
      "Recompensa por acortar distancias: +  0.616026834715633\n",
      "Penalización por duración del episodio: -  0.48743868193565343\n",
      "Recompensa por acortar distancias: +  0.6160168076353358\n",
      "Penalización por duración del episodio: -  0.4876020875366129\n",
      "Step: 1200, Mean Reward (últimos 10 pasos): 0.12841472029685974\n",
      "Recompensa por acortar distancias: +  0.6160168076353358\n",
      "Penalización por duración del episodio: -  0.48781993004585983\n",
      "Recompensa por acortar distancias: +  0.6160166835651081\n",
      "Penalización por duración del episodio: -  0.4882119032808592\n",
      "Recompensa por acortar distancias: +  0.6160166835651081\n",
      "Penalización por duración del episodio: -  0.4885879371935532\n",
      "Recompensa por acortar distancias: +  0.6160160180972654\n",
      "Penalización por duración del episodio: -  0.48897874686789466\n",
      "Recompensa por acortar distancias: +  0.6159883162030312\n",
      "Penalización por duración del episodio: -  0.48909154802830396\n",
      "Recompensa por acortar distancias: +  0.6159883162030312\n",
      "Penalización por duración del episodio: -  0.48920914623772005\n",
      "Recompensa por acortar distancias: +  0.6159883162030312\n",
      "Penalización por duración del episodio: -  0.4893751703209741\n",
      "Recompensa por acortar distancias: +  0.6159883162030312\n",
      "Penalización por duración del episodio: -  0.4894562201440277\n",
      "Recompensa por acortar distancias: +  0.6159883162030312\n",
      "Penalización por duración del episodio: -  0.4897786256290494\n",
      "Recompensa por acortar distancias: +  0.6156515303046579\n",
      "Penalización por duración del episodio: -  0.4898869480246553\n",
      "Step: 1210, Mean Reward (últimos 10 pasos): 0.12576457858085632\n",
      "Recompensa por acortar distancias: +  0.6156515303046579\n",
      "Penalización por duración del episodio: -  0.4901605197515166\n",
      "Recompensa por acortar distancias: +  0.6155293491058711\n",
      "Penalización por duración del episodio: -  0.4905441592336449\n",
      "Recompensa por acortar distancias: +  0.6151501313181521\n",
      "Penalización por duración del episodio: -  0.4906688677230653\n",
      "Recompensa por acortar distancias: +  0.6151501313181521\n",
      "Penalización por duración del episodio: -  0.49092558733257396\n",
      "Recompensa por acortar distancias: +  0.6149113822343005\n",
      "Penalización por duración del episodio: -  0.49105830166666264\n",
      "steer input from model: -0.1 , throttle:  1.0\n",
      "reward: 0.12385308056763789\n",
      "Recompensa por acortar distancias: +  0.6147491927737203\n",
      "Penalización por duración del episodio: -  0.49132090372933523\n",
      "Recompensa por acortar distancias: +  0.6145613495236515\n",
      "Penalización por duración del episodio: -  0.49170291300461677\n",
      "Recompensa por acortar distancias: +  0.6145613495236515\n",
      "Penalización por duración del episodio: -  0.4918304442751484\n",
      "Recompensa por acortar distancias: +  0.6145613495236515\n",
      "Penalización por duración del episodio: -  0.4919688397285048\n",
      "Recompensa por acortar distancias: +  0.6145613495236515\n",
      "Penalización por duración del episodio: -  0.49246846187347243\n",
      "Step: 1220, Mean Reward (últimos 10 pasos): 0.12209288775920868\n",
      "Recompensa por acortar distancias: +  0.6131839065579611\n",
      "Penalización por duración del episodio: -  0.4925944975697516\n",
      "Recompensa por acortar distancias: +  0.6131839065579611\n",
      "Penalización por duración del episodio: -  0.49272621928610905\n",
      "Recompensa por acortar distancias: +  0.612861842400699\n",
      "Penalización por duración del episodio: -  0.492861821483416\n",
      "Recompensa por acortar distancias: +  0.612861842400699\n",
      "Penalización por duración del episodio: -  0.49297383189625216\n",
      "Recompensa por acortar distancias: +  0.612861842400699\n",
      "Penalización por duración del episodio: -  0.4932581934590733\n",
      "Recompensa por acortar distancias: +  0.612861842400699\n",
      "Penalización por duración del episodio: -  0.4936612425967973\n",
      "Recompensa por acortar distancias: +  0.6117049359351174\n",
      "Penalización por duración del episodio: -  0.4940559147838355\n",
      "Recompensa por acortar distancias: +  0.611490825964428\n",
      "Penalización por duración del episodio: -  0.4944400933369134\n",
      "Recompensa por acortar distancias: +  0.611490825964428\n",
      "Penalización por duración del episodio: -  0.49483420752757096\n",
      "Recompensa por acortar distancias: +  0.6111717418423068\n",
      "Penalización por duración del episodio: -  0.495209143157395\n",
      "Step: 1230, Mean Reward (últimos 10 pasos): 0.11596260219812393\n",
      "Recompensa por acortar distancias: +  0.6111681440537392\n",
      "Penalización por duración del episodio: -  0.49559824513813366\n",
      "Recompensa por acortar distancias: +  0.6111681440537392\n",
      "Penalización por duración del episodio: -  0.4957257417957419\n",
      "Recompensa por acortar distancias: +  0.6111611410793748\n",
      "Penalización por duración del episodio: -  0.49586321018206075\n",
      "Recompensa por acortar distancias: +  0.6111611410793748\n",
      "Penalización por duración del episodio: -  0.4960007030341596\n",
      "Recompensa por acortar distancias: +  0.6111611410793748\n",
      "Penalización por duración del episodio: -  0.4961716386794593\n",
      "steer input from model: -0.05 , throttle:  0.3\n",
      "reward: 0.11498950239991551\n",
      "Recompensa por acortar distancias: +  0.611159616963179\n",
      "Penalización por duración del episodio: -  0.4962848393387786\n",
      "Recompensa por acortar distancias: +  0.6111590957036096\n",
      "Penalización por duración del episodio: -  0.49678233535483207\n",
      "Recompensa por acortar distancias: +  0.6111590957036096\n",
      "Penalización por duración del episodio: -  0.4971711102977312\n",
      "Recompensa por acortar distancias: +  0.6111590957036096\n",
      "Penalización por duración del episodio: -  0.49729425568135277\n",
      "Recompensa por acortar distancias: +  0.6111590957036096\n",
      "Penalización por duración del episodio: -  0.4974058503226463\n",
      "Step: 1240, Mean Reward (últimos 10 pasos): 0.11375324428081512\n",
      "Recompensa por acortar distancias: +  0.6111590617084115\n",
      "Penalización por duración del episodio: -  0.4975570396272867\n",
      "Recompensa por acortar distancias: +  0.6111590617084115\n",
      "Penalización por duración del episodio: -  0.497952478648473\n",
      "Recompensa por acortar distancias: +  0.6111587897467874\n",
      "Penalización por duración del episodio: -  0.49835051300490446\n",
      "Recompensa por acortar distancias: +  0.611159514977631\n",
      "Penalización por duración del episodio: -  0.49845835459008137\n",
      "Recompensa por acortar distancias: +  0.611159514977631\n",
      "Penalización por duración del episodio: -  0.4985851385210842\n",
      "Recompensa por acortar distancias: +  0.6111609314427036\n",
      "Penalización por duración del episodio: -  0.4986973017128062\n",
      "Recompensa por acortar distancias: +  0.6111609314427036\n",
      "Penalización por duración del episodio: -  0.4991491862402714\n",
      "Recompensa por acortar distancias: +  0.6111620759451111\n",
      "Penalización por duración del episodio: -  0.499544400102823\n",
      "Recompensa por acortar distancias: +  0.6111620759451111\n",
      "Penalización por duración del episodio: -  0.49994118213680705\n",
      "Penalización por duración del episodio\n",
      "Step: 1250, Mean Reward (últimos 10 pasos): -10.0\n",
      "Recompensa por acortar distancias: +  0.9156966426304628\n",
      "Penalización por parar muy lejos: -  0.1659320430312731\n",
      "Penalización por duración del episodio: -  0.26905761455480987\n",
      "Recompensa por acortar distancias: +  0.9156966426304628\n",
      "Penalización por duración del episodio: -  0.2691545915020869\n",
      "Recompensa por acortar distancias: +  0.9156966426304628\n",
      "Penalización por duración del episodio: -  0.26924456345403364\n",
      "Recompensa por acortar distancias: +  0.9156966426304628\n",
      "Penalización por parar muy lejos: -  0.1659320430312731\n",
      "Penalización por duración del episodio: -  0.2696518790503868\n",
      "Recompensa por acortar distancias: +  0.9156960610296153\n",
      "Penalización por parar muy lejos: -  0.1659310003350935\n",
      "Penalización por duración del episodio: -  0.2697450508185239\n",
      "Recompensa por acortar distancias: +  0.9156959800469299\n",
      "Penalización por parar muy lejos: -  0.16593085514996583\n",
      "Penalización por duración del episodio: -  0.26980493922167326\n",
      "Recompensa por acortar distancias: +  0.9156959800469299\n",
      "Penalización por parar muy lejos: -  0.16593085514996583\n",
      "Penalización por duración del episodio: -  0.26996846206196595\n",
      "Recompensa por acortar distancias: +  0.9156959800469299\n",
      "Penalización por parar muy lejos: -  0.16593085514996583\n",
      "Penalización por duración del episodio: -  0.270271205280846\n",
      "Recompensa por acortar distancias: +  0.9156959800469299\n",
      "Penalización por duración del episodio: -  0.27057431744986027\n",
      "Recompensa por acortar distancias: +  0.9156959653227976\n",
      "Penalización por duración del episodio: -  0.2708842828859262\n",
      "Step: 1260, Mean Reward (últimos 10 pasos): 0.6448116898536682\n",
      "Recompensa por acortar distancias: +  0.9156960168572501\n",
      "Penalización por duración del episodio: -  0.27118702131711697\n",
      "Recompensa por acortar distancias: +  0.9156961125640147\n",
      "Penalización por duración del episodio: -  0.271497436834316\n",
      "Recompensa por acortar distancias: +  0.9156960757537324\n",
      "Penalización por duración del episodio: -  0.2715890800639687\n",
      "Recompensa por acortar distancias: +  0.9156962450809104\n",
      "Penalización por parar muy lejos: -  0.16593133030167126\n",
      "Penalización por duración del episodio: -  0.2718047294101312\n",
      "Recompensa por acortar distancias: +  0.9156962450809104\n",
      "Penalización por parar muy lejos: -  0.16593133030167126\n",
      "Penalización por duración del episodio: -  0.27211083736152325\n",
      "Recompensa por acortar distancias: +  0.9156962450809104\n",
      "Penalización por duración del episodio: -  0.2724188670314013\n",
      "Recompensa por acortar distancias: +  0.9156962450809104\n",
      "Penalización por duración del episodio: -  0.272509542195995\n",
      "Recompensa por acortar distancias: +  0.9156962450809104\n",
      "Penalización por duración del episodio: -  0.272637439198861\n",
      "Recompensa por acortar distancias: +  0.9156962450809104\n",
      "Penalización por parar muy lejos: -  0.16593133030167126\n",
      "Penalización por duración del episodio: -  0.27271444603836514\n",
      "Recompensa por acortar distancias: +  0.9156962450809104\n",
      "Penalización por parar muy lejos: -  0.16593133030167126\n",
      "Penalización por duración del episodio: -  0.2730557356964571\n",
      "steer input from model: 0.9 , throttle:  0.0\n",
      "reward: 0.47670917908278204\n",
      "Step: 1270, Mean Reward (últimos 10 pasos): 0.47670918703079224\n",
      "Recompensa por acortar distancias: +  0.9156962229947743\n",
      "Penalización por parar muy lejos: -  0.16593129070565418\n",
      "Penalización por duración del episodio: -  0.2731899374360774\n",
      "Recompensa por acortar distancias: +  0.9156962229947743\n",
      "Penalización por parar muy lejos: -  0.16593129070565418\n",
      "Penalización por duración del episodio: -  0.2733702773746044\n",
      "Recompensa por acortar distancias: +  0.9156962229947743\n",
      "Penalización por parar muy lejos: -  0.16593129070565418\n",
      "Penalización por duración del episodio: -  0.27368272270936717\n",
      "Recompensa por acortar distancias: +  0.9156963849596507\n",
      "Penalización por parar muy lejos: -  0.1659315810766219\n",
      "Penalización por duración del episodio: -  0.2737586243563231\n",
      "Recompensa por acortar distancias: +  0.9156963849596507\n",
      "Penalización por duración del episodio: -  0.27387282856739753\n",
      "Recompensa por acortar distancias: +  0.9156963849596507\n",
      "Penalización por parar muy lejos: -  0.1659315810766219\n",
      "Penalización por duración del episodio: -  0.27396492464843636\n",
      "Recompensa por acortar distancias: +  0.9156963849596507\n",
      "Penalización por duración del episodio: -  0.2742943274476434\n",
      "Recompensa por acortar distancias: +  0.9156963849596507\n",
      "Penalización por duración del episodio: -  0.2746077384834524\n",
      "Recompensa por acortar distancias: +  0.9156966573544877\n",
      "Penalización por duración del episodio: -  0.27472568780002204\n",
      "Recompensa por acortar distancias: +  0.9156967383365824\n",
      "Penalización por duración del episodio: -  0.27484662420782924\n",
      "Step: 1280, Mean Reward (últimos 10 pasos): 0.6408501267433167\n",
      "Recompensa por acortar distancias: +  0.9156967383365824\n",
      "Penalización por parar muy lejos: -  0.1659322146146916\n",
      "Penalización por duración del episodio: -  0.2749440093023932\n",
      "Recompensa por acortar distancias: +  0.9156967383365824\n",
      "Penalización por duración del episodio: -  0.27504749135993045\n",
      "Recompensa por acortar distancias: +  0.9156967383365824\n",
      "Penalización por duración del episodio: -  0.2752303053087644\n",
      "Recompensa por acortar distancias: +  0.9156967383365824\n",
      "Penalización por parar muy lejos: -  0.1659322146146916\n",
      "Penalización por duración del episodio: -  0.2755444701640239\n",
      "Recompensa por acortar distancias: +  0.9156969518344935\n",
      "Penalización por duración del episodio: -  0.2756439888434101\n",
      "Recompensa por acortar distancias: +  0.9156970033683983\n",
      "Penalización por parar muy lejos: -  0.16593268976951547\n",
      "Penalización por duración del episodio: -  0.2758647628815331\n",
      "Recompensa por acortar distancias: +  0.9156970033683983\n",
      "Penalización por duración del episodio: -  0.2761831602720528\n",
      "Recompensa por acortar distancias: +  0.9156970033683983\n",
      "Penalización por parar muy lejos: -  0.16593268976951547\n",
      "Penalización por duración del episodio: -  0.2764917450837318\n",
      "Recompensa por acortar distancias: +  0.9156971285220487\n",
      "Penalización por parar muy lejos: -  0.1659329141485612\n",
      "Penalización por duración del episodio: -  0.27681257976849455\n",
      "Recompensa por acortar distancias: +  0.9156971800558555\n",
      "Penalización por duración del episodio: -  0.27711991739763103\n",
      "steer input from model: 0.9 , throttle:  1.0\n",
      "reward: 0.6385772626582245\n",
      "Step: 1290, Mean Reward (últimos 10 pasos): 0.6385772824287415\n",
      "Recompensa por acortar distancias: +  0.9156971800558555\n",
      "Penalización por parar muy lejos: -  0.1659330065400036\n",
      "Penalización por duración del episodio: -  0.2772022507031453\n",
      "Recompensa por acortar distancias: +  0.9156971800558555\n",
      "Penalización por duración del episodio: -  0.2774500197839369\n",
      "Recompensa por acortar distancias: +  0.9156972683994581\n",
      "Penalización por duración del episodio: -  0.2775811101856989\n",
      "Recompensa por acortar distancias: +  0.9156972831233836\n",
      "Penalización por duración del episodio: -  0.27767723295213703\n",
      "Recompensa por acortar distancias: +  0.9156972831233836\n",
      "Penalización por parar muy lejos: -  0.16593319132301204\n",
      "Penalización por duración del episodio: -  0.2780792548531735\n",
      "Recompensa por acortar distancias: +  0.9156972831233836\n",
      "Penalización por parar muy lejos: -  0.16593319132301204\n",
      "Penalización por duración del episodio: -  0.2781682645075302\n",
      "Recompensa por acortar distancias: +  0.9156972831233836\n",
      "Penalización por parar muy lejos: -  0.16593319132301204\n",
      "Penalización por duración del episodio: -  0.27840315785326697\n",
      "Recompensa por acortar distancias: +  0.9156972831233836\n",
      "Penalización por parar muy lejos: -  0.16593319132301204\n",
      "Penalización por duración del episodio: -  0.27851735403955347\n",
      "Recompensa por acortar distancias: +  0.9156970328163313\n",
      "Penalización por duración del episodio: -  0.2787171886646109\n",
      "Recompensa por acortar distancias: +  0.9156970769882131\n",
      "Penalización por parar muy lejos: -  0.16593282175715998\n",
      "Penalización por duración del episodio: -  0.279031067404975\n",
      "Step: 1300, Mean Reward (últimos 10 pasos): 0.4707331955432892\n",
      "Recompensa por acortar distancias: +  0.9156970769882131\n",
      "Penalización por duración del episodio: -  0.2791465441391717\n",
      "Recompensa por acortar distancias: +  0.9156970769882131\n",
      "Penalización por duración del episodio: -  0.2792658795821096\n",
      "Recompensa por acortar distancias: +  0.9156970475402941\n",
      "Penalización por duración del episodio: -  0.279362672142318\n",
      "Recompensa por acortar distancias: +  0.9156970475402941\n",
      "Penalización por duración del episodio: -  0.27945894754858774\n",
      "Recompensa por acortar distancias: +  0.9156972242276673\n",
      "Penalización por parar muy lejos: -  0.16593308573270132\n",
      "Penalización por duración del episodio: -  0.279669997833066\n",
      "Recompensa por acortar distancias: +  0.9156972831233836\n",
      "Penalización por duración del episodio: -  0.27976270617469484\n",
      "Recompensa por acortar distancias: +  0.9156972831233836\n",
      "Penalización por duración del episodio: -  0.2799864844521884\n",
      "Recompensa por acortar distancias: +  0.9156972831233836\n",
      "Penalización por duración del episodio: -  0.28030059262474444\n",
      "Recompensa por acortar distancias: +  0.9156972831233836\n",
      "Penalización por duración del episodio: -  0.2804053928569997\n",
      "Recompensa por acortar distancias: +  0.9156971506079694\n",
      "Penalización por duración del episodio: -  0.28049224503691994\n",
      "steer input from model: 0.1 , throttle:  0.3\n",
      "reward: 0.6352049055710495\n",
      "Step: 1310, Mean Reward (últimos 10 pasos): 0.6352049112319946\n",
      "Recompensa por acortar distancias: +  0.9156971506079694\n",
      "Penalización por duración del episodio: -  0.28063154973863785\n",
      "Recompensa por acortar distancias: +  0.9156973125712279\n",
      "Penalización por parar muy lejos: -  0.16593324411818758\n",
      "Penalización por duración del episodio: -  0.2809480113372802\n",
      "Recompensa por acortar distancias: +  0.9156973125712279\n",
      "Penalización por duración del episodio: -  0.28103620882583397\n",
      "Recompensa por acortar distancias: +  0.9156974156386088\n",
      "Penalización por parar muy lejos: -  0.16593342890140797\n",
      "Penalización por duración del episodio: -  0.2812721561209187\n",
      "Recompensa por acortar distancias: +  0.9156974230005601\n",
      "Penalización por parar muy lejos: -  0.1659334421002157\n",
      "Penalización por duración del episodio: -  0.2813555273399668\n",
      "Recompensa por acortar distancias: +  0.9156974818961505\n",
      "Penalización por parar muy lejos: -  0.16593354769070812\n",
      "Penalización por duración del episodio: -  0.2814596564275147\n",
      "Recompensa por acortar distancias: +  0.9156975334297612\n",
      "Penalización por duración del episodio: -  0.2815945364479358\n",
      "Recompensa por acortar distancias: +  0.9156975334297612\n",
      "Penalización por parar muy lejos: -  0.16593364008243308\n",
      "Penalización por duración del episodio: -  0.28171115645343076\n",
      "Recompensa por acortar distancias: +  0.9156975334297612\n",
      "Penalización por duración del episodio: -  0.28190144086111585\n",
      "Recompensa por acortar distancias: +  0.9156975334297612\n",
      "Penalización por duración del episodio: -  0.28220837933237053\n",
      "Step: 1320, Mean Reward (últimos 10 pasos): 0.6334891319274902\n",
      "Recompensa por acortar distancias: +  0.9156975334297612\n",
      "Penalización por parar muy lejos: -  0.16593364008243308\n",
      "Penalización por duración del episodio: -  0.28229944977253923\n",
      "Recompensa por acortar distancias: +  0.9156975334297612\n",
      "Penalización por duración del episodio: -  0.28252832266953753\n",
      "Recompensa por acortar distancias: +  0.9156975039819871\n",
      "Penalización por parar muy lejos: -  0.16593358728715663\n",
      "Penalización por duración del episodio: -  0.2826312214059686\n",
      "Recompensa por acortar distancias: +  0.9156976070491556\n",
      "Penalización por duración del episodio: -  0.2828393744729757\n",
      "Recompensa por acortar distancias: +  0.9156976070491556\n",
      "Penalización por parar muy lejos: -  0.1659337720706831\n",
      "Penalización por duración del episodio: -  0.2831629740440463\n",
      "Recompensa por acortar distancias: +  0.9156976217730275\n",
      "Penalización por parar muy lejos: -  0.1659337984683432\n",
      "Penalización por duración del episodio: -  0.2832463024589695\n",
      "Recompensa por acortar distancias: +  0.9156976438588309\n",
      "Penalización por duración del episodio: -  0.28333955571099906\n",
      "Recompensa por acortar distancias: +  0.9156976438588309\n",
      "Penalización por parar muy lejos: -  0.16593383806483963\n",
      "Penalización por duración del episodio: -  0.2834508700924412\n",
      "Recompensa por acortar distancias: +  0.9156976217730275\n",
      "Penalización por parar muy lejos: -  0.1659337984683432\n",
      "Penalización por duración del episodio: -  0.28352617601257263\n",
      "Recompensa por acortar distancias: +  0.9156976438588309\n",
      "Penalización por duración del episodio: -  0.28378968684469214\n",
      "steer input from model: 0.0 , throttle:  0.3\n",
      "reward: 0.6319079570141388\n",
      "Step: 1330, Mean Reward (últimos 10 pasos): 0.6319079399108887\n",
      "Recompensa por acortar distancias: +  0.9156976217730275\n",
      "Penalización por parar muy lejos: -  0.1659337984683432\n",
      "Penalización por duración del episodio: -  0.2838879192928928\n",
      "Recompensa por acortar distancias: +  0.9156976217730275\n",
      "Penalización por parar muy lejos: -  0.1659337984683432\n",
      "Penalización por duración del episodio: -  0.2841125948472809\n",
      "Recompensa por acortar distancias: +  0.9156976217730275\n",
      "Penalización por parar muy lejos: -  0.1659337984683432\n",
      "Penalización por duración del episodio: -  0.2842271433980999\n",
      "Recompensa por acortar distancias: +  0.9156976217730275\n",
      "Penalización por parar muy lejos: -  0.1659337984683432\n",
      "Penalización por duración del episodio: -  0.28442706257230355\n",
      "Recompensa por acortar distancias: +  0.9156976217730275\n",
      "Penalización por parar muy lejos: -  0.1659337984683432\n",
      "Penalización por duración del episodio: -  0.2845147649708657\n",
      "Recompensa por acortar distancias: +  0.9156976217730275\n",
      "Penalización por parar muy lejos: -  0.1659337984683432\n",
      "Penalización por duración del episodio: -  0.2846146583864931\n",
      "Recompensa por acortar distancias: +  0.9156974671722563\n",
      "Penalización por parar muy lejos: -  0.16593352129307995\n",
      "Penalización por duración del episodio: -  0.28473292200630845\n",
      "Recompensa por acortar distancias: +  0.9156974598103085\n",
      "Penalización por parar muy lejos: -  0.16593350809426713\n",
      "Penalización por duración del episodio: -  0.28482129795752265\n",
      "Recompensa por acortar distancias: +  0.9156974598103085\n",
      "Penalización por parar muy lejos: -  0.16593350809426713\n",
      "Penalización por duración del episodio: -  0.28507645167886597\n",
      "Recompensa por acortar distancias: +  0.9156974598103085\n",
      "Penalización por duración del episodio: -  0.2853911525016726\n",
      "Step: 1340, Mean Reward (últimos 10 pasos): 0.6303063035011292\n",
      "Recompensa por acortar distancias: +  0.9156973641049325\n",
      "Penalización por duración del episodio: -  0.2857148395202264\n",
      "Recompensa por acortar distancias: +  0.9156974156386088\n",
      "Penalización por parar muy lejos: -  0.16593342890140797\n",
      "Penalización por duración del episodio: -  0.286038147825126\n",
      "Recompensa por acortar distancias: +  0.9156974156386088\n",
      "Penalización por parar muy lejos: -  0.16593342890140797\n",
      "Penalización por duración del episodio: -  0.28611962275224684\n",
      "Recompensa por acortar distancias: +  0.9156974156386088\n",
      "Penalización por parar muy lejos: -  0.16593342890140797\n",
      "Penalización por duración del episodio: -  0.28634985527708384\n",
      "Recompensa por acortar distancias: +  0.9156974156386088\n",
      "Penalización por parar muy lejos: -  0.16593342890140797\n",
      "Penalización por duración del episodio: -  0.2866663244942548\n",
      "Recompensa por acortar distancias: +  0.9156970843501915\n",
      "Penalización por parar muy lejos: -  0.1659328349559291\n",
      "Penalización por duración del episodio: -  0.28672968439481245\n",
      "Recompensa por acortar distancias: +  0.9156970843501915\n",
      "Penalización por parar muy lejos: -  0.1659328349559291\n",
      "Penalización por duración del episodio: -  0.28698491035955265\n",
      "Recompensa por acortar distancias: +  0.9156970843501915\n",
      "Penalización por duración del episodio: -  0.2870683177790042\n",
      "Recompensa por acortar distancias: +  0.9156970843501915\n",
      "Penalización por parar muy lejos: -  0.1659328349559291\n",
      "Penalización por duración del episodio: -  0.28715289631504\n",
      "Recompensa por acortar distancias: +  0.9156970843501915\n",
      "Penalización por duración del episodio: -  0.2872854010345349\n",
      "steer input from model: 0.9 , throttle:  0.7\n",
      "reward: 0.6284116833156566\n",
      "Step: 1350, Mean Reward (últimos 10 pasos): 0.6284117102622986\n",
      "Recompensa por acortar distancias: +  0.9156969812824427\n",
      "Penalización por duración del episodio: -  0.28737464153457665\n",
      "Recompensa por acortar distancias: +  0.9156969812824427\n",
      "Penalización por parar muy lejos: -  0.16593265017323852\n",
      "Penalización por duración del episodio: -  0.2874527350465505\n",
      "Recompensa por acortar distancias: +  0.9156971358840228\n",
      "Penalización por parar muy lejos: -  0.16593292734733617\n",
      "Penalización por duración del episodio: -  0.28763490476236625\n",
      "Recompensa por acortar distancias: +  0.915697194779795\n",
      "Penalización por parar muy lejos: -  0.16593303293756617\n",
      "Penalización por duración del episodio: -  0.2877686855708679\n",
      "Recompensa por acortar distancias: +  0.9156971506079694\n",
      "Penalización por duración del episodio: -  0.28795003113645445\n",
      "Recompensa por acortar distancias: +  0.9156971506079694\n",
      "Penalización por duración del episodio: -  0.28802193522880576\n",
      "Recompensa por acortar distancias: +  0.9156971506079694\n",
      "Penalización por duración del episodio: -  0.2881331416681348\n",
      "Recompensa por acortar distancias: +  0.9156971506079694\n",
      "Penalización por duración del episodio: -  0.2882763741587839\n",
      "Recompensa por acortar distancias: +  0.9156971506079694\n",
      "Penalización por duración del episodio: -  0.2883683518893973\n",
      "Recompensa por acortar distancias: +  0.9156971506079694\n",
      "Penalización por parar muy lejos: -  0.16593295374488862\n",
      "Penalización por duración del episodio: -  0.2885070045605149\n",
      "Step: 1360, Mean Reward (últimos 10 pasos): 0.4612571895122528\n",
      "Recompensa por acortar distancias: +  0.9156971506079694\n",
      "Penalización por duración del episodio: -  0.2889228133109114\n",
      "Recompensa por acortar distancias: +  0.9156969960064137\n",
      "Penalización por duración del episodio: -  0.2889882677859882\n",
      "Recompensa por acortar distancias: +  0.9156969960064137\n",
      "Penalización por parar muy lejos: -  0.16593267657075564\n",
      "Penalización por duración del episodio: -  0.28925072754940906\n",
      "Recompensa por acortar distancias: +  0.9156969960064137\n",
      "Penalización por duración del episodio: -  0.2893623430765038\n",
      "Recompensa por acortar distancias: +  0.9156969960064137\n",
      "Penalización por duración del episodio: -  0.28957404098261136\n",
      "Recompensa por acortar distancias: +  0.9156971137980985\n",
      "Penalización por parar muy lejos: -  0.1659328877510138\n",
      "Penalización por duración del episodio: -  0.2898916002950315\n",
      "Recompensa por acortar distancias: +  0.9156971800558555\n",
      "Penalización por duración del episodio: -  0.2902091691513328\n",
      "Recompensa por acortar distancias: +  0.9156971800558555\n",
      "Penalización por duración del episodio: -  0.2903054465992407\n",
      "Recompensa por acortar distancias: +  0.9156971800558555\n",
      "Penalización por parar muy lejos: -  0.1659330065400036\n",
      "Penalización por duración del episodio: -  0.2903884287137129\n",
      "Recompensa por acortar distancias: +  0.9156971800558555\n",
      "Penalización por parar muy lejos: -  0.1659330065400036\n",
      "Penalización por duración del episodio: -  0.29052820654332756\n",
      "steer input from model: -0.1 , throttle:  0.0\n",
      "reward: 0.45923596697252445\n",
      "Step: 1370, Mean Reward (últimos 10 pasos): 0.4592359662055969\n",
      "Recompensa por acortar distancias: +  0.9156970549022747\n",
      "Penalización por duración del episodio: -  0.29063791133208294\n",
      "Recompensa por acortar distancias: +  0.9156970549022747\n",
      "Penalización por duración del episodio: -  0.2907620215763333\n",
      "Recompensa por acortar distancias: +  0.9156970769882131\n",
      "Penalización por duración del episodio: -  0.2908379454977679\n",
      "Recompensa por acortar distancias: +  0.9156970769882131\n",
      "Penalización por parar muy lejos: -  0.16593282175715998\n",
      "Penalización por duración del episodio: -  0.29118216148216075\n",
      "Recompensa por acortar distancias: +  0.9156970769882131\n",
      "Penalización por duración del episodio: -  0.2915145087529159\n",
      "Recompensa por acortar distancias: +  0.9156972683994581\n",
      "Penalización por duración del episodio: -  0.29162637343687525\n",
      "Recompensa por acortar distancias: +  0.9156972683994581\n",
      "Penalización por duración del episodio: -  0.2917205385987318\n",
      "Recompensa por acortar distancias: +  0.9156973272951463\n",
      "Penalización por parar muy lejos: -  0.1659332705157804\n",
      "Penalización por duración del episodio: -  0.2918459951318574\n",
      "Recompensa por acortar distancias: +  0.915697378828843\n",
      "Penalización por duración del episodio: -  0.29194879714688193\n",
      "Recompensa por acortar distancias: +  0.915697378828843\n",
      "Penalización por parar muy lejos: -  0.16593336290738175\n",
      "Penalización por duración del episodio: -  0.29216960187427476\n",
      "Step: 1380, Mean Reward (últimos 10 pasos): 0.4575944244861603\n",
      "Recompensa por acortar distancias: +  0.915697378828843\n",
      "Penalización por parar muy lejos: -  0.16593336290738175\n",
      "Penalización por duración del episodio: -  0.29249570854879064\n",
      "Recompensa por acortar distancias: +  0.915697378828843\n",
      "Penalización por parar muy lejos: -  0.16593336290738175\n",
      "Penalización por duración del episodio: -  0.2925962218325699\n",
      "Recompensa por acortar distancias: +  0.9156972168657003\n",
      "Penalización por duración del episodio: -  0.2928180394651817\n",
      "Recompensa por acortar distancias: +  0.915697194779795\n",
      "Penalización por duración del episodio: -  0.29314877930204863\n",
      "Recompensa por acortar distancias: +  0.915697194779795\n",
      "Penalización por duración del episodio: -  0.29324054450538173\n",
      "Recompensa por acortar distancias: +  0.915697194779795\n",
      "Penalización por parar muy lejos: -  0.16593303293756617\n",
      "Penalización por duración del episodio: -  0.29348526959209154\n",
      "Recompensa por acortar distancias: +  0.9156971653319136\n",
      "Penalización por parar muy lejos: -  0.16593298014244443\n",
      "Penalización por duración del episodio: -  0.29382032339431063\n",
      "Recompensa por acortar distancias: +  0.9156972831233836\n",
      "Penalización por duración del episodio: -  0.29413835411079353\n",
      "Recompensa por acortar distancias: +  0.9156972831233836\n",
      "Penalización por duración del episodio: -  0.29445631805452227\n",
      "Recompensa por acortar distancias: +  0.9156972831233836\n",
      "Penalización por parar muy lejos: -  0.16593319132301204\n",
      "Penalización por duración del episodio: -  0.2945620747437873\n",
      "steer input from model: -0.1 , throttle:  0.0\n",
      "reward: 0.4552020170565843\n",
      "Step: 1390, Mean Reward (últimos 10 pasos): 0.45520201325416565\n",
      "Recompensa por acortar distancias: +  0.9156972831233836\n",
      "Penalización por duración del episodio: -  0.2947722369761501\n",
      "Recompensa por acortar distancias: +  0.9156970401783131\n",
      "Penalización por parar muy lejos: -  0.16593275576332722\n",
      "Penalización por duración del episodio: -  0.29511122622978164\n",
      "Recompensa por acortar distancias: +  0.9156970401783131\n",
      "Penalización por parar muy lejos: -  0.16593275576332722\n",
      "Penalización por duración del episodio: -  0.29542845679141394\n",
      "Recompensa por acortar distancias: +  0.9156969739204561\n",
      "Penalización por duración del episodio: -  0.2957466698814336\n",
      "Recompensa por acortar distancias: +  0.9156970401783131\n",
      "Penalización por duración del episodio: -  0.2958721064135261\n",
      "Recompensa por acortar distancias: +  0.9156970401783131\n",
      "Penalización por duración del episodio: -  0.29596761618966305\n",
      "Recompensa por acortar distancias: +  0.9156971506079694\n",
      "Penalización por duración del episodio: -  0.29607428914360934\n",
      "Recompensa por acortar distancias: +  0.9156971653319136\n",
      "Penalización por duración del episodio: -  0.2962143840051129\n",
      "Recompensa por acortar distancias: +  0.9156971653319136\n",
      "Penalización por parar muy lejos: -  0.16593298014244443\n",
      "Penalización por duración del episodio: -  0.29633835945428716\n",
      "Recompensa por acortar distancias: +  0.9156971653319136\n",
      "Penalización por parar muy lejos: -  0.16593298014244443\n",
      "Penalización por duración del episodio: -  0.2967219537160187\n",
      "Step: 1400, Mean Reward (últimos 10 pasos): 0.45304223895072937\n",
      "Recompensa por acortar distancias: +  0.9156971653319136\n",
      "Penalización por duración del episodio: -  0.29705623656240654\n",
      "Recompensa por acortar distancias: +  0.9156971137980985\n",
      "Penalización por parar muy lejos: -  0.1659328877510138\n",
      "Penalización por duración del episodio: -  0.2971755802976012\n",
      "Recompensa por acortar distancias: +  0.9156972168657003\n",
      "Penalización por parar muy lejos: -  0.16593307253391626\n",
      "Penalización por duración del episodio: -  0.2973808680170708\n",
      "Recompensa por acortar distancias: +  0.9156972168657003\n",
      "Penalización por duración del episodio: -  0.29772294166249086\n",
      "Recompensa por acortar distancias: +  0.9156972831233836\n",
      "Penalización por parar muy lejos: -  0.16593319132301204\n",
      "Penalización por duración del episodio: -  0.298041657960236\n",
      "Recompensa por acortar distancias: +  0.9156973567429766\n",
      "Penalización por parar muy lejos: -  0.16593332331097613\n",
      "Penalización por duración del episodio: -  0.29810951946321124\n",
      "Recompensa por acortar distancias: +  0.9156973567429766\n",
      "Penalización por duración del episodio: -  0.2983703281694042\n",
      "Recompensa por acortar distancias: +  0.9156973567429766\n",
      "Penalización por duración del episodio: -  0.2984791224445201\n",
      "Recompensa por acortar distancias: +  0.9156973567429766\n",
      "Penalización por duración del episodio: -  0.2985568722712312\n",
      "Recompensa por acortar distancias: +  0.9156973567429766\n",
      "Penalización por duración del episodio: -  0.29865730073893537\n",
      "steer input from model: -0.05 , throttle:  0.3\n",
      "reward: 0.6170400560040412\n",
      "Step: 1410, Mean Reward (últimos 10 pasos): 0.6170400381088257\n",
      "Recompensa por acortar distancias: +  0.9156973567429766\n",
      "Penalización por parar muy lejos: -  0.16593332331097613\n",
      "Penalización por duración del episodio: -  0.2987665247247239\n",
      "Recompensa por acortar distancias: +  0.9156973567429766\n",
      "Penalización por parar muy lejos: -  0.16593332331097613\n",
      "Penalización por duración del episodio: -  0.2990256093802947\n",
      "Recompensa por acortar distancias: +  0.9156971653319136\n",
      "Penalización por parar muy lejos: -  0.16593298014244443\n",
      "Penalización por duración del episodio: -  0.29909150525090356\n",
      "Recompensa por acortar distancias: +  0.915697194779795\n",
      "Penalización por duración del episodio: -  0.299343495614707\n",
      "Recompensa por acortar distancias: +  0.915697194779795\n",
      "Penalización por duración del episodio: -  0.29967852265189615\n",
      "Recompensa por acortar distancias: +  0.915697194779795\n",
      "Penalización por parar muy lejos: -  0.16593303293756617\n",
      "Penalización por duración del episodio: -  0.30000374033658905\n",
      "Recompensa por acortar distancias: +  0.9156973641049325\n",
      "Penalización por duración del episodio: -  0.30033346314565146\n",
      "Recompensa por acortar distancias: +  0.9156974009147041\n",
      "Penalización por duración del episodio: -  0.30066045501601973\n",
      "Recompensa por acortar distancias: +  0.9156974009147041\n",
      "Penalización por parar muy lejos: -  0.16593340250379493\n",
      "Penalización por duración del episodio: -  0.30097973426711316\n",
      "Recompensa por acortar distancias: +  0.915697194779795\n",
      "Penalización por duración del episodio: -  0.30107977501216343\n",
      "Step: 1420, Mean Reward (últimos 10 pasos): 0.6146174073219299\n",
      "Recompensa por acortar distancias: +  0.915697194779795\n",
      "Penalización por parar muy lejos: -  0.16593303293756617\n",
      "Penalización por duración del episodio: -  0.30131175449345304\n",
      "Recompensa por acortar distancias: +  0.915697194779795\n",
      "Penalización por duración del episodio: -  0.3014000054344721\n",
      "Recompensa por acortar distancias: +  0.915697194779795\n",
      "Penalización por duración del episodio: -  0.30164018600712905\n",
      "Recompensa por acortar distancias: +  0.9156971653319136\n",
      "Penalización por duración del episodio: -  0.3019663432380935\n",
      "Recompensa por acortar distancias: +  0.9156972683994581\n",
      "Penalización por parar muy lejos: -  0.16593316492542934\n",
      "Penalización por duración del episodio: -  0.30230385387583425\n",
      "Recompensa por acortar distancias: +  0.9156974303625111\n",
      "Penalización por duración del episodio: -  0.30261956948607566\n",
      "Recompensa por acortar distancias: +  0.9156974303625111\n",
      "Penalización por parar muy lejos: -  0.1659334552990243\n",
      "Penalización por duración del episodio: -  0.3029420015446973\n",
      "Recompensa por acortar distancias: +  0.9156974303625111\n",
      "Penalización por parar muy lejos: -  0.1659334552990243\n",
      "Penalización por duración del episodio: -  0.3030602632026106\n",
      "Recompensa por acortar distancias: +  0.9156974082766567\n",
      "Penalización por duración del episodio: -  0.3031729449489785\n",
      "Recompensa por acortar distancias: +  0.9156973935527511\n",
      "Penalización por parar muy lejos: -  0.16593338930498974\n",
      "Penalización por duración del episodio: -  0.30329001820847107\n",
      "steer input from model: 0.0 , throttle:  0.0\n",
      "reward: 0.4464739860392903\n",
      "Step: 1430, Mean Reward (últimos 10 pasos): 0.44647398591041565\n",
      "Recompensa por acortar distancias: +  0.9156973935527511\n",
      "Penalización por duración del episodio: -  0.3036109078154288\n",
      "Recompensa por acortar distancias: +  0.9156973935527511\n",
      "Penalización por parar muy lejos: -  0.16593338930498974\n",
      "Penalización por duración del episodio: -  0.30395362767558204\n",
      "Recompensa por acortar distancias: +  0.9156975481536447\n",
      "Penalización por parar muy lejos: -  0.16593366648007635\n",
      "Penalización por duración del episodio: -  0.30407003334773897\n",
      "Recompensa por acortar distancias: +  0.9156975481536447\n",
      "Penalización por parar muy lejos: -  0.16593366648007635\n",
      "Penalización por duración del episodio: -  0.3042775372742095\n",
      "Recompensa por acortar distancias: +  0.9156975923252814\n",
      "Penalización por parar muy lejos: -  0.16593374567302638\n",
      "Penalización por duración del episodio: -  0.30461391809611316\n",
      "Recompensa por acortar distancias: +  0.9156976364968971\n",
      "Penalización por duración del episodio: -  0.3047035882594732\n",
      "Recompensa por acortar distancias: +  0.9156976364968971\n",
      "Penalización por duración del episodio: -  0.30494710685048626\n",
      "Recompensa por acortar distancias: +  0.9156976364968971\n",
      "Penalización por duración del episodio: -  0.30528400926614707\n",
      "Recompensa por acortar distancias: +  0.9156975923252814\n",
      "Penalización por parar muy lejos: -  0.16593374567302638\n",
      "Penalización por duración del episodio: -  0.30560713048917815\n",
      "Recompensa por acortar distancias: +  0.915697562877526\n",
      "Penalización por parar muy lejos: -  0.165933692877723\n",
      "Penalización por duración del episodio: -  0.30593999108165537\n",
      "Step: 1440, Mean Reward (últimos 10 pasos): 0.4438238739967346\n",
      "Recompensa por acortar distancias: +  0.915697562877526\n",
      "Penalización por duración del episodio: -  0.306064519824661\n",
      "Recompensa por acortar distancias: +  0.9156974450864109\n",
      "Penalización por duración del episodio: -  0.3062595797787391\n",
      "Recompensa por acortar distancias: +  0.9156974009147041\n",
      "Penalización por parar muy lejos: -  0.16593340250379493\n",
      "Penalización por duración del episodio: -  0.3063498300126899\n",
      "Recompensa por acortar distancias: +  0.9156974450864109\n",
      "Penalización por duración del episodio: -  0.3065836833751564\n",
      "Recompensa por acortar distancias: +  0.9156974966200422\n",
      "Penalización por duración del episodio: -  0.3069215143079842\n",
      "Recompensa por acortar distancias: +  0.9156974966200422\n",
      "Penalización por parar muy lejos: -  0.16593357408833959\n",
      "Penalización por duración del episodio: -  0.3072469977216582\n",
      "Recompensa por acortar distancias: +  0.915697378828843\n",
      "Penalización por duración del episodio: -  0.3075778269556656\n",
      "Recompensa por acortar distancias: +  0.9156974303625111\n",
      "Penalización por duración del episodio: -  0.3079054906521166\n",
      "Recompensa por acortar distancias: +  0.9156974745342036\n",
      "Penalización por parar muy lejos: -  0.16593353449189358\n",
      "Penalización por duración del episodio: -  0.30824193444866094\n",
      "Recompensa por acortar distancias: +  0.9156976217730275\n",
      "Penalización por parar muy lejos: -  0.1659337984683432\n",
      "Penalización por duración del episodio: -  0.3083299262484745\n",
      "steer input from model: -0.25 , throttle:  0.0\n",
      "reward: 0.4414338970562098\n",
      "Step: 1450, Mean Reward (últimos 10 pasos): 0.4414339065551758\n",
      "Recompensa por acortar distancias: +  0.9156976438588309\n",
      "Penalización por duración del episodio: -  0.3084691288456163\n",
      "Recompensa por acortar distancias: +  0.9156976438588309\n",
      "Penalización por parar muy lejos: -  0.16593383806483963\n",
      "Penalización por duración del episodio: -  0.30857699486732454\n",
      "Recompensa por acortar distancias: +  0.9156977174781378\n",
      "Penalización por parar muy lejos: -  0.16593397005321583\n",
      "Penalización por duración del episodio: -  0.30890155291835725\n",
      "Recompensa por acortar distancias: +  0.9156977101162097\n",
      "Penalización por duración del episodio: -  0.30901451701960453\n",
      "Recompensa por acortar distancias: +  0.9156977101162097\n",
      "Penalización por parar muy lejos: -  0.16593395685437445\n",
      "Penalización por duración del episodio: -  0.3092440889226664\n",
      "Recompensa por acortar distancias: +  0.9156977101162097\n",
      "Penalización por parar muy lejos: -  0.16593395685437445\n",
      "Penalización por duración del episodio: -  0.3093542747111629\n",
      "Recompensa por acortar distancias: +  0.9156977101162097\n",
      "Penalización por parar muy lejos: -  0.16593395685437445\n",
      "Penalización por duración del episodio: -  0.30958514273040616\n",
      "Recompensa por acortar distancias: +  0.9156973714668881\n",
      "Penalización por duración del episodio: -  0.3099134523288342\n",
      "Recompensa por acortar distancias: +  0.915697378828843\n",
      "Penalización por parar muy lejos: -  0.16593336290738175\n",
      "Penalización por duración del episodio: -  0.3102489739894282\n",
      "Recompensa por acortar distancias: +  0.9156974450864109\n",
      "Penalización por duración del episodio: -  0.31033985862749874\n",
      "Step: 1460, Mean Reward (últimos 10 pasos): 0.6053575873374939\n",
      "Recompensa por acortar distancias: +  0.9156974450864109\n",
      "Penalización por duración del episodio: -  0.31041627897633056\n",
      "Recompensa por acortar distancias: +  0.9156974082766567\n",
      "Penalización por duración del episodio: -  0.31057528175424215\n",
      "Recompensa por acortar distancias: +  0.9156974745342036\n",
      "Penalización por parar muy lejos: -  0.16593353449189358\n",
      "Penalización por duración del episodio: -  0.3107071791279917\n",
      "Recompensa por acortar distancias: +  0.9156975187058752\n",
      "Penalización por parar muy lejos: -  0.16593361368479315\n",
      "Penalización por duración del episodio: -  0.31091255073640817\n",
      "Recompensa por acortar distancias: +  0.9156975039819871\n",
      "Penalización por parar muy lejos: -  0.16593358728715663\n",
      "Penalización por duración del episodio: -  0.31123667068895133\n",
      "Recompensa por acortar distancias: +  0.9156975039819871\n",
      "Penalización por duración del episodio: -  0.3115671635598563\n",
      "Recompensa por acortar distancias: +  0.9156975039819871\n",
      "Penalización por duración del episodio: -  0.3117003761266675\n",
      "Recompensa por acortar distancias: +  0.9156974303625111\n",
      "Penalización por parar muy lejos: -  0.1659334552990243\n",
      "Penalización por duración del episodio: -  0.311800201121279\n",
      "Recompensa por acortar distancias: +  0.9156974303625111\n",
      "Penalización por parar muy lejos: -  0.1659334552990243\n",
      "Penalización por duración del episodio: -  0.3118940722059088\n",
      "Recompensa por acortar distancias: +  0.9156975923252814\n",
      "Penalización por parar muy lejos: -  0.16593374567302638\n",
      "Penalización por duración del episodio: -  0.3122298873468003\n",
      "steer input from model: -0.9 , throttle:  0.0\n",
      "reward: 0.43753395930545463\n",
      "Step: 1470, Mean Reward (últimos 10 pasos): 0.4375339448451996\n",
      "Recompensa por acortar distancias: +  0.9156975923252814\n",
      "Penalización por parar muy lejos: -  0.16593374567302638\n",
      "Penalización por duración del episodio: -  0.3125659766612114\n",
      "Recompensa por acortar distancias: +  0.9156975923252814\n",
      "Penalización por duración del episodio: -  0.3129117768463602\n",
      "Recompensa por acortar distancias: +  0.9156977101162097\n",
      "Penalización por parar muy lejos: -  0.16593395685437445\n",
      "Penalización por duración del episodio: -  0.31299033229869316\n",
      "Recompensa por acortar distancias: +  0.9156976806684916\n",
      "Penalización por duración del episodio: -  0.3132481581472401\n",
      "Recompensa por acortar distancias: +  0.9156976806684916\n",
      "Penalización por parar muy lejos: -  0.16593390405901723\n",
      "Penalización por duración del episodio: -  0.31359407623551716\n",
      "Recompensa por acortar distancias: +  0.9156976806684916\n",
      "Penalización por duración del episodio: -  0.3136860084276859\n",
      "Recompensa por acortar distancias: +  0.9156976806684916\n",
      "Penalización por duración del episodio: -  0.31383622523918947\n",
      "Recompensa por acortar distancias: +  0.9156975334297612\n",
      "Penalización por parar muy lejos: -  0.16593364008243308\n",
      "Penalización por duración del episodio: -  0.313923995542393\n",
      "Recompensa por acortar distancias: +  0.9156975334297612\n",
      "Penalización por parar muy lejos: -  0.16593364008243308\n",
      "Penalización por duración del episodio: -  0.3140124108547412\n",
      "Recompensa por acortar distancias: +  0.915697658582697\n",
      "Penalización por parar muy lejos: -  0.16593386446250816\n",
      "Penalización por duración del episodio: -  0.31411923899537797\n",
      "Step: 1480, Mean Reward (últimos 10 pasos): 0.43564456701278687\n",
      "Recompensa por acortar distancias: +  0.915697658582697\n",
      "Penalización por parar muy lejos: -  0.16593386446250816\n",
      "Penalización por duración del episodio: -  0.3142571035668641\n",
      "Recompensa por acortar distancias: +  0.915697658582697\n",
      "Penalización por duración del episodio: -  0.3143841471668628\n",
      "Recompensa por acortar distancias: +  0.915697658582697\n",
      "Penalización por duración del episodio: -  0.31459389363382567\n",
      "Recompensa por acortar distancias: +  0.915697658582697\n",
      "Penalización por parar muy lejos: -  0.16593386446250816\n",
      "Penalización por duración del episodio: -  0.31493475736521\n",
      "Recompensa por acortar distancias: +  0.9156976070491556\n",
      "Penalización por duración del episodio: -  0.3150161652858354\n",
      "Recompensa por acortar distancias: +  0.9156976364968971\n",
      "Penalización por duración del episodio: -  0.315280324101257\n",
      "Recompensa por acortar distancias: +  0.9156976364968971\n",
      "Penalización por parar muy lejos: -  0.1659338248660067\n",
      "Penalización por duración del episodio: -  0.31561124293421156\n",
      "Recompensa por acortar distancias: +  0.9156976364968971\n",
      "Penalización por duración del episodio: -  0.3159590904182913\n",
      "Recompensa por acortar distancias: +  0.9156973272951463\n",
      "Penalización por duración del episodio: -  0.31605828726662266\n",
      "Recompensa por acortar distancias: +  0.9156973272951463\n",
      "Penalización por parar muy lejos: -  0.1659332705157804\n",
      "Penalización por duración del episodio: -  0.3163051642038209\n",
      "steer input from model: 0.05 , throttle:  0.0\n",
      "reward: 0.433458892575545\n",
      "Step: 1490, Mean Reward (últimos 10 pasos): 0.4334588944911957\n",
      "Recompensa por acortar distancias: +  0.9156974745342036\n",
      "Penalización por duración del episodio: -  0.3164259444021808\n",
      "Recompensa por acortar distancias: +  0.9156974745342036\n",
      "Penalización por parar muy lejos: -  0.16593353449189358\n",
      "Penalización por duración del episodio: -  0.31665834949158805\n",
      "Recompensa por acortar distancias: +  0.9156974303625111\n",
      "Penalización por parar muy lejos: -  0.1659334552990243\n",
      "Penalización por duración del episodio: -  0.31700158214696433\n",
      "Recompensa por acortar distancias: +  0.9156973567429766\n",
      "Penalización por duración del episodio: -  0.317096519647256\n",
      "Recompensa por acortar distancias: +  0.9156974009147041\n",
      "Penalización por duración del episodio: -  0.3171881882751148\n",
      "Recompensa por acortar distancias: +  0.9156974303625111\n",
      "Penalización por duración del episodio: -  0.31731697893222954\n",
      "Recompensa por acortar distancias: +  0.9156974303625111\n",
      "Penalización por parar muy lejos: -  0.1659334552990243\n",
      "Penalización por duración del episodio: -  0.3174386015025684\n",
      "Recompensa por acortar distancias: +  0.9156974303625111\n",
      "Penalización por parar muy lejos: -  0.1659334552990243\n",
      "Penalización por duración del episodio: -  0.31767730645346665\n",
      "Recompensa por acortar distancias: +  0.9156974303625111\n",
      "Penalización por duración del episodio: -  0.3180079180388023\n",
      "Recompensa por acortar distancias: +  0.9156974303625111\n",
      "Penalización por parar muy lejos: -  0.1659334552990243\n",
      "Penalización por duración del episodio: -  0.318337559443215\n",
      "Step: 1500, Mean Reward (últimos 10 pasos): 0.43142640590667725\n",
      "Recompensa por acortar distancias: +  0.9156971358840228\n",
      "Penalización por duración del episodio: -  0.3184427697782658\n",
      "Recompensa por acortar distancias: +  0.9156971358840228\n",
      "Penalización por parar muy lejos: -  0.16593292734733617\n",
      "Penalización por duración del episodio: -  0.3185651297047984\n",
      "Recompensa por acortar distancias: +  0.9156973125712279\n",
      "Penalización por parar muy lejos: -  0.16593324411818758\n",
      "Penalización por duración del episodio: -  0.3186824518896741\n",
      "Recompensa por acortar distancias: +  0.9156973125712279\n",
      "Penalización por parar muy lejos: -  0.16593324411818758\n",
      "Penalización por duración del episodio: -  0.3187705595777556\n",
      "Recompensa por acortar distancias: +  0.9156973125712279\n",
      "Penalización por parar muy lejos: -  0.16593324411818758\n",
      "Penalización por duración del episodio: -  0.31901392605528195\n",
      "Recompensa por acortar distancias: +  0.9156973125712279\n",
      "Penalización por duración del episodio: -  0.31935440902185536\n",
      "Recompensa por acortar distancias: +  0.9156974745342036\n",
      "Penalización por duración del episodio: -  0.31945376454427254\n",
      "Recompensa por acortar distancias: +  0.9156973861907973\n",
      "Penalización por parar muy lejos: -  0.1659333761061853\n",
      "Penalización por duración del episodio: -  0.3195762996841114\n",
      "Recompensa por acortar distancias: +  0.9156973861907973\n",
      "Penalización por duración del episodio: -  0.3196753444087838\n",
      "Recompensa por acortar distancias: +  0.9156973861907973\n",
      "Penalización por duración del episodio: -  0.31977251768416065\n",
      "steer input from model: -0.9 , throttle:  0.3\n",
      "reward: 0.5959248685066367\n",
      "Step: 1510, Mean Reward (últimos 10 pasos): 0.5959248542785645\n",
      "Recompensa por acortar distancias: +  0.9156973861907973\n",
      "Penalización por duración del episodio: -  0.31985620533918835\n",
      "Recompensa por acortar distancias: +  0.9156973861907973\n",
      "Penalización por duración del episodio: -  0.3199857117121772\n",
      "Recompensa por acortar distancias: +  0.9156973861907973\n",
      "Penalización por duración del episodio: -  0.3203863008484825\n",
      "Recompensa por acortar distancias: +  0.9156973272951463\n",
      "Penalización por duración del episodio: -  0.3204863454605758\n",
      "Recompensa por acortar distancias: +  0.9156973272951463\n",
      "Penalización por parar muy lejos: -  0.1659332705157804\n",
      "Penalización por duración del episodio: -  0.3206113802906972\n",
      "Recompensa por acortar distancias: +  0.9156973125712279\n",
      "Penalización por parar muy lejos: -  0.16593324411818758\n",
      "Penalización por duración del episodio: -  0.32073165694882544\n",
      "Recompensa por acortar distancias: +  0.9156973125712279\n",
      "Penalización por duración del episodio: -  0.32085485119885937\n",
      "Recompensa por acortar distancias: +  0.9156973125712279\n",
      "Penalización por parar muy lejos: -  0.16593324411818758\n",
      "Penalización por duración del episodio: -  0.3210635565365303\n",
      "Recompensa por acortar distancias: +  0.9156973125712279\n",
      "Penalización por parar muy lejos: -  0.16593324411818758\n",
      "Penalización por duración del episodio: -  0.3214141282722908\n",
      "Recompensa por acortar distancias: +  0.9156972389515999\n",
      "Penalización por duración del episodio: -  0.3217572425255733\n",
      "Step: 1520, Mean Reward (últimos 10 pasos): 0.593940019607544\n",
      "Recompensa por acortar distancias: +  0.9156972831233836\n",
      "Penalización por parar muy lejos: -  0.16593319132301204\n",
      "Penalización por duración del episodio: -  0.32187645999873643\n",
      "Recompensa por acortar distancias: +  0.9156972831233836\n",
      "Penalización por parar muy lejos: -  0.16593319132301204\n",
      "Penalización por duración del episodio: -  0.3220952860437876\n",
      "Recompensa por acortar distancias: +  0.9156972831233836\n",
      "Penalización por duración del episodio: -  0.3224281717394897\n",
      "Recompensa por acortar distancias: +  0.9156972831233836\n",
      "Penalización por parar muy lejos: -  0.16593319132301204\n",
      "Penalización por duración del episodio: -  0.32253144266223366\n",
      "Recompensa por acortar distancias: +  0.9156972831233836\n",
      "Penalización por parar muy lejos: -  0.16593319132301204\n",
      "Penalización por duración del episodio: -  0.32277612191288957\n",
      "Recompensa por acortar distancias: +  0.9156973567429766\n",
      "Penalización por duración del episodio: -  0.32287085060105153\n",
      "Recompensa por acortar distancias: +  0.9156973567429766\n",
      "Penalización por duración del episodio: -  0.32311145122818213\n",
      "Recompensa por acortar distancias: +  0.9156973567429766\n",
      "Penalización por duración del episodio: -  0.32346884423257105\n",
      "Recompensa por acortar distancias: +  0.9156973272951463\n",
      "Penalización por parar muy lejos: -  0.1659332705157804\n",
      "Penalización por duración del episodio: -  0.32357025414720714\n",
      "Recompensa por acortar distancias: +  0.9156973272951463\n",
      "Penalización por parar muy lejos: -  0.1659332705157804\n",
      "Penalización por duración del episodio: -  0.3237262026044031\n",
      "steer input from model: -0.1 , throttle:  0.0\n",
      "reward: 0.42603785417496276\n",
      "Step: 1530, Mean Reward (últimos 10 pasos): 0.42603784799575806\n",
      "Recompensa por acortar distancias: +  0.9156974450864109\n",
      "Penalización por duración del episodio: -  0.32417782366805725\n",
      "Recompensa por acortar distancias: +  0.9156973861907973\n",
      "Penalización por parar muy lejos: -  0.1659333761061853\n",
      "Penalización por duración del episodio: -  0.3245287802518674\n",
      "Recompensa por acortar distancias: +  0.9156973861907973\n",
      "Penalización por parar muy lejos: -  0.1659333761061853\n",
      "Penalización por duración del episodio: -  0.32462034773983073\n",
      "Recompensa por acortar distancias: +  0.9156973861907973\n",
      "Penalización por parar muy lejos: -  0.1659333761061853\n",
      "Penalización por duración del episodio: -  0.32475361732172775\n",
      "Recompensa por acortar distancias: +  0.9156973861907973\n",
      "Penalización por parar muy lejos: -  0.1659333761061853\n",
      "Penalización por duración del episodio: -  0.32520604523417274\n",
      "Recompensa por acortar distancias: +  0.9156974966200422\n",
      "Penalización por duración del episodio: -  0.3255382201863187\n",
      "Recompensa por acortar distancias: +  0.9156974598103085\n",
      "Penalización por duración del episodio: -  0.325875771493335\n",
      "Recompensa por acortar distancias: +  0.9156975187058752\n",
      "Penalización por duración del episodio: -  0.3259800659121282\n",
      "Recompensa por acortar distancias: +  0.9156975187058752\n",
      "Penalización por parar muy lejos: -  0.16593361368479315\n",
      "Penalización por duración del episodio: -  0.3260908796037227\n",
      "Recompensa por acortar distancias: +  0.9156974598103085\n",
      "Penalización por duración del episodio: -  0.3265485794542724\n",
      "Step: 1540, Mean Reward (últimos 10 pasos): 0.5891488790512085\n",
      "Recompensa por acortar distancias: +  0.9156974598103085\n",
      "Penalización por parar muy lejos: -  0.16593350809426713\n",
      "Penalización por duración del episodio: -  0.3266401528354865\n",
      "Recompensa por acortar distancias: +  0.9156974598103085\n",
      "Penalización por duración del episodio: -  0.32689703151882643\n",
      "Recompensa por acortar distancias: +  0.9156974598103085\n",
      "Penalización por duración del episodio: -  0.3270029581299449\n",
      "Recompensa por acortar distancias: +  0.9156974598103085\n",
      "Penalización por parar muy lejos: -  0.16593350809426713\n",
      "Penalización por duración del episodio: -  0.32713924063699046\n",
      "Recompensa por acortar distancias: +  0.9156973641049325\n",
      "Penalización por parar muy lejos: -  0.16593333650977715\n",
      "Penalización por duración del episodio: -  0.3272382212975113\n",
      "Recompensa por acortar distancias: +  0.9156973641049325\n",
      "Penalización por duración del episodio: -  0.32737334666214596\n",
      "Recompensa por acortar distancias: +  0.9156974966200422\n",
      "Penalización por duración del episodio: -  0.32747454276449706\n",
      "Recompensa por acortar distancias: +  0.9156974966200422\n",
      "Penalización por parar muy lejos: -  0.16593357408833959\n",
      "Penalización por duración del episodio: -  0.3279037674080439\n",
      "Recompensa por acortar distancias: +  0.9156974745342036\n",
      "Penalización por duración del episodio: -  0.328015910041269\n",
      "Recompensa por acortar distancias: +  0.9156974745342036\n",
      "Penalización por parar muy lejos: -  0.16593353449189358\n",
      "Penalización por duración del episodio: -  0.3281174023522884\n",
      "steer input from model: -0.1 , throttle:  0.0\n",
      "reward: 0.42164653769002153\n",
      "Step: 1550, Mean Reward (últimos 10 pasos): 0.4216465353965759\n",
      "Recompensa por acortar distancias: +  0.9156974230005601\n",
      "Penalización por duración del episodio: -  0.3282386087141874\n",
      "Recompensa por acortar distancias: +  0.9156974230005601\n",
      "Penalización por parar muy lejos: -  0.1659334421002157\n",
      "Penalización por duración del episodio: -  0.32835422236840667\n",
      "Recompensa por acortar distancias: +  0.9156975481536447\n",
      "Penalización por duración del episodio: -  0.3285930233081258\n",
      "Recompensa por acortar distancias: +  0.9156975481536447\n",
      "Penalización por duración del episodio: -  0.3289270293535709\n",
      "Recompensa por acortar distancias: +  0.9156975481536447\n",
      "Penalización por duración del episodio: -  0.32927296096391717\n",
      "Recompensa por acortar distancias: +  0.9156975481536447\n",
      "Penalización por parar muy lejos: -  0.16593366648007635\n",
      "Penalización por duración del episodio: -  0.3296141781490381\n",
      "Recompensa por acortar distancias: +  0.9156974966200422\n",
      "Penalización por duración del episodio: -  0.32995958101151823\n",
      "Recompensa por acortar distancias: +  0.9156975481536447\n",
      "Penalización por parar muy lejos: -  0.16593366648007635\n",
      "Penalización por duración del episodio: -  0.3303055946734071\n",
      "Recompensa por acortar distancias: +  0.9156976806684916\n",
      "Penalización por duración del episodio: -  0.3306592534334002\n",
      "Recompensa por acortar distancias: +  0.9156976806684916\n",
      "Penalización por parar muy lejos: -  0.16593390405901723\n",
      "Penalización por duración del episodio: -  0.3307430063916781\n",
      "Step: 1560, Mean Reward (últimos 10 pasos): 0.41902077198028564\n",
      "Recompensa por acortar distancias: +  0.9156976806684916\n",
      "Penalización por duración del episodio: -  0.3309948311732238\n",
      "Recompensa por acortar distancias: +  0.9156976806684916\n",
      "Penalización por duración del episodio: -  0.3313475421914684\n",
      "Recompensa por acortar distancias: +  0.9156974450864109\n",
      "Penalización por parar muy lejos: -  0.16593348169664404\n",
      "Penalización por duración del episodio: -  0.33167201978651245\n",
      "Recompensa por acortar distancias: +  0.915697378828843\n",
      "Penalización por parar muy lejos: -  0.16593336290738175\n",
      "Penalización por duración del episodio: -  0.33180102150783886\n",
      "Recompensa por acortar distancias: +  0.915697378828843\n",
      "Penalización por duración del episodio: -  0.3320234815235104\n",
      "Recompensa por acortar distancias: +  0.915697378828843\n",
      "Penalización por parar muy lejos: -  0.16593336290738175\n",
      "Penalización por duración del episodio: -  0.33213103762572743\n",
      "Recompensa por acortar distancias: +  0.915697378828843\n",
      "Penalización por parar muy lejos: -  0.16593336290738175\n",
      "Penalización por duración del episodio: -  0.3322342104223931\n",
      "Recompensa por acortar distancias: +  0.9156974966200422\n",
      "Penalización por duración del episodio: -  0.33236708359030925\n",
      "Recompensa por acortar distancias: +  0.9156974966200422\n",
      "Penalización por parar muy lejos: -  0.16593357408833959\n",
      "Penalización por duración del episodio: -  0.33247778575333553\n",
      "Recompensa por acortar distancias: +  0.9156975923252814\n",
      "Penalización por duración del episodio: -  0.3327060949422027\n",
      "steer input from model: 0.9 , throttle:  0.3\n",
      "reward: 0.5829914973830786\n",
      "Step: 1570, Mean Reward (últimos 10 pasos): 0.5829914808273315\n",
      "Recompensa por acortar distancias: +  0.9156975776014049\n",
      "Penalización por duración del episodio: -  0.33282748962311764\n",
      "Recompensa por acortar distancias: +  0.9156975776014049\n",
      "Penalización por duración del episodio: -  0.33305339825109187\n",
      "Recompensa por acortar distancias: +  0.9156975776014049\n",
      "Penalización por duración del episodio: -  0.33339846674884643\n",
      "Recompensa por acortar distancias: +  0.9156975776014049\n",
      "Penalización por duración del episodio: -  0.33375158655685466\n",
      "Recompensa por acortar distancias: +  0.9156974966200422\n",
      "Penalización por parar muy lejos: -  0.16593357408833959\n",
      "Penalización por duración del episodio: -  0.3338733786395533\n",
      "Recompensa por acortar distancias: +  0.9156974966200422\n",
      "Penalización por parar muy lejos: -  0.16593357408833959\n",
      "Penalización por duración del episodio: -  0.3340955520957715\n",
      "Recompensa por acortar distancias: +  0.9156974966200422\n",
      "Penalización por duración del episodio: -  0.33444048491740663\n",
      "Recompensa por acortar distancias: +  0.9156974745342036\n",
      "Penalización por parar muy lejos: -  0.16593353449189358\n",
      "Penalización por duración del episodio: -  0.3345406347156612\n",
      "Recompensa por acortar distancias: +  0.9156974303625111\n",
      "Penalización por parar muy lejos: -  0.1659334552990243\n",
      "Penalización por duración del episodio: -  0.33462949763694466\n",
      "Recompensa por acortar distancias: +  0.9156974303625111\n",
      "Penalización por parar muy lejos: -  0.1659334552990243\n",
      "Penalización por duración del episodio: -  0.33476355999971397\n",
      "Step: 1580, Mean Reward (últimos 10 pasos): 0.41500040888786316\n",
      "Recompensa por acortar distancias: +  0.9156974303625111\n",
      "Penalización por parar muy lejos: -  0.1659334552990243\n",
      "Penalización por duración del episodio: -  0.3351353758278914\n",
      "Recompensa por acortar distancias: +  0.9156974598103085\n",
      "Penalización por duración del episodio: -  0.3352299650310914\n",
      "Recompensa por acortar distancias: +  0.9156974598103085\n",
      "Penalización por duración del episodio: -  0.33547664239597963\n",
      "Recompensa por acortar distancias: +  0.9156974598103085\n",
      "Penalización por duración del episodio: -  0.3355570489048783\n",
      "Recompensa por acortar distancias: +  0.9156974598103085\n",
      "Penalización por duración del episodio: -  0.33569131665806773\n",
      "Recompensa por acortar distancias: +  0.9156974598103085\n",
      "Penalización por duración del episodio: -  0.3358139703097884\n",
      "Recompensa por acortar distancias: +  0.9156974303625111\n",
      "Penalización por duración del episodio: -  0.33592530138216636\n",
      "Recompensa por acortar distancias: +  0.9156974303625111\n",
      "Penalización por parar muy lejos: -  0.1659334552990243\n",
      "Penalización por duración del episodio: -  0.3361685338828904\n",
      "Recompensa por acortar distancias: +  0.9156975187058752\n",
      "Penalización por parar muy lejos: -  0.16593361368479315\n",
      "Penalización por duración del episodio: -  0.3362974253004877\n",
      "Recompensa por acortar distancias: +  0.9156975187058752\n",
      "Penalización por duración del episodio: -  0.3365209505377539\n",
      "steer input from model: 0.25 , throttle:  0.3\n",
      "reward: 0.5791765681681214\n",
      "Step: 1590, Mean Reward (últimos 10 pasos): 0.5791765451431274\n",
      "Recompensa por acortar distancias: +  0.9156975187058752\n",
      "Penalización por duración del episodio: -  0.33664365786892336\n",
      "Recompensa por acortar distancias: +  0.9156975187058752\n",
      "Penalización por duración del episodio: -  0.33674481521561106\n",
      "Recompensa por acortar distancias: +  0.9156975334297612\n",
      "Penalización por parar muy lejos: -  0.16593364008243308\n",
      "Penalización por duración del episodio: -  0.3368339193389489\n",
      "Recompensa por acortar distancias: +  0.9156975334297612\n",
      "Penalización por duración del episodio: -  0.33694258859953397\n",
      "Recompensa por acortar distancias: +  0.9156975334297612\n",
      "Penalización por duración del episodio: -  0.3372291910005283\n",
      "Recompensa por acortar distancias: +  0.9156975481536447\n",
      "Penalización por parar muy lejos: -  0.16593366648007635\n",
      "Penalización por duración del episodio: -  0.3373389035690426\n",
      "Recompensa por acortar distancias: +  0.9156975481536447\n",
      "Penalización por duración del episodio: -  0.33747680588670076\n",
      "Recompensa por acortar distancias: +  0.9156975481536447\n",
      "Penalización por duración del episodio: -  0.3379472364889856\n",
      "Recompensa por acortar distancias: +  0.9156975481536447\n",
      "Penalización por duración del episodio: -  0.33808972103651674\n",
      "Recompensa por acortar distancias: +  0.9156973714668881\n",
      "Penalización por parar muy lejos: -  0.16593334970857904\n",
      "Penalización por duración del episodio: -  0.33830452233208785\n",
      "Step: 1600, Mean Reward (últimos 10 pasos): 0.4114595055580139\n",
      "Recompensa por acortar distancias: +  0.9156973714668881\n",
      "Penalización por duración del episodio: -  0.3384430074697817\n",
      "Recompensa por acortar distancias: +  0.9156973714668881\n",
      "Penalización por duración del episodio: -  0.33865759265188744\n",
      "Recompensa por acortar distancias: +  0.9156973714668881\n",
      "Penalización por duración del episodio: -  0.33900419123202313\n",
      "Recompensa por acortar distancias: +  0.915537147686205\n",
      "Penalización por duración del episodio: -  0.3391050113541571\n",
      "Recompensa por acortar distancias: +  0.9154252807055985\n",
      "Penalización por parar muy lejos: -  0.16544682045336237\n",
      "Penalización por duración del episodio: -  0.33936037004882896\n",
      "Recompensa por acortar distancias: +  0.9152974360202756\n",
      "Penalización por parar muy lejos: -  0.16521910413862323\n",
      "Penalización por duración del episodio: -  0.33970077800567505\n",
      "Recompensa por acortar distancias: +  0.9152974360202756\n",
      "Penalización por parar muy lejos: -  0.16521910413862323\n",
      "Penalización por duración del episodio: -  0.3400535132963167\n",
      "Recompensa por acortar distancias: +  0.9143098055938378\n",
      "Penalización por duración del episodio: -  0.34015064802886225\n",
      "Recompensa por acortar distancias: +  0.9143098055938378\n",
      "Penalización por duración del episodio: -  0.3402862781505029\n",
      "Recompensa por acortar distancias: +  0.9140428585354746\n",
      "Penalización por parar muy lejos: -  0.16301398660407587\n",
      "Penalización por duración del episodio: -  0.34075016458290736\n",
      "steer input from model: 0.05 , throttle:  0.0\n",
      "reward: 0.4102787073484914\n",
      "Step: 1610, Mean Reward (últimos 10 pasos): 0.41027870774269104\n",
      "Recompensa por acortar distancias: +  0.9140428585354746\n",
      "Penalización por duración del episodio: -  0.3410917934102446\n",
      "Recompensa por acortar distancias: +  0.9125064554659478\n",
      "Penalización por parar muy lejos: -  0.16038451853317126\n",
      "Penalización por duración del episodio: -  0.3412236334016988\n",
      "Recompensa por acortar distancias: +  0.9125064554659478\n",
      "Penalización por parar muy lejos: -  0.16038451853317126\n",
      "Penalización por duración del episodio: -  0.3413392078513645\n",
      "Recompensa por acortar distancias: +  0.91198844277873\n",
      "Penalización por parar muy lejos: -  0.15951504346103532\n",
      "Penalización por duración del episodio: -  0.3417851845745076\n",
      "Recompensa por acortar distancias: +  0.9116529804312452\n",
      "Penalización por parar muy lejos: -  0.1589564669534029\n",
      "Penalización por duración del episodio: -  0.3418844084201314\n",
      "Recompensa por acortar distancias: +  0.9116529804312452\n",
      "Penalización por duración del episodio: -  0.3421287185219561\n",
      "Recompensa por acortar distancias: +  0.9116529804312452\n",
      "Penalización por duración del episodio: -  0.3424793117153621\n",
      "Recompensa por acortar distancias: +  0.9095428374777469\n",
      "Penalización por duración del episodio: -  0.3425721403424544\n",
      "Recompensa por acortar distancias: +  0.9095428374777469\n",
      "Penalización por parar muy lejos: -  0.1555216302676512\n",
      "Penalización por duración del episodio: -  0.3426648575016778\n",
      "Recompensa por acortar distancias: +  0.9090655849597874\n",
      "Penalización por parar muy lejos: -  0.15476311201618526\n",
      "Penalización por duración del episodio: -  0.34283545923145065\n",
      "Step: 1620, Mean Reward (últimos 10 pasos): 0.4114670157432556\n",
      "Recompensa por acortar distancias: +  0.9090655849597874\n",
      "Penalización por parar muy lejos: -  0.15476311201618526\n",
      "Penalización por duración del episodio: -  0.34317896102147427\n",
      "Recompensa por acortar distancias: +  0.9090655849597874\n",
      "Penalización por parar muy lejos: -  0.15476311201618526\n",
      "Penalización por duración del episodio: -  0.343541241421764\n",
      "Recompensa por acortar distancias: +  0.9069143379735186\n",
      "Penalización por duración del episodio: -  0.3439036448485487\n",
      "Recompensa por acortar distancias: +  0.9062159912477993\n",
      "Penalización por duración del episodio: -  0.34402162761289\n",
      "Recompensa por acortar distancias: +  0.9062159912477993\n",
      "Penalización por duración del episodio: -  0.3442473171851273\n",
      "Recompensa por acortar distancias: +  0.9062159912477993\n",
      "Penalización por parar muy lejos: -  0.1503681291774914\n",
      "Penalización por duración del episodio: -  0.34461094139705767\n",
      "Recompensa por acortar distancias: +  0.9040031462822715\n",
      "Penalización por parar muy lejos: -  0.1471059097590987\n",
      "Penalización por duración del episodio: -  0.34498291510106893\n",
      "Recompensa por acortar distancias: +  0.9035305279921096\n",
      "Penalización por duración del episodio: -  0.3453403849705064\n",
      "Recompensa por acortar distancias: +  0.9019711301946293\n",
      "Penalización por duración del episodio: -  0.34543729060203404\n",
      "Recompensa por acortar distancias: +  0.9019711301946293\n",
      "Penalización por parar muy lejos: -  0.14421924840118522\n",
      "Penalización por duración del episodio: -  0.345685696502504\n",
      "steer input from model: 0.0 , throttle:  0.0\n",
      "reward: 0.4120661852909401\n",
      "Step: 1630, Mean Reward (últimos 10 pasos): 0.41206619143486023\n",
      "Recompensa por acortar distancias: +  0.9012194989554523\n",
      "Penalización por parar muy lejos: -  0.14317679798689084\n",
      "Penalización por duración del episodio: -  0.34578789568138685\n",
      "Recompensa por acortar distancias: +  0.9007313553131584\n",
      "Penalización por duración del episodio: -  0.3459162068206908\n",
      "Recompensa por acortar distancias: +  0.9007313553131584\n",
      "Penalización por parar muy lejos: -  0.1425069006604193\n",
      "Penalización por duración del episodio: -  0.3460494879477662\n",
      "Recompensa por acortar distancias: +  0.9001654834540704\n",
      "Penalización por duración del episodio: -  0.34638647512551624\n",
      "Recompensa por acortar distancias: +  0.899654034365106\n",
      "Penalización por parar muy lejos: -  0.14104790249358912\n",
      "Penalización por duración del episodio: -  0.34648300067678267\n",
      "Recompensa por acortar distancias: +  0.899654034365106\n",
      "Penalización por duración del episodio: -  0.34656375154141866\n",
      "Recompensa por acortar distancias: +  0.899654034365106\n",
      "Penalización por parar muy lejos: -  0.14104790249358912\n",
      "Penalización por duración del episodio: -  0.346669674525145\n",
      "Recompensa por acortar distancias: +  0.899654034365106\n",
      "Penalización por parar muy lejos: -  0.14104790249358912\n",
      "Penalización por duración del episodio: -  0.3470946745596644\n",
      "Recompensa por acortar distancias: +  0.896794457163181\n",
      "Penalización por parar muy lejos: -  0.1373003343928799\n",
      "Penalización por duración del episodio: -  0.3474555612007589\n",
      "Recompensa por acortar distancias: +  0.896794457163181\n",
      "Penalización por parar muy lejos: -  0.1373003343928799\n",
      "Penalización por duración del episodio: -  0.34781944631116235\n",
      "Step: 1640, Mean Reward (últimos 10 pasos): 0.4116746783256531\n",
      "Recompensa por acortar distancias: +  0.8952556437300937\n",
      "Penalización por duración del episodio: -  0.34792942164594604\n",
      "Recompensa por acortar distancias: +  0.8947087236452248\n",
      "Penalización por parar muy lejos: -  0.1346759715927003\n",
      "Penalización por duración del episodio: -  0.348026094122499\n",
      "Recompensa por acortar distancias: +  0.8943162972941527\n",
      "Penalización por duración del episodio: -  0.3481821834890235\n",
      "Recompensa por acortar distancias: +  0.8938942867263888\n",
      "Penalización por duración del episodio: -  0.3482869953681099\n",
      "Recompensa por acortar distancias: +  0.8938942867263888\n",
      "Penalización por duración del episodio: -  0.34840613261131137\n",
      "Recompensa por acortar distancias: +  0.8933013118054209\n",
      "Penalización por parar muy lejos: -  0.13295444998034953\n",
      "Penalización por duración del episodio: -  0.3484644011067071\n",
      "Recompensa por acortar distancias: +  0.8933013118054209\n",
      "Penalización por duración del episodio: -  0.34861155667033206\n",
      "Recompensa por acortar distancias: +  0.8933013118054209\n",
      "Penalización por duración del episodio: -  0.34889397935754607\n",
      "Recompensa por acortar distancias: +  0.8933013118054209\n",
      "Penalización por parar muy lejos: -  0.13295444998034953\n",
      "Penalización por duración del episodio: -  0.3492485617541726\n",
      "Recompensa por acortar distancias: +  0.8916724674270501\n",
      "Penalización por parar muy lejos: -  0.1310097143565875\n",
      "Penalización por duración del episodio: -  0.34961444621058885\n",
      "steer input from model: -0.05 , throttle:  0.0\n",
      "reward: 0.41104830685987376\n",
      "Step: 1650, Mean Reward (últimos 10 pasos): 0.4110482931137085\n",
      "Recompensa por acortar distancias: +  0.8915322210587394\n",
      "Penalización por parar muy lejos: -  0.1308445993856228\n",
      "Penalización por duración del episodio: -  0.3499755504173284\n",
      "Recompensa por acortar distancias: +  0.8913884267687593\n",
      "Penalización por duración del episodio: -  0.35032924600696635\n",
      "Recompensa por acortar distancias: +  0.8913813309990555\n",
      "Penalización por parar muy lejos: -  0.1306673597298759\n",
      "Penalización por duración del episodio: -  0.3506832853611451\n",
      "Recompensa por acortar distancias: +  0.8913777298671749\n",
      "Penalización por duración del episodio: -  0.35078579528761966\n",
      "Recompensa por acortar distancias: +  0.8913777298671749\n",
      "Penalización por parar muy lejos: -  0.1306631348746654\n",
      "Penalización por duración del episodio: -  0.3510475427998654\n",
      "Recompensa por acortar distancias: +  0.8913777298671749\n",
      "Penalización por duración del episodio: -  0.35116119428915454\n",
      "Recompensa por acortar distancias: +  0.8913777298671749\n",
      "Penalización por parar muy lejos: -  0.1306631348746654\n",
      "Penalización por duración del episodio: -  0.35125962838850766\n",
      "Recompensa por acortar distancias: +  0.8913777298671749\n",
      "Penalización por duración del episodio: -  0.3513333413694974\n",
      "Recompensa por acortar distancias: +  0.8913777298671749\n",
      "Penalización por parar muy lejos: -  0.1306631348746654\n",
      "Penalización por duración del episodio: -  0.3514356178497452\n",
      "Recompensa por acortar distancias: +  0.8913777298671749\n",
      "Penalización por parar muy lejos: -  0.1306631348746654\n",
      "Penalización por duración del episodio: -  0.35159768948911096\n",
      "Step: 1660, Mean Reward (últimos 10 pasos): 0.4091168940067291\n",
      "Recompensa por acortar distancias: +  0.8913763170868041\n",
      "Penalización por parar muy lejos: -  0.13066147746316728\n",
      "Penalización por duración del episodio: -  0.3517748383750542\n",
      "Recompensa por acortar distancias: +  0.891377429768119\n",
      "Penalización por duración del episodio: -  0.35189741723686024\n",
      "Recompensa por acortar distancias: +  0.891377429768119\n",
      "Penalización por parar muy lejos: -  0.1306627828086372\n",
      "Penalización por duración del episodio: -  0.35212120319898704\n",
      "Recompensa por acortar distancias: +  0.891377429768119\n",
      "Penalización por duración del episodio: -  0.3521957277351019\n",
      "Recompensa por acortar distancias: +  0.891377429768119\n",
      "Penalización por parar muy lejos: -  0.1306627828086372\n",
      "Penalización por duración del episodio: -  0.3524744765897401\n",
      "Recompensa por acortar distancias: +  0.8913808046863223\n",
      "Penalización por duración del episodio: -  0.35283064431371824\n",
      "Recompensa por acortar distancias: +  0.8913837224620398\n",
      "Penalización por duración del episodio: -  0.35319314662788986\n",
      "Recompensa por acortar distancias: +  0.8913837224620398\n",
      "Penalización por parar muy lejos: -  0.13067016553119204\n",
      "Penalización por duración del episodio: -  0.35354058222653834\n",
      "Recompensa por acortar distancias: +  0.8913837224620398\n",
      "Penalización por parar muy lejos: -  0.13067016553119204\n",
      "Penalización por duración del episodio: -  0.35390061296243613\n",
      "Recompensa por acortar distancias: +  0.8913909519704969\n",
      "Penalización por duración del episodio: -  0.35426463272827735\n",
      "steer input from model: 0.0 , throttle:  0.7\n",
      "reward: 0.5371263192422195\n",
      "Step: 1670, Mean Reward (últimos 10 pasos): 0.5371263027191162\n",
      "Recompensa por acortar distancias: +  0.8913909519704969\n",
      "Penalización por parar muy lejos: -  0.13067864824571962\n",
      "Penalización por duración del episodio: -  0.3543692000913274\n",
      "Recompensa por acortar distancias: +  0.8913909519704969\n",
      "Penalización por parar muy lejos: -  0.13067864824571962\n",
      "Penalización por duración del episodio: -  0.35462000355934836\n",
      "Recompensa por acortar distancias: +  0.8913909519704969\n",
      "Penalización por duración del episodio: -  0.3547198867438112\n",
      "Recompensa por acortar distancias: +  0.8913959191272965\n",
      "Penalización por duración del episodio: -  0.3548206176600115\n",
      "Recompensa por acortar distancias: +  0.8913959191272965\n",
      "Penalización por parar muy lejos: -  0.13068447699764468\n",
      "Penalización por duración del episodio: -  0.35493995927218386\n",
      "Recompensa por acortar distancias: +  0.8913975948052658\n",
      "Penalización por duración del episodio: -  0.3553581301386604\n",
      "Recompensa por acortar distancias: +  0.8913985180341154\n",
      "Penalización por parar muy lejos: -  0.13068752688802843\n",
      "Penalización por duración del episodio: -  0.35571453457704355\n",
      "Recompensa por acortar distancias: +  0.8913985180341154\n",
      "Penalización por parar muy lejos: -  0.13068752688802843\n",
      "Penalización por duración del episodio: -  0.35582889586171984\n",
      "Recompensa por acortar distancias: +  0.8913985180341154\n",
      "Penalización por parar muy lejos: -  0.13068752688802843\n",
      "Penalización por duración del episodio: -  0.3559353975804668\n",
      "Recompensa por acortar distancias: +  0.8913985180341154\n",
      "Penalización por duración del episodio: -  0.3560698253186024\n",
      "Step: 1680, Mean Reward (últimos 10 pasos): 0.5353286862373352\n",
      "Recompensa por acortar distancias: +  0.8914033371768225\n",
      "Penalización por duración del episodio: -  0.3561782454941323\n",
      "Recompensa por acortar distancias: +  0.8914033371768225\n",
      "Penalización por parar muy lejos: -  0.13069318261746016\n",
      "Penalización por duración del episodio: -  0.3563007060784097\n",
      "Recompensa por acortar distancias: +  0.8914059036167973\n",
      "Penalización por duración del episodio: -  0.35678395708207045\n",
      "Recompensa por acortar distancias: +  0.8914059036167973\n",
      "Penalización por parar muy lejos: -  0.1306961947574667\n",
      "Penalización por duración del episodio: -  0.3569045568705536\n",
      "Recompensa por acortar distancias: +  0.8913858507328759\n",
      "Penalización por duración del episodio: -  0.35713671872546143\n",
      "Recompensa por acortar distancias: +  0.8913867417334354\n",
      "Penalización por duración del episodio: -  0.35731175331716575\n",
      "Recompensa por acortar distancias: +  0.8913867417334354\n",
      "Penalización por duración del episodio: -  0.35749540729812024\n",
      "Recompensa por acortar distancias: +  0.8913899917536077\n",
      "Penalización por duración del episodio: -  0.3578482399608456\n",
      "Recompensa por acortar distancias: +  0.8913899917536077\n",
      "Penalización por parar muy lejos: -  0.13067752152361328\n",
      "Penalización por duración del episodio: -  0.3579429610869822\n",
      "Recompensa por acortar distancias: +  0.8913899917536077\n",
      "Penalización por duración del episodio: -  0.3582017254913314\n",
      "steer input from model: -0.9 , throttle:  1.0\n",
      "reward: 0.5331882662622762\n",
      "Step: 1690, Mean Reward (últimos 10 pasos): 0.5331882834434509\n",
      "Recompensa por acortar distancias: +  0.8913899917536077\n",
      "Penalización por duración del episodio: -  0.35856287213553695\n",
      "Recompensa por acortar distancias: +  0.8913661547499326\n",
      "Penalización por duración del episodio: -  0.3589225005642476\n",
      "Recompensa por acortar distancias: +  0.8913747565459399\n",
      "Penalización por parar muy lejos: -  0.1306596467483545\n",
      "Penalización por duración del episodio: -  0.35904578999799025\n",
      "Recompensa por acortar distancias: +  0.8913747565459399\n",
      "Penalización por duración del episodio: -  0.359161239848219\n",
      "Recompensa por acortar distancias: +  0.8913747565459399\n",
      "Penalización por duración del episodio: -  0.3596393394441839\n",
      "Recompensa por acortar distancias: +  0.8913185039132705\n",
      "Penalización por duración del episodio: -  0.35974023823870205\n",
      "Recompensa por acortar distancias: +  0.8913022343267889\n",
      "Penalización por duración del episodio: -  0.35999332772377035\n",
      "Recompensa por acortar distancias: +  0.8913022343267889\n",
      "Penalización por parar muy lejos: -  0.13057461836316323\n",
      "Penalización por duración del episodio: -  0.3603523813355085\n",
      "Recompensa por acortar distancias: +  0.8913022343267889\n",
      "Penalización por parar muy lejos: -  0.13057461836316323\n",
      "Penalización por duración del episodio: -  0.36073371508186025\n",
      "Recompensa por acortar distancias: +  0.8913022343267889\n",
      "Penalización por parar muy lejos: -  0.13057461836316323\n",
      "Penalización por duración del episodio: -  0.36083442347598\n",
      "Step: 1700, Mean Reward (últimos 10 pasos): 0.399893194437027\n",
      "Recompensa por acortar distancias: +  0.8910863932425267\n",
      "Penalización por duración del episodio: -  0.3611049660298132\n",
      "Recompensa por acortar distancias: +  0.8910030097930784\n",
      "Penalización por duración del episodio: -  0.3614781989878498\n",
      "Recompensa por acortar distancias: +  0.8910030097930784\n",
      "Penalización por parar muy lejos: -  0.13022481540658834\n",
      "Penalización por duración del episodio: -  0.3615781335935761\n",
      "Recompensa por acortar distancias: +  0.8909413342827757\n",
      "Penalización por duración del episodio: -  0.36184080862743495\n",
      "Recompensa por acortar distancias: +  0.890940495673968\n",
      "Penalización por parar muy lejos: -  0.13015194141228753\n",
      "Penalización por duración del episodio: -  0.36199676283409266\n",
      "Recompensa por acortar distancias: +  0.8909402779127443\n",
      "Penalización por parar muy lejos: -  0.13015168768823573\n",
      "Penalización por duración del episodio: -  0.3621957106337262\n",
      "Recompensa por acortar distancias: +  0.8909397728905656\n",
      "Penalización por parar muy lejos: -  0.13015109926598978\n",
      "Penalización por duración del episodio: -  0.36256572285983235\n",
      "Recompensa por acortar distancias: +  0.8909397728905656\n",
      "Penalización por parar muy lejos: -  0.13015109926598978\n",
      "Penalización por duración del episodio: -  0.3629166483557307\n",
      "Recompensa por acortar distancias: +  0.8909397728905656\n",
      "Penalización por parar muy lejos: -  0.13015109926598978\n",
      "Penalización por duración del episodio: -  0.3632845731062104\n",
      "Recompensa por acortar distancias: +  0.8909389713373893\n",
      "Penalización por parar muy lejos: -  0.13015016535275775\n",
      "Penalización por duración del episodio: -  0.3633805973246052\n",
      "steer input from model: 0.1 , throttle:  0.0\n",
      "reward: 0.3974082086600263\n",
      "Step: 1710, Mean Reward (últimos 10 pasos): 0.39740821719169617\n",
      "Recompensa por acortar distancias: +  0.8909389713373893\n",
      "Penalización por duración del episodio: -  0.3636573476044572\n",
      "Recompensa por acortar distancias: +  0.8909389713373893\n",
      "Penalización por duración del episodio: -  0.36373934357412635\n",
      "Recompensa por acortar distancias: +  0.8909391705678523\n",
      "Penalización por parar muy lejos: -  0.130150397480948\n",
      "Penalización por duración del episodio: -  0.3640089415785226\n",
      "Recompensa por acortar distancias: +  0.8909394161305417\n",
      "Penalización por parar muy lejos: -  0.13015068359292264\n",
      "Penalización por duración del episodio: -  0.36413015386051917\n",
      "Recompensa por acortar distancias: +  0.8909394809960768\n",
      "Penalización por duración del episodio: -  0.3643730166819574\n",
      "Recompensa por acortar distancias: +  0.8909396616927459\n",
      "Penalización por parar muy lejos: -  0.13015096970543216\n",
      "Penalización por duración del episodio: -  0.3644656239851021\n",
      "Recompensa por acortar distancias: +  0.8909398284894381\n",
      "Penalización por duración del episodio: -  0.3647351865496264\n",
      "Recompensa por acortar distancias: +  0.8909398284894381\n",
      "Penalización por duración del episodio: -  0.36509645405355234\n",
      "Recompensa por acortar distancias: +  0.8909398284894381\n",
      "Penalización por parar muy lejos: -  0.13015116404630966\n",
      "Penalización por duración del episodio: -  0.3654720663098355\n",
      "Recompensa por acortar distancias: +  0.8909226889590125\n",
      "Penalización por parar muy lejos: -  0.13013119681107374\n",
      "Penalización por duración del episodio: -  0.3658259714968007\n",
      "Step: 1720, Mean Reward (últimos 10 pasos): 0.3949655294418335\n",
      "Recompensa por acortar distancias: +  0.8909145052622374\n",
      "Penalización por parar muy lejos: -  0.13012166484598217\n",
      "Penalización por duración del episodio: -  0.366179429531397\n",
      "Recompensa por acortar distancias: +  0.8909145052622374\n",
      "Penalización por duración del episodio: -  0.3665518700854465\n",
      "Recompensa por acortar distancias: +  0.8908929451760763\n",
      "Penalización por parar muy lejos: -  0.13009655857051605\n",
      "Penalización por duración del episodio: -  0.36664896928519525\n",
      "Recompensa por acortar distancias: +  0.8908930239708164\n",
      "Penalización por duración del episodio: -  0.3667542632073843\n",
      "Recompensa por acortar distancias: +  0.8908930239708164\n",
      "Penalización por duración del episodio: -  0.3669207373821212\n",
      "Recompensa por acortar distancias: +  0.8908930239708164\n",
      "Penalización por parar muy lejos: -  0.13009665030993814\n",
      "Penalización por duración del episodio: -  0.3672770451499406\n",
      "Recompensa por acortar distancias: +  0.8908930239708164\n",
      "Penalización por parar muy lejos: -  0.13009665030993814\n",
      "Penalización por duración del episodio: -  0.36762908044611764\n",
      "Recompensa por acortar distancias: +  0.8908927736814694\n",
      "Penalización por duración del episodio: -  0.3677830481393093\n",
      "Recompensa por acortar distancias: +  0.8908927736814694\n",
      "Penalización por duración del episodio: -  0.3679885208098784\n",
      "Recompensa por acortar distancias: +  0.8908929637160197\n",
      "Penalización por duración del episodio: -  0.36836279154722673\n",
      "steer input from model: -0.1 , throttle:  0.7\n",
      "reward: 0.5225301721687929\n",
      "Step: 1730, Mean Reward (últimos 10 pasos): 0.522530198097229\n",
      "Recompensa por acortar distancias: +  0.8908990585725494\n",
      "Penalización por duración del episodio: -  0.36873801445787363\n",
      "Recompensa por acortar distancias: +  0.8908786129728276\n",
      "Penalización por duración del episodio: -  0.3688567632787824\n",
      "Recompensa por acortar distancias: +  0.8908650950605057\n",
      "Penalización por duración del episodio: -  0.369112191436594\n",
      "Recompensa por acortar distancias: +  0.8908687342863787\n",
      "Penalización por duración del episodio: -  0.3692173861278713\n",
      "Recompensa por acortar distancias: +  0.8908687342863787\n",
      "Penalización por parar muy lejos: -  0.13006837558714762\n",
      "Penalización por duración del episodio: -  0.36947642256846186\n",
      "Recompensa por acortar distancias: +  0.8908687342863787\n",
      "Penalización por parar muy lejos: -  0.13006837558714762\n",
      "Penalización por duración del episodio: -  0.36955933523043555\n",
      "Recompensa por acortar distancias: +  0.8908687342863787\n",
      "Penalización por duración del episodio: -  0.3698595781959734\n",
      "Recompensa por acortar distancias: +  0.8908687342863787\n",
      "Penalización por duración del episodio: -  0.36998347263548664\n",
      "Recompensa por acortar distancias: +  0.8908265683683185\n",
      "Penalización por parar muy lejos: -  0.13001931731959215\n",
      "Penalización por duración del episodio: -  0.3702449157805928\n",
      "Recompensa por acortar distancias: +  0.8908061479546785\n",
      "Penalización por duración del episodio: -  0.3705999925992716\n",
      "Step: 1740, Mean Reward (últimos 10 pasos): 0.5202061533927917\n",
      "Recompensa por acortar distancias: +  0.8908061479546785\n",
      "Penalización por duración del episodio: -  0.3706731037271715\n",
      "Recompensa por acortar distancias: +  0.8908061479546785\n",
      "Penalización por duración del episodio: -  0.3709668592710999\n",
      "Recompensa por acortar distancias: +  0.8907770165147407\n",
      "Penalización por parar muy lejos: -  0.12996170717606845\n",
      "Penalización por duración del episodio: -  0.371089815596024\n",
      "Recompensa por acortar distancias: +  0.8907698903349506\n",
      "Penalización por duración del episodio: -  0.37133028493986403\n",
      "Recompensa por acortar distancias: +  0.8907476508766368\n",
      "Penalización por duración del episodio: -  0.371418250176997\n",
      "Recompensa por acortar distancias: +  0.8907284056445428\n",
      "Penalización por duración del episodio: -  0.37152497874801427\n",
      "Recompensa por acortar distancias: +  0.8907284056445428\n",
      "Penalización por duración del episodio: -  0.3716700702133378\n",
      "Recompensa por acortar distancias: +  0.8907284056445428\n",
      "Penalización por duración del episodio: -  0.37205341753934423\n",
      "Recompensa por acortar distancias: +  0.8907284056445428\n",
      "Penalización por parar muy lejos: -  0.1299052344079062\n",
      "Penalización por duración del episodio: -  0.3724197070236149\n",
      "Recompensa por acortar distancias: +  0.8905576440587155\n",
      "Penalización por parar muy lejos: -  0.12970719506004832\n",
      "Penalización por duración del episodio: -  0.37255044478240956\n",
      "steer input from model: 0.0 , throttle:  0.0\n",
      "reward: 0.3883000042162576\n",
      "Step: 1750, Mean Reward (últimos 10 pasos): 0.38830000162124634\n",
      "Recompensa por acortar distancias: +  0.8905576440587155\n",
      "Penalización por duración del episodio: -  0.3726675171481857\n",
      "Recompensa por acortar distancias: +  0.8904959893004412\n",
      "Penalización por duración del episodio: -  0.3727607565581065\n",
      "Recompensa por acortar distancias: +  0.8904959893004412\n",
      "Penalización por duración del episodio: -  0.3731416552596028\n",
      "Recompensa por acortar distancias: +  0.8904959893004412\n",
      "Penalización por parar muy lejos: -  0.12963582112946967\n",
      "Penalización por duración del episodio: -  0.37351605000195254\n",
      "Recompensa por acortar distancias: +  0.8903212354791981\n",
      "Penalización por parar muy lejos: -  0.12943389201439365\n",
      "Penalización por duración del episodio: -  0.37386930394750467\n",
      "Recompensa por acortar distancias: +  0.8903174126123986\n",
      "Penalización por duración del episodio: -  0.3742492357479809\n",
      "Recompensa por acortar distancias: +  0.8903174126123986\n",
      "Penalización por parar muy lejos: -  0.12942948081474814\n",
      "Penalización por duración del episodio: -  0.3743230518438298\n",
      "Recompensa por acortar distancias: +  0.8903174126123986\n",
      "Penalización por duración del episodio: -  0.37442305350319693\n",
      "Recompensa por acortar distancias: +  0.8903174126123986\n",
      "Penalización por duración del episodio: -  0.37461619627612003\n",
      "Recompensa por acortar distancias: +  0.8903174126123986\n",
      "Penalización por duración del episodio: -  0.3749730529633572\n",
      "Step: 1760, Mean Reward (últimos 10 pasos): 0.5153443813323975\n",
      "Recompensa por acortar distancias: +  0.8902760287730961\n",
      "Penalización por parar muy lejos: -  0.1293817448864616\n",
      "Penalización por duración del episodio: -  0.3753471452318104\n",
      "Recompensa por acortar distancias: +  0.8902760287730961\n",
      "Penalización por duración del episodio: -  0.3755108235376885\n",
      "Recompensa por acortar distancias: +  0.8902503234787235\n",
      "Penalización por parar muy lejos: -  0.12935210952634862\n",
      "Penalización por duración del episodio: -  0.37563084702931465\n",
      "Recompensa por acortar distancias: +  0.8902503234787235\n",
      "Penalización por duración del episodio: -  0.37575669072768914\n",
      "Recompensa por acortar distancias: +  0.8902501743931167\n",
      "Penalización por parar muy lejos: -  0.12935193768174783\n",
      "Penalización por duración del episodio: -  0.37585784646378523\n",
      "Recompensa por acortar distancias: +  0.8902501743931167\n",
      "Penalización por duración del episodio: -  0.37596531707257275\n",
      "Recompensa por acortar distancias: +  0.8902513018486115\n",
      "Penalización por duración del episodio: -  0.37644464219462065\n",
      "Recompensa por acortar distancias: +  0.8902297619655885\n",
      "Penalización por duración del episodio: -  0.3766032713342364\n",
      "Recompensa por acortar distancias: +  0.8902297619655885\n",
      "Penalización por duración del episodio: -  0.3768073923231802\n",
      "Recompensa por acortar distancias: +  0.8902297619655885\n",
      "Penalización por duración del episodio: -  0.3771849210669102\n",
      "steer input from model: -0.9 , throttle:  0.3\n",
      "reward: 0.5130448408986783\n",
      "Step: 1770, Mean Reward (últimos 10 pasos): 0.5130448341369629\n",
      "Recompensa por acortar distancias: +  0.8902297619655885\n",
      "Penalización por parar muy lejos: -  0.1293284129167631\n",
      "Penalización por duración del episodio: -  0.37755434563581974\n",
      "Recompensa por acortar distancias: +  0.8901619964364555\n",
      "Penalización por parar muy lejos: -  0.12925036858952837\n",
      "Penalización por duración del episodio: -  0.3779315635471456\n",
      "Recompensa por acortar distancias: +  0.8901619964364555\n",
      "Penalización por parar muy lejos: -  0.12925036858952837\n",
      "Penalización por duración del episodio: -  0.37831773293334137\n",
      "Recompensa por acortar distancias: +  0.890160569792274\n",
      "Penalización por duración del episodio: -  0.37844297218632683\n",
      "Recompensa por acortar distancias: +  0.890160569792274\n",
      "Penalización por parar muy lejos: -  0.12924872643410973\n",
      "Penalización por duración del episodio: -  0.3786825830478173\n",
      "Recompensa por acortar distancias: +  0.890160569792274\n",
      "Penalización por duración del episodio: -  0.3790571159874542\n",
      "Recompensa por acortar distancias: +  0.890160569792274\n",
      "Penalización por parar muy lejos: -  0.12924872643410973\n",
      "Penalización por duración del episodio: -  0.3794236193600072\n",
      "Recompensa por acortar distancias: +  0.890160042955512\n",
      "Penalización por duración del episodio: -  0.3797965277654373\n",
      "Recompensa por acortar distancias: +  0.890160042955512\n",
      "Penalización por duración del episodio: -  0.37987996226310056\n",
      "Recompensa por acortar distancias: +  0.890160042955512\n",
      "Penalización por duración del episodio: -  0.3800052621326499\n",
      "Step: 1780, Mean Reward (últimos 10 pasos): 0.5101547837257385\n",
      "Recompensa por acortar distancias: +  0.890160257420302\n",
      "Penalización por duración del episodio: -  0.38016119596584386\n",
      "Recompensa por acortar distancias: +  0.890160257420302\n",
      "Penalización por parar muy lejos: -  0.12924836687957533\n",
      "Penalización por duración del episodio: -  0.38029299332895106\n",
      "Recompensa por acortar distancias: +  0.89016231346629\n",
      "Penalización por parar muy lejos: -  0.12925073351536756\n",
      "Penalización por duración del episodio: -  0.3804397508860039\n",
      "Recompensa por acortar distancias: +  0.8901333392212852\n",
      "Penalización por duración del episodio: -  0.38089666700169833\n",
      "Recompensa por acortar distancias: +  0.8901043442836511\n",
      "Penalización por duración del episodio: -  0.3810046707551681\n",
      "Recompensa por acortar distancias: +  0.8901043442836511\n",
      "Penalización por duración del episodio: -  0.3812684013840691\n",
      "Recompensa por acortar distancias: +  0.8901043442836511\n",
      "Penalización por duración del episodio: -  0.38140241082450516\n",
      "Recompensa por acortar distancias: +  0.8901043442836511\n",
      "Penalización por duración del episodio: -  0.38164428096892367\n",
      "Recompensa por acortar distancias: +  0.8901043442836511\n",
      "Penalización por duración del episodio: -  0.3820215800175324\n",
      "Recompensa por acortar distancias: +  0.8900107284115807\n",
      "Penalización por duración del episodio: -  0.3821348960172407\n",
      "steer input from model: 0.05 , throttle:  0.7\n",
      "reward: 0.50787583239434\n",
      "Step: 1790, Mean Reward (últimos 10 pasos): 0.5078758597373962\n",
      "Recompensa por acortar distancias: +  0.8900107284115807\n",
      "Penalización por parar muy lejos: -  0.12907645257102873\n",
      "Penalización por duración del episodio: -  0.3822446386076272\n",
      "Recompensa por acortar distancias: +  0.8900107284115807\n",
      "Penalización por duración del episodio: -  0.38237072737075817\n",
      "Recompensa por acortar distancias: +  0.8900107284115807\n",
      "Penalización por parar muy lejos: -  0.12907645257102873\n",
      "Penalización por duración del episodio: -  0.3827706958749041\n",
      "Recompensa por acortar distancias: +  0.8899699902577629\n",
      "Penalización por duración del episodio: -  0.3831360104863181\n",
      "Recompensa por acortar distancias: +  0.8899696027009573\n",
      "Penalización por duración del episodio: -  0.383512471656593\n",
      "Recompensa por acortar distancias: +  0.8899696027009573\n",
      "Penalización por duración del episodio: -  0.38388694661650996\n",
      "Recompensa por acortar distancias: +  0.8899696027009573\n",
      "Penalización por duración del episodio: -  0.38426795069304254\n",
      "Recompensa por acortar distancias: +  0.8899013460356912\n",
      "Penalización por parar muy lejos: -  0.12895094794476059\n",
      "Penalización por duración del episodio: -  0.3846283468896178\n",
      "Recompensa por acortar distancias: +  0.8899013460356912\n",
      "Penalización por duración del episodio: -  0.3850058672741363\n",
      "Recompensa por acortar distancias: +  0.8898278308071832\n",
      "Penalización por duración del episodio: -  0.38511258379327773\n",
      "Step: 1800, Mean Reward (últimos 10 pasos): 0.5047152638435364\n",
      "Recompensa por acortar distancias: +  0.8898122118719759\n",
      "Penalización por duración del episodio: -  0.3852490398639844\n",
      "Recompensa por acortar distancias: +  0.8898122118719759\n",
      "Penalización por duración del episodio: -  0.3854033030232198\n",
      "Recompensa por acortar distancias: +  0.8897855275691647\n",
      "Penalización por parar muy lejos: -  0.1288182908113583\n",
      "Penalización por duración del episodio: -  0.3854914677756733\n",
      "Recompensa por acortar distancias: +  0.8897423447075643\n",
      "Penalización por duración del episodio: -  0.3857323086127425\n",
      "Recompensa por acortar distancias: +  0.8897423447075643\n",
      "Penalización por parar muy lejos: -  0.12876889066505476\n",
      "Penalización por duración del episodio: -  0.38581899292845845\n",
      "Recompensa por acortar distancias: +  0.8897423447075643\n",
      "Penalización por parar muy lejos: -  0.12876889066505476\n",
      "Penalización por duración del episodio: -  0.3861025583648357\n",
      "Recompensa por acortar distancias: +  0.8897423447075643\n",
      "Penalización por parar muy lejos: -  0.12876889066505476\n",
      "Penalización por duración del episodio: -  0.3864722841402717\n",
      "Recompensa por acortar distancias: +  0.889699502659483\n",
      "Penalización por parar muy lejos: -  0.1287199130948048\n",
      "Penalización por duración del episodio: -  0.3865751940024373\n",
      "Recompensa por acortar distancias: +  0.8896992265741109\n",
      "Penalización por duración del episodio: -  0.3868352415690576\n",
      "Recompensa por acortar distancias: +  0.8896992265741109\n",
      "Penalización por duración del episodio: -  0.3872008478130801\n",
      "steer input from model: -0.9 , throttle:  0.3\n",
      "reward: 0.5024983787610309\n",
      "Step: 1810, Mean Reward (últimos 10 pasos): 0.5024983882904053\n",
      "Recompensa por acortar distancias: +  0.8896987024781794\n",
      "Penalización por parar muy lejos: -  0.12871899862701514\n",
      "Penalización por duración del episodio: -  0.3873611032859921\n",
      "Recompensa por acortar distancias: +  0.8896895210866821\n",
      "Penalización por duración del episodio: -  0.3875676168013497\n",
      "Recompensa por acortar distancias: +  0.8896923289227273\n",
      "Penalización por parar muy lejos: -  0.12871171516896557\n",
      "Penalización por duración del episodio: -  0.38792922587213546\n",
      "Recompensa por acortar distancias: +  0.8896740066639341\n",
      "Penalización por parar muy lejos: -  0.1286907811936691\n",
      "Penalización por duración del episodio: -  0.3880265488348995\n",
      "Recompensa por acortar distancias: +  0.8896740066639341\n",
      "Penalización por parar muy lejos: -  0.1286907811936691\n",
      "Penalización por duración del episodio: -  0.38816003355802564\n",
      "Recompensa por acortar distancias: +  0.8896740066639341\n",
      "Penalización por parar muy lejos: -  0.1286907811936691\n",
      "Penalización por duración del episodio: -  0.388306390057105\n",
      "Recompensa por acortar distancias: +  0.8896740066639341\n",
      "Penalización por parar muy lejos: -  0.1286907811936691\n",
      "Penalización por duración del episodio: -  0.38866976351687776\n",
      "Recompensa por acortar distancias: +  0.8896740066639341\n",
      "Penalización por duración del episodio: -  0.3887784626084435\n",
      "Recompensa por acortar distancias: +  0.8896740066639341\n",
      "Penalización por duración del episodio: -  0.3890385423037062\n",
      "Recompensa por acortar distancias: +  0.8895526849428246\n",
      "Penalización por parar muy lejos: -  0.1285523157966744\n",
      "Penalización por duración del episodio: -  0.3894208153706851\n",
      "Step: 1820, Mean Reward (últimos 10 pasos): 0.3715795576572418\n",
      "Recompensa por acortar distancias: +  0.8895526849428246\n",
      "Penalización por duración del episodio: -  0.38979919237364513\n",
      "Recompensa por acortar distancias: +  0.8894508183197335\n",
      "Penalización por duración del episodio: -  0.3901611883731721\n",
      "Recompensa por acortar distancias: +  0.88935286262841\n",
      "Penalización por parar muy lejos: -  0.12832482349199978\n",
      "Penalización por duración del episodio: -  0.3905256660834526\n",
      "Recompensa por acortar distancias: +  0.88935286262841\n",
      "Penalización por duración del episodio: -  0.3908979635726952\n",
      "Recompensa por acortar distancias: +  0.88935286262841\n",
      "Penalización por duración del episodio: -  0.39100890267127775\n",
      "Recompensa por acortar distancias: +  0.8890841787615655\n",
      "Penalización por duración del episodio: -  0.3912598203012683\n",
      "Recompensa por acortar distancias: +  0.8889922962610425\n",
      "Penalización por duración del episodio: -  0.3916435983078103\n",
      "Recompensa por acortar distancias: +  0.8889922962610425\n",
      "Penalización por duración del episodio: -  0.3917274575568936\n",
      "Recompensa por acortar distancias: +  0.8889922962610425\n",
      "Penalización por duración del episodio: -  0.39184634958872816\n",
      "Recompensa por acortar distancias: +  0.8887312164046428\n",
      "Penalización por duración del episodio: -  0.39196938541539944\n",
      "steer input from model: 0.25 , throttle:  0.7\n",
      "reward: 0.49676183098924337\n",
      "Step: 1830, Mean Reward (últimos 10 pasos): 0.49676182866096497\n",
      "Recompensa por acortar distancias: +  0.8887312164046428\n",
      "Penalización por parar muy lejos: -  0.12762157073030966\n",
      "Penalización por duración del episodio: -  0.39239499714078563\n",
      "Recompensa por acortar distancias: +  0.88850483878709\n",
      "Penalización por duración del episodio: -  0.3927758209021585\n",
      "Recompensa por acortar distancias: +  0.8883454878812991\n",
      "Penalización por parar muy lejos: -  0.127188579054169\n",
      "Penalización por duración del episodio: -  0.39314978989949545\n",
      "Recompensa por acortar distancias: +  0.8883454878812991\n",
      "Penalización por parar muy lejos: -  0.127188579054169\n",
      "Penalización por duración del episodio: -  0.39351870616731555\n",
      "Recompensa por acortar distancias: +  0.888282397797284\n",
      "Penalización por duración del episodio: -  0.3936066222645638\n",
      "Recompensa por acortar distancias: +  0.888281375685863\n",
      "Penalización por duración del episodio: -  0.3939018886520895\n",
      "Recompensa por acortar distancias: +  0.888281375685863\n",
      "Penalización por duración del episodio: -  0.3942733012507896\n",
      "Recompensa por acortar distancias: +  0.8882571218013361\n",
      "Penalización por duración del episodio: -  0.39437845644754355\n",
      "Recompensa por acortar distancias: +  0.8882571218013361\n",
      "Penalización por duración del episodio: -  0.3946406951700341\n",
      "Recompensa por acortar distancias: +  0.888242037113383\n",
      "Penalización por parar muy lejos: -  0.12707288809045253\n",
      "Penalización por duración del episodio: -  0.39476022795644095\n",
      "Step: 1840, Mean Reward (últimos 10 pasos): 0.36640891432762146\n",
      "Recompensa por acortar distancias: +  0.888242037113383\n",
      "Penalización por parar muy lejos: -  0.12707288809045253\n",
      "Penalización por duración del episodio: -  0.39489418684700917\n",
      "Recompensa por acortar distancias: +  0.8882523793332104\n",
      "Penalización por parar muy lejos: -  0.1270844457338272\n",
      "Penalización por duración del episodio: -  0.39501620201373894\n",
      "Recompensa por acortar distancias: +  0.8882523793332104\n",
      "Penalización por parar muy lejos: -  0.1270844457338272\n",
      "Penalización por duración del episodio: -  0.39515925718187456\n",
      "Recompensa por acortar distancias: +  0.888248895731562\n",
      "Penalización por parar muy lejos: -  0.1270805525325891\n",
      "Penalización por duración del episodio: -  0.3952847885508703\n",
      "Recompensa por acortar distancias: +  0.888248895731562\n",
      "Penalización por duración del episodio: -  0.3957585674471327\n",
      "Recompensa por acortar distancias: +  0.888248895731562\n",
      "Penalización por duración del episodio: -  0.39612417610131123\n",
      "Recompensa por acortar distancias: +  0.8882880760451993\n",
      "Penalización por parar muy lejos: -  0.1271243516311727\n",
      "Penalización por duración del episodio: -  0.3962601884929229\n",
      "Recompensa por acortar distancias: +  0.8883126457546394\n",
      "Penalización por parar muy lejos: -  0.12715183118273032\n",
      "Penalización por duración del episodio: -  0.3965034731929582\n",
      "Recompensa por acortar distancias: +  0.8883126457546394\n",
      "Penalización por parar muy lejos: -  0.12715183118273032\n",
      "Penalización por duración del episodio: -  0.3966089193196844\n",
      "Recompensa por acortar distancias: +  0.8883126457546394\n",
      "Penalización por parar muy lejos: -  0.12715183118273032\n",
      "Penalización por duración del episodio: -  0.3968851661435254\n",
      "steer input from model: 0.1 , throttle:  0.0\n",
      "reward: 0.36427564842838367\n",
      "Step: 1850, Mean Reward (últimos 10 pasos): 0.36427563428878784\n",
      "Recompensa por acortar distancias: +  0.8883144150833854\n",
      "Penalización por parar muy lejos: -  0.12715381045666396\n",
      "Penalización por duración del episodio: -  0.3972510856566568\n",
      "Recompensa por acortar distancias: +  0.8883148597771309\n",
      "Penalización por parar muy lejos: -  0.12715430792537463\n",
      "Penalización por duración del episodio: -  0.39762183133256196\n",
      "Recompensa por acortar distancias: +  0.8883151057772615\n",
      "Penalización por duración del episodio: -  0.3980109057520943\n",
      "Recompensa por acortar distancias: +  0.8883151057772615\n",
      "Penalización por parar muy lejos: -  0.12715458312154596\n",
      "Penalización por duración del episodio: -  0.3981679976631528\n",
      "Recompensa por acortar distancias: +  0.8883151057772615\n",
      "Penalización por duración del episodio: -  0.39837565189829705\n",
      "Recompensa por acortar distancias: +  0.8883154936995816\n",
      "Penalización por parar muy lejos: -  0.12715501708577298\n",
      "Penalización por duración del episodio: -  0.3987580305775635\n",
      "Recompensa por acortar distancias: +  0.8882894198602826\n",
      "Penalización por duración del episodio: -  0.39910959346637404\n",
      "Recompensa por acortar distancias: +  0.8882700088773499\n",
      "Penalización por duración del episodio: -  0.39925962607383503\n",
      "Recompensa por acortar distancias: +  0.8882357177709453\n",
      "Penalización por parar muy lejos: -  0.12706582699748376\n",
      "Penalización por duración del episodio: -  0.39936744188083567\n",
      "Recompensa por acortar distancias: +  0.8882338100728608\n",
      "Penalización por duración del episodio: -  0.39984861136156147\n",
      "Step: 1860, Mean Reward (últimos 10 pasos): 0.4883852005004883\n",
      "Recompensa por acortar distancias: +  0.88821024789161\n",
      "Penalización por duración del episodio: -  0.3999804207376577\n",
      "Recompensa por acortar distancias: +  0.88821024789161\n",
      "Penalización por duración del episodio: -  0.4001015663081503\n",
      "Recompensa por acortar distancias: +  0.88821024789161\n",
      "Penalización por parar muy lejos: -  0.12703737445508462\n",
      "Penalización por duración del episodio: -  0.4005911081278491\n",
      "Recompensa por acortar distancias: +  0.88821024789161\n",
      "Penalización por parar muy lejos: -  0.12703737445508462\n",
      "Penalización por duración del episodio: -  0.4007224491917696\n",
      "Recompensa por acortar distancias: +  0.88821024789161\n",
      "Penalización por parar muy lejos: -  0.12703737445508462\n",
      "Penalización por duración del episodio: -  0.40083600220686255\n",
      "Recompensa por acortar distancias: +  0.8881014846427259\n",
      "Penalización por duración del episodio: -  0.40134653809535675\n",
      "Recompensa por acortar distancias: +  0.8880571750957725\n",
      "Penalización por parar muy lejos: -  0.12686660976319875\n",
      "Penalización por duración del episodio: -  0.4017146792405553\n",
      "Recompensa por acortar distancias: +  0.888034722992367\n",
      "Penalización por duración del episodio: -  0.40182400396648743\n",
      "Recompensa por acortar distancias: +  0.8880344811936548\n",
      "Penalización por duración del episodio: -  0.4020783744335826\n",
      "Recompensa por acortar distancias: +  0.8880343057707742\n",
      "Penalización por parar muy lejos: -  0.12684113160409244\n",
      "Penalización por duración del episodio: -  0.4022366869619448\n",
      "steer input from model: -0.25 , throttle:  0.0\n",
      "reward: 0.35895648720473694\n",
      "Step: 1870, Mean Reward (últimos 10 pasos): 0.3589564859867096\n",
      "Recompensa por acortar distancias: +  0.8880372310344451\n",
      "Penalización por parar muy lejos: -  0.12684439007164205\n",
      "Penalización por duración del episodio: -  0.4024579619726075\n",
      "Recompensa por acortar distancias: +  0.8880372310344451\n",
      "Penalización por parar muy lejos: -  0.12684439007164205\n",
      "Penalización por duración del episodio: -  0.4028298950098514\n",
      "Recompensa por acortar distancias: +  0.8880372310344451\n",
      "Penalización por parar muy lejos: -  0.12684439007164205\n",
      "Penalización por duración del episodio: -  0.4032008268461071\n",
      "Recompensa por acortar distancias: +  0.8879552367277536\n",
      "Penalización por duración del episodio: -  0.403584982580357\n",
      "Recompensa por acortar distancias: +  0.88791786210165\n",
      "Penalización por parar muy lejos: -  0.12671154277682914\n",
      "Penalización por duración del episodio: -  0.40368101418236\n",
      "Recompensa por acortar distancias: +  0.88791786210165\n",
      "Penalización por duración del episodio: -  0.40379513340143164\n",
      "Recompensa por acortar distancias: +  0.88791786210165\n",
      "Penalización por duración del episodio: -  0.40388007383083946\n",
      "Recompensa por acortar distancias: +  0.88791786210165\n",
      "Penalización por parar muy lejos: -  0.12671154277682914\n",
      "Penalización por duración del episodio: -  0.4040370031921168\n",
      "Recompensa por acortar distancias: +  0.8878378712472614\n",
      "Penalización por duración del episodio: -  0.404347015993794\n",
      "Recompensa por acortar distancias: +  0.887789014858695\n",
      "Penalización por parar muy lejos: -  0.12656841891972845\n",
      "Penalización por duración del episodio: -  0.404484132916034\n",
      "Step: 1880, Mean Reward (últimos 10 pasos): 0.3567364513874054\n",
      "Recompensa por acortar distancias: +  0.8877675800032875\n",
      "Penalización por parar muy lejos: -  0.12654463636335309\n",
      "Penalización por duración del episodio: -  0.40471469315758274\n",
      "Recompensa por acortar distancias: +  0.8877528177075086\n",
      "Penalización por duración del episodio: -  0.40484990833816675\n",
      "Recompensa por acortar distancias: +  0.8877528177075086\n",
      "Penalización por parar muy lejos: -  0.1265282617228719\n",
      "Penalización por duración del episodio: -  0.40498847594012993\n",
      "Recompensa por acortar distancias: +  0.8877528177075086\n",
      "Penalización por duración del episodio: -  0.4051230538220831\n",
      "Recompensa por acortar distancias: +  0.8877528177075086\n",
      "Penalización por duración del episodio: -  0.4054631501174146\n",
      "Recompensa por acortar distancias: +  0.8877528177075086\n",
      "Penalización por parar muy lejos: -  0.1265282617228719\n",
      "Penalización por duración del episodio: -  0.40560258354157086\n",
      "Recompensa por acortar distancias: +  0.8877528177075086\n",
      "Penalización por parar muy lejos: -  0.1265282617228719\n",
      "Penalización por duración del episodio: -  0.4058421601717354\n",
      "Recompensa por acortar distancias: +  0.8877528177075086\n",
      "Penalización por duración del episodio: -  0.40600301255202315\n",
      "Recompensa por acortar distancias: +  0.8877497291465715\n",
      "Penalización por duración del episodio: -  0.4061199345413016\n",
      "Recompensa por acortar distancias: +  0.8877497291465715\n",
      "Penalización por duración del episodio: -  0.4062680257010212\n",
      "steer input from model: -0.05 , throttle:  0.3\n",
      "reward: 0.48148170344555025\n",
      "Step: 1890, Mean Reward (últimos 10 pasos): 0.4814817011356354\n",
      "Recompensa por acortar distancias: +  0.8877496721262869\n",
      "Penalización por parar muy lejos: -  0.12652477305713616\n",
      "Penalización por duración del episodio: -  0.4064141725925602\n",
      "Recompensa por acortar distancias: +  0.8877496721262869\n",
      "Penalización por parar muy lejos: -  0.12652477305713616\n",
      "Penalización por duración del episodio: -  0.40651248929715206\n",
      "Recompensa por acortar distancias: +  0.8877496721262869\n",
      "Penalización por duración del episodio: -  0.40660863328773716\n",
      "Recompensa por acortar distancias: +  0.8877496721262869\n",
      "Penalización por parar muy lejos: -  0.12652477305713616\n",
      "Penalización por duración del episodio: -  0.4067646739787635\n",
      "Recompensa por acortar distancias: +  0.8877496721262869\n",
      "Penalización por duración del episodio: -  0.4068440419625027\n",
      "Recompensa por acortar distancias: +  0.8877496721262869\n",
      "Penalización por parar muy lejos: -  0.12652477305713616\n",
      "Penalización por duración del episodio: -  0.40695401449881974\n",
      "Recompensa por acortar distancias: +  0.8877496721262869\n",
      "Penalización por parar muy lejos: -  0.12652477305713616\n",
      "Penalización por duración del episodio: -  0.407111345579\n",
      "Recompensa por acortar distancias: +  0.8877496531195199\n",
      "Penalización por parar muy lejos: -  0.12652475197783486\n",
      "Penalización por duración del episodio: -  0.4073649130602611\n",
      "Recompensa por acortar distancias: +  0.8877496388644426\n",
      "Penalización por duración del episodio: -  0.4075177922089109\n",
      "Recompensa por acortar distancias: +  0.8877496388644426\n",
      "Penalización por duración del episodio: -  0.40774085438315494\n",
      "Step: 1900, Mean Reward (últimos 10 pasos): 0.4800087809562683\n",
      "Recompensa por acortar distancias: +  0.8877496388644426\n",
      "Penalización por parar muy lejos: -  0.1265247361683609\n",
      "Penalización por duración del episodio: -  0.40811919588252454\n",
      "Recompensa por acortar distancias: +  0.8877496388644426\n",
      "Penalización por duración del episodio: -  0.40849924782228425\n",
      "Recompensa por acortar distancias: +  0.8877496958847418\n",
      "Penalización por duración del episodio: -  0.4085833762116105\n",
      "Recompensa por acortar distancias: +  0.8877496958847418\n",
      "Penalización por parar muy lejos: -  0.12652479940626696\n",
      "Penalización por duración del episodio: -  0.40871669751889284\n",
      "Recompensa por acortar distancias: +  0.8877537252551488\n",
      "Penalización por parar muy lejos: -  0.1265292682867355\n",
      "Penalización por duración del episodio: -  0.40888371954948555\n",
      "Recompensa por acortar distancias: +  0.8877537252551488\n",
      "Penalización por duración del episodio: -  0.40924985747101256\n",
      "Recompensa por acortar distancias: +  0.8877537252551488\n",
      "Penalización por parar muy lejos: -  0.1265292682867355\n",
      "Penalización por duración del episodio: -  0.4093748927060081\n",
      "Recompensa por acortar distancias: +  0.8877342804760303\n",
      "Penalización por parar muy lejos: -  0.12650770507628029\n",
      "Penalización por duración del episodio: -  0.4096282271370456\n",
      "Recompensa por acortar distancias: +  0.8877342804760303\n",
      "Penalización por parar muy lejos: -  0.12650770507628029\n",
      "Penalización por duración del episodio: -  0.40978583156657056\n",
      "Recompensa por acortar distancias: +  0.8877344373005338\n",
      "Penalización por parar muy lejos: -  0.12650787896056856\n",
      "Penalización por duración del episodio: -  0.4099064590741684\n",
      "steer input from model: -0.1 , throttle:  0.0\n",
      "reward: 0.3513200992657968\n",
      "Step: 1910, Mean Reward (últimos 10 pasos): 0.3513200879096985\n",
      "Recompensa por acortar distancias: +  0.8877344373005338\n",
      "Penalización por duración del episodio: -  0.4100402415317477\n",
      "Recompensa por acortar distancias: +  0.8877344373005338\n",
      "Penalización por duración del episodio: -  0.4101751678486015\n",
      "Recompensa por acortar distancias: +  0.8877344373005338\n",
      "Penalización por parar muy lejos: -  0.12650787896056856\n",
      "Penalización por duración del episodio: -  0.41037416456169895\n",
      "Recompensa por acortar distancias: +  0.8877344373005338\n",
      "Penalización por duración del episodio: -  0.4107476689917798\n",
      "Recompensa por acortar distancias: +  0.8877344373005338\n",
      "Penalización por duración del episodio: -  0.4108829602948898\n",
      "Recompensa por acortar distancias: +  0.8877020418498254\n",
      "Penalización por duración del episodio: -  0.41099649443407016\n",
      "Recompensa por acortar distancias: +  0.8877020418498254\n",
      "Penalización por duración del episodio: -  0.41113672841102555\n",
      "Recompensa por acortar distancias: +  0.8877020418498254\n",
      "Penalización por parar muy lejos: -  0.1264719682895972\n",
      "Penalización por duración del episodio: -  0.41128233398244973\n",
      "Recompensa por acortar distancias: +  0.8876873148101659\n",
      "Penalización por parar muy lejos: -  0.1264556490971454\n",
      "Penalización por duración del episodio: -  0.41150853138416815\n",
      "Recompensa por acortar distancias: +  0.8876873148101659\n",
      "Penalización por duración del episodio: -  0.41160903322857395\n",
      "Step: 1920, Mean Reward (últimos 10 pasos): 0.4760782718658447\n",
      "Recompensa por acortar distancias: +  0.8876873148101659\n",
      "Penalización por duración del episodio: -  0.4118925405591579\n",
      "Recompensa por acortar distancias: +  0.8876806067452401\n",
      "Penalización por parar muy lejos: -  0.12644821703411016\n",
      "Penalización por duración del episodio: -  0.41201549238541574\n",
      "Recompensa por acortar distancias: +  0.8876806067452401\n",
      "Penalización por duración del episodio: -  0.412161797878425\n",
      "Recompensa por acortar distancias: +  0.8876723198289421\n",
      "Penalización por parar muy lejos: -  0.126439036766124\n",
      "Penalización por duración del episodio: -  0.41232493042619306\n",
      "Recompensa por acortar distancias: +  0.8876723198289421\n",
      "Penalización por parar muy lejos: -  0.126439036766124\n",
      "Penalización por duración del episodio: -  0.4126595570783981\n",
      "Recompensa por acortar distancias: +  0.8876723198289421\n",
      "Penalización por duración del episodio: -  0.41301804349959437\n",
      "Recompensa por acortar distancias: +  0.8876723198289421\n",
      "Penalización por duración del episodio: -  0.4131801899585199\n",
      "Recompensa por acortar distancias: +  0.8875770175875721\n",
      "Penalización por parar muy lejos: -  0.126333544122694\n",
      "Penalización por duración del episodio: -  0.41338676884392545\n",
      "Recompensa por acortar distancias: +  0.8875770175875721\n",
      "Penalización por parar muy lejos: -  0.126333544122694\n",
      "Penalización por duración del episodio: -  0.4137592694077424\n",
      "Recompensa por acortar distancias: +  0.887559901655675\n",
      "Penalización por parar muy lejos: -  0.12631461427865776\n",
      "Penalización por duración del episodio: -  0.4141271541662976\n",
      "steer input from model: -0.9 , throttle:  0.0\n",
      "reward: 0.34711813321071966\n",
      "Step: 1930, Mean Reward (últimos 10 pasos): 0.3471181392669678\n",
      "Recompensa por acortar distancias: +  0.887523163954819\n",
      "Penalización por parar muy lejos: -  0.12627399987613908\n",
      "Penalización por duración del episodio: -  0.41451264376344277\n",
      "Recompensa por acortar distancias: +  0.8875001707890181\n",
      "Penalización por parar muy lejos: -  0.1262485919605946\n",
      "Penalización por duración del episodio: -  0.41489817441249566\n",
      "Recompensa por acortar distancias: +  0.8875001707890181\n",
      "Penalización por parar muy lejos: -  0.1262485919605946\n",
      "Penalización por duración del episodio: -  0.415281568821955\n",
      "Recompensa por acortar distancias: +  0.8875001707890181\n",
      "Penalización por duración del episodio: -  0.41538669562781994\n",
      "Recompensa por acortar distancias: +  0.8875001707890181\n",
      "Penalización por parar muy lejos: -  0.1262485919605946\n",
      "Penalización por duración del episodio: -  0.41565643742304414\n",
      "Recompensa por acortar distancias: +  0.8873601524379224\n",
      "Penalización por parar muy lejos: -  0.1260940609326395\n",
      "Penalización por duración del episodio: -  0.41603358736889073\n",
      "Recompensa por acortar distancias: +  0.8873114576610741\n",
      "Penalización por parar muy lejos: -  0.12604039623497132\n",
      "Penalización por duración del episodio: -  0.41641157727819245\n",
      "Recompensa por acortar distancias: +  0.8872626204958152\n",
      "Penalización por duración del episodio: -  0.4167926269469848\n",
      "Recompensa por acortar distancias: +  0.8872616904027902\n",
      "Penalización por parar muy lejos: -  0.12598559069512452\n",
      "Penalización por duración del episodio: -  0.4171646401537842\n",
      "Recompensa por acortar distancias: +  0.8872616904027902\n",
      "Penalización por parar muy lejos: -  0.12598559069512452\n",
      "Penalización por duración del episodio: -  0.4172762747014161\n",
      "Step: 1940, Mean Reward (últimos 10 pasos): 0.34399983286857605\n",
      "Recompensa por acortar distancias: +  0.8872616904027902\n",
      "Penalización por parar muy lejos: -  0.12598559069512452\n",
      "Penalización por duración del episodio: -  0.4175488372627141\n",
      "Recompensa por acortar distancias: +  0.8872616904027902\n",
      "Penalización por parar muy lejos: -  0.12598559069512452\n",
      "Penalización por duración del episodio: -  0.41764981955645525\n",
      "Recompensa por acortar distancias: +  0.8872616904027902\n",
      "Penalización por parar muy lejos: -  0.12598559069512452\n",
      "Penalización por duración del episodio: -  0.41791982959397667\n",
      "Recompensa por acortar distancias: +  0.8872061827279072\n",
      "Penalización por parar muy lejos: -  0.1259245125515438\n",
      "Penalización por duración del episodio: -  0.4180355060796334\n",
      "Recompensa por acortar distancias: +  0.8871856433767596\n",
      "Penalización por parar muy lejos: -  0.12590192504812148\n",
      "Penalización por duración del episodio: -  0.4181699861068128\n",
      "Recompensa por acortar distancias: +  0.8871856433767596\n",
      "Penalización por duración del episodio: -  0.41866675797179975\n",
      "Recompensa por acortar distancias: +  0.8871856433767596\n",
      "Penalización por duración del episodio: -  0.41879036161304695\n",
      "Recompensa por acortar distancias: +  0.8871486557249768\n",
      "Penalización por duración del episodio: -  0.4188914630445147\n",
      "Recompensa por acortar distancias: +  0.8871486557249768\n",
      "Penalización por parar muy lejos: -  0.1258612668382677\n",
      "Penalización por duración del episodio: -  0.4190534043412379\n",
      "Recompensa por acortar distancias: +  0.8871279448926114\n",
      "Penalización por duración del episodio: -  0.4192042003582362\n",
      "steer input from model: -0.25 , throttle:  1.0\n",
      "reward: 0.4679237445343752\n",
      "Step: 1950, Mean Reward (últimos 10 pasos): 0.46792373061180115\n",
      "Recompensa por acortar distancias: +  0.8871279448926114\n",
      "Penalización por duración del episodio: -  0.41932606599088756\n",
      "Recompensa por acortar distancias: +  0.887130475439589\n",
      "Penalización por duración del episodio: -  0.41944562496757054\n",
      "Recompensa por acortar distancias: +  0.887130475439589\n",
      "Penalización por duración del episodio: -  0.41955540996424884\n",
      "Recompensa por acortar distancias: +  0.887130475439589\n",
      "Penalización por parar muy lejos: -  0.12584129077110945\n",
      "Penalización por duración del episodio: -  0.4198152179631756\n",
      "Recompensa por acortar distancias: +  0.887130475439589\n",
      "Penalización por parar muy lejos: -  0.12584129077110945\n",
      "Penalización por duración del episodio: -  0.4199331894116993\n",
      "Recompensa por acortar distancias: +  0.887130475439589\n",
      "Penalización por parar muy lejos: -  0.12584129077110945\n",
      "Penalización por duración del episodio: -  0.42018729405631394\n",
      "Recompensa por acortar distancias: +  0.887130475439589\n",
      "Penalización por parar muy lejos: -  0.12584129077110945\n",
      "Penalización por duración del episodio: -  0.42033313148524626\n",
      "Recompensa por acortar distancias: +  0.887130475439589\n",
      "Penalización por parar muy lejos: -  0.12584129077110945\n",
      "Penalización por duración del episodio: -  0.4205654916726211\n",
      "Recompensa por acortar distancias: +  0.8870352641282007\n",
      "Penalización por duración del episodio: -  0.4206755026505555\n",
      "Recompensa por acortar distancias: +  0.8870352641282007\n",
      "Penalización por duración del episodio: -  0.42081341388064963\n",
      "Step: 1960, Mean Reward (últimos 10 pasos): 0.4662218391895294\n",
      "Recompensa por acortar distancias: +  0.8870181622325618\n",
      "Penalización por parar muy lejos: -  0.12571800601132305\n",
      "Penalización por duración del episodio: -  0.42092390750976094\n",
      "Recompensa por acortar distancias: +  0.8870181622325618\n",
      "Penalización por parar muy lejos: -  0.12571800601132305\n",
      "Penalización por duración del episodio: -  0.4213207537675575\n",
      "Recompensa por acortar distancias: +  0.8870181622325618\n",
      "Penalización por duración del episodio: -  0.4216911128603066\n",
      "Recompensa por acortar distancias: +  0.8869462464833824\n",
      "Penalización por parar muy lejos: -  0.1256391754378808\n",
      "Penalización por duración del episodio: -  0.42182354987729387\n",
      "Recompensa por acortar distancias: +  0.8869462464833824\n",
      "Penalización por parar muy lejos: -  0.1256391754378808\n",
      "Penalización por duración del episodio: -  0.42207534900722843\n",
      "Recompensa por acortar distancias: +  0.8869462464833824\n",
      "Penalización por parar muy lejos: -  0.1256391754378808\n",
      "Penalización por duración del episodio: -  0.42220659719946596\n",
      "Recompensa por acortar distancias: +  0.8869462464833824\n",
      "Penalización por parar muy lejos: -  0.1256391754378808\n",
      "Penalización por duración del episodio: -  0.4224551130763324\n",
      "Recompensa por acortar distancias: +  0.8869462464833824\n",
      "Penalización por duración del episodio: -  0.4228338575082188\n",
      "Recompensa por acortar distancias: +  0.8868518852699\n",
      "Penalización por parar muy lejos: -  0.1255358717154075\n",
      "Penalización por duración del episodio: -  0.42293554480229445\n",
      "Recompensa por acortar distancias: +  0.8868518852699\n",
      "Penalización por parar muy lejos: -  0.1255358717154075\n",
      "Penalización por duración del episodio: -  0.4232070823165934\n",
      "steer input from model: 0.05 , throttle:  0.0\n",
      "reward: 0.33810893123789915\n",
      "Step: 1970, Mean Reward (últimos 10 pasos): 0.33810892701148987\n",
      "Recompensa por acortar distancias: +  0.8868518852699\n",
      "Penalización por parar muy lejos: -  0.1255358717154075\n",
      "Penalización por duración del episodio: -  0.4235949595705121\n",
      "Recompensa por acortar distancias: +  0.8868320218284471\n",
      "Penalización por duración del episodio: -  0.4237228233244779\n",
      "Recompensa por acortar distancias: +  0.8868318016913606\n",
      "Penalización por parar muy lejos: -  0.12551390392607692\n",
      "Penalización por duración del episodio: -  0.42382832850986374\n",
      "Recompensa por acortar distancias: +  0.8868318016913606\n",
      "Penalización por parar muy lejos: -  0.12551390392607692\n",
      "Penalización por duración del episodio: -  0.4239308362255838\n",
      "Recompensa por acortar distancias: +  0.8868316581234943\n",
      "Penalización por duración del episodio: -  0.4240541906915893\n",
      "Recompensa por acortar distancias: +  0.8868316581234943\n",
      "Penalización por parar muy lejos: -  0.1255137469129872\n",
      "Penalización por duración del episodio: -  0.4243615436898647\n",
      "Recompensa por acortar distancias: +  0.8868317251218516\n",
      "Penalización por parar muy lejos: -  0.12551382018574145\n",
      "Penalización por duración del episodio: -  0.42473345273689106\n",
      "Recompensa por acortar distancias: +  0.8868317251218516\n",
      "Penalización por duración del episodio: -  0.42512269423372706\n",
      "Recompensa por acortar distancias: +  0.8868317251218516\n",
      "Penalización por duración del episodio: -  0.4252834283861456\n",
      "Recompensa por acortar distancias: +  0.8868323616045215\n",
      "Penalización por parar muy lejos: -  0.12551451627873422\n",
      "Penalización por duración del episodio: -  0.4255210972628834\n",
      "Step: 1980, Mean Reward (últimos 10 pasos): 0.3357967436313629\n",
      "Recompensa por acortar distancias: +  0.8868162236511934\n",
      "Penalización por duración del episodio: -  0.4258919998322593\n",
      "Recompensa por acortar distancias: +  0.8868162236511934\n",
      "Penalización por parar muy lejos: -  0.12549686898689136\n",
      "Penalización por duración del episodio: -  0.42627777286973517\n",
      "Recompensa por acortar distancias: +  0.886816118355464\n",
      "Penalización por parar muy lejos: -  0.12549675385732714\n",
      "Penalización por duración del episodio: -  0.4264138538060331\n",
      "Recompensa por acortar distancias: +  0.886816118355464\n",
      "Penalización por duración del episodio: -  0.42652696276397356\n",
      "Recompensa por acortar distancias: +  0.886816032204349\n",
      "Penalización por parar muy lejos: -  0.1254966596604783\n",
      "Penalización por duración del episodio: -  0.4266639447584753\n",
      "Recompensa por acortar distancias: +  0.886816032204349\n",
      "Penalización por parar muy lejos: -  0.1254966596604783\n",
      "Penalización por duración del episodio: -  0.42676170760824583\n",
      "Recompensa por acortar distancias: +  0.886816032204349\n",
      "Penalización por parar muy lejos: -  0.1254966596604783\n",
      "Penalización por duración del episodio: -  0.4270391339740748\n",
      "Recompensa por acortar distancias: +  0.886816032204349\n",
      "Penalización por duración del episodio: -  0.4274265962048351\n",
      "Recompensa por acortar distancias: +  0.886816032204349\n",
      "Penalización por duración del episodio: -  0.42779999469648045\n",
      "Recompensa por acortar distancias: +  0.8867714221756948\n",
      "Penalización por parar muy lejos: -  0.12544789998941522\n",
      "Penalización por duración del episodio: -  0.42791166785362933\n",
      "steer input from model: -0.9 , throttle:  0.0\n",
      "reward: 0.3334118543326503\n",
      "Step: 1990, Mean Reward (últimos 10 pasos): 0.33341184258461\n",
      "Recompensa por acortar distancias: +  0.8867714221756948\n",
      "Penalización por duración del episodio: -  0.4281720102513161\n",
      "Recompensa por acortar distancias: +  0.8867714221756948\n",
      "Penalización por duración del episodio: -  0.428282738752046\n",
      "Recompensa por acortar distancias: +  0.8867587769266607\n",
      "Penalización por duración del episodio: -  0.42838906658848663\n",
      "Recompensa por acortar distancias: +  0.8867587769266607\n",
      "Penalización por duración del episodio: -  0.4285562983351197\n",
      "Recompensa por acortar distancias: +  0.8867479788913017\n",
      "Penalización por duración del episodio: -  0.42865720110213495\n",
      "Recompensa por acortar distancias: +  0.8867374146226799\n",
      "Penalización por duración del episodio: -  0.4289413675716365\n",
      "Recompensa por acortar distancias: +  0.8867384442696199\n",
      "Penalización por parar muy lejos: -  0.125411875665675\n",
      "Penalización por duración del episodio: -  0.42905184788659684\n",
      "Recompensa por acortar distancias: +  0.8867384442696199\n",
      "Penalización por parar muy lejos: -  0.125411875665675\n",
      "Penalización por duración del episodio: -  0.4293212597806531\n",
      "Recompensa por acortar distancias: +  0.8867384442696199\n",
      "Penalización por parar muy lejos: -  0.125411875665675\n",
      "Penalización por duración del episodio: -  0.4297057457974226\n",
      "Recompensa por acortar distancias: +  0.8867384442696199\n",
      "Penalización por duración del episodio: -  0.4298142239061582\n",
      "Step: 2000, Mean Reward (últimos 10 pasos): 0.4569242298603058\n",
      "Recompensa por acortar distancias: +  0.88661853372435\n",
      "Penalización por parar muy lejos: -  0.1252810397510535\n",
      "Penalización por duración del episodio: -  0.43006979868615774\n",
      "Recompensa por acortar distancias: +  0.8866016644497858\n",
      "Penalización por duración del episodio: -  0.4304476807498234\n",
      "Recompensa por acortar distancias: +  0.8866016644497858\n",
      "Penalización por duración del episodio: -  0.43084833379447773\n",
      "Recompensa por acortar distancias: +  0.886484439527055\n",
      "Penalización por duración del episodio: -  0.43095167287587105\n",
      "Recompensa por acortar distancias: +  0.886484439527055\n",
      "Penalización por duración del episodio: -  0.4310477207625313\n",
      "Recompensa por acortar distancias: +  0.8864373010935349\n",
      "Penalización por duración del episodio: -  0.43123116576079407\n",
      "Recompensa por acortar distancias: +  0.8864373010935349\n",
      "Penalización por duración del episodio: -  0.4316201628634135\n",
      "Recompensa por acortar distancias: +  0.8863035918461061\n",
      "Penalización por duración del episodio: -  0.43199513359214764\n",
      "Recompensa por acortar distancias: +  0.8863035918461061\n",
      "Penalización por duración del episodio: -  0.4323754778122181\n",
      "Recompensa por acortar distancias: +  0.8858895034623714\n",
      "Penalización por duración del episodio: -  0.43274634440466186\n",
      "steer input from model: 0.9 , throttle:  0.7\n",
      "reward: 0.4531431590577095\n",
      "Step: 2010, Mean Reward (últimos 10 pasos): 0.4531431496143341\n",
      "Recompensa por acortar distancias: +  0.8857434196084372\n",
      "Penalización por duración del episodio: -  0.4331358547655578\n",
      "Recompensa por acortar distancias: +  0.8857434196084372\n",
      "Penalización por duración del episodio: -  0.4335146100001381\n",
      "Recompensa por acortar distancias: +  0.8851597809948628\n",
      "Penalización por parar muy lejos: -  0.12370819824307903\n",
      "Penalización por duración del episodio: -  0.4336373247601531\n",
      "Recompensa por acortar distancias: +  0.884969422594637\n",
      "Penalización por duración del episodio: -  0.4339082593572154\n",
      "Recompensa por acortar distancias: +  0.8848104319069442\n",
      "Penalización por parar muy lejos: -  0.12333661498283005\n",
      "Penalización por duración del episodio: -  0.4343009611916452\n",
      "Recompensa por acortar distancias: +  0.8848104319069442\n",
      "Penalización por duración del episodio: -  0.43469593084814684\n",
      "Recompensa por acortar distancias: +  0.8848104319069442\n",
      "Penalización por parar muy lejos: -  0.12333661498283005\n",
      "Penalización por duración del episodio: -  0.43483704504447224\n",
      "Recompensa por acortar distancias: +  0.8836289053937627\n",
      "Penalización por parar muy lejos: -  0.12209413874608921\n",
      "Penalización por duración del episodio: -  0.4350823809548317\n",
      "Recompensa por acortar distancias: +  0.8833452117820972\n",
      "Penalización por parar muy lejos: -  0.12179904106603354\n",
      "Penalización por duración del episodio: -  0.43518625208665807\n",
      "Recompensa por acortar distancias: +  0.8833452117820972\n",
      "Penalización por parar muy lejos: -  0.12179904106603354\n",
      "Penalización por duración del episodio: -  0.4354547611300182\n",
      "Step: 2020, Mean Reward (últimos 10 pasos): 0.3260914087295532\n",
      "Recompensa por acortar distancias: +  0.8833452117820972\n",
      "Penalización por duración del episodio: -  0.43583685174814224\n",
      "Recompensa por acortar distancias: +  0.8824423360506459\n",
      "Penalización por parar muy lejos: -  0.1208680521621485\n",
      "Penalización por duración del episodio: -  0.43622978980981886\n",
      "Recompensa por acortar distancias: +  0.8816957266419838\n",
      "Penalización por duración del episodio: -  0.43633565835548216\n",
      "Recompensa por acortar distancias: +  0.8816957266419838\n",
      "Penalización por duración del episodio: -  0.4364854439650715\n",
      "Recompensa por acortar distancias: +  0.8816957266419838\n",
      "Penalización por duración del episodio: -  0.4366325551147085\n",
      "Recompensa por acortar distancias: +  0.8816957266419838\n",
      "Penalización por duración del episodio: -  0.4370404721959013\n",
      "Recompensa por acortar distancias: +  0.8816957266419838\n",
      "Penalización por duración del episodio: -  0.4374226414373085\n",
      "Recompensa por acortar distancias: +  0.8799386903107862\n",
      "Penalización por parar muy lejos: -  0.11834984603647505\n",
      "Penalización por duración del episodio: -  0.43754477481332277\n",
      "Recompensa por acortar distancias: +  0.8796411275271868\n",
      "Penalización por duración del episodio: -  0.43782104030061547\n",
      "Recompensa por acortar distancias: +  0.8796411275271868\n",
      "Penalización por parar muy lejos: -  0.11805658355282286\n",
      "Penalización por duración del episodio: -  0.43821107910176993\n",
      "steer input from model: 0.9 , throttle:  0.0\n",
      "reward: 0.323373464872594\n",
      "Step: 2030, Mean Reward (últimos 10 pasos): 0.3233734667301178\n",
      "Recompensa por acortar distancias: +  0.8786157547184662\n",
      "Penalización por duración del episodio: -  0.43832551297582323\n",
      "Recompensa por acortar distancias: +  0.8783493599867361\n",
      "Penalización por parar muy lejos: -  0.11679790525505017\n",
      "Penalización por duración del episodio: -  0.43860004364946603\n",
      "Recompensa por acortar distancias: +  0.8779597831378037\n",
      "Penalización por parar muy lejos: -  0.1164228438176643\n",
      "Penalización por duración del episodio: -  0.4389907629767045\n",
      "Recompensa por acortar distancias: +  0.8779597831378037\n",
      "Penalización por duración del episodio: -  0.43938376027676534\n",
      "Recompensa por acortar distancias: +  0.8779597831378037\n",
      "Penalización por parar muy lejos: -  0.1164228438176643\n",
      "Penalización por duración del episodio: -  0.43948643810997384\n",
      "Recompensa por acortar distancias: +  0.8779597831378037\n",
      "Penalización por parar muy lejos: -  0.1164228438176643\n",
      "Penalización por duración del episodio: -  0.4396300477628663\n",
      "Recompensa por acortar distancias: +  0.8765528075260814\n",
      "Penalización por duración del episodio: -  0.43978821743690644\n",
      "Recompensa por acortar distancias: +  0.8765528075260814\n",
      "Penalización por parar muy lejos: -  0.11508541620458276\n",
      "Penalización por duración del episodio: -  0.4401818561324408\n",
      "Recompensa por acortar distancias: +  0.8762066203607876\n",
      "Penalización por duración del episodio: -  0.4402699441884132\n",
      "Recompensa por acortar distancias: +  0.8762066203607876\n",
      "Penalización por duración del episodio: -  0.44037867140971954\n",
      "Step: 2040, Mean Reward (últimos 10 pasos): 0.43582794070243835\n",
      "Recompensa por acortar distancias: +  0.8762066203607876\n",
      "Penalización por duración del episodio: -  0.4404947493924939\n",
      "Recompensa por acortar distancias: +  0.8752632672572486\n",
      "Penalización por duración del episodio: -  0.4406341220769144\n",
      "Recompensa por acortar distancias: +  0.8752632672572486\n",
      "Penalización por parar muy lejos: -  0.11388267003621522\n",
      "Penalización por duración del episodio: -  0.44096897086223213\n",
      "Recompensa por acortar distancias: +  0.8744504235737594\n",
      "Penalización por duración del episodio: -  0.4413661551172452\n",
      "Recompensa por acortar distancias: +  0.8741933199414378\n",
      "Penalización por duración del episodio: -  0.44175284879314597\n",
      "Recompensa por acortar distancias: +  0.8741933199414378\n",
      "Penalización por parar muy lejos: -  0.11290103578765497\n",
      "Penalización por duración del episodio: -  0.4421440765341485\n",
      "Recompensa por acortar distancias: +  0.8725149737649207\n",
      "Penalización por duración del episodio: -  0.4425422812599381\n",
      "Recompensa por acortar distancias: +  0.872146077713369\n",
      "Penalización por parar muy lejos: -  0.1110627343327366\n",
      "Penalización por duración del episodio: -  0.4429274941124322\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 625      |\n",
      "|    ep_rew_mean     | 180      |\n",
      "| time/              |          |\n",
      "|    fps             | 49       |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 41       |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "Recompensa por acortar distancias: +  0.8710525119651976\n",
      "Penalización por parar muy lejos: -  0.11010167205091648\n",
      "Penalización por duración del episodio: -  0.4849215049025551\n",
      "Recompensa por acortar distancias: +  0.8710523566458579\n",
      "Penalización por duración del episodio: -  0.48505680459877226\n",
      "steer input from model: -0.05 , throttle:  0.3\n",
      "reward: 0.38599555204708563\n",
      "Step: 2050, Mean Reward (últimos 10 pasos): 0.3859955668449402\n",
      "Recompensa por acortar distancias: +  0.8710523566458579\n",
      "Penalización por duración del episodio: -  0.485309348040759\n",
      "Recompensa por acortar distancias: +  0.8710523566458579\n",
      "Penalización por duración del episodio: -  0.4857183035886188\n",
      "Recompensa por acortar distancias: +  0.8710523994925883\n",
      "Penalización por duración del episodio: -  0.4858188406745587\n",
      "Recompensa por acortar distancias: +  0.8710523994925883\n",
      "Penalización por parar muy lejos: -  0.11010157393860184\n",
      "Penalización por duración del episodio: -  0.4861050330917046\n",
      "Recompensa por acortar distancias: +  0.8710525708793884\n",
      "Penalización por duración del episodio: -  0.486493834092933\n",
      "Recompensa por acortar distancias: +  0.8710525708793884\n",
      "Penalización por duración del episodio: -  0.486899591349148\n",
      "Recompensa por acortar distancias: +  0.8710525708793884\n",
      "Penalización por parar muy lejos: -  0.11010172344311182\n",
      "Penalización por duración del episodio: -  0.4872883895138234\n",
      "Recompensa por acortar distancias: +  0.8710523620016999\n",
      "Penalización por duración del episodio: -  0.48768187322817225\n",
      "Recompensa por acortar distancias: +  0.8710525601677189\n",
      "Penalización por duración del episodio: -  0.4877832354385357\n",
      "Recompensa por acortar distancias: +  0.8710525601677189\n",
      "Penalización por parar muy lejos: -  0.11010171409907472\n",
      "Penalización por duración del episodio: -  0.4878856709073959\n",
      "Step: 2060, Mean Reward (últimos 10 pasos): 0.2730651795864105\n",
      "Recompensa por acortar distancias: +  0.8710525601677189\n",
      "Penalización por duración del episodio: -  0.48806112289815373\n",
      "Recompensa por acortar distancias: +  0.8710523245108023\n",
      "Penalización por duración del episodio: -  0.48846376270040703\n",
      "Recompensa por acortar distancias: +  0.8710525655235537\n",
      "Penalización por duración del episodio: -  0.4888475679300974\n",
      "Recompensa por acortar distancias: +  0.8710525655235537\n",
      "Penalización por parar muy lejos: -  0.11010171877109322\n",
      "Penalización por duración del episodio: -  0.48923449622904386\n",
      "Recompensa por acortar distancias: +  0.8710525655235537\n",
      "Penalización por duración del episodio: -  0.48961791631209606\n",
      "Recompensa por acortar distancias: +  0.8710216431317815\n",
      "Penalización por duración del episodio: -  0.49002060514345314\n",
      "Recompensa por acortar distancias: +  0.8709966563540098\n",
      "Penalización por parar muy lejos: -  0.11005296637461817\n",
      "Penalización por duración del episodio: -  0.49041720565120894\n",
      "Recompensa por acortar distancias: +  0.871005560777287\n",
      "Penalización por duración del episodio: -  0.49080368885655556\n",
      "Recompensa por acortar distancias: +  0.8710056679272066\n",
      "Penalización por duración del episodio: -  0.4911885325191101\n",
      "Recompensa por acortar distancias: +  0.8710056679272066\n",
      "Penalización por parar muy lejos: -  0.11006082190618335\n",
      "Penalización por duración del episodio: -  0.4912871598289366\n",
      "steer input from model: 0.25 , throttle:  0.0\n",
      "reward: 0.2696576861920866\n",
      "Step: 2070, Mean Reward (últimos 10 pasos): 0.2696576714515686\n",
      "Recompensa por acortar distancias: +  0.8710056679272066\n",
      "Penalización por parar muy lejos: -  0.11006082190618335\n",
      "Penalización por duración del episodio: -  0.49157749221949054\n",
      "Recompensa por acortar distancias: +  0.8710056679272066\n",
      "Penalización por duración del episodio: -  0.49195925777734056\n",
      "Recompensa por acortar distancias: +  0.8709583270683149\n",
      "Penalización por duración del episodio: -  0.4920621389222956\n",
      "Recompensa por acortar distancias: +  0.8709290095774529\n",
      "Penalización por parar muy lejos: -  0.1099940282042053\n",
      "Penalización por duración del episodio: -  0.4921981587779516\n",
      "Recompensa por acortar distancias: +  0.8709290095774529\n",
      "Penalización por duración del episodio: -  0.4923673479693222\n",
      "Recompensa por acortar distancias: +  0.8709290095774529\n",
      "Penalización por duración del episodio: -  0.49274538409381397\n",
      "Recompensa por acortar distancias: +  0.8708779342880979\n",
      "Penalización por duración del episodio: -  0.49289154624586456\n",
      "Recompensa por acortar distancias: +  0.8708779342880979\n",
      "Penalización por parar muy lejos: -  0.10994956391664165\n",
      "Penalización por duración del episodio: -  0.49298560149290827\n",
      "Recompensa por acortar distancias: +  0.8708613272250394\n",
      "Penalización por parar muy lejos: -  0.10993511303283952\n",
      "Penalización por duración del episodio: -  0.4935127560959526\n",
      "Recompensa por acortar distancias: +  0.8708603297781334\n",
      "Penalización por duración del episodio: -  0.49389091733993173\n",
      "Step: 2080, Mean Reward (últimos 10 pasos): 0.37696942687034607\n",
      "Recompensa por acortar distancias: +  0.8708603297781334\n",
      "Penalización por duración del episodio: -  0.4939821169134956\n",
      "Recompensa por acortar distancias: +  0.8708603297781334\n",
      "Penalización por parar muy lejos: -  0.1099342451929094\n",
      "Penalización por duración del episodio: -  0.4942860527937898\n",
      "Recompensa por acortar distancias: +  0.8708603297781334\n",
      "Penalización por duración del episodio: -  0.4944107297789067\n",
      "Recompensa por acortar distancias: +  0.8708603297781334\n",
      "Penalización por parar muy lejos: -  0.1099342451929094\n",
      "Penalización por duración del episodio: -  0.49452332704400687\n",
      "Recompensa por acortar distancias: +  0.8708603297781334\n",
      "Penalización por parar muy lejos: -  0.1099342451929094\n",
      "Penalización por duración del episodio: -  0.4946510746264363\n",
      "Recompensa por acortar distancias: +  0.8708593376873365\n",
      "Penalización por parar muy lejos: -  0.10993338202474164\n",
      "Penalización por duración del episodio: -  0.4950703251376553\n",
      "Recompensa por acortar distancias: +  0.8708593484126772\n",
      "Penalización por parar muy lejos: -  0.10993339135625761\n",
      "Penalización por duración del episodio: -  0.4954645625992318\n",
      "Recompensa por acortar distancias: +  0.870859080278934\n",
      "Penalización por duración del episodio: -  0.49585778653115903\n",
      "Recompensa por acortar distancias: +  0.8708592411592367\n",
      "Penalización por duración del episodio: -  0.4962382013117166\n",
      "Recompensa por acortar distancias: +  0.8708592411592367\n",
      "Penalización por parar muy lejos: -  0.10993329804112888\n",
      "Penalización por duración del episodio: -  0.49663065407704704\n",
      "steer input from model: 0.0 , throttle:  0.0\n",
      "reward: 0.26429528904106087\n",
      "Step: 2090, Mean Reward (últimos 10 pasos): 0.2642952799797058\n",
      "Recompensa por acortar distancias: +  0.8708592411592367\n",
      "Penalización por parar muy lejos: -  0.10993329804112888\n",
      "Penalización por duración del episodio: -  0.4970074832131991\n",
      "Recompensa por acortar distancias: +  0.870859402039369\n",
      "Penalización por duración del episodio: -  0.4973821938817718\n",
      "Recompensa por acortar distancias: +  0.8708592733352769\n",
      "Penalización por duración del episodio: -  0.4977767792830932\n",
      "Recompensa por acortar distancias: +  0.8708626785942508\n",
      "Penalización por parar muy lejos: -  0.1099362888255495\n",
      "Penalización por duración del episodio: -  0.49817350723185033\n",
      "Recompensa por acortar distancias: +  0.870827549807717\n",
      "Penalización por duración del episodio: -  0.4982866771523321\n",
      "Recompensa por acortar distancias: +  0.8708263322214276\n",
      "Penalización por duración del episodio: -  0.4984308413523109\n",
      "Recompensa por acortar distancias: +  0.8708263322214276\n",
      "Penalización por duración del episodio: -  0.4985780992691832\n",
      "Recompensa por acortar distancias: +  0.8708301351347387\n",
      "Penalización por parar muy lejos: -  0.10990797954619015\n",
      "Penalización por duración del episodio: -  0.498963798575886\n",
      "Recompensa por acortar distancias: +  0.8708301351347387\n",
      "Penalización por duración del episodio: -  0.49905976763925974\n",
      "Recompensa por acortar distancias: +  0.8708301351347387\n",
      "Penalización por parar muy lejos: -  0.10990797954619015\n",
      "Penalización por duración del episodio: -  0.4993466678999796\n",
      "Step: 2100, Mean Reward (últimos 10 pasos): 0.26157549023628235\n",
      "Recompensa por acortar distancias: +  0.8708301351347387\n",
      "Penalización por duración del episodio: -  0.49973785283583344\n",
      "Penalización por duración del episodio\n",
      "Recompensa por acortar distancias: +  0.9156966573544877\n",
      "Penalización por parar muy lejos: -  0.16593206942871283\n",
      "Penalización por duración del episodio: -  0.26932613248190246\n",
      "Recompensa por acortar distancias: +  0.9156966573544877\n",
      "Penalización por duración del episodio: -  0.26964071351271895\n",
      "Recompensa por acortar distancias: +  0.9156960610296153\n",
      "Penalización por duración del episodio: -  0.2697396123842018\n",
      "Recompensa por acortar distancias: +  0.9156960463054958\n",
      "Penalización por duración del episodio: -  0.26979965972507547\n",
      "Recompensa por acortar distancias: +  0.9156960610296153\n",
      "Penalización por duración del episodio: -  0.269956536459649\n",
      "Recompensa por acortar distancias: +  0.9156960757537324\n",
      "Penalización por duración del episodio: -  0.2700213089737836\n",
      "Recompensa por acortar distancias: +  0.9156960757537324\n",
      "Penalización por parar muy lejos: -  0.16593102673240037\n",
      "Penalización por duración del episodio: -  0.2702592054269891\n",
      "Recompensa por acortar distancias: +  0.9156960757537324\n",
      "Penalización por duración del episodio: -  0.27057180470897746\n",
      "Step: 2110, Mean Reward (últimos 10 pasos): 0.6451242566108704\n",
      "Recompensa por acortar distancias: +  0.9156960168572501\n",
      "Penalización por parar muy lejos: -  0.16593092114319308\n",
      "Penalización por duración del episodio: -  0.27088378374178634\n",
      "Recompensa por acortar distancias: +  0.9156960315813741\n",
      "Penalización por parar muy lejos: -  0.16593094754048984\n",
      "Penalización por duración del episodio: -  0.2712014927717143\n",
      "Recompensa por acortar distancias: +  0.9156962671670412\n",
      "Penalización por duración del episodio: -  0.27151367766372025\n",
      "Recompensa por acortar distancias: +  0.9156964291318408\n",
      "Penalización por parar muy lejos: -  0.16593166026877465\n",
      "Penalización por duración del episodio: -  0.27182808410005754\n",
      "Recompensa por acortar distancias: +  0.9156965174761578\n",
      "Penalización por parar muy lejos: -  0.16593181865317094\n",
      "Penalización por duración del episodio: -  0.27212464078779813\n",
      "Recompensa por acortar distancias: +  0.9156965616482846\n",
      "Penalización por parar muy lejos: -  0.16593189784541454\n",
      "Penalización por duración del episodio: -  0.27242797339448116\n",
      "Recompensa por acortar distancias: +  0.9156965616482846\n",
      "Penalización por duración del episodio: -  0.2727370078435398\n",
      "Recompensa por acortar distancias: +  0.9156965763723223\n",
      "Penalización por parar muy lejos: -  0.1659319242428358\n",
      "Penalización por duración del episodio: -  0.2730445292312603\n",
      "Recompensa por acortar distancias: +  0.9156963849596507\n",
      "Penalización por duración del episodio: -  0.2733484737318177\n",
      "Recompensa por acortar distancias: +  0.9156965910963577\n",
      "Penalización por duración del episodio: -  0.2736572212969931\n",
      "Step: 2120, Mean Reward (últimos 10 pasos): 0.6420393586158752\n",
      "Recompensa por acortar distancias: +  0.9156968266806051\n",
      "Penalización por parar muy lejos: -  0.16593237299951183\n",
      "Penalización por duración del episodio: -  0.2739577637737267\n",
      "Recompensa por acortar distancias: +  0.9156969297485253\n",
      "Penalización por duración del episodio: -  0.2742777598656169\n",
      "steer input from model: 0.05 , throttle:  0.3\n",
      "reward: 0.6414191698829084\n",
      "Recompensa por acortar distancias: +  0.9156969297485253\n",
      "Penalización por duración del episodio: -  0.2746062044757026\n",
      "Recompensa por acortar distancias: +  0.915696811956607\n",
      "Penalización por duración del episodio: -  0.2746934234073695\n",
      "Recompensa por acortar distancias: +  0.915696811956607\n",
      "Penalización por duración del episodio: -  0.2747826692740995\n",
      "Recompensa por acortar distancias: +  0.9156967972326069\n",
      "Penalización por duración del episodio: -  0.2749250600165753\n",
      "Recompensa por acortar distancias: +  0.9156967972326069\n",
      "Penalización por duración del episodio: -  0.27500581042442895\n",
      "Recompensa por acortar distancias: +  0.9156967972326069\n",
      "Penalización por parar muy lejos: -  0.16593232020455828\n",
      "Penalización por duración del episodio: -  0.27522920193204137\n",
      "Recompensa por acortar distancias: +  0.915696870852585\n",
      "Penalización por parar muy lejos: -  0.1659324521919673\n",
      "Penalización por duración del episodio: -  0.2755397917919334\n",
      "Recompensa por acortar distancias: +  0.9156969444725047\n",
      "Penalización por duración del episodio: -  0.275631940510607\n",
      "Step: 2130, Mean Reward (últimos 10 pasos): 0.6400650143623352\n",
      "Recompensa por acortar distancias: +  0.9156970033683983\n",
      "Penalización por parar muy lejos: -  0.16593268976951547\n",
      "Penalización por duración del episodio: -  0.27584873658162357\n",
      "Recompensa por acortar distancias: +  0.915697062264255\n",
      "Penalización por parar muy lejos: -  0.16593279535962438\n",
      "Penalización por duración del episodio: -  0.2761552220862359\n",
      "Recompensa por acortar distancias: +  0.915697062264255\n",
      "Penalización por duración del episodio: -  0.27646717846509\n",
      "Recompensa por acortar distancias: +  0.915697062264255\n",
      "Penalización por parar muy lejos: -  0.16593279535962438\n",
      "Penalización por duración del episodio: -  0.276779872695871\n",
      "Recompensa por acortar distancias: +  0.9156969444725047\n",
      "Penalización por duración del episodio: -  0.2770870207731847\n",
      "Recompensa por acortar distancias: +  0.915696811956607\n",
      "Penalización por parar muy lejos: -  0.16593234660203335\n",
      "Penalización por duración del episodio: -  0.2774101643533313\n",
      "Recompensa por acortar distancias: +  0.915696870852585\n",
      "Penalización por duración del episodio: -  0.2777230374948904\n",
      "Recompensa por acortar distancias: +  0.9156969444725047\n",
      "Penalización por duración del episodio: -  0.2780322464426081\n",
      "Recompensa por acortar distancias: +  0.9156969886444285\n",
      "Penalización por parar muy lejos: -  0.1659326633719967\n",
      "Penalización por duración del episodio: -  0.27811581873282415\n",
      "Recompensa por acortar distancias: +  0.9156969886444285\n",
      "Penalización por duración del episodio: -  0.2783520449906739\n",
      "Step: 2140, Mean Reward (últimos 10 pasos): 0.6373449563980103\n",
      "Recompensa por acortar distancias: +  0.9156969886444285\n",
      "Penalización por parar muy lejos: -  0.1659326633719967\n",
      "Penalización por duración del episodio: -  0.2786529906710323\n",
      "Recompensa por acortar distancias: +  0.9156967751466021\n",
      "Penalización por parar muy lejos: -  0.16593228060835197\n",
      "Penalización por duración del episodio: -  0.2787189716723292\n",
      "steer input from model: -0.9 , throttle:  0.0\n",
      "reward: 0.47104552286592094\n",
      "Recompensa por acortar distancias: +  0.9156967825086042\n",
      "Penalización por duración del episodio: -  0.27897655076800854\n",
      "Recompensa por acortar distancias: +  0.9156967825086042\n",
      "Penalización por duración del episodio: -  0.2792973656253821\n",
      "Recompensa por acortar distancias: +  0.915696892938567\n",
      "Penalización por parar muy lejos: -  0.1659324917882064\n",
      "Penalización por duración del episodio: -  0.27961564970388536\n",
      "Recompensa por acortar distancias: +  0.915697025454349\n",
      "Penalización por duración del episodio: -  0.2797030248259084\n",
      "Recompensa por acortar distancias: +  0.9156970549022747\n",
      "Penalización por parar muy lejos: -  0.1659327821608578\n",
      "Penalización por duración del episodio: -  0.2799279417178416\n",
      "Recompensa por acortar distancias: +  0.9156971064361227\n",
      "Penalización por parar muy lejos: -  0.16593287455224134\n",
      "Penalización por duración del episodio: -  0.28023693624990276\n",
      "Recompensa por acortar distancias: +  0.9156971064361227\n",
      "Penalización por parar muy lejos: -  0.16593287455224134\n",
      "Penalización por duración del episodio: -  0.2805447674873381\n",
      "Recompensa por acortar distancias: +  0.9156971064361227\n",
      "Penalización por parar muy lejos: -  0.16593287455224134\n",
      "Penalización por duración del episodio: -  0.28086548898685265\n",
      "Step: 2150, Mean Reward (últimos 10 pasos): 0.468898743391037\n",
      "Recompensa por acortar distancias: +  0.9156969812824427\n",
      "Penalización por duración del episodio: -  0.281175841949556\n",
      "Recompensa por acortar distancias: +  0.9156968414046006\n",
      "Penalización por parar muy lejos: -  0.1659323993969936\n",
      "Penalización por duración del episodio: -  0.28150171872746926\n",
      "Recompensa por acortar distancias: +  0.9156970033683983\n",
      "Penalización por parar muy lejos: -  0.16593268976951547\n",
      "Penalización por duración del episodio: -  0.28181502293569055\n",
      "Recompensa por acortar distancias: +  0.9156971800558555\n",
      "Penalización por parar muy lejos: -  0.1659330065400036\n",
      "Penalización por duración del episodio: -  0.2819220740911148\n",
      "Recompensa por acortar distancias: +  0.9156972242276673\n",
      "Penalización por duración del episodio: -  0.2821296060743681\n",
      "Recompensa por acortar distancias: +  0.9156972242276673\n",
      "Penalización por duración del episodio: -  0.28245150056117657\n",
      "Recompensa por acortar distancias: +  0.9156972242276673\n",
      "Penalización por duración del episodio: -  0.28276331828885987\n",
      "Recompensa por acortar distancias: +  0.9156971064361227\n",
      "Penalización por duración del episodio: -  0.283079302405446\n",
      "Recompensa por acortar distancias: +  0.9156971064361227\n",
      "Penalización por parar muy lejos: -  0.16593287455224134\n",
      "Penalización por duración del episodio: -  0.2833849304397737\n",
      "Recompensa por acortar distancias: +  0.915697194779795\n",
      "Penalización por parar muy lejos: -  0.16593303293756617\n",
      "Penalización por duración del episodio: -  0.2836932336305468\n",
      "Step: 2160, Mean Reward (últimos 10 pasos): 0.46607092022895813\n",
      "Recompensa por acortar distancias: +  0.9156973420190626\n",
      "Penalización por parar muy lejos: -  0.1659332969133766\n",
      "Penalización por duración del episodio: -  0.2840184316681531\n",
      "Recompensa por acortar distancias: +  0.9156973861907973\n",
      "Penalización por duración del episodio: -  0.2841169010081945\n",
      "steer input from model: -0.9 , throttle:  0.7\n",
      "reward: 0.6315804851826028\n",
      "Recompensa por acortar distancias: +  0.9156973861907973\n",
      "Penalización por duración del episodio: -  0.2843342338055754\n",
      "Recompensa por acortar distancias: +  0.9156973861907973\n",
      "Penalización por duración del episodio: -  0.2844214288615301\n",
      "Recompensa por acortar distancias: +  0.9156973861907973\n",
      "Penalización por duración del episodio: -  0.28464422758678926\n",
      "Recompensa por acortar distancias: +  0.9156971800558555\n",
      "Penalización por parar muy lejos: -  0.1659330065400036\n",
      "Penalización por duración del episodio: -  0.28473013002453124\n",
      "Recompensa por acortar distancias: +  0.9156971800558555\n",
      "Penalización por duración del episodio: -  0.28497190384183335\n",
      "Recompensa por acortar distancias: +  0.9156971506079694\n",
      "Penalización por parar muy lejos: -  0.16593295374488862\n",
      "Penalización por duración del episodio: -  0.2852933071604964\n",
      "Recompensa por acortar distancias: +  0.9156969591964816\n",
      "Penalización por duración del episodio: -  0.2856133082431017\n",
      "Recompensa por acortar distancias: +  0.9156970401783131\n",
      "Penalización por duración del episodio: -  0.28592165193933944\n",
      "Step: 2170, Mean Reward (últimos 10 pasos): 0.6297754049301147\n",
      "Recompensa por acortar distancias: +  0.9156970769882131\n",
      "Penalización por duración del episodio: -  0.2862416176592167\n",
      "Recompensa por acortar distancias: +  0.9156970769882131\n",
      "Penalización por duración del episodio: -  0.28631822619630787\n",
      "Recompensa por acortar distancias: +  0.9156970769882131\n",
      "Penalización por duración del episodio: -  0.28656057429577203\n",
      "Recompensa por acortar distancias: +  0.9156970769882131\n",
      "Penalización por duración del episodio: -  0.2866613369946482\n",
      "Recompensa por acortar distancias: +  0.9156968266806051\n",
      "Penalización por duración del episodio: -  0.286875680501873\n",
      "Recompensa por acortar distancias: +  0.9156968266806051\n",
      "Penalización por parar muy lejos: -  0.16593237299951183\n",
      "Penalización por duración del episodio: -  0.2871887241931441\n",
      "Recompensa por acortar distancias: +  0.9156968414046006\n",
      "Penalización por parar muy lejos: -  0.1659323993969936\n",
      "Penalización por duración del episodio: -  0.28750024775976807\n",
      "Recompensa por acortar distancias: +  0.9156969444725047\n",
      "Penalización por parar muy lejos: -  0.1659325841794604\n",
      "Penalización por duración del episodio: -  0.28781754403316656\n",
      "Recompensa por acortar distancias: +  0.9156970328163313\n",
      "Penalización por parar muy lejos: -  0.1659327425645632\n",
      "Penalización por duración del episodio: -  0.28813175283585685\n",
      "Recompensa por acortar distancias: +  0.915697062264255\n",
      "Penalización por parar muy lejos: -  0.16593279535962438\n",
      "Penalización por duración del episodio: -  0.28844573021521097\n",
      "Step: 2180, Mean Reward (últimos 10 pasos): 0.4613185226917267\n",
      "Recompensa por acortar distancias: +  0.915697062264255\n",
      "Penalización por duración del episodio: -  0.28877559985959744\n",
      "Recompensa por acortar distancias: +  0.915696892938567\n",
      "Penalización por duración del episodio: -  0.2888723250332826\n",
      "steer input from model: 0.0 , throttle:  0.3\n",
      "reward: 0.6268245679052844\n",
      "Recompensa por acortar distancias: +  0.9156969150245438\n",
      "Penalización por duración del episodio: -  0.2890891511360654\n",
      "Recompensa por acortar distancias: +  0.9156969150245438\n",
      "Penalización por duración del episodio: -  0.28923069053800693\n",
      "Recompensa por acortar distancias: +  0.9156969150245438\n",
      "Penalización por parar muy lejos: -  0.1659325313844531\n",
      "Penalización por duración del episodio: -  0.2893154221298929\n",
      "Recompensa por acortar distancias: +  0.9156969150245438\n",
      "Penalización por duración del episodio: -  0.2897285263634672\n",
      "Recompensa por acortar distancias: +  0.915696892938567\n",
      "Penalización por duración del episodio: -  0.28980323566875593\n",
      "Recompensa por acortar distancias: +  0.9156969444725047\n",
      "Penalización por parar muy lejos: -  0.1659325841794604\n",
      "Penalización por duración del episodio: -  0.29005497891894455\n",
      "Recompensa por acortar distancias: +  0.915697025454349\n",
      "Penalización por duración del episodio: -  0.2903657315265519\n",
      "Recompensa por acortar distancias: +  0.915697025454349\n",
      "Penalización por duración del episodio: -  0.2906714405303488\n",
      "Step: 2190, Mean Reward (últimos 10 pasos): 0.6250255703926086\n",
      "Recompensa por acortar distancias: +  0.915697025454349\n",
      "Penalización por duración del episodio: -  0.29098576540146126\n",
      "Recompensa por acortar distancias: +  0.9156969739204561\n",
      "Penalización por duración del episodio: -  0.29131245304549463\n",
      "Recompensa por acortar distancias: +  0.9156969739204561\n",
      "Penalización por duración del episodio: -  0.29163941570037055\n",
      "Recompensa por acortar distancias: +  0.915697018092366\n",
      "Penalización por duración del episodio: -  0.291725799804728\n",
      "Recompensa por acortar distancias: +  0.9156970769882131\n",
      "Penalización por parar muy lejos: -  0.16593282175715998\n",
      "Penalización por duración del episodio: -  0.2919632968949546\n",
      "Recompensa por acortar distancias: +  0.9156971726938848\n",
      "Penalización por duración del episodio: -  0.2920494218952507\n",
      "Recompensa por acortar distancias: +  0.9156972242276673\n",
      "Penalización por duración del episodio: -  0.29228007059563554\n",
      "Recompensa por acortar distancias: +  0.9156972536755301\n",
      "Penalización por duración del episodio: -  0.2925920568151854\n",
      "Recompensa por acortar distancias: +  0.9156972536755301\n",
      "Penalización por duración del episodio: -  0.2929327900925417\n",
      "Recompensa por acortar distancias: +  0.9156971064361227\n",
      "Penalización por duración del episodio: -  0.29325447404782506\n",
      "Step: 2200, Mean Reward (últimos 10 pasos): 0.6224426031112671\n",
      "Recompensa por acortar distancias: +  0.9156971358840228\n",
      "Penalización por duración del episodio: -  0.29359800238524486\n",
      "Recompensa por acortar distancias: +  0.9156972242276673\n",
      "Penalización por parar muy lejos: -  0.16593308573270132\n",
      "Penalización por duración del episodio: -  0.29393386860471965\n",
      "steer input from model: 0.25 , throttle:  0.0\n",
      "reward: 0.4558302698902464\n",
      "Recompensa por acortar distancias: +  0.9156972536755301\n",
      "Penalización por parar muy lejos: -  0.16593313852784994\n",
      "Penalización por duración del episodio: -  0.29425265922691896\n",
      "Recompensa por acortar distancias: +  0.9156972536755301\n",
      "Penalización por parar muy lejos: -  0.16593313852784994\n",
      "Penalización por duración del episodio: -  0.2945787955296842\n",
      "Recompensa por acortar distancias: +  0.9156972536755301\n",
      "Penalización por parar muy lejos: -  0.16593313852784994\n",
      "Penalización por duración del episodio: -  0.29489225766622923\n",
      "Recompensa por acortar distancias: +  0.9156972536755301\n",
      "Penalización por duración del episodio: -  0.2949950411235646\n",
      "Recompensa por acortar distancias: +  0.9156969444725047\n",
      "Penalización por parar muy lejos: -  0.1659325841794604\n",
      "Penalización por duración del episodio: -  0.2952105965262096\n",
      "Recompensa por acortar distancias: +  0.915696870852585\n",
      "Penalización por parar muy lejos: -  0.1659324521919673\n",
      "Penalización por duración del episodio: -  0.295543718492543\n",
      "Recompensa por acortar distancias: +  0.9156966941645394\n",
      "Penalización por duración del episodio: -  0.29586872388599184\n",
      "Recompensa por acortar distancias: +  0.9156968561285941\n",
      "Penalización por duración del episodio: -  0.29619499008256106\n",
      "Step: 2210, Mean Reward (últimos 10 pasos): 0.6195018887519836\n",
      "Recompensa por acortar distancias: +  0.9156969960064137\n",
      "Penalización por duración del episodio: -  0.2962910275115821\n",
      "Recompensa por acortar distancias: +  0.9156970328163313\n",
      "Penalización por parar muy lejos: -  0.1659327425645632\n",
      "Penalización por duración del episodio: -  0.2965206290352436\n",
      "Recompensa por acortar distancias: +  0.9156970328163313\n",
      "Penalización por duración del episodio: -  0.29684598730394646\n",
      "Recompensa por acortar distancias: +  0.9156970328163313\n",
      "Penalización por duración del episodio: -  0.2969108796459204\n",
      "Recompensa por acortar distancias: +  0.9156970328163313\n",
      "Penalización por duración del episodio: -  0.29716404752447584\n",
      "Recompensa por acortar distancias: +  0.9156969886444285\n",
      "Penalización por parar muy lejos: -  0.1659326633719967\n",
      "Penalización por duración del episodio: -  0.2975004215127808\n",
      "Recompensa por acortar distancias: +  0.9156969886444285\n",
      "Penalización por duración del episodio: -  0.29756580003361954\n",
      "Recompensa por acortar distancias: +  0.9156970917121691\n",
      "Penalización por duración del episodio: -  0.2978201024993213\n",
      "Recompensa por acortar distancias: +  0.9156966205444212\n",
      "Penalización por parar muy lejos: -  0.16593200343511977\n",
      "Penalización por duración del episodio: -  0.29814495523976714\n",
      "Recompensa por acortar distancias: +  0.915597062220937\n",
      "Penalización por parar muy lejos: -  0.1657536863923398\n",
      "Penalización por duración del episodio: -  0.2984744796906265\n",
      "Step: 2220, Mean Reward (últimos 10 pasos): 0.45136889815330505\n",
      "Recompensa por acortar distancias: +  0.915444534940584\n",
      "Penalización por duración del episodio: -  0.2988004218341338\n",
      "Recompensa por acortar distancias: +  0.915444534940584\n",
      "Penalización por parar muy lejos: -  0.16548116487853165\n",
      "Penalización por duración del episodio: -  0.2991463273617998\n",
      "steer input from model: -0.25 , throttle:  0.0\n",
      "reward: 0.45081704270025247\n",
      "Recompensa por acortar distancias: +  0.9147626583196062\n",
      "Penalización por parar muy lejos: -  0.1642726359264904\n",
      "Penalización por duración del episodio: -  0.299467818297389\n",
      "Recompensa por acortar distancias: +  0.9147626583196062\n",
      "Penalización por duración del episodio: -  0.2997967589271091\n",
      "Recompensa por acortar distancias: +  0.9144913897172232\n",
      "Penalización por duración del episodio: -  0.3001305935747443\n",
      "Recompensa por acortar distancias: +  0.9143320614331392\n",
      "Penalización por parar muy lejos: -  0.16351760251032565\n",
      "Penalización por duración del episodio: -  0.3002257949291931\n",
      "Recompensa por acortar distancias: +  0.9143320614331392\n",
      "Penalización por duración del episodio: -  0.30045517935198346\n",
      "Recompensa por acortar distancias: +  0.9141598550471647\n",
      "Penalización por duración del episodio: -  0.30077582859025126\n",
      "Recompensa por acortar distancias: +  0.9140879174882464\n",
      "Penalización por parar muy lejos: -  0.1630922687524543\n",
      "Penalización por duración del episodio: -  0.3011074799424528\n",
      "Recompensa por acortar distancias: +  0.9140879174882464\n",
      "Penalización por duración del episodio: -  0.3011982460765211\n",
      "Step: 2230, Mean Reward (últimos 10 pasos): 0.6128896474838257\n",
      "Recompensa por acortar distancias: +  0.9134694495217067\n",
      "Penalización por parar muy lejos: -  0.16202364477619105\n",
      "Penalización por duración del episodio: -  0.3013010184072348\n",
      "Recompensa por acortar distancias: +  0.9134694495217067\n",
      "Penalización por parar muy lejos: -  0.16202364477619105\n",
      "Penalización por duración del episodio: -  0.3014565347168817\n",
      "Recompensa por acortar distancias: +  0.9133176393346988\n",
      "Penalización por duración del episodio: -  0.30178559844221614\n",
      "Recompensa por acortar distancias: +  0.9129219087657736\n",
      "Penalización por parar muy lejos: -  0.16108800575784918\n",
      "Penalización por duración del episodio: -  0.3021110707556541\n",
      "Recompensa por acortar distancias: +  0.9125746527331241\n",
      "Penalización por duración del episodio: -  0.3024463140022352\n",
      "Recompensa por acortar distancias: +  0.9122028752544352\n",
      "Penalización por duración del episodio: -  0.3027706497812821\n",
      "Recompensa por acortar distancias: +  0.9120592078819582\n",
      "Penalización por duración del episodio: -  0.30311401247510567\n",
      "Recompensa por acortar distancias: +  0.9120592078819582\n",
      "Penalización por parar muy lejos: -  0.159633323077103\n",
      "Penalización por duración del episodio: -  0.3031905539245415\n",
      "Recompensa por acortar distancias: +  0.9120592078819582\n",
      "Penalización por parar muy lejos: -  0.159633323077103\n",
      "Penalización por duración del episodio: -  0.30344630173263587\n",
      "Recompensa por acortar distancias: +  0.9109372817417034\n",
      "Penalización por parar muy lejos: -  0.15777638998835175\n",
      "Penalización por duración del episodio: -  0.3037777778917041\n",
      "Step: 2240, Mean Reward (últimos 10 pasos): 0.44938310980796814\n",
      "Recompensa por acortar distancias: +  0.9102875103315408\n",
      "Penalización por duración del episodio: -  0.30411581047878355\n",
      "Recompensa por acortar distancias: +  0.909730166144933\n",
      "Penalización por parar muy lejos: -  0.15582117638559545\n",
      "Penalización por duración del episodio: -  0.30419911533355337\n",
      "steer input from model: -0.1 , throttle:  0.0\n",
      "reward: 0.44970987442578414\n",
      "Recompensa por acortar distancias: +  0.909730166144933\n",
      "Penalización por parar muy lejos: -  0.15582117638559545\n",
      "Penalización por duración del episodio: -  0.30430353070946864\n",
      "Recompensa por acortar distancias: +  0.909507907420383\n",
      "Penalización por duración del episodio: -  0.3044155842814902\n",
      "Recompensa por acortar distancias: +  0.9093028618411577\n",
      "Penalización por parar muy lejos: -  0.15513939894912349\n",
      "Penalización por duración del episodio: -  0.30476012333592184\n",
      "Recompensa por acortar distancias: +  0.9087359326272291\n",
      "Penalización por duración del episodio: -  0.3048373230290192\n",
      "Recompensa por acortar distancias: +  0.9087359326272291\n",
      "Penalización por parar muy lejos: -  0.1542430272209766\n",
      "Penalización por duración del episodio: -  0.3050965661274804\n",
      "Recompensa por acortar distancias: +  0.9087359326272291\n",
      "Penalización por parar muy lejos: -  0.1542430272209766\n",
      "Penalización por duración del episodio: -  0.30541392667090667\n",
      "Recompensa por acortar distancias: +  0.9087359326272291\n",
      "Penalización por duración del episodio: -  0.30552319454206\n",
      "Recompensa por acortar distancias: +  0.9079439150922313\n",
      "Penalización por duración del episodio: -  0.3057482079730813\n",
      "Step: 2250, Mean Reward (últimos 10 pasos): 0.602195680141449\n",
      "Recompensa por acortar distancias: +  0.9078872656369313\n",
      "Penalización por duración del episodio: -  0.30608144819943905\n",
      "Recompensa por acortar distancias: +  0.9078740415948751\n",
      "Penalización por duración del episodio: -  0.3064159300594184\n",
      "Recompensa por acortar distancias: +  0.9078193167704018\n",
      "Penalización por duración del episodio: -  0.30675324723694164\n",
      "Recompensa por acortar distancias: +  0.9077606580357106\n",
      "Penalización por parar muy lejos: -  0.15272246482971394\n",
      "Penalización por duración del episodio: -  0.3070903248946305\n",
      "Recompensa por acortar distancias: +  0.9077307330043969\n",
      "Penalización por parar muy lejos: -  0.1526762311457233\n",
      "Penalización por duración del episodio: -  0.3074215222322144\n",
      "Recompensa por acortar distancias: +  0.9077307330043969\n",
      "Penalización por duración del episodio: -  0.3077485905769742\n",
      "Recompensa por acortar distancias: +  0.9075150824442416\n",
      "Penalización por parar muy lejos: -  0.1523437907308421\n",
      "Penalización por duración del episodio: -  0.3080768888870741\n",
      "Recompensa por acortar distancias: +  0.9075150824442416\n",
      "Penalización por parar muy lejos: -  0.1523437907308421\n",
      "Penalización por duración del episodio: -  0.30814978347212446\n",
      "Recompensa por acortar distancias: +  0.9074746766785247\n",
      "Penalización por duración del episodio: -  0.30840571193292315\n",
      "Recompensa por acortar distancias: +  0.907474356379306\n",
      "Penalización por parar muy lejos: -  0.1522811534235742\n",
      "Penalización por duración del episodio: -  0.3085055040182906\n",
      "Step: 2260, Mean Reward (últimos 10 pasos): 0.4466876983642578\n",
      "Recompensa por acortar distancias: +  0.907474356379306\n",
      "Penalización por parar muy lejos: -  0.1522811534235742\n",
      "Penalización por duración del episodio: -  0.308738046907793\n",
      "Recompensa por acortar distancias: +  0.9074609189300139\n",
      "Penalización por duración del episodio: -  0.3090733852920092\n",
      "steer input from model: -0.9 , throttle:  1.0\n",
      "reward: 0.5983875336380047\n",
      "Recompensa por acortar distancias: +  0.9074610791006343\n",
      "Penalización por parar muy lejos: -  0.15226074268449644\n",
      "Penalización por duración del episodio: -  0.30940783467446953\n",
      "Recompensa por acortar distancias: +  0.9074610791006343\n",
      "Penalización por duración del episodio: -  0.30973831403256435\n",
      "Recompensa por acortar distancias: +  0.9074220541803587\n",
      "Penalización por duración del episodio: -  0.31006287764538343\n",
      "Recompensa por acortar distancias: +  0.9074227111259853\n",
      "Penalización por parar muy lejos: -  0.1522017881996325\n",
      "Penalización por duración del episodio: -  0.3103866690096253\n",
      "Recompensa por acortar distancias: +  0.9074227111259853\n",
      "Penalización por duración del episodio: -  0.3104554244906943\n",
      "Recompensa por acortar distancias: +  0.9074227111259853\n",
      "Penalización por parar muy lejos: -  0.1522017881996325\n",
      "Penalización por duración del episodio: -  0.3107291667166544\n",
      "Recompensa por acortar distancias: +  0.9073682826118963\n",
      "Penalización por duración del episodio: -  0.31080956706849505\n",
      "Recompensa por acortar distancias: +  0.9073687475235279\n",
      "Penalización por parar muy lejos: -  0.1521189389760331\n",
      "Penalización por duración del episodio: -  0.3110743448594705\n",
      "Step: 2270, Mean Reward (últimos 10 pasos): 0.44417545199394226\n",
      "Recompensa por acortar distancias: +  0.9073550157160851\n",
      "Penalización por parar muy lejos: -  0.15209786963319252\n",
      "Penalización por duración del episodio: -  0.3114225860348219\n",
      "Recompensa por acortar distancias: +  0.9073550157160851\n",
      "Penalización por parar muy lejos: -  0.15209786963319252\n",
      "Penalización por duración del episodio: -  0.3117527214489395\n",
      "Recompensa por acortar distancias: +  0.9073157260811032\n",
      "Penalización por parar muy lejos: -  0.15203761444921718\n",
      "Penalización por duración del episodio: -  0.31209677631313404\n",
      "Recompensa por acortar distancias: +  0.9072995087329744\n",
      "Penalización por duración del episodio: -  0.3124222317626475\n",
      "Recompensa por acortar distancias: +  0.907269457398398\n",
      "Penalización por duración del episodio: -  0.31276014558189874\n",
      "Recompensa por acortar distancias: +  0.907221642836862\n",
      "Penalización por duración del episodio: -  0.31309601769441736\n",
      "Recompensa por acortar distancias: +  0.9071682807757022\n",
      "Penalización por duración del episodio: -  0.31342960279802135\n",
      "Recompensa por acortar distancias: +  0.907144617941513\n",
      "Penalización por duración del episodio: -  0.31376279574817534\n",
      "Recompensa por acortar distancias: +  0.907144617941513\n",
      "Penalización por parar muy lejos: -  0.1517756955066532\n",
      "Penalización por duración del episodio: -  0.3140890000975417\n",
      "Recompensa por acortar distancias: +  0.9069507140058586\n",
      "Penalización por parar muy lejos: -  0.15147985240889347\n",
      "Penalización por duración del episodio: -  0.31442060976574815\n",
      "Step: 2280, Mean Reward (últimos 10 pasos): 0.441050261259079\n",
      "Recompensa por acortar distancias: +  0.9069507140058586\n",
      "Penalización por parar muy lejos: -  0.15147985240889347\n",
      "Penalización por duración del episodio: -  0.3147563838881742\n",
      "Recompensa por acortar distancias: +  0.9067389238774832\n",
      "Penalización por parar muy lejos: -  0.15115789131592403\n",
      "Penalización por duración del episodio: -  0.31507950928009454\n",
      "steer input from model: -0.05 , throttle:  0.0\n",
      "reward: 0.44050152328146464\n",
      "Recompensa por acortar distancias: +  0.9066140856091163\n",
      "Penalización por parar muy lejos: -  0.1509686836904918\n",
      "Penalización por duración del episodio: -  0.31541307381349876\n",
      "Recompensa por acortar distancias: +  0.9065777207670123\n",
      "Penalización por duración del episodio: -  0.31575502921863746\n",
      "Recompensa por acortar distancias: +  0.9065777207670123\n",
      "Penalización por parar muy lejos: -  0.15091364760783693\n",
      "Penalización por duración del episodio: -  0.31610320422691207\n",
      "Recompensa por acortar distancias: +  0.9065745948814885\n",
      "Penalización por parar muy lejos: -  0.15090891842795992\n",
      "Penalización por duración del episodio: -  0.3164435042739342\n",
      "Recompensa por acortar distancias: +  0.906574211206905\n",
      "Penalización por parar muy lejos: -  0.1509083379814619\n",
      "Penalización por duración del episodio: -  0.31677338666591354\n",
      "Recompensa por acortar distancias: +  0.9065735044342352\n",
      "Penalización por parar muy lejos: -  0.15090726874271843\n",
      "Penalización por duración del episodio: -  0.31710376319329703\n",
      "Recompensa por acortar distancias: +  0.906573468085797\n",
      "Penalización por duración del episodio: -  0.31720368980268987\n",
      "Recompensa por acortar distancias: +  0.9065734600083645\n",
      "Penalización por parar muy lejos: -  0.15090720153363404\n",
      "Penalización por duración del episodio: -  0.3172951426102842\n",
      "Step: 2290, Mean Reward (últimos 10 pasos): 0.43837112188339233\n",
      "Recompensa por acortar distancias: +  0.9065734923180906\n",
      "Penalización por duración del episodio: -  0.31745115980999183\n",
      "Recompensa por acortar distancias: +  0.906575741858132\n",
      "Penalización por parar muy lejos: -  0.15091065366843825\n",
      "Penalización por duración del episodio: -  0.3175298270425299\n",
      "Recompensa por acortar distancias: +  0.906575741858132\n",
      "Penalización por duración del episodio: -  0.3177971368410209\n",
      "Recompensa por acortar distancias: +  0.9065633384933546\n",
      "Penalización por duración del episodio: -  0.3181301992118721\n",
      "Recompensa por acortar distancias: +  0.9065633384933546\n",
      "Penalización por duración del episodio: -  0.31846657842437986\n",
      "Recompensa por acortar distancias: +  0.9065106471151909\n",
      "Penalización por duración del episodio: -  0.3188053164711746\n",
      "Recompensa por acortar distancias: +  0.9065106471151909\n",
      "Penalización por parar muy lejos: -  0.1508122291496565\n",
      "Penalización por duración del episodio: -  0.31913854743746584\n",
      "Recompensa por acortar distancias: +  0.9064672765377224\n",
      "Penalización por duración del episodio: -  0.3192252143745364\n",
      "Recompensa por acortar distancias: +  0.9064671714240115\n",
      "Penalización por duración del episodio: -  0.319481511349895\n",
      "Recompensa por acortar distancias: +  0.9064639573190133\n",
      "Penalización por duración del episodio: -  0.3198200806811734\n",
      "Step: 2300, Mean Reward (últimos 10 pasos): 0.5866438746452332\n",
      "Recompensa por acortar distancias: +  0.9064646001479368\n",
      "Penalización por duración del episodio: -  0.3201544083194687\n",
      "Recompensa por acortar distancias: +  0.9064646001479368\n",
      "Penalización por duración del episodio: -  0.32049863542064544\n",
      "steer input from model: -0.1 , throttle:  0.3\n",
      "reward: 0.5859659647272915\n",
      "Recompensa por acortar distancias: +  0.9064389566912211\n",
      "Penalización por parar muy lejos: -  0.15070396396030594\n",
      "Penalización por duración del episodio: -  0.3208185890294414\n",
      "Recompensa por acortar distancias: +  0.9064253115766668\n",
      "Penalización por duración del episodio: -  0.32114946009432277\n",
      "Recompensa por acortar distancias: +  0.9063925058533416\n",
      "Penalización por duración del episodio: -  0.32125201656375785\n",
      "Recompensa por acortar distancias: +  0.9063925058533416\n",
      "Penalización por parar muy lejos: -  0.15063388882010717\n",
      "Penalización por duración del episodio: -  0.32134967150586713\n",
      "Recompensa por acortar distancias: +  0.9063815939462226\n",
      "Penalización por parar muy lejos: -  0.15061743566689242\n",
      "Penalización por duración del episodio: -  0.32144128888451784\n",
      "Recompensa por acortar distancias: +  0.9063683662308124\n",
      "Penalización por parar muy lejos: -  0.15059749498752917\n",
      "Penalización por duración del episodio: -  0.32183272185505285\n",
      "Recompensa por acortar distancias: +  0.9063517978631631\n",
      "Penalización por parar muy lejos: -  0.15057252492720957\n",
      "Penalización por duración del episodio: -  0.3221823395288156\n",
      "Recompensa por acortar distancias: +  0.9063515954975296\n",
      "Penalización por parar muy lejos: -  0.15057221998905268\n",
      "Penalización por duración del episodio: -  0.32253054140848664\n",
      "Step: 2310, Mean Reward (últimos 10 pasos): 0.4332488477230072\n",
      "Recompensa por acortar distancias: +  0.9063515954975296\n",
      "Penalización por parar muy lejos: -  0.15057221998905268\n",
      "Penalización por duración del episodio: -  0.3226233462124821\n",
      "Recompensa por acortar distancias: +  0.9063510167296535\n",
      "Penalización por duración del episodio: -  0.3228736340462783\n",
      "Recompensa por acortar distancias: +  0.9063509600668918\n",
      "Penalización por parar muy lejos: -  0.1505712624865426\n",
      "Penalización por duración del episodio: -  0.3232179501672894\n",
      "Recompensa por acortar distancias: +  0.9063506281843848\n",
      "Penalización por duración del episodio: -  0.3235552151079078\n",
      "Recompensa por acortar distancias: +  0.9063468640772647\n",
      "Penalización por parar muy lejos: -  0.15056509067975046\n",
      "Penalización por duración del episodio: -  0.32388744253270113\n",
      "Recompensa por acortar distancias: +  0.9063243292144352\n",
      "Penalización por parar muy lejos: -  0.15053114336538592\n",
      "Penalización por duración del episodio: -  0.3239837146748009\n",
      "Recompensa por acortar distancias: +  0.9063243292144352\n",
      "Penalización por parar muy lejos: -  0.15053114336538592\n",
      "Penalización por duración del episodio: -  0.3242404975411983\n",
      "Recompensa por acortar distancias: +  0.9062995380844627\n",
      "Penalización por parar muy lejos: -  0.1504938128609253\n",
      "Penalización por duración del episodio: -  0.3245866022603408\n",
      "Recompensa por acortar distancias: +  0.9062995380844627\n",
      "Penalización por parar muy lejos: -  0.1504938128609253\n",
      "Penalización por duración del episodio: -  0.324924557387494\n",
      "Recompensa por acortar distancias: +  0.9062818166972771\n",
      "Penalización por parar muy lejos: -  0.15046713807621848\n",
      "Penalización por duración del episodio: -  0.32525925196053596\n",
      "Step: 2320, Mean Reward (últimos 10 pasos): 0.43055543303489685\n",
      "Recompensa por acortar distancias: +  0.9062732343515771\n",
      "Penalización por parar muy lejos: -  0.1504542226853761\n",
      "Penalización por duración del episodio: -  0.32560055917595065\n",
      "Recompensa por acortar distancias: +  0.9062354822970382\n",
      "Penalización por parar muy lejos: -  0.1503974338306064\n",
      "Penalización por duración del episodio: -  0.3259423029620424\n",
      "steer input from model: -0.05 , throttle:  0.0\n",
      "reward: 0.42989574550438936\n",
      "Recompensa por acortar distancias: +  0.9062251050823736\n",
      "Penalización por duración del episodio: -  0.32628574130276383\n",
      "Recompensa por acortar distancias: +  0.9062286345044207\n",
      "Penalización por parar muy lejos: -  0.15038713706558685\n",
      "Penalización por duración del episodio: -  0.326649654907708\n",
      "Recompensa por acortar distancias: +  0.9062194845054556\n",
      "Penalización por duración del episodio: -  0.3269835500471051\n",
      "Recompensa por acortar distancias: +  0.9062194845054556\n",
      "Penalización por parar muy lejos: -  0.1503733805181179\n",
      "Penalización por duración del episodio: -  0.32707436755239\n",
      "Recompensa por acortar distancias: +  0.9062123519759676\n",
      "Penalización por duración del episodio: -  0.32731836601240594\n",
      "Recompensa por acortar distancias: +  0.9062078209461335\n",
      "Penalización por parar muy lejos: -  0.1503558482091041\n",
      "Penalización por duración del episodio: -  0.3273996075928584\n",
      "Recompensa por acortar distancias: +  0.9062078209461335\n",
      "Penalización por parar muy lejos: -  0.1503558482091041\n",
      "Penalización por duración del episodio: -  0.32766226583716257\n",
      "Recompensa por acortar distancias: +  0.9062078209461335\n",
      "Penalización por parar muy lejos: -  0.1503558482091041\n",
      "Penalización por duración del episodio: -  0.32799913547909954\n",
      "Step: 2330, Mean Reward (últimos 10 pasos): 0.4278528392314911\n",
      "Recompensa por acortar distancias: +  0.906200444431287\n",
      "Penalización por parar muy lejos: -  0.15034476193280027\n",
      "Penalización por duración del episodio: -  0.32834115629884447\n",
      "Recompensa por acortar distancias: +  0.906200594398581\n",
      "Penalización por parar muy lejos: -  0.15034498730644283\n",
      "Penalización por duración del episodio: -  0.32868520057763273\n",
      "Recompensa por acortar distancias: +  0.9062006430365761\n",
      "Penalización por duración del episodio: -  0.3290294024376546\n",
      "Recompensa por acortar distancias: +  0.9062006430365761\n",
      "Penalización por duración del episodio: -  0.3293653196629306\n",
      "Recompensa por acortar distancias: +  0.906205178430269\n",
      "Penalización por duración del episodio: -  0.3297151530485109\n",
      "Recompensa por acortar distancias: +  0.906205178430269\n",
      "Penalización por parar muy lejos: -  0.15035187656464788\n",
      "Penalización por duración del episodio: -  0.33006727337548747\n",
      "Recompensa por acortar distancias: +  0.9061927836538507\n",
      "Penalización por duración del episodio: -  0.3304008959146345\n",
      "Recompensa por acortar distancias: +  0.9061929093113384\n",
      "Penalización por parar muy lejos: -  0.1503334387880097\n",
      "Penalización por duración del episodio: -  0.3307461464787568\n",
      "Recompensa por acortar distancias: +  0.9061950738392125\n",
      "Penalización por parar muy lejos: -  0.15033669130319985\n",
      "Penalización por duración del episodio: -  0.33109533897680615\n",
      "Recompensa por acortar distancias: +  0.9061950738392125\n",
      "Penalización por duración del episodio: -  0.331174315678775\n",
      "Step: 2340, Mean Reward (últimos 10 pasos): 0.5750207304954529\n",
      "Recompensa por acortar distancias: +  0.9061950738392125\n",
      "Penalización por parar muy lejos: -  0.15033669130319985\n",
      "Penalización por duración del episodio: -  0.3314366556062223\n",
      "Recompensa por acortar distancias: +  0.9061950738392125\n",
      "Penalización por duración del episodio: -  0.3315454263715483\n",
      "steer input from model: 0.05 , throttle:  0.3\n",
      "reward: 0.5746496474676641\n",
      "Recompensa por acortar distancias: +  0.9061859736030322\n",
      "Penalización por duración del episodio: -  0.331777409561154\n",
      "Recompensa por acortar distancias: +  0.9061859290119533\n",
      "Penalización por duración del episodio: -  0.33211749894538817\n",
      "Recompensa por acortar distancias: +  0.9061859290119533\n",
      "Penalización por duración del episodio: -  0.3324653511413519\n",
      "Recompensa por acortar distancias: +  0.9061993054834708\n",
      "Penalización por parar muy lejos: -  0.15034305032042783\n",
      "Penalización por duración del episodio: -  0.3328101196966765\n",
      "Recompensa por acortar distancias: +  0.9062114644283339\n",
      "Penalización por parar muy lejos: -  0.15036132459054014\n",
      "Penalización por duración del episodio: -  0.3331589816703183\n",
      "Recompensa por acortar distancias: +  0.9062116386962715\n",
      "Penalización por duración del episodio: -  0.3335047037083157\n",
      "Recompensa por acortar distancias: +  0.9062116386962715\n",
      "Penalización por parar muy lejos: -  0.15036158653503415\n",
      "Penalización por duración del episodio: -  0.33385430590660287\n",
      "Recompensa por acortar distancias: +  0.906211772436585\n",
      "Penalización por duración del episodio: -  0.3341998679768003\n",
      "Step: 2350, Mean Reward (últimos 10 pasos): 0.5720118880271912\n",
      "Recompensa por acortar distancias: +  0.9062119750730977\n",
      "Penalización por parar muy lejos: -  0.15036209214988697\n",
      "Penalización por duración del episodio: -  0.33455744457201997\n",
      "Recompensa por acortar distancias: +  0.9062121696037809\n",
      "Penalización por parar muy lejos: -  0.1503623845542959\n",
      "Penalización por duración del episodio: -  0.3349121523457447\n",
      "Recompensa por acortar distancias: +  0.9062122587635563\n",
      "Penalización por duración del episodio: -  0.33526065995670645\n",
      "Recompensa por acortar distancias: +  0.9062162668222471\n",
      "Penalización por duración del episodio: -  0.33560675826097924\n",
      "Recompensa por acortar distancias: +  0.9062162668222471\n",
      "Penalización por parar muy lejos: -  0.1503685434308971\n",
      "Penalización por duración del episodio: -  0.3359610701069976\n",
      "Recompensa por acortar distancias: +  0.9062162668222471\n",
      "Penalización por parar muy lejos: -  0.1503685434308971\n",
      "Penalización por duración del episodio: -  0.3363221602562347\n",
      "Recompensa por acortar distancias: +  0.9061903393830274\n",
      "Penalización por parar muy lejos: -  0.15032957726278012\n",
      "Penalización por duración del episodio: -  0.3366780160368082\n",
      "Recompensa por acortar distancias: +  0.9061899461865359\n",
      "Penalización por duración del episodio: -  0.337019806819919\n",
      "Recompensa por acortar distancias: +  0.9061899988830588\n",
      "Penalización por duración del episodio: -  0.3371208918825149\n",
      "Recompensa por acortar distancias: +  0.906196103392937\n",
      "Penalización por duración del episodio: -  0.33737482629182275\n",
      "Step: 2360, Mean Reward (últimos 10 pasos): 0.5688212513923645\n",
      "Recompensa por acortar distancias: +  0.9061959372058167\n",
      "Penalización por duración del episodio: -  0.3377417932079394\n",
      "Recompensa por acortar distancias: +  0.9061959372058167\n",
      "Penalización por duración del episodio: -  0.3380952592575103\n",
      "steer input from model: 0.0 , throttle:  0.7\n",
      "reward: 0.5681006779483064\n",
      "Recompensa por acortar distancias: +  0.9061835818728888\n",
      "Penalización por parar muy lejos: -  0.15031942439906712\n",
      "Penalización por duración del episodio: -  0.33844144872408244\n",
      "Recompensa por acortar distancias: +  0.90617322383431\n",
      "Penalización por parar muy lejos: -  0.15030386426668316\n",
      "Penalización por duración del episodio: -  0.3387801097995583\n",
      "Recompensa por acortar distancias: +  0.906172360280299\n",
      "Penalización por duración del episodio: -  0.3391409831470154\n",
      "Recompensa por acortar distancias: +  0.9061737184488914\n",
      "Penalización por parar muy lejos: -  0.15030460722524985\n",
      "Penalización por duración del episodio: -  0.3392316582593973\n",
      "Recompensa por acortar distancias: +  0.9061661084232668\n",
      "Penalización por duración del episodio: -  0.3394990870266315\n",
      "Recompensa por acortar distancias: +  0.9061617740697407\n",
      "Penalización por duración del episodio: -  0.3396086623880227\n",
      "Recompensa por acortar distancias: +  0.9061646569011012\n",
      "Penalización por parar muy lejos: -  0.15029099694745482\n",
      "Penalización por duración del episodio: -  0.33970634511666525\n",
      "Recompensa por acortar distancias: +  0.9061531372642991\n",
      "Penalización por duración del episodio: -  0.3398529990871968\n",
      "Step: 2370, Mean Reward (últimos 10 pasos): 0.5663001537322998\n",
      "Recompensa por acortar distancias: +  0.9061531372642991\n",
      "Penalización por duración del episodio: -  0.3402119012421941\n",
      "Recompensa por acortar distancias: +  0.9061531372642991\n",
      "Penalización por parar muy lejos: -  0.15027369783048927\n",
      "Penalización por duración del episodio: -  0.34055680305415276\n",
      "Recompensa por acortar distancias: +  0.9061204366489265\n",
      "Penalización por duración del episodio: -  0.3409065451576921\n",
      "Recompensa por acortar distancias: +  0.9061186315922982\n",
      "Penalización por duración del episodio: -  0.34125437030135125\n",
      "Recompensa por acortar distancias: +  0.9061186315922982\n",
      "Penalización por duración del episodio: -  0.3413330917897249\n",
      "Recompensa por acortar distancias: +  0.9061186315922982\n",
      "Penalización por parar muy lejos: -  0.15022190161998947\n",
      "Penalización por duración del episodio: -  0.34160960550638\n",
      "Recompensa por acortar distancias: +  0.9060609548160963\n",
      "Penalización por duración del episodio: -  0.34193881629705397\n",
      "Recompensa por acortar distancias: +  0.9060620181575292\n",
      "Penalización por parar muy lejos: -  0.15013698838206313\n",
      "Penalización por duración del episodio: -  0.34228291279629547\n",
      "Recompensa por acortar distancias: +  0.9060620181575292\n",
      "Penalización por duración del episodio: -  0.3426400311515906\n",
      "Recompensa por acortar distancias: +  0.9060340836009954\n",
      "Penalización por parar muy lejos: -  0.15009512141270148\n",
      "Penalización por duración del episodio: -  0.34300215255621525\n",
      "Step: 2380, Mean Reward (últimos 10 pasos): 0.412936806678772\n",
      "Recompensa por acortar distancias: +  0.9060191350284222\n",
      "Penalización por parar muy lejos: -  0.1500727257409548\n",
      "Penalización por duración del episodio: -  0.34335579686943957\n",
      "Recompensa por acortar distancias: +  0.9060180874928632\n",
      "Penalización por duración del episodio: -  0.34370559225164143\n",
      "steer input from model: 0.1 , throttle:  1.0\n",
      "reward: 0.5623124952412217\n",
      "Recompensa por acortar distancias: +  0.9060180144085964\n",
      "Penalización por parar muy lejos: -  0.15007104708880994\n",
      "Penalización por duración del episodio: -  0.34380707256356563\n",
      "Recompensa por acortar distancias: +  0.9060180144085964\n",
      "Penalización por parar muy lejos: -  0.15007104708880994\n",
      "Penalización por duración del episodio: -  0.3438977166285441\n",
      "Recompensa por acortar distancias: +  0.9060180468904991\n",
      "Penalización por duración del episodio: -  0.3440408735950785\n",
      "Recompensa por acortar distancias: +  0.9060180956133341\n",
      "Penalización por parar muy lejos: -  0.15007116872975013\n",
      "Penalización por duración del episodio: -  0.3444008736322285\n",
      "Recompensa por acortar distancias: +  0.9060181037338044\n",
      "Penalización por parar muy lejos: -  0.1500711808938486\n",
      "Penalización por duración del episodio: -  0.3447638476675912\n",
      "Recompensa por acortar distancias: +  0.9060181037338044\n",
      "Penalización por duración del episodio: -  0.3448592061911159\n",
      "Recompensa por acortar distancias: +  0.9059867296656767\n",
      "Penalización por duración del episodio: -  0.3451045596839237\n",
      "Recompensa por acortar distancias: +  0.9059893005318848\n",
      "Penalización por duración del episodio: -  0.34545989495844975\n",
      "Step: 2390, Mean Reward (últimos 10 pasos): 0.5605294108390808\n",
      "Recompensa por acortar distancias: +  0.905967155713193\n",
      "Penalización por duración del episodio: -  0.34581969628373005\n",
      "Recompensa por acortar distancias: +  0.9059421945409404\n",
      "Penalización por parar muy lejos: -  0.1499575489146335\n",
      "Penalización por duración del episodio: -  0.346170176637911\n",
      "Recompensa por acortar distancias: +  0.9059415728734781\n",
      "Penalización por duración del episodio: -  0.3465260609458137\n",
      "Recompensa por acortar distancias: +  0.9059420279506744\n",
      "Penalización por duración del episodio: -  0.3465947487882426\n",
      "Recompensa por acortar distancias: +  0.9059420279506744\n",
      "Penalización por duración del episodio: -  0.34687851423085464\n",
      "Recompensa por acortar distancias: +  0.9059420279506744\n",
      "Penalización por duración del episodio: -  0.34722606114226845\n",
      "Recompensa por acortar distancias: +  0.9059105538999482\n",
      "Penalización por parar muy lejos: -  0.14991022975786328\n",
      "Penalización por duración del episodio: -  0.34757134343135426\n",
      "Recompensa por acortar distancias: +  0.9058975023040396\n",
      "Penalización por parar muy lejos: -  0.1498907185939846\n",
      "Penalización por duración del episodio: -  0.3479181924170149\n",
      "Recompensa por acortar distancias: +  0.9058961730719863\n",
      "Penalización por duración del episodio: -  0.347987950517581\n",
      "Recompensa por acortar distancias: +  0.9058962462411608\n",
      "Penalización por parar muy lejos: -  0.14988884111177883\n",
      "Penalización por duración del episodio: -  0.34828284460545755\n",
      "Step: 2400, Mean Reward (últimos 10 pasos): 0.4077245593070984\n",
      "Recompensa por acortar distancias: +  0.9058962868906801\n",
      "Penalización por duración del episodio: -  0.348631610564037\n",
      "Recompensa por acortar distancias: +  0.9058903844157394\n",
      "Penalización por parar muy lejos: -  0.1498800797842698\n",
      "Penalización por duración del episodio: -  0.34896541546511617\n",
      "steer input from model: -0.25 , throttle:  0.0\n",
      "reward: 0.4070448891663535\n",
      "Recompensa por acortar distancias: +  0.9058903844157394\n",
      "Penalización por parar muy lejos: -  0.1498800797842698\n",
      "Penalización por duración del episodio: -  0.3493186496305259\n",
      "Recompensa por acortar distancias: +  0.9058903844157394\n",
      "Penalización por duración del episodio: -  0.3496693005235139\n",
      "Recompensa por acortar distancias: +  0.9058398502095253\n",
      "Penalización por parar muy lejos: -  0.14980458701950636\n",
      "Penalización por duración del episodio: -  0.35001875801976634\n",
      "Recompensa por acortar distancias: +  0.9058398502095253\n",
      "Penalización por parar muy lejos: -  0.14980458701950636\n",
      "Penalización por duración del episodio: -  0.35036610283945474\n",
      "Recompensa por acortar distancias: +  0.9058539337563224\n",
      "Penalización por duración del episodio: -  0.35071363350922447\n",
      "Recompensa por acortar distancias: +  0.9058541370856517\n",
      "Penalización por parar muy lejos: -  0.1498259232446988\n",
      "Penalización por duración del episodio: -  0.351071126689269\n",
      "Recompensa por acortar distancias: +  0.9058520915746662\n",
      "Penalización por parar muy lejos: -  0.1498228681178312\n",
      "Penalización por duración del episodio: -  0.3514241571192458\n",
      "Recompensa por acortar distancias: +  0.9058520915746662\n",
      "Penalización por duración del episodio: -  0.35178204195970575\n",
      "Step: 2410, Mean Reward (últimos 10 pasos): 0.5540700554847717\n",
      "Recompensa por acortar distancias: +  0.9058175884185891\n",
      "Penalización por parar muy lejos: -  0.14977135171081435\n",
      "Penalización por duración del episodio: -  0.3521454619103421\n",
      "Recompensa por acortar distancias: +  0.9058056318948026\n",
      "Penalización por duración del episodio: -  0.3525056900966442\n",
      "Recompensa por acortar distancias: +  0.9057829030208956\n",
      "Penalización por parar muy lejos: -  0.149719594944945\n",
      "Penalización por duración del episodio: -  0.3528513593070071\n",
      "Recompensa por acortar distancias: +  0.9057589318792246\n",
      "Penalización por duración del episodio: -  0.35321124050573116\n",
      "Recompensa por acortar distancias: +  0.9057327405200598\n",
      "Penalización por parar muy lejos: -  0.1496447998367296\n",
      "Penalización por duración del episodio: -  0.35331367329254365\n",
      "Recompensa por acortar distancias: +  0.9057327405200598\n",
      "Penalización por duración del episodio: -  0.3535775712411405\n",
      "Recompensa por acortar distancias: +  0.9057327405200598\n",
      "Penalización por parar muy lejos: -  0.1496447998367296\n",
      "Penalización por duración del episodio: -  0.353933960861068\n",
      "Recompensa por acortar distancias: +  0.9057327405200598\n",
      "Penalización por parar muy lejos: -  0.1496447998367296\n",
      "Penalización por duración del episodio: -  0.3543015578002421\n",
      "Recompensa por acortar distancias: +  0.9057176716314946\n",
      "Penalización por parar muy lejos: -  0.1496223442542343\n",
      "Penalización por duración del episodio: -  0.35465889341326917\n",
      "Recompensa por acortar distancias: +  0.9057172237255351\n",
      "Penalización por duración del episodio: -  0.3550227131679401\n",
      "Step: 2420, Mean Reward (últimos 10 pasos): 0.5506945252418518\n",
      "Recompensa por acortar distancias: +  0.9057172807318541\n",
      "Penalización por duración del episodio: -  0.3551513458420987\n",
      "Recompensa por acortar distancias: +  0.9057172807318541\n",
      "Penalización por duración del episodio: -  0.35538351089109305\n",
      "steer input from model: -0.05 , throttle:  0.3\n",
      "reward: 0.5503337698407611\n",
      "Recompensa por acortar distancias: +  0.9057171789348343\n",
      "Penalización por duración del episodio: -  0.3557549864699504\n",
      "Recompensa por acortar distancias: +  0.9057184982165786\n",
      "Penalización por duración del episodio: -  0.35611804729545815\n",
      "Recompensa por acortar distancias: +  0.9057184982165786\n",
      "Penalización por parar muy lejos: -  0.14962357587186464\n",
      "Penalización por duración del episodio: -  0.35621951923176504\n",
      "Recompensa por acortar distancias: +  0.9057184982165786\n",
      "Penalización por parar muy lejos: -  0.14962357587186464\n",
      "Penalización por duración del episodio: -  0.3564682730112382\n",
      "Recompensa por acortar distancias: +  0.9056959785780887\n",
      "Penalización por duración del episodio: -  0.35682546456213365\n",
      "Recompensa por acortar distancias: +  0.9056959785780887\n",
      "Penalización por parar muy lejos: -  0.14959002789476974\n",
      "Penalización por duración del episodio: -  0.35718189023927466\n",
      "Recompensa por acortar distancias: +  0.9056941865735042\n",
      "Penalización por duración del episodio: -  0.3575413930551897\n",
      "Recompensa por acortar distancias: +  0.9056898571274581\n",
      "Penalización por parar muy lejos: -  0.14958091095360085\n",
      "Penalización por duración del episodio: -  0.3579089570738312\n",
      "Step: 2430, Mean Reward (últimos 10 pasos): 0.39819997549057007\n",
      "Recompensa por acortar distancias: +  0.9056847780489262\n",
      "Penalización por parar muy lejos: -  0.14957334721225263\n",
      "Penalización por duración del episodio: -  0.3579894216682817\n",
      "Recompensa por acortar distancias: +  0.9056847780489262\n",
      "Penalización por parar muy lejos: -  0.14957334721225263\n",
      "Penalización por duración del episodio: -  0.3580811068117779\n",
      "Recompensa por acortar distancias: +  0.9056847780489262\n",
      "Penalización por duración del episodio: -  0.35826863582239377\n",
      "Recompensa por acortar distancias: +  0.9056847780489262\n",
      "Penalización por duración del episodio: -  0.3586209940511999\n",
      "Recompensa por acortar distancias: +  0.9056728267885175\n",
      "Penalización por parar muy lejos: -  0.14955555213064828\n",
      "Penalización por duración del episodio: -  0.35897143664649694\n",
      "Recompensa por acortar distancias: +  0.9056619700881882\n",
      "Penalización por parar muy lejos: -  0.14953939008033815\n",
      "Penalización por duración del episodio: -  0.35932892907356195\n",
      "Recompensa por acortar distancias: +  0.9056611226888756\n",
      "Penalización por parar muy lejos: -  0.14953812871258237\n",
      "Penalización por duración del episodio: -  0.3596856772196754\n",
      "Recompensa por acortar distancias: +  0.9056613060210356\n",
      "Penalización por duración del episodio: -  0.35979497862099574\n",
      "Recompensa por acortar distancias: +  0.9056612978729464\n",
      "Penalización por parar muy lejos: -  0.14953838947538978\n",
      "Penalización por duración del episodio: -  0.35989336451583503\n",
      "Recompensa por acortar distancias: +  0.9056613304652994\n",
      "Penalización por parar muy lejos: -  0.14953843798944183\n",
      "Penalización por duración del episodio: -  0.3600550617163639\n",
      "Step: 2440, Mean Reward (últimos 10 pasos): 0.3960678279399872\n",
      "Recompensa por acortar distancias: +  0.9056613549095578\n",
      "Penalización por duración del episodio: -  0.36013288126819115\n",
      "Recompensa por acortar distancias: +  0.9056614037980572\n",
      "Penalización por duración del episodio: -  0.36040222714802345\n",
      "steer input from model: -0.1 , throttle:  0.3\n",
      "reward: 0.5452591766500337\n",
      "Recompensa por acortar distancias: +  0.9056614037980572\n",
      "Penalización por parar muy lejos: -  0.14953854714610632\n",
      "Penalización por duración del episodio: -  0.36076258584208737\n",
      "Recompensa por acortar distancias: +  0.9056614037980572\n",
      "Penalización por duración del episodio: -  0.3611291026245277\n",
      "Recompensa por acortar distancias: +  0.905639026789602\n",
      "Penalización por duración del episodio: -  0.36147849064584126\n",
      "Recompensa por acortar distancias: +  0.905639026789602\n",
      "Penalización por duración del episodio: -  0.3618469966884688\n",
      "Recompensa por acortar distancias: +  0.9056055379619901\n",
      "Penalización por duración del episodio: -  0.36221579197423465\n",
      "Recompensa por acortar distancias: +  0.905590100255103\n",
      "Penalización por duración del episodio: -  0.3625876755248749\n",
      "Recompensa por acortar distancias: +  0.9055775307345214\n",
      "Penalización por parar muy lejos: -  0.14941379363274065\n",
      "Penalización por duración del episodio: -  0.36268977065942204\n",
      "Recompensa por acortar distancias: +  0.9055775307345214\n",
      "Penalización por parar muy lejos: -  0.14941379363274065\n",
      "Penalización por duración del episodio: -  0.3627758340179016\n",
      "Step: 2450, Mean Reward (últimos 10 pasos): 0.39338791370391846\n",
      "Recompensa por acortar distancias: +  0.9055775307345214\n",
      "Penalización por parar muy lejos: -  0.14941379363274065\n",
      "Penalización por duración del episodio: -  0.36294969052022164\n",
      "Recompensa por acortar distancias: +  0.9055775307345214\n",
      "Penalización por parar muy lejos: -  0.14941379363274065\n",
      "Penalización por duración del episodio: -  0.36330667133360545\n",
      "Recompensa por acortar distancias: +  0.9055815141668232\n",
      "Penalización por duración del episodio: -  0.3634053400374822\n",
      "Recompensa por acortar distancias: +  0.9055814122384976\n",
      "Penalización por parar muy lejos: -  0.14941956293083938\n",
      "Penalización por duración del episodio: -  0.3636681339174339\n",
      "Recompensa por acortar distancias: +  0.9055814122384976\n",
      "Penalización por duración del episodio: -  0.3640177728938676\n",
      "Recompensa por acortar distancias: +  0.9055692902192077\n",
      "Penalización por parar muy lejos: -  0.14940154660335433\n",
      "Penalización por duración del episodio: -  0.3641165353174285\n",
      "Recompensa por acortar distancias: +  0.9055651432145237\n",
      "Penalización por duración del episodio: -  0.3643951321825105\n",
      "Recompensa por acortar distancias: +  0.9055434268836531\n",
      "Penalización por parar muy lejos: -  0.14936312017992348\n",
      "Penalización por duración del episodio: -  0.3645045364050626\n",
      "Recompensa por acortar distancias: +  0.9055251490746167\n",
      "Penalización por duración del episodio: -  0.3647529029713666\n",
      "Recompensa por acortar distancias: +  0.9054895551609142\n",
      "Penalización por parar muy lejos: -  0.14928313671884946\n",
      "Penalización por duración del episodio: -  0.36511095036187124\n",
      "Step: 2460, Mean Reward (últimos 10 pasos): 0.39109545946121216\n",
      "Recompensa por acortar distancias: +  0.9054895551609142\n",
      "Penalización por parar muy lejos: -  0.14928313671884946\n",
      "Penalización por duración del episodio: -  0.36547742390823956\n",
      "Recompensa por acortar distancias: +  0.9053434266842175\n",
      "Penalización por parar muy lejos: -  0.14906656239107277\n",
      "Penalización por duración del episodio: -  0.36585357286178544\n",
      "steer input from model: 0.9 , throttle:  0.0\n",
      "reward: 0.39042329143135934\n",
      "Recompensa por acortar distancias: +  0.9052947226718043\n",
      "Penalización por parar muy lejos: -  0.14899450312902515\n",
      "Penalización por duración del episodio: -  0.3662235050249974\n",
      "Recompensa por acortar distancias: +  0.9052758906541595\n",
      "Penalización por duración del episodio: -  0.3665973485204166\n",
      "Recompensa por acortar distancias: +  0.9052753631785668\n",
      "Penalización por duración del episodio: -  0.36695422212081247\n",
      "Recompensa por acortar distancias: +  0.9052682726699783\n",
      "Penalización por duración del episodio: -  0.36732291045314036\n",
      "Recompensa por acortar distancias: +  0.9052677901382838\n",
      "Penalización por duración del episodio: -  0.3676789052436816\n",
      "Recompensa por acortar distancias: +  0.9052677901382838\n",
      "Penalización por parar muy lejos: -  0.1489546820994163\n",
      "Penalización por duración del episodio: -  0.3680399741046521\n",
      "Recompensa por acortar distancias: +  0.9052443478978593\n",
      "Penalización por parar muy lejos: -  0.14892003702904896\n",
      "Penalización por duración del episodio: -  0.3684076372545952\n",
      "Recompensa por acortar distancias: +  0.9052442129222632\n",
      "Penalización por duración del episodio: -  0.3687624888677023\n",
      "Step: 2470, Mean Reward (últimos 10 pasos): 0.5364817380905151\n",
      "Recompensa por acortar distancias: +  0.9052442579141476\n",
      "Penalización por parar muy lejos: -  0.14891990407054692\n",
      "Penalización por duración del episodio: -  0.36912428935924596\n",
      "Recompensa por acortar distancias: +  0.905244356078193\n",
      "Penalización por duración del episodio: -  0.3694981123147423\n",
      "Recompensa por acortar distancias: +  0.9052418283250124\n",
      "Penalización por parar muy lejos: -  0.14891631422801233\n",
      "Penalización por duración del episodio: -  0.3698538659613912\n",
      "Recompensa por acortar distancias: +  0.9052418283250124\n",
      "Penalización por parar muy lejos: -  0.14891631422801233\n",
      "Penalización por duración del episodio: -  0.37022885581755244\n",
      "Recompensa por acortar distancias: +  0.9052138022139817\n",
      "Penalización por duración del episodio: -  0.37032185637946724\n",
      "Recompensa por acortar distancias: +  0.9052060242768252\n",
      "Penalización por duración del episodio: -  0.37060618228930425\n",
      "Recompensa por acortar distancias: +  0.9052060242768252\n",
      "Penalización por duración del episodio: -  0.37097437003841455\n",
      "Recompensa por acortar distancias: +  0.9051745671067806\n",
      "Penalización por parar muy lejos: -  0.14881699336030077\n",
      "Penalización por duración del episodio: -  0.3713411604632953\n",
      "Recompensa por acortar distancias: +  0.9051650384918314\n",
      "Penalización por duración del episodio: -  0.3717178600942714\n",
      "Recompensa por acortar distancias: +  0.9051636181308907\n",
      "Penalización por duración del episodio: -  0.37207051810739716\n",
      "Step: 2480, Mean Reward (últimos 10 pasos): 0.5330930948257446\n",
      "Recompensa por acortar distancias: +  0.9051636181308907\n",
      "Penalización por duración del episodio: -  0.37244510636110534\n",
      "Recompensa por acortar distancias: +  0.9051679610189888\n",
      "Penalización por parar muy lejos: -  0.14880724487022176\n",
      "Penalización por duración del episodio: -  0.3728072432306724\n",
      "steer input from model: 0.05 , throttle:  0.0\n",
      "reward: 0.3835534729180946\n",
      "Recompensa por acortar distancias: +  0.9051772028781233\n",
      "Penalización por duración del episodio: -  0.37317446959653\n",
      "Recompensa por acortar distancias: +  0.9052038761398341\n",
      "Penalización por duración del episodio: -  0.37325714080127675\n",
      "Recompensa por acortar distancias: +  0.9052078777771464\n",
      "Penalización por duración del episodio: -  0.37336012346193737\n",
      "Recompensa por acortar distancias: +  0.9052224427871437\n",
      "Penalización por duración del episodio: -  0.37354119506756295\n",
      "Recompensa por acortar distancias: +  0.9052256869111561\n",
      "Penalización por parar muy lejos: -  0.14889246836599984\n",
      "Penalización por duración del episodio: -  0.37362126548060215\n",
      "Recompensa por acortar distancias: +  0.9052367930898277\n",
      "Penalización por duración del episodio: -  0.37375273188747854\n",
      "Recompensa por acortar distancias: +  0.9052367930898277\n",
      "Penalización por duración del episodio: -  0.37390880269621163\n",
      "Recompensa por acortar distancias: +  0.9052449082492514\n",
      "Penalización por parar muy lejos: -  0.1489208650001063\n",
      "Penalización por duración del episodio: -  0.37401467678402484\n",
      "Step: 2490, Mean Reward (últimos 10 pasos): 0.3823093771934509\n",
      "Recompensa por acortar distancias: +  0.9052449082492514\n",
      "Penalización por parar muy lejos: -  0.1489208650001063\n",
      "Penalización por duración del episodio: -  0.3742706931824216\n",
      "Recompensa por acortar distancias: +  0.9052417424294261\n",
      "Penalización por parar muy lejos: -  0.148916187315694\n",
      "Penalización por duración del episodio: -  0.3746361539963158\n",
      "Recompensa por acortar distancias: +  0.9052417424294261\n",
      "Penalización por duración del episodio: -  0.37500231100889836\n",
      "Recompensa por acortar distancias: +  0.9052501844051888\n",
      "Penalización por parar muy lejos: -  0.14892866141017716\n",
      "Penalización por duración del episodio: -  0.3753777118579071\n",
      "Recompensa por acortar distancias: +  0.9052501844051888\n",
      "Penalización por duración del episodio: -  0.3757473402276564\n",
      "Recompensa por acortar distancias: +  0.9051833704904579\n",
      "Penalización por parar muy lejos: -  0.14882998612625167\n",
      "Penalización por duración del episodio: -  0.37612062119949813\n",
      "Recompensa por acortar distancias: +  0.9051313294596057\n",
      "Penalización por duración del episodio: -  0.37623452820115094\n",
      "Recompensa por acortar distancias: +  0.9051054652259999\n",
      "Penalización por parar muy lejos: -  0.14871507702670883\n",
      "Penalización por duración del episodio: -  0.3764818036577075\n",
      "Recompensa por acortar distancias: +  0.9050785541559878\n",
      "Penalización por duración del episodio: -  0.37685644318667066\n",
      "Recompensa por acortar distancias: +  0.9050785541559878\n",
      "Penalización por duración del episodio: -  0.3772195237118244\n",
      "Step: 2500, Mean Reward (últimos 10 pasos): 0.5278590321540833\n",
      "Recompensa por acortar distancias: +  0.9049030470945465\n",
      "Penalización por parar muy lejos: -  0.14841724905817108\n",
      "Penalización por duración del episodio: -  0.3775879026192558\n",
      "Recompensa por acortar distancias: +  0.9048626213929185\n",
      "Penalización por duración del episodio: -  0.37794800935619144\n",
      "steer input from model: -0.05 , throttle:  0.3\n",
      "reward: 0.5269146120367271\n",
      "Recompensa por acortar distancias: +  0.9047142690759773\n",
      "Penalización por duración del episodio: -  0.3783077797639685\n",
      "Recompensa por acortar distancias: +  0.9045618774128273\n",
      "Penalización por parar muy lejos: -  0.1479176605569825\n",
      "Penalización por duración del episodio: -  0.37842346154383805\n",
      "Recompensa por acortar distancias: +  0.9045154906151275\n",
      "Penalización por parar muy lejos: -  0.1478499651371132\n",
      "Penalización por duración del episodio: -  0.3785448892999183\n",
      "Recompensa por acortar distancias: +  0.9044690300913213\n",
      "Penalización por duración del episodio: -  0.37868633585207295\n",
      "Recompensa por acortar distancias: +  0.9044298572194944\n",
      "Penalización por parar muy lejos: -  0.14772513891498698\n",
      "Penalización por duración del episodio: -  0.3790632327872581\n",
      "Recompensa por acortar distancias: +  0.9043899525565967\n",
      "Penalización por parar muy lejos: -  0.14766703452920255\n",
      "Penalización por duración del episodio: -  0.3794371038865319\n",
      "Recompensa por acortar distancias: +  0.9043899525565967\n",
      "Penalización por parar muy lejos: -  0.14766703452920255\n",
      "Penalización por duración del episodio: -  0.37980408128288995\n",
      "Recompensa por acortar distancias: +  0.9040259900948592\n",
      "Penalización por duración del episodio: -  0.3801649038947294\n",
      "Step: 2510, Mean Reward (últimos 10 pasos): 0.5238611102104187\n",
      "Recompensa por acortar distancias: +  0.9040259900948592\n",
      "Penalización por duración del episodio: -  0.38023910473812517\n",
      "Recompensa por acortar distancias: +  0.9038028555045776\n",
      "Penalización por parar muy lejos: -  0.1468168409556878\n",
      "Penalización por duración del episodio: -  0.3805237514233135\n",
      "Recompensa por acortar distancias: +  0.9037087010655165\n",
      "Penalización por duración del episodio: -  0.38088753088220545\n",
      "Recompensa por acortar distancias: +  0.9036955466558043\n",
      "Penalización por parar muy lejos: -  0.14666238231005116\n",
      "Penalización por duración del episodio: -  0.3812493462310291\n",
      "Recompensa por acortar distancias: +  0.9036751562231701\n",
      "Penalización por duración del episodio: -  0.3816137577501408\n",
      "Recompensa por acortar distancias: +  0.9036751562231701\n",
      "Penalización por duración del episodio: -  0.381979670251498\n",
      "Recompensa por acortar distancias: +  0.9036005632103485\n",
      "Penalización por duración del episodio: -  0.38234910057232774\n",
      "Recompensa por acortar distancias: +  0.9036005632103485\n",
      "Penalización por parar muy lejos: -  0.14652590502970317\n",
      "Penalización por duración del episodio: -  0.3827374121341478\n",
      "Recompensa por acortar distancias: +  0.9035796272088052\n",
      "Penalización por duración del episodio: -  0.38311254160158514\n",
      "Recompensa por acortar distancias: +  0.9035792283884067\n",
      "Penalización por duración del episodio: -  0.3834797215282615\n",
      "Step: 2520, Mean Reward (últimos 10 pasos): 0.5200995206832886\n",
      "Recompensa por acortar distancias: +  0.9035705536801553\n",
      "Penalización por parar muy lejos: -  0.1464828325669851\n",
      "Penalización por duración del episodio: -  0.38384899670019673\n",
      "Recompensa por acortar distancias: +  0.9035705536801553\n",
      "Penalización por duración del episodio: -  0.38422406365288675\n",
      "steer input from model: -0.9 , throttle:  1.0\n",
      "reward: 0.5193464900272685\n",
      "Recompensa por acortar distancias: +  0.9035273400927906\n",
      "Penalización por duración del episodio: -  0.38433273546914876\n",
      "Recompensa por acortar distancias: +  0.9035273400927906\n",
      "Penalización por parar muy lejos: -  0.14642084786362225\n",
      "Penalización por duración del episodio: -  0.38458591718855106\n",
      "Recompensa por acortar distancias: +  0.903506344157775\n",
      "Penalización por duración del episodio: -  0.38495409655618\n",
      "Recompensa por acortar distancias: +  0.903483531238253\n",
      "Penalización por duración del episodio: -  0.3850576462410646\n",
      "Recompensa por acortar distancias: +  0.9034659370135686\n",
      "Penalización por parar muy lejos: -  0.14633285250769368\n",
      "Penalización por duración del episodio: -  0.38532147031816294\n",
      "Recompensa por acortar distancias: +  0.9034543709204474\n",
      "Penalización por parar muy lejos: -  0.14631628790138143\n",
      "Penalización por duración del episodio: -  0.3857103392668401\n",
      "Recompensa por acortar distancias: +  0.9034541712790645\n",
      "Penalización por duración del episodio: -  0.3860761620708634\n",
      "Recompensa por acortar distancias: +  0.9034541712790645\n",
      "Penalización por parar muy lejos: -  0.1463160020102742\n",
      "Penalización por duración del episodio: -  0.3864487276145724\n",
      "Step: 2530, Mean Reward (últimos 10 pasos): 0.3706894516944885\n",
      "Recompensa por acortar distancias: +  0.9034541712790645\n",
      "Penalización por duración del episodio: -  0.3868152960822591\n",
      "Recompensa por acortar distancias: +  0.9034433984160666\n",
      "Penalización por parar muy lejos: -  0.14630057648891254\n",
      "Penalización por duración del episodio: -  0.38718268299278386\n",
      "Recompensa por acortar distancias: +  0.9034079568581117\n",
      "Penalización por duración del episodio: -  0.38756200301032745\n",
      "Recompensa por acortar distancias: +  0.9033623304422457\n",
      "Penalización por parar muy lejos: -  0.14618458878575297\n",
      "Penalización por duración del episodio: -  0.38794329924671117\n",
      "Recompensa por acortar distancias: +  0.9033177134044702\n",
      "Penalización por duración del episodio: -  0.38832275066586985\n",
      "Recompensa por acortar distancias: +  0.9032784855208792\n",
      "Penalización por duración del episodio: -  0.38869527312960944\n",
      "Recompensa por acortar distancias: +  0.9032784855208792\n",
      "Penalización por parar muy lejos: -  0.14606479943711204\n",
      "Penalización por duración del episodio: -  0.38906746661772706\n",
      "Recompensa por acortar distancias: +  0.9032323960616659\n",
      "Penalización por parar muy lejos: -  0.14599902549200786\n",
      "Penalización por duración del episodio: -  0.3894210421279913\n",
      "Recompensa por acortar distancias: +  0.9032321459975724\n",
      "Penalización por duración del episodio: -  0.38980287848038264\n",
      "Recompensa por acortar distancias: +  0.9032347299653812\n",
      "Penalización por parar muy lejos: -  0.14600235492705366\n",
      "Penalización por duración del episodio: -  0.38991105714012636\n",
      "Step: 2540, Mean Reward (últimos 10 pasos): 0.36732131242752075\n",
      "Recompensa por acortar distancias: +  0.9032303538546851\n",
      "Penalización por parar muy lejos: -  0.14599611228797713\n",
      "Penalización por duración del episodio: -  0.3900053444565619\n",
      "Recompensa por acortar distancias: +  0.9032349133414007\n",
      "Penalización por parar muy lejos: -  0.14600261652818866\n",
      "Penalización por duración del episodio: -  0.39016663429679327\n",
      "steer input from model: 0.9 , throttle:  0.0\n",
      "reward: 0.36706566251641876\n",
      "Recompensa por acortar distancias: +  0.9032355301493707\n",
      "Penalización por duración del episodio: -  0.3902553613249875\n",
      "Recompensa por acortar distancias: +  0.9032428440573373\n",
      "Penalización por duración del episodio: -  0.39054926186118355\n",
      "Recompensa por acortar distancias: +  0.9032462028718893\n",
      "Penalización por duración del episodio: -  0.3909446154338277\n",
      "Recompensa por acortar distancias: +  0.9032462028718893\n",
      "Penalización por duración del episodio: -  0.3913229448616172\n",
      "Recompensa por acortar distancias: +  0.9032485114756141\n",
      "Penalización por duración del episodio: -  0.3916978317090689\n",
      "Recompensa por acortar distancias: +  0.9032414063195374\n",
      "Penalización por duración del episodio: -  0.39207146545378274\n",
      "Recompensa por acortar distancias: +  0.9032532785449879\n",
      "Penalización por parar muy lejos: -  0.1460288202287043\n",
      "Penalización por duración del episodio: -  0.3921409050484215\n",
      "Recompensa por acortar distancias: +  0.9032502241444318\n",
      "Penalización por duración del episodio: -  0.39244893207381665\n",
      "Step: 2550, Mean Reward (últimos 10 pasos): 0.5108013153076172\n",
      "Recompensa por acortar distancias: +  0.9032425065032195\n",
      "Penalización por duración del episodio: -  0.3925255869509903\n",
      "Recompensa por acortar distancias: +  0.9032414563281289\n",
      "Penalización por duración del episodio: -  0.39281245299815815\n",
      "Recompensa por acortar distancias: +  0.903227911491318\n",
      "Penalización por duración del episodio: -  0.39317729867708834\n",
      "Recompensa por acortar distancias: +  0.9032166950852611\n",
      "Penalización por parar muy lejos: -  0.14597663073169542\n",
      "Penalización por duración del episodio: -  0.3935660377441291\n",
      "Recompensa por acortar distancias: +  0.9032166950852611\n",
      "Penalización por parar muy lejos: -  0.14597663073169542\n",
      "Penalización por duración del episodio: -  0.393931573247264\n",
      "Recompensa por acortar distancias: +  0.9032211676152162\n",
      "Penalización por parar muy lejos: -  0.145983009411027\n",
      "Penalización por duración del episodio: -  0.394309014313494\n",
      "Recompensa por acortar distancias: +  0.9032211676152162\n",
      "Penalización por duración del episodio: -  0.39469106999680525\n",
      "Recompensa por acortar distancias: +  0.903221288491843\n",
      "Penalización por duración del episodio: -  0.39478616968637764\n",
      "Recompensa por acortar distancias: +  0.903221309332627\n",
      "Penalización por parar muy lejos: -  0.14598321153511842\n",
      "Penalización por duración del episodio: -  0.3948918510474525\n",
      "Recompensa por acortar distancias: +  0.9032212843236858\n",
      "Penalización por parar muy lejos: -  0.14598317586614423\n",
      "Penalización por duración del episodio: -  0.39506609777073315\n",
      "Step: 2560, Mean Reward (últimos 10 pasos): 0.36217200756073\n",
      "Recompensa por acortar distancias: +  0.9032213176689396\n",
      "Penalización por parar muy lejos: -  0.14598322342477807\n",
      "Penalización por duración del episodio: -  0.39519298653860324\n",
      "Recompensa por acortar distancias: +  0.9032214010320294\n",
      "Penalización por duración del episodio: -  0.3954461794418477\n",
      "steer input from model: -0.25 , throttle:  0.7\n",
      "reward: 0.5077752215901817\n",
      "Recompensa por acortar distancias: +  0.9032213426778734\n",
      "Penalización por parar muy lejos: -  0.14598325909376186\n",
      "Penalización por duración del episodio: -  0.3958132394002255\n",
      "Recompensa por acortar distancias: +  0.9032213426778734\n",
      "Penalización por parar muy lejos: -  0.14598325909376186\n",
      "Penalización por duración del episodio: -  0.39618964506811166\n",
      "Recompensa por acortar distancias: +  0.903221288491843\n",
      "Penalización por duración del episodio: -  0.39629550175238754\n",
      "Recompensa por acortar distancias: +  0.9032212926600001\n",
      "Penalización por parar muy lejos: -  0.1459831877558015\n",
      "Penalización por duración del episodio: -  0.39655188182435286\n",
      "Recompensa por acortar distancias: +  0.9032212926600001\n",
      "Penalización por parar muy lejos: -  0.1459831877558015\n",
      "Penalización por duración del episodio: -  0.3969287053723025\n",
      "Recompensa por acortar distancias: +  0.9032214343772476\n",
      "Penalización por duración del episodio: -  0.397288118957536\n",
      "Recompensa por acortar distancias: +  0.9032215594217237\n",
      "Penalización por parar muy lejos: -  0.14598356822525752\n",
      "Penalización por duración del episodio: -  0.3976657407374442\n",
      "Recompensa por acortar distancias: +  0.9032216928023393\n",
      "Penalización por parar muy lejos: -  0.14598375846029377\n",
      "Penalización por duración del episodio: -  0.3980469805339938\n",
      "Step: 2570, Mean Reward (últimos 10 pasos): 0.3591909408569336\n",
      "Recompensa por acortar distancias: +  0.9032216928023393\n",
      "Penalización por parar muy lejos: -  0.14598375846029377\n",
      "Penalización por duración del episodio: -  0.39842503537259605\n",
      "Recompensa por acortar distancias: +  0.9032216511209146\n",
      "Penalización por parar muy lejos: -  0.14598369901182284\n",
      "Penalización por duración del episodio: -  0.3988216637669763\n",
      "Recompensa por acortar distancias: +  0.903221626112052\n",
      "Penalización por duración del episodio: -  0.3991987370172825\n",
      "Recompensa por acortar distancias: +  0.9032216594572008\n",
      "Penalización por duración del episodio: -  0.39956160697893994\n",
      "Recompensa por acortar distancias: +  0.9032218011739686\n",
      "Penalización por parar muy lejos: -  0.1459839130264121\n",
      "Penalización por duración del episodio: -  0.3996624253670791\n",
      "Recompensa por acortar distancias: +  0.9032218011739686\n",
      "Penalización por parar muy lejos: -  0.1459839130264121\n",
      "Penalización por duración del episodio: -  0.39995391122450163\n",
      "Recompensa por acortar distancias: +  0.9032217928376933\n",
      "Penalización por duración del episodio: -  0.40004194474836535\n",
      "Recompensa por acortar distancias: +  0.9032217928376933\n",
      "Penalización por parar muy lejos: -  0.14598390113670584\n",
      "Penalización por duración del episodio: -  0.4003382104857976\n",
      "Recompensa por acortar distancias: +  0.9032218178465174\n",
      "Penalización por parar muy lejos: -  0.14598393680582694\n",
      "Penalización por duración del episodio: -  0.4007182753252467\n",
      "Recompensa por acortar distancias: +  0.9032218178465174\n",
      "Penalización por duración del episodio: -  0.40111351096017994\n",
      "Step: 2580, Mean Reward (últimos 10 pasos): 0.5021083354949951\n",
      "Recompensa por acortar distancias: +  0.9032045270358481\n",
      "Penalización por duración del episodio: -  0.40148845659500976\n",
      "Recompensa por acortar distancias: +  0.9032011419159759\n",
      "Penalización por duración del episodio: -  0.4018597523710838\n",
      "steer input from model: -0.1 , throttle:  0.3\n",
      "reward: 0.5013413895448922\n",
      "Recompensa por acortar distancias: +  0.9031959473023631\n",
      "Penalización por parar muy lejos: -  0.1459470469061184\n",
      "Penalización por duración del episodio: -  0.4022370366501052\n",
      "Recompensa por acortar distancias: +  0.9031900853447874\n",
      "Penalización por duración del episodio: -  0.4023372350016743\n",
      "Recompensa por acortar distancias: +  0.9031943171596281\n",
      "Penalización por parar muy lejos: -  0.1459447229705005\n",
      "Penalización por duración del episodio: -  0.4026216792219444\n",
      "Recompensa por acortar distancias: +  0.9031857032619679\n",
      "Penalización por parar muy lejos: -  0.14593244406556327\n",
      "Penalización por duración del episodio: -  0.4029856252595432\n",
      "Recompensa por acortar distancias: +  0.9031857032619679\n",
      "Penalización por parar muy lejos: -  0.14593244406556327\n",
      "Penalización por duración del episodio: -  0.40337151048530606\n",
      "Recompensa por acortar distancias: +  0.9031857032619679\n",
      "Penalización por parar muy lejos: -  0.14593244406556327\n",
      "Penalización por duración del episodio: -  0.40349893173140466\n",
      "Recompensa por acortar distancias: +  0.9031851320354615\n",
      "Penalización por parar muy lejos: -  0.1459316298606213\n",
      "Penalización por duración del episodio: -  0.4037581007656949\n",
      "Recompensa por acortar distancias: +  0.9031851320354615\n",
      "Penalización por parar muy lejos: -  0.1459316298606213\n",
      "Penalización por duración del episodio: -  0.40413634778319707\n",
      "Step: 2590, Mean Reward (últimos 10 pasos): 0.3531171679496765\n",
      "Recompensa por acortar distancias: +  0.9031848985405487\n",
      "Penalización por duración del episodio: -  0.4042373653602473\n",
      "Recompensa por acortar distancias: +  0.9031848985405487\n",
      "Penalización por duración del episodio: -  0.4045140597758274\n",
      "Recompensa por acortar distancias: +  0.9031849986098586\n",
      "Penalización por duración del episodio: -  0.4048961533032244\n",
      "Recompensa por acortar distancias: +  0.9031852737999847\n",
      "Penalización por parar muy lejos: -  0.14593183192572995\n",
      "Penalización por duración del episodio: -  0.4052826088209159\n",
      "Recompensa por acortar distancias: +  0.9031852737999847\n",
      "Penalización por parar muy lejos: -  0.14593183192572995\n",
      "Penalización por duración del episodio: -  0.40564813735480537\n",
      "Recompensa por acortar distancias: +  0.9031852737999847\n",
      "Penalización por parar muy lejos: -  0.14593183192572995\n",
      "Penalización por duración del episodio: -  0.4060382708795254\n",
      "Recompensa por acortar distancias: +  0.9031852571218151\n",
      "Penalización por duración del episodio: -  0.40640663220125245\n",
      "Recompensa por acortar distancias: +  0.9031850569835801\n",
      "Penalización por parar muy lejos: -  0.14593152288506947\n",
      "Penalización por duración del episodio: -  0.4067868125254084\n",
      "Recompensa por acortar distancias: +  0.9031838936727757\n",
      "Penalización por parar muy lejos: -  0.14592986477233025\n",
      "Penalización por duración del episodio: -  0.4068657560952577\n",
      "Recompensa por acortar distancias: +  0.9031802493853888\n",
      "Penalización por duración del episodio: -  0.4071668340604737\n",
      "Step: 2600, Mean Reward (últimos 10 pasos): 0.4960134029388428\n",
      "Recompensa por acortar distancias: +  0.9031724850603894\n",
      "Penalización por parar muy lejos: -  0.1459136053976683\n",
      "Penalización por duración del episodio: -  0.407241818057595\n",
      "Recompensa por acortar distancias: +  0.9031623764273926\n",
      "Penalización por duración del episodio: -  0.40755031134254904\n",
      "steer input from model: -0.1 , throttle:  1.0\n",
      "reward: 0.49561206508484357\n",
      "Recompensa por acortar distancias: +  0.903158247630569\n",
      "Penalización por duración del episodio: -  0.40794469827017604\n",
      "Recompensa por acortar distancias: +  0.903158247630569\n",
      "Penalización por duración del episodio: -  0.4083184040536685\n",
      "Recompensa por acortar distancias: +  0.9030946902139226\n",
      "Penalización por duración del episodio: -  0.40869242904471775\n",
      "Recompensa por acortar distancias: +  0.9030748999271228\n",
      "Penalización por duración del episodio: -  0.4090698391109777\n",
      "Recompensa por acortar distancias: +  0.9030441514705886\n",
      "Penalización por duración del episodio: -  0.4094470277642777\n",
      "Recompensa por acortar distancias: +  0.903019311749828\n",
      "Penalización por duración del episodio: -  0.40955881511403736\n",
      "Recompensa por acortar distancias: +  0.9030106129558368\n",
      "Penalización por duración del episodio: -  0.40982884402226516\n",
      "Recompensa por acortar distancias: +  0.9029898758640369\n",
      "Penalización por parar muy lejos: -  0.14565379018745075\n",
      "Penalización por duración del episodio: -  0.41021863692477306\n",
      "Step: 2610, Mean Reward (últimos 10 pasos): 0.34711745381355286\n",
      "Recompensa por acortar distancias: +  0.9029898758640369\n",
      "Penalización por duración del episodio: -  0.4105794393200403\n",
      "Recompensa por acortar distancias: +  0.9029898758640369\n",
      "Penalización por duración del episodio: -  0.41068901271413083\n",
      "Recompensa por acortar distancias: +  0.9028470229216642\n",
      "Penalización por parar muy lejos: -  0.14545111111890358\n",
      "Penalización por duración del episodio: -  0.41097220776554705\n",
      "Recompensa por acortar distancias: +  0.9028048923853706\n",
      "Penalización por duración del episodio: -  0.41136216272506565\n",
      "Recompensa por acortar distancias: +  0.9026919284493649\n",
      "Penalización por parar muy lejos: -  0.14523162918912266\n",
      "Penalización por duración del episodio: -  0.4117547815050911\n",
      "Recompensa por acortar distancias: +  0.9026437752042741\n",
      "Penalización por duración del episodio: -  0.41213236109033463\n",
      "Recompensa por acortar distancias: +  0.9026350170231892\n",
      "Penalización por duración del episodio: -  0.4125028736745486\n",
      "Recompensa por acortar distancias: +  0.9026350170231892\n",
      "Penalización por duración del episodio: -  0.4128769010904463\n",
      "Recompensa por acortar distancias: +  0.9026350170231892\n",
      "Penalización por parar muy lejos: -  0.14515123815528042\n",
      "Penalización por duración del episodio: -  0.4129667751305874\n",
      "Recompensa por acortar distancias: +  0.9026225448307857\n",
      "Penalización por duración del episodio: -  0.4132694302807241\n",
      "Step: 2620, Mean Reward (últimos 10 pasos): 0.48935312032699585\n",
      "Recompensa por acortar distancias: +  0.9026222807871142\n",
      "Penalización por duración del episodio: -  0.41366979548945004\n",
      "Recompensa por acortar distancias: +  0.9026217485066599\n",
      "Penalización por duración del episodio: -  0.41405064844255135\n",
      "steer input from model: 0.0 , throttle:  1.0\n",
      "reward: 0.48857110006410853\n",
      "Recompensa por acortar distancias: +  0.9025868721947184\n",
      "Penalización por parar muy lejos: -  0.14508329205630116\n",
      "Penalización por duración del episodio: -  0.4144332821058424\n",
      "Recompensa por acortar distancias: +  0.9025755391873113\n",
      "Penalización por duración del episodio: -  0.4145197261218328\n",
      "Recompensa por acortar distancias: +  0.9025754427489795\n",
      "Penalización por duración del episodio: -  0.4148018977085185\n",
      "Recompensa por acortar distancias: +  0.9025762058673626\n",
      "Penalización por parar muy lejos: -  0.14506824644956368\n",
      "Penalización por duración del episodio: -  0.4151757724234872\n",
      "Recompensa por acortar distancias: +  0.9025762058673626\n",
      "Penalización por duración del episodio: -  0.4155633929339057\n",
      "Recompensa por acortar distancias: +  0.902541616993318\n",
      "Penalización por duración del episodio: -  0.4159319000818916\n",
      "Recompensa por acortar distancias: +  0.9025272380848616\n",
      "Penalización por parar muy lejos: -  0.1449992094095009\n",
      "Penalización por duración del episodio: -  0.4163190171860891\n",
      "Recompensa por acortar distancias: +  0.9025023599506915\n",
      "Penalización por duración del episodio: -  0.4166888640659521\n",
      "Step: 2630, Mean Reward (últimos 10 pasos): 0.4858134984970093\n",
      "Recompensa por acortar distancias: +  0.9024660646390172\n",
      "Penalización por duración del episodio: -  0.41707830412921026\n",
      "Recompensa por acortar distancias: +  0.9024191091974094\n",
      "Penalización por duración del episodio: -  0.4174691812303855\n",
      "Recompensa por acortar distancias: +  0.9024191091974094\n",
      "Penalización por parar muy lejos: -  0.14484697034330493\n",
      "Penalización por duración del episodio: -  0.41784478158869043\n",
      "Recompensa por acortar distancias: +  0.9022891578374472\n",
      "Penalización por duración del episodio: -  0.41793305908396183\n",
      "Recompensa por acortar distancias: +  0.9022891578374472\n",
      "Penalización por parar muy lejos: -  0.1446643808586018\n",
      "Penalización por duración del episodio: -  0.4182228440797815\n",
      "Recompensa por acortar distancias: +  0.9022424713259366\n",
      "Penalización por parar muy lejos: -  0.14459888303083665\n",
      "Penalización por duración del episodio: -  0.4185823767864334\n",
      "Recompensa por acortar distancias: +  0.9022079534995618\n",
      "Penalización por duración del episodio: -  0.4186651970333234\n",
      "Recompensa por acortar distancias: +  0.9022075033415895\n",
      "Penalización por parar muy lejos: -  0.14454985985545807\n",
      "Penalización por duración del episodio: -  0.4189511370367115\n",
      "Recompensa por acortar distancias: +  0.9022069816608803\n",
      "Penalización por parar muy lejos: -  0.14454912871091966\n",
      "Penalización por duración del episodio: -  0.41933541834995625\n",
      "Recompensa por acortar distancias: +  0.9022064725990866\n",
      "Penalización por parar muy lejos: -  0.14454841525832465\n",
      "Penalización por duración del episodio: -  0.41942109585392406\n",
      "Step: 2640, Mean Reward (últimos 10 pasos): 0.3382369577884674\n",
      "Recompensa por acortar distancias: +  0.9022063505921901\n",
      "Penalización por parar muy lejos: -  0.1445482442659887\n",
      "Penalización por duración del episodio: -  0.41971138929840707\n",
      "Recompensa por acortar distancias: +  0.9022063505921901\n",
      "Penalización por duración del episodio: -  0.42010296146567944\n",
      "steer input from model: -0.9 , throttle:  0.3\n",
      "reward: 0.4821033891265107\n",
      "Recompensa por acortar distancias: +  0.9022063505921901\n",
      "Penalización por duración del episodio: -  0.4204733764751981\n",
      "Recompensa por acortar distancias: +  0.9021817529133159\n",
      "Penalización por duración del episodio: -  0.4208571943040743\n",
      "Recompensa por acortar distancias: +  0.9021817529133159\n",
      "Penalización por duración del episodio: -  0.42123021509988867\n",
      "Recompensa por acortar distancias: +  0.9021680926347286\n",
      "Penalización por parar muy lejos: -  0.1444946435077288\n",
      "Penalización por duración del episodio: -  0.42161318629109623\n",
      "Recompensa por acortar distancias: +  0.9021536603822385\n",
      "Penalización por duración del episodio: -  0.4220020672045358\n",
      "Recompensa por acortar distancias: +  0.9021544517010205\n",
      "Penalización por duración del episodio: -  0.42239124844979103\n",
      "Recompensa por acortar distancias: +  0.9021544517010205\n",
      "Penalización por parar muy lejos: -  0.14447554058837084\n",
      "Penalización por duración del episodio: -  0.4227808519034801\n",
      "Recompensa por acortar distancias: +  0.902133462985705\n",
      "Penalización por duración del episodio: -  0.42315546676858146\n",
      "Step: 2650, Mean Reward (últimos 10 pasos): 0.4789780080318451\n",
      "Recompensa por acortar distancias: +  0.9021334798254326\n",
      "Penalización por duración del episodio: -  0.4235451301725373\n",
      "Recompensa por acortar distancias: +  0.9021235776197678\n",
      "Penalización por duración del episodio: -  0.4236580984437543\n",
      "Recompensa por acortar distancias: +  0.9021161419581677\n",
      "Penalización por duración del episodio: -  0.4239199540040943\n",
      "Recompensa por acortar distancias: +  0.9021138766338906\n",
      "Penalización por parar muy lejos: -  0.14441874523443637\n",
      "Penalización por duración del episodio: -  0.42430251208678016\n",
      "Recompensa por acortar distancias: +  0.9021167356506669\n",
      "Penalización por parar muy lejos: -  0.14442274587646856\n",
      "Penalización por duración del episodio: -  0.42437797927367227\n",
      "Recompensa por acortar distancias: +  0.9021167356506669\n",
      "Penalización por parar muy lejos: -  0.14442274587646856\n",
      "Penalización por duración del episodio: -  0.42469247739702914\n",
      "Recompensa por acortar distancias: +  0.9021167356506669\n",
      "Penalización por duración del episodio: -  0.4250681855008538\n",
      "Recompensa por acortar distancias: +  0.9021005574346741\n",
      "Penalización por duración del episodio: -  0.4254381639147273\n",
      "Recompensa por acortar distancias: +  0.9020821108553411\n",
      "Penalización por parar muy lejos: -  0.14437430836229584\n",
      "Penalización por duración del episodio: -  0.4258279462544247\n",
      "Recompensa por acortar distancias: +  0.9020817065120548\n",
      "Penalización por duración del episodio: -  0.4261984863943153\n",
      "Step: 2660, Mean Reward (últimos 10 pasos): 0.47588321566581726\n",
      "Recompensa por acortar distancias: +  0.9020825320446817\n",
      "Penalización por parar muy lejos: -  0.14437489740198836\n",
      "Penalización por duración del episodio: -  0.42630167966956484\n",
      "Recompensa por acortar distancias: +  0.9020714879261627\n",
      "Penalización por parar muy lejos: -  0.1443594534417595\n",
      "Penalización por duración del episodio: -  0.4265686312054645\n",
      "steer input from model: 0.1 , throttle:  0.0\n",
      "reward: 0.33114340327893865\n",
      "Recompensa por acortar distancias: +  0.9020541697597037\n",
      "Penalización por parar muy lejos: -  0.14433524182025498\n",
      "Penalización por duración del episodio: -  0.42668967679430075\n",
      "Recompensa por acortar distancias: +  0.9020511574428178\n",
      "Penalización por duración del episodio: -  0.4269671145450681\n",
      "Recompensa por acortar distancias: +  0.9020509847060594\n",
      "Penalización por parar muy lejos: -  0.1443307897465271\n",
      "Penalización por duración del episodio: -  0.4273468584593934\n",
      "Recompensa por acortar distancias: +  0.9020509847060594\n",
      "Penalización por parar muy lejos: -  0.1443307897465271\n",
      "Penalización por duración del episodio: -  0.42772379923473003\n",
      "Recompensa por acortar distancias: +  0.9020277638863937\n",
      "Penalización por duración del episodio: -  0.4281141970468088\n",
      "Recompensa por acortar distancias: +  0.9020276206108001\n",
      "Penalización por parar muy lejos: -  0.14429813880626635\n",
      "Penalización por duración del episodio: -  0.42848782843801597\n",
      "Recompensa por acortar distancias: +  0.9020273298450506\n",
      "Penalización por parar muy lejos: -  0.14429773254830988\n",
      "Penalización por duración del episodio: -  0.42889333943054636\n",
      "Recompensa por acortar distancias: +  0.9020274351950487\n",
      "Penalización por parar muy lejos: -  0.1442978797431118\n",
      "Penalización por duración del episodio: -  0.4292799092664013\n",
      "Step: 2670, Mean Reward (últimos 10 pasos): 0.32844963669776917\n",
      "Recompensa por acortar distancias: +  0.9020275700428989\n",
      "Penalización por duración del episodio: -  0.42965504397378496\n",
      "Recompensa por acortar distancias: +  0.9020275700428989\n",
      "Penalización por duración del episodio: -  0.43004600259998615\n",
      "Recompensa por acortar distancias: +  0.9020147250425228\n",
      "Penalización por duración del episodio: -  0.43042414257298\n",
      "Recompensa por acortar distancias: +  0.9020192470921372\n",
      "Penalización por duración del episodio: -  0.4308143486840997\n",
      "Recompensa por acortar distancias: +  0.902001870111067\n",
      "Penalización por duración del episodio: -  0.43091849847475866\n",
      "Recompensa por acortar distancias: +  0.9019921794494833\n",
      "Penalización por parar muy lejos: -  0.14424863532897964\n",
      "Penalización por duración del episodio: -  0.4311987580315645\n",
      "Recompensa por acortar distancias: +  0.9019948097961484\n",
      "Penalización por parar muy lejos: -  0.14425230830921534\n",
      "Penalización por duración del episodio: -  0.43158899974383697\n",
      "Recompensa por acortar distancias: +  0.9019948688096145\n",
      "Penalización por duración del episodio: -  0.43196749744040663\n",
      "Recompensa por acortar distancias: +  0.9019948688096145\n",
      "Penalización por duración del episodio: -  0.432079431149364\n",
      "Recompensa por acortar distancias: +  0.9019948688096145\n",
      "Penalización por parar muy lejos: -  0.14425239071671508\n",
      "Penalización por duración del episodio: -  0.4323571746194536\n",
      "Step: 2680, Mean Reward (últimos 10 pasos): 0.32538530230522156\n",
      "Recompensa por acortar distancias: +  0.9019948688096145\n",
      "Penalización por parar muy lejos: -  0.14425239071671508\n",
      "Penalización por duración del episodio: -  0.43274994377348536\n",
      "Recompensa por acortar distancias: +  0.9019945400198991\n",
      "Penalización por duración del episodio: -  0.433134420567486\n",
      "steer input from model: -0.9 , throttle:  0.3\n",
      "reward: 0.46886011945241307\n",
      "Recompensa por acortar distancias: +  0.901994312395674\n",
      "Penalización por duración del episodio: -  0.43351801180251076\n",
      "Recompensa por acortar distancias: +  0.9019944388536351\n",
      "Penalización por duración del episodio: -  0.43360855122975406\n",
      "Recompensa por acortar distancias: +  0.9019945062978214\n",
      "Penalización por duración del episodio: -  0.433897618453472\n",
      "Recompensa por acortar distancias: +  0.9019894099299423\n",
      "Penalización por duración del episodio: -  0.43401208896110843\n",
      "Recompensa por acortar distancias: +  0.9019927948887972\n",
      "Penalización por duración del episodio: -  0.4342967554723538\n",
      "Recompensa por acortar distancias: +  0.9019830992116202\n",
      "Penalización por parar muy lejos: -  0.1442359570812185\n",
      "Penalización por duración del episodio: -  0.4346744995237934\n",
      "Recompensa por acortar distancias: +  0.9019830992116202\n",
      "Penalización por duración del episodio: -  0.43505754648945116\n",
      "Recompensa por acortar distancias: +  0.9019723739537658\n",
      "Penalización por parar muy lejos: -  0.1442209845223137\n",
      "Penalización por duración del episodio: -  0.4354530027896692\n",
      "Step: 2690, Mean Reward (últimos 10 pasos): 0.3222983777523041\n",
      "Recompensa por acortar distancias: +  0.9019772603153433\n",
      "Penalización por duración del episodio: -  0.4358482656991298\n",
      "Recompensa por acortar distancias: +  0.9019537118729617\n",
      "Penalización por duración del episodio: -  0.435954465012758\n",
      "Recompensa por acortar distancias: +  0.9019371342879697\n",
      "Penalización por duración del episodio: -  0.43625271039970165\n",
      "Recompensa por acortar distancias: +  0.9019112613487521\n",
      "Penalización por duración del episodio: -  0.43662684874168983\n",
      "Recompensa por acortar distancias: +  0.9018638104185149\n",
      "Penalización por duración del episodio: -  0.4370194839120385\n",
      "Recompensa por acortar distancias: +  0.9018638104185149\n",
      "Penalización por parar muy lejos: -  0.1440695836192249\n",
      "Penalización por duración del episodio: -  0.4374026875262621\n",
      "Recompensa por acortar distancias: +  0.9018233812523743\n",
      "Penalización por parar muy lejos: -  0.144013273676656\n",
      "Penalización por duración del episodio: -  0.4377834718868271\n",
      "Recompensa por acortar distancias: +  0.9018232039358162\n",
      "Penalización por parar muy lejos: -  0.144013026795112\n",
      "Penalización por duración del episodio: -  0.4381608373347074\n",
      "Recompensa por acortar distancias: +  0.9018227986397546\n",
      "Penalización por parar muy lejos: -  0.1440124624957619\n",
      "Penalización por duración del episodio: -  0.43854899959100685\n",
      "Recompensa por acortar distancias: +  0.9018161532604438\n",
      "Penalización por parar muy lejos: -  0.1440032105999446\n",
      "Penalización por duración del episodio: -  0.43893499413134646\n",
      "Step: 2700, Mean Reward (últimos 10 pasos): 0.3188779354095459\n",
      "Recompensa por acortar distancias: +  0.9017984063602021\n",
      "Penalización por parar muy lejos: -  0.14397850799199485\n",
      "Penalización por duración del episodio: -  0.4393129524180436\n",
      "Recompensa por acortar distancias: +  0.901798220557882\n",
      "Penalización por parar muy lejos: -  0.14397824940613044\n",
      "Penalización por duración del episodio: -  0.4397044379088145\n",
      "steer input from model: -0.25 , throttle:  0.0\n",
      "reward: 0.31811553324293695\n",
      "Recompensa por acortar distancias: +  0.901798220557882\n",
      "Penalización por duración del episodio: -  0.43978057534230663\n",
      "Recompensa por acortar distancias: +  0.901798220557882\n",
      "Penalización por parar muy lejos: -  0.14397824940613044\n",
      "Penalización por duración del episodio: -  0.4400826036853844\n",
      "Recompensa por acortar distancias: +  0.9017844787634738\n",
      "Penalización por duración del episodio: -  0.4404655691663773\n",
      "Recompensa por acortar distancias: +  0.9017844787634738\n",
      "Penalización por duración del episodio: -  0.4408646969267854\n",
      "Recompensa por acortar distancias: +  0.9017351774885957\n",
      "Penalización por duración del episodio: -  0.44095601714884836\n",
      "Recompensa por acortar distancias: +  0.9017351774885957\n",
      "Penalización por duración del episodio: -  0.4412597217300068\n",
      "Recompensa por acortar distancias: +  0.9017083568892208\n",
      "Penalización por parar muy lejos: -  0.14385328012794377\n",
      "Penalización por duración del episodio: -  0.44164751294130705\n",
      "Recompensa por acortar distancias: +  0.901700360578673\n",
      "Penalización por duración del episodio: -  0.4420345991291897\n",
      "Step: 2710, Mean Reward (últimos 10 pasos): 0.45966577529907227\n",
      "Recompensa por acortar distancias: +  0.901700360578673\n",
      "Penalización por parar muy lejos: -  0.14384216933037625\n",
      "Penalización por duración del episodio: -  0.4424205559488623\n",
      "Recompensa por acortar distancias: +  0.9016993462061016\n",
      "Penalización por duración del episodio: -  0.4428163237225034\n",
      "Recompensa por acortar distancias: +  0.9016993462061016\n",
      "Penalización por parar muy lejos: -  0.1438407599779093\n",
      "Penalización por duración del episodio: -  0.4431943075280941\n",
      "Recompensa por acortar distancias: +  0.9016992194088744\n",
      "Penalización por duración del episodio: -  0.4435808250055955\n",
      "Recompensa por acortar distancias: +  0.9016991602367851\n",
      "Penalización por duración del episodio: -  0.443689503996034\n",
      "Recompensa por acortar distancias: +  0.9016991940494113\n",
      "Penalización por duración del episodio: -  0.4439718191209047\n",
      "Recompensa por acortar distancias: +  0.9016992785809319\n",
      "Penalización por duración del episodio: -  0.4443455406037061\n",
      "Recompensa por acortar distancias: +  0.9016992785809319\n",
      "Penalización por parar muy lejos: -  0.14384066602148668\n",
      "Penalización por duración del episodio: -  0.4447224925959709\n",
      "Recompensa por acortar distancias: +  0.9016992785809319\n",
      "Penalización por parar muy lejos: -  0.14384066602148668\n",
      "Penalización por duración del episodio: -  0.44483108048438413\n",
      "Recompensa por acortar distancias: +  0.9016972540332184\n",
      "Penalización por parar muy lejos: -  0.14383785322472997\n",
      "Penalización por duración del episodio: -  0.4450987014742279\n",
      "Step: 2720, Mean Reward (últimos 10 pasos): 0.31276071071624756\n",
      "Recompensa por acortar distancias: +  0.9016872744566404\n",
      "Penalización por parar muy lejos: -  0.14382398956535933\n",
      "Penalización por duración del episodio: -  0.4454941851861262\n",
      "Recompensa por acortar distancias: +  0.9016841506341051\n",
      "Penalización por parar muy lejos: -  0.1438196504273323\n",
      "Penalización por duración del episodio: -  0.44587412774240015\n",
      "steer input from model: 0.0 , throttle:  0.0\n",
      "reward: 0.3119903724643726\n",
      "Recompensa por acortar distancias: +  0.9016832713825853\n",
      "Penalización por duración del episodio: -  0.44624804165709\n",
      "Recompensa por acortar distancias: +  0.9016839688663364\n",
      "Penalización por duración del episodio: -  0.44663613496041327\n",
      "Recompensa por acortar distancias: +  0.9016838251427726\n",
      "Penalización por parar muy lejos: -  0.1438191983177279\n",
      "Penalización por duración del episodio: -  0.4470335285328151\n",
      "Recompensa por acortar distancias: +  0.9016838251427726\n",
      "Penalización por duración del episodio: -  0.44712184546056244\n",
      "Recompensa por acortar distancias: +  0.9016838251427726\n",
      "Penalización por duración del episodio: -  0.447433047001051\n",
      "Recompensa por acortar distancias: +  0.9016983867701289\n",
      "Penalización por duración del episodio: -  0.44781915020074664\n",
      "Recompensa por acortar distancias: +  0.9017056309393746\n",
      "Penalización por duración del episodio: -  0.4482010767443655\n",
      "Recompensa por acortar distancias: +  0.9016908716041623\n",
      "Penalización por parar muy lejos: -  0.14382898646140574\n",
      "Penalización por duración del episodio: -  0.4485884133782741\n",
      "Step: 2730, Mean Reward (últimos 10 pasos): 0.30927348136901855\n",
      "Recompensa por acortar distancias: +  0.9016969497138577\n",
      "Penalización por parar muy lejos: -  0.14383743042833888\n",
      "Penalización por duración del episodio: -  0.44870785143429454\n",
      "Recompensa por acortar distancias: +  0.9016903643754212\n",
      "Penalización por duración del episodio: -  0.4489658087338613\n",
      "Recompensa por acortar distancias: +  0.9016805109945514\n",
      "Penalización por parar muy lejos: -  0.14381459508725236\n",
      "Penalización por duración del episodio: -  0.44936345029252167\n",
      "Recompensa por acortar distancias: +  0.9016805109945514\n",
      "Penalización por parar muy lejos: -  0.14381459508725236\n",
      "Penalización por duración del episodio: -  0.4497308469800011\n",
      "Recompensa por acortar distancias: +  0.9016805109945514\n",
      "Penalización por duración del episodio: -  0.44985204040579413\n",
      "Recompensa por acortar distancias: +  0.9016605014012478\n",
      "Penalización por duración del episodio: -  0.4501274323847246\n",
      "Recompensa por acortar distancias: +  0.9016604760328858\n",
      "Penalización por parar muy lejos: -  0.1437867728130285\n",
      "Penalización por duración del episodio: -  0.45052237547470303\n",
      "Recompensa por acortar distancias: +  0.9016604760328858\n",
      "Penalización por parar muy lejos: -  0.1437867728130285\n",
      "Penalización por duración del episodio: -  0.4506355566789325\n",
      "Recompensa por acortar distancias: +  0.901660391471637\n",
      "Penalización por parar muy lejos: -  0.1437866554041855\n",
      "Penalización por duración del episodio: -  0.45090393386565264\n",
      "Recompensa por acortar distancias: +  0.9016605901904687\n",
      "Penalización por duración del episodio: -  0.451031205657728\n",
      "Step: 2740, Mean Reward (últimos 10 pasos): 0.4506293833255768\n",
      "Recompensa por acortar distancias: +  0.9016606409271345\n",
      "Penalización por duración del episodio: -  0.4511223364341847\n",
      "Recompensa por acortar distancias: +  0.9016606747515654\n",
      "Penalización por duración del episodio: -  0.45128399728256297\n",
      "steer input from model: -0.25 , throttle:  1.0\n",
      "reward: 0.45037667746900245\n",
      "Recompensa por acortar distancias: +  0.9016605732782418\n",
      "Penalización por duración del episodio: -  0.4516713863145817\n",
      "Recompensa por acortar distancias: +  0.9016606324710251\n",
      "Penalización por duración del episodio: -  0.45205774137590277\n",
      "Recompensa por acortar distancias: +  0.9016606324710251\n",
      "Penalización por duración del episodio: -  0.4524433154987074\n",
      "Recompensa por acortar distancias: +  0.9016332524207539\n",
      "Penalización por parar muy lejos: -  0.14374898302635591\n",
      "Penalización por duración del episodio: -  0.45283261521385537\n",
      "Recompensa por acortar distancias: +  0.9016332524207539\n",
      "Penalización por duración del episodio: -  0.45291664372786733\n",
      "Recompensa por acortar distancias: +  0.9016219516776861\n",
      "Penalización por duración del episodio: -  0.4532111722987761\n",
      "Recompensa por acortar distancias: +  0.9016161655202578\n",
      "Penalización por duración del episodio: -  0.4536130359602709\n",
      "Recompensa por acortar distancias: +  0.9016039916056331\n",
      "Penalización por parar muy lejos: -  0.14370838494670396\n",
      "Penalización por duración del episodio: -  0.4537198934856493\n",
      "Step: 2750, Mean Reward (últimos 10 pasos): 0.3041757047176361\n",
      "Recompensa por acortar distancias: +  0.9016039916056331\n",
      "Penalización por duración del episodio: -  0.4540112958538188\n",
      "Recompensa por acortar distancias: +  0.9015866717094435\n",
      "Penalización por duración del episodio: -  0.45439236662901256\n",
      "Recompensa por acortar distancias: +  0.9015866717094435\n",
      "Penalización por duración del episodio: -  0.4547779541747188\n",
      "Recompensa por acortar distancias: +  0.9015866717094435\n",
      "Penalización por duración del episodio: -  0.45516826686646067\n",
      "Recompensa por acortar distancias: +  0.9014783078769816\n",
      "Penalización por duración del episodio: -  0.45555482052267365\n",
      "Recompensa por acortar distancias: +  0.9014021060271574\n",
      "Penalización por parar muy lejos: -  0.14342882986320604\n",
      "Penalización por duración del episodio: -  0.4559479274341227\n",
      "Recompensa por acortar distancias: +  0.9013598709936677\n",
      "Penalización por parar muy lejos: -  0.14337046786663454\n",
      "Penalización por duración del episodio: -  0.4560366891057243\n",
      "Recompensa por acortar distancias: +  0.9013595403066139\n",
      "Penalización por duración del episodio: -  0.4563433428626105\n",
      "Recompensa por acortar distancias: +  0.9013505096246958\n",
      "Penalización por parar muy lejos: -  0.1433575376560438\n",
      "Penalización por duración del episodio: -  0.4567357607514438\n",
      "Recompensa por acortar distancias: +  0.9013505096246958\n",
      "Penalización por duración del episodio: -  0.4571132336962022\n",
      "Step: 2760, Mean Reward (últimos 10 pasos): 0.44423726201057434\n",
      "Recompensa por acortar distancias: +  0.9013505096246958\n",
      "Penalización por duración del episodio: -  0.45750612929307705\n",
      "Recompensa por acortar distancias: +  0.9012218378945636\n",
      "Penalización por parar muy lejos: -  0.14318002120448747\n",
      "Penalización por duración del episodio: -  0.4578865785334281\n",
      "steer input from model: -0.25 , throttle:  0.0\n",
      "reward: 0.30015523815664796\n",
      "Recompensa por acortar distancias: +  0.9011630608186915\n",
      "Penalización por parar muy lejos: -  0.14309906129330713\n",
      "Penalización por duración del episodio: -  0.45828897705395516\n",
      "Recompensa por acortar distancias: +  0.9011622496191172\n",
      "Penalización por parar muy lejos: -  0.14309794450862098\n",
      "Penalización por duración del episodio: -  0.45868919231651306\n",
      "Recompensa por acortar distancias: +  0.9011617484562086\n",
      "Penalización por parar muy lejos: -  0.1430972545615007\n",
      "Penalización por duración del episodio: -  0.459077903971656\n",
      "Recompensa por acortar distancias: +  0.9011615615813245\n",
      "Penalización por duración del episodio: -  0.45945762955181757\n",
      "Recompensa por acortar distancias: +  0.9011615615813245\n",
      "Penalización por parar muy lejos: -  0.14309699729379224\n",
      "Penalización por duración del episodio: -  0.4598339852182551\n",
      "Recompensa por acortar distancias: +  0.9011609712245107\n",
      "Penalización por duración del episodio: -  0.45991187234521486\n",
      "Recompensa por acortar distancias: +  0.9011610391794117\n",
      "Penalización por duración del episodio: -  0.4602458758262703\n",
      "Recompensa por acortar distancias: +  0.9011610391794117\n",
      "Penalización por duración del episodio: -  0.4606262423897851\n",
      "Step: 2770, Mean Reward (últimos 10 pasos): 0.4405348002910614\n",
      "Recompensa por acortar distancias: +  0.9011621094636164\n",
      "Penalización por parar muy lejos: -  0.14309775155702859\n",
      "Penalización por duración del episodio: -  0.4607035805872055\n",
      "Recompensa por acortar distancias: +  0.9011540990703458\n",
      "Penalización por parar muy lejos: -  0.14308672444130616\n",
      "Penalización por duración del episodio: -  0.46101312406313927\n",
      "Recompensa por acortar distancias: +  0.9011509601637308\n",
      "Penalización por parar muy lejos: -  0.14308240382917903\n",
      "Penalización por duración del episodio: -  0.4614141718771522\n",
      "Recompensa por acortar distancias: +  0.9011380850459119\n",
      "Penalización por parar muy lejos: -  0.14306468402522057\n",
      "Penalización por duración del episodio: -  0.4617883255915792\n",
      "Recompensa por acortar distancias: +  0.9011380850459119\n",
      "Penalización por duración del episodio: -  0.4621635890963913\n",
      "Recompensa por acortar distancias: +  0.9010884056407705\n",
      "Penalización por duración del episodio: -  0.46256105070120085\n",
      "Recompensa por acortar distancias: +  0.9010695087182674\n",
      "Penalización por duración del episodio: -  0.4626381446822445\n",
      "Recompensa por acortar distancias: +  0.9010695087182674\n",
      "Penalización por parar muy lejos: -  0.14297036897695525\n",
      "Penalización por duración del episodio: -  0.4629612273834284\n",
      "Recompensa por acortar distancias: +  0.9010675066293125\n",
      "Penalización por parar muy lejos: -  0.1429676170975927\n",
      "Penalización por duración del episodio: -  0.46335849941311164\n",
      "Recompensa por acortar distancias: +  0.9010674343664039\n",
      "Penalización por parar muy lejos: -  0.14296751777368505\n",
      "Penalización por duración del episodio: -  0.46343291418829513\n",
      "Step: 2780, Mean Reward (últimos 10 pasos): 0.29466700553894043\n",
      "Recompensa por acortar distancias: +  0.9010675278831001\n",
      "Penalización por parar muy lejos: -  0.14296764631051767\n",
      "Penalización por duración del episodio: -  0.46354542872074256\n",
      "Recompensa por acortar distancias: +  0.9010675278831001\n",
      "Penalización por parar muy lejos: -  0.14296764631051767\n",
      "Penalización por duración del episodio: -  0.463738783570781\n",
      "steer input from model: 0.0 , throttle:  0.0\n",
      "reward: 0.2943610980018013\n",
      "Recompensa por acortar distancias: +  0.9010673365988647\n",
      "Penalización por parar muy lejos: -  0.14296738339437212\n",
      "Penalización por duración del episodio: -  0.4641390695683601\n",
      "Recompensa por acortar distancias: +  0.9010672940912122\n",
      "Penalización por duración del episodio: -  0.4645202167119348\n",
      "Recompensa por acortar distancias: +  0.9010672940912122\n",
      "Penalización por duración del episodio: -  0.4649277750422072\n",
      "Recompensa por acortar distancias: +  0.9010580440393189\n",
      "Penalización por duración del episodio: -  0.4653133732462707\n",
      "Recompensa por acortar distancias: +  0.9010580440393189\n",
      "Penalización por duración del episodio: -  0.4657176051441111\n",
      "Recompensa por acortar distancias: +  0.9010355278281731\n",
      "Penalización por duración del episodio: -  0.4658029562123956\n",
      "Recompensa por acortar distancias: +  0.9010239533333179\n",
      "Penalización por parar muy lejos: -  0.14290777609951924\n",
      "Penalización por duración del episodio: -  0.46610547708719025\n",
      "Recompensa por acortar distancias: +  0.9010143722099322\n",
      "Penalización por duración del episodio: -  0.46620970487675395\n",
      "Step: 2790, Mean Reward (últimos 10 pasos): 0.43480467796325684\n",
      "Recompensa por acortar distancias: +  0.9010143722099322\n",
      "Penalización por duración del episodio: -  0.4664859194994206\n",
      "Recompensa por acortar distancias: +  0.9010026721688279\n",
      "Penalización por parar muy lejos: -  0.14287855249357834\n",
      "Penalización por duración del episodio: -  0.46687547443687705\n",
      "Recompensa por acortar distancias: +  0.9010026721688279\n",
      "Penalización por duración del episodio: -  0.4672557757024905\n",
      "Recompensa por acortar distancias: +  0.9009754523712454\n",
      "Penalización por duración del episodio: -  0.46764033515836056\n",
      "Recompensa por acortar distancias: +  0.900973712357733\n",
      "Penalización por parar muy lejos: -  0.14283880143554542\n",
      "Penalización por duración del episodio: -  0.46804372676479944\n",
      "Recompensa por acortar distancias: +  0.9009224229186604\n",
      "Penalización por parar muy lejos: -  0.1427684480830843\n",
      "Penalización por duración del episodio: -  0.4684285307384618\n",
      "Recompensa por acortar distancias: +  0.9008919819116896\n",
      "Penalización por parar muy lejos: -  0.14272672135299808\n",
      "Penalización por duración del episodio: -  0.46882894576949163\n",
      "Recompensa por acortar distancias: +  0.9008914582416391\n",
      "Penalización por parar muy lejos: -  0.1427260037258351\n",
      "Penalización por duración del episodio: -  0.4692108569534294\n",
      "Recompensa por acortar distancias: +  0.9008914582416391\n",
      "Penalización por parar muy lejos: -  0.1427260037258351\n",
      "Penalización por duración del episodio: -  0.4696039090649221\n",
      "Recompensa por acortar distancias: +  0.9008914582416391\n",
      "Penalización por parar muy lejos: -  0.1427260037258351\n",
      "Penalización por duración del episodio: -  0.46972509652744726\n",
      "Step: 2800, Mean Reward (últimos 10 pasos): 0.2884403467178345\n",
      "Recompensa por acortar distancias: +  0.9008905045597738\n",
      "Penalización por duración del episodio: -  0.47000627561879943\n",
      "Recompensa por acortar distancias: +  0.900890398121559\n",
      "Penalización por parar muy lejos: -  0.14272455097761436\n",
      "Penalización por duración del episodio: -  0.47040695868434\n",
      "steer input from model: -0.9 , throttle:  0.0\n",
      "reward: 0.2877588884596046\n",
      "Recompensa por acortar distancias: +  0.9008900915789321\n",
      "Penalización por duración del episodio: -  0.4705056579244256\n",
      "Recompensa por acortar distancias: +  0.9008901980174397\n",
      "Penalización por duración del episodio: -  0.47080163877083214\n",
      "Recompensa por acortar distancias: +  0.9008903512887123\n",
      "Penalización por parar muy lejos: -  0.14272448680026636\n",
      "Penalización por duración del episodio: -  0.4711867374147611\n",
      "Recompensa por acortar distancias: +  0.9008905556500808\n",
      "Penalización por parar muy lejos: -  0.14272476684705224\n",
      "Penalización por duración del episodio: -  0.4713139825136346\n",
      "Recompensa por acortar distancias: +  0.9008905556500808\n",
      "Penalización por duración del episodio: -  0.47158007515993283\n",
      "Recompensa por acortar distancias: +  0.9008905726801779\n",
      "Penalización por duración del episodio: -  0.47197296691742807\n",
      "Recompensa por acortar distancias: +  0.9008905726801779\n",
      "Penalización por duración del episodio: -  0.4723682405904262\n",
      "Recompensa por acortar distancias: +  0.9008732006276035\n",
      "Penalización por duración del episodio: -  0.4727573208829209\n",
      "Step: 2810, Mean Reward (últimos 10 pasos): 0.4281158745288849\n",
      "Recompensa por acortar distancias: +  0.9008732006276035\n",
      "Penalización por duración del episodio: -  0.4731379353983332\n",
      "Recompensa por acortar distancias: +  0.900829085581569\n",
      "Penalización por parar muy lejos: -  0.14264057508209113\n",
      "Penalización por duración del episodio: -  0.4735317465515153\n",
      "Recompensa por acortar distancias: +  0.9008273304994373\n",
      "Penalización por duración del episodio: -  0.4739102782624877\n",
      "Recompensa por acortar distancias: +  0.900828250643031\n",
      "Penalización por duración del episodio: -  0.47431812960639413\n",
      "Recompensa por acortar distancias: +  0.900828250643031\n",
      "Penalización por duración del episodio: -  0.4747071510252231\n",
      "Recompensa por acortar distancias: +  0.9007865255700195\n",
      "Penalización por parar muy lejos: -  0.14258233470390513\n",
      "Penalización por duración del episodio: -  0.4751042238728681\n",
      "Recompensa por acortar distancias: +  0.9007865255700195\n",
      "Penalización por parar muy lejos: -  0.14258233470390513\n",
      "Penalización por duración del episodio: -  0.47548474440381727\n",
      "Recompensa por acortar distancias: +  0.9007332142315995\n",
      "Penalización por parar muy lejos: -  0.1425094412021719\n",
      "Penalización por duración del episodio: -  0.47557952074055027\n",
      "Recompensa por acortar distancias: +  0.9006834476363564\n",
      "Penalización por parar muy lejos: -  0.14244145394299965\n",
      "Penalización por duración del episodio: -  0.4758718941076495\n",
      "Recompensa por acortar distancias: +  0.9006563502687002\n",
      "Penalización por duración del episodio: -  0.47600764451955074\n",
      "Step: 2820, Mean Reward (últimos 10 pasos): 0.4246487021446228\n",
      "Recompensa por acortar distancias: +  0.9006563502687002\n",
      "Penalización por duración del episodio: -  0.4762496289431749\n",
      "Recompensa por acortar distancias: +  0.9006464942739396\n",
      "Penalización por duración del episodio: -  0.47635284041449794\n",
      "steer input from model: -0.9 , throttle:  0.7\n",
      "reward: 0.4242936538594417\n",
      "Recompensa por acortar distancias: +  0.9006464942739396\n",
      "Penalización por duración del episodio: -  0.47663066799281395\n",
      "Recompensa por acortar distancias: +  0.9006464942739396\n",
      "Penalización por parar muy lejos: -  0.14239100822501416\n",
      "Penalización por duración del episodio: -  0.4770286262107982\n",
      "Recompensa por acortar distancias: +  0.9005794675133767\n",
      "Penalización por parar muy lejos: -  0.14229958933041936\n",
      "Penalización por duración del episodio: -  0.47742707756507113\n",
      "Recompensa por acortar distancias: +  0.9005590962852871\n",
      "Penalización por parar muy lejos: -  0.14227182524124837\n",
      "Penalización por duración del episodio: -  0.477815373414136\n",
      "Recompensa por acortar distancias: +  0.9005467547500834\n",
      "Penalización por duración del episodio: -  0.47790295130597177\n",
      "Recompensa por acortar distancias: +  0.9005294230558427\n",
      "Penalización por parar muy lejos: -  0.1422314005224428\n",
      "Penalización por duración del episodio: -  0.47821069226692214\n",
      "Recompensa por acortar distancias: +  0.9005246732413773\n",
      "Penalización por parar muy lejos: -  0.1422249315951509\n",
      "Penalización por duración del episodio: -  0.47861471286806245\n",
      "Recompensa por acortar distancias: +  0.900524203374664\n",
      "Penalización por duración del episodio: -  0.4789969072525789\n",
      "Step: 2830, Mean Reward (últimos 10 pasos): 0.42152729630470276\n",
      "Recompensa por acortar distancias: +  0.9005241094010844\n",
      "Penalización por parar muy lejos: -  0.1422241637172006\n",
      "Penalización por duración del episodio: -  0.47938050075142585\n",
      "Recompensa por acortar distancias: +  0.9005241094010844\n",
      "Penalización por duración del episodio: -  0.4794702145074116\n",
      "Recompensa por acortar distancias: +  0.9005241094010844\n",
      "Penalización por parar muy lejos: -  0.1422241637172006\n",
      "Penalización por duración del episodio: -  0.47977151529178547\n",
      "Recompensa por acortar distancias: +  0.9005235840018891\n",
      "Penalización por duración del episodio: -  0.48016679178842986\n",
      "Recompensa por acortar distancias: +  0.9005235840018891\n",
      "Penalización por parar muy lejos: -  0.14222344819767782\n",
      "Penalización por duración del episodio: -  0.48056162295115473\n",
      "Recompensa por acortar distancias: +  0.9005236096311754\n",
      "Penalización por parar muy lejos: -  0.14222348310099953\n",
      "Penalización por duración del episodio: -  0.48094091440848774\n",
      "Recompensa por acortar distancias: +  0.9005237206913482\n",
      "Penalización por duración del episodio: -  0.4810421851343458\n",
      "Recompensa por acortar distancias: +  0.9005237335059766\n",
      "Penalización por duración del episodio: -  0.4813169898678087\n",
      "Recompensa por acortar distancias: +  0.9005237463206032\n",
      "Penalización por duración del episodio: -  0.48171817622122526\n",
      "Recompensa por acortar distancias: +  0.9005237463206032\n",
      "Penalización por duración del episodio: -  0.4821004978056695\n",
      "Step: 2840, Mean Reward (últimos 10 pasos): 0.41842323541641235\n",
      "Recompensa por acortar distancias: +  0.9005026087333652\n",
      "Penalización por parar muy lejos: -  0.14219488804149835\n",
      "Penalización por duración del episodio: -  0.48248750166591814\n",
      "Recompensa por acortar distancias: +  0.9005070048944827\n",
      "Penalización por duración del episodio: -  0.4828780569459397\n",
      "steer input from model: 0.0 , throttle:  0.7\n",
      "reward: 0.41762894794854294\n",
      "Recompensa por acortar distancias: +  0.9005290172792152\n",
      "Penalización por duración del episodio: -  0.4832631556599676\n",
      "Recompensa por acortar distancias: +  0.9005342794471041\n",
      "Penalización por parar muy lejos: -  0.14223801513803144\n",
      "Penalización por duración del episodio: -  0.48366180791182717\n",
      "Recompensa por acortar distancias: +  0.900540728682009\n",
      "Penalización por parar muy lejos: -  0.14224680011654756\n",
      "Penalización por duración del episodio: -  0.484043719321353\n",
      "Recompensa por acortar distancias: +  0.9005409678517791\n",
      "Penalización por parar muy lejos: -  0.14224712592577904\n",
      "Penalización por duración del episodio: -  0.484446091816614\n",
      "Recompensa por acortar distancias: +  0.9005409678517791\n",
      "Penalización por parar muy lejos: -  0.14224712592577904\n",
      "Penalización por duración del episodio: -  0.4848391887423462\n",
      "Recompensa por acortar distancias: +  0.9004981654017639\n",
      "Penalización por parar muy lejos: -  0.14218883925385464\n",
      "Penalización por duración del episodio: -  0.48521908375023143\n",
      "Recompensa por acortar distancias: +  0.9004981654017639\n",
      "Penalización por parar muy lejos: -  0.14218883925385464\n",
      "Penalización por duración del episodio: -  0.4853207882163319\n",
      "Recompensa por acortar distancias: +  0.9004851377325184\n",
      "Penalización por parar muy lejos: -  0.142171107074148\n",
      "Penalización por duración del episodio: -  0.4856197151179015\n",
      "Step: 2850, Mean Reward (últimos 10 pasos): 0.27269431948661804\n",
      "Recompensa por acortar distancias: +  0.9004851377325184\n",
      "Penalización por parar muy lejos: -  0.142171107074148\n",
      "Penalización por duración del episodio: -  0.48602065084527524\n",
      "Recompensa por acortar distancias: +  0.9004850565451722\n",
      "Penalización por duración del episodio: -  0.486416613380697\n",
      "Recompensa por acortar distancias: +  0.9004811338442601\n",
      "Penalización por duración del episodio: -  0.48681941295373904\n",
      "Recompensa por acortar distancias: +  0.9004811338442601\n",
      "Penalización por duración del episodio: -  0.48721306844443385\n",
      "Recompensa por acortar distancias: +  0.900478749390223\n",
      "Penalización por parar muy lejos: -  0.14216241322259243\n",
      "Penalización por duración del episodio: -  0.4875951121264763\n",
      "Recompensa por acortar distancias: +  0.9004842190301634\n",
      "Penalización por parar muy lejos: -  0.14216985676049704\n",
      "Penalización por duración del episodio: -  0.4879817214655505\n",
      "Recompensa por acortar distancias: +  0.9004683648849605\n",
      "Penalización por duración del episodio: -  0.48836427043357905\n",
      "Recompensa por acortar distancias: +  0.9004496062311176\n",
      "Penalización por duración del episodio: -  0.4884517111064322\n",
      "Recompensa por acortar distancias: +  0.9004481999533462\n",
      "Penalización por duración del episodio: -  0.4887510151593851\n",
      "Recompensa por acortar distancias: +  0.9004319174752626\n",
      "Penalización por parar muy lejos: -  0.14209870867832067\n",
      "Penalización por duración del episodio: -  0.48885065391505883\n",
      "Step: 2860, Mean Reward (últimos 10 pasos): 0.2694825530052185\n",
      "Recompensa por acortar distancias: +  0.9004319174752626\n",
      "Penalización por duración del episodio: -  0.4891616695173657\n",
      "Recompensa por acortar distancias: +  0.9004319174752626\n",
      "Penalización por duración del episodio: -  0.48954024944907615\n",
      "steer input from model: -0.25 , throttle:  1.0\n",
      "reward: 0.4108916680261865\n",
      "Recompensa por acortar distancias: +  0.9004319174752626\n",
      "Penalización por parar muy lejos: -  0.14209870867832067\n",
      "Penalización por duración del episodio: -  0.489939426429622\n",
      "Recompensa por acortar distancias: +  0.900354401110214\n",
      "Penalización por parar muy lejos: -  0.14199337550482896\n",
      "Penalización por duración del episodio: -  0.4903412676570078\n",
      "Recompensa por acortar distancias: +  0.9003525743854355\n",
      "Penalización por parar muy lejos: -  0.1419908949231899\n",
      "Penalización por duración del episodio: -  0.490432059639442\n",
      "Recompensa por acortar distancias: +  0.9003524246525757\n",
      "Penalización por duración del episodio: -  0.490739760817403\n",
      "Recompensa por acortar distancias: +  0.9003524460429965\n",
      "Penalización por duración del episodio: -  0.4908394336337863\n",
      "Recompensa por acortar distancias: +  0.9003524289306601\n",
      "Penalización por parar muy lejos: -  0.14199069740770515\n",
      "Penalización por duración del episodio: -  0.4911386590132415\n",
      "Recompensa por acortar distancias: +  0.9003524631553301\n",
      "Penalización por duración del episodio: -  0.4912510802210398\n",
      "Recompensa por acortar distancias: +  0.9003523690374624\n",
      "Penalización por duración del episodio: -  0.4915273671044353\n",
      "Step: 2870, Mean Reward (últimos 10 pasos): 0.40882501006126404\n",
      "Recompensa por acortar distancias: +  0.9003523690374624\n",
      "Penalización por duración del episodio: -  0.49191019208282577\n",
      "Recompensa por acortar distancias: +  0.9003523690374624\n",
      "Penalización por duración del episodio: -  0.4922936164945426\n",
      "Recompensa por acortar distancias: +  0.9003130122859584\n",
      "Penalización por parar muy lejos: -  0.14193719077626854\n",
      "Penalización por duración del episodio: -  0.49267724066616614\n",
      "Recompensa por acortar distancias: +  0.9002806881683536\n",
      "Penalización por duración del episodio: -  0.4930673095241337\n",
      "Recompensa por acortar distancias: +  0.9002572139578815\n",
      "Penalización por duración del episodio: -  0.49346431169765936\n",
      "Recompensa por acortar distancias: +  0.9002232933313694\n",
      "Penalización por duración del episodio: -  0.4938548321471425\n",
      "Recompensa por acortar distancias: +  0.9001953046275141\n",
      "Penalización por parar muy lejos: -  0.1417776189331486\n",
      "Penalización por duración del episodio: -  0.49423903092145616\n",
      "Recompensa por acortar distancias: +  0.9001953046275141\n",
      "Penalización por parar muy lejos: -  0.1417776189331486\n",
      "Penalización por duración del episodio: -  0.4943165604479688\n",
      "Recompensa por acortar distancias: +  0.9001953046275141\n",
      "Penalización por duración del episodio: -  0.49463812998278656\n",
      "Recompensa por acortar distancias: +  0.9000951838434998\n",
      "Penalización por duración del episodio: -  0.49503295668581127\n",
      "Step: 2880, Mean Reward (últimos 10 pasos): 0.4050622284412384\n",
      "Recompensa por acortar distancias: +  0.9000653360755023\n",
      "Penalización por duración del episodio: -  0.4954151484988792\n",
      "Recompensa por acortar distancias: +  0.8999931497811128\n",
      "Penalización por parar muy lejos: -  0.1415043039341451\n",
      "Penalización por duración del episodio: -  0.4957972383893877\n",
      "steer input from model: 0.25 , throttle:  0.0\n",
      "reward: 0.2626916074575799\n",
      "Recompensa por acortar distancias: +  0.8999219177677492\n",
      "Penalización por duración del episodio: -  0.49618513238270157\n",
      "Recompensa por acortar distancias: +  0.8998350578269583\n",
      "Penalización por parar muy lejos: -  0.1412912103486067\n",
      "Penalización por duración del episodio: -  0.49657332301731083\n",
      "Recompensa por acortar distancias: +  0.8998350578269583\n",
      "Penalización por parar muy lejos: -  0.1412912103486067\n",
      "Penalización por duración del episodio: -  0.4969630793671918\n",
      "Recompensa por acortar distancias: +  0.8998350578269583\n",
      "Penalización por duración del episodio: -  0.4970940380666001\n",
      "Recompensa por acortar distancias: +  0.8996062374885236\n",
      "Penalización por parar muy lejos: -  0.14098378371374062\n",
      "Penalización por duración del episodio: -  0.4973420214694009\n",
      "Recompensa por acortar distancias: +  0.8995619876611937\n",
      "Penalización por duración del episodio: -  0.4977315700721728\n",
      "Recompensa por acortar distancias: +  0.8994760229613352\n",
      "Penalización por duración del episodio: -  0.49814419406503035\n",
      "Recompensa por acortar distancias: +  0.8993956537721348\n",
      "Penalización por duración del episodio: -  0.4985319596990451\n",
      "Step: 2890, Mean Reward (últimos 10 pasos): 0.4008637070655823\n",
      "Recompensa por acortar distancias: +  0.8993052274386504\n",
      "Penalización por parar muy lejos: -  0.14058116343739657\n",
      "Penalización por duración del episodio: -  0.4989113348044809\n",
      "Recompensa por acortar distancias: +  0.8992672830128328\n",
      "Penalización por duración del episodio: -  0.4993028347241849\n",
      "Recompensa por acortar distancias: +  0.8992672830128328\n",
      "Penalización por duración del episodio: -  0.49969091419342365\n",
      "Penalización por duración del episodio\n",
      "Recompensa por acortar distancias: +  0.9156968414046006\n",
      "Penalización por parar muy lejos: -  0.1659323993969936\n",
      "Penalización por duración del episodio: -  0.26932590727417516\n",
      "Recompensa por acortar distancias: +  0.915696377597617\n",
      "Penalización por duración del episodio: -  0.2696374784724038\n",
      "Recompensa por acortar distancias: +  0.915696377597617\n",
      "Penalización por duración del episodio: -  0.2699453206819469\n",
      "Recompensa por acortar distancias: +  0.915696377597617\n",
      "Penalización por duración del episodio: -  0.27000794390691674\n",
      "Recompensa por acortar distancias: +  0.915696377597617\n",
      "Penalización por parar muy lejos: -  0.1659315678779327\n",
      "Penalización por duración del episodio: -  0.2702527777435633\n",
      "Recompensa por acortar distancias: +  0.915696377597617\n",
      "Penalización por duración del episodio: -  0.2705575896479416\n",
      "Step: 2900, Mean Reward (últimos 10 pasos): 0.6451388001441956\n",
      "Recompensa por acortar distancias: +  0.915696377597617\n",
      "Penalización por parar muy lejos: -  0.1659315678779327\n",
      "Penalización por duración del episodio: -  0.27085865305247264\n",
      "Recompensa por acortar distancias: +  0.9156962377188657\n",
      "Penalización por parar muy lejos: -  0.16593131710299808\n",
      "Penalización por duración del episodio: -  0.27117280008649813\n",
      "Recompensa por acortar distancias: +  0.9156962377188657\n",
      "Penalización por parar muy lejos: -  0.16593131710299808\n",
      "Penalización por duración del episodio: -  0.2714812579148399\n",
      "Recompensa por acortar distancias: +  0.9156962303568201\n",
      "Penalización por parar muy lejos: -  0.16593130390432573\n",
      "Penalización por duración del episodio: -  0.27179056808600605\n",
      "Recompensa por acortar distancias: +  0.9156963923216838\n",
      "Penalización por parar muy lejos: -  0.16593159427531193\n",
      "Penalización por duración del episodio: -  0.2720933228000226\n",
      "Recompensa por acortar distancias: +  0.9156964806660359\n",
      "Penalización por duración del episodio: -  0.27240699171271254\n",
      "Recompensa por acortar distancias: +  0.9156964806660359\n",
      "Penalización por duración del episodio: -  0.27271188302299054\n",
      "Recompensa por acortar distancias: +  0.9156963923216838\n",
      "Penalización por parar muy lejos: -  0.16593159427531193\n",
      "Penalización por duración del episodio: -  0.2730131403531783\n",
      "Recompensa por acortar distancias: +  0.9156964806660359\n",
      "Penalización por parar muy lejos: -  0.16593175265965776\n",
      "Penalización por duración del episodio: -  0.27331882460221624\n",
      "Recompensa por acortar distancias: +  0.9156964070457484\n",
      "Penalización por parar muy lejos: -  0.16593162067269449\n",
      "Penalización por duración del episodio: -  0.2736203532617502\n",
      "Step: 2910, Mean Reward (últimos 10 pasos): 0.4761444330215454\n",
      "Recompensa por acortar distancias: +  0.9156965910963577\n",
      "Penalización por parar muy lejos: -  0.16593195064026042\n",
      "Penalización por duración del episodio: -  0.2739314118100184\n",
      "Recompensa por acortar distancias: +  0.9156967604225958\n",
      "Penalización por duración del episodio: -  0.2742457559644627\n",
      "Recompensa por acortar distancias: +  0.9156967604225958\n",
      "Penalización por duración del episodio: -  0.2745452379165336\n",
      "Recompensa por acortar distancias: +  0.9156967604225958\n",
      "Penalización por duración del episodio: -  0.27463528978933854\n",
      "steer input from model: 0.0 , throttle:  1.0\n",
      "reward: 0.6410614706332574\n",
      "Recompensa por acortar distancias: +  0.9156967088885559\n",
      "Penalización por duración del episodio: -  0.27484893360047186\n",
      "Recompensa por acortar distancias: +  0.915696701526548\n",
      "Penalización por duración del episodio: -  0.27516525357380556\n",
      "Recompensa por acortar distancias: +  0.9156968045946072\n",
      "Penalización por duración del episodio: -  0.2754863247791305\n",
      "Recompensa por acortar distancias: +  0.9156969223865349\n",
      "Penalización por parar muy lejos: -  0.16593254458320367\n",
      "Penalización por duración del episodio: -  0.2757822514536838\n",
      "Recompensa por acortar distancias: +  0.9156970328163313\n",
      "Penalización por duración del episodio: -  0.27610503592196856\n",
      "Recompensa por acortar distancias: +  0.915697062264255\n",
      "Penalización por parar muy lejos: -  0.16593279535962438\n",
      "Penalización por duración del episodio: -  0.27643126812986735\n",
      "Step: 2920, Mean Reward (últimos 10 pasos): 0.4733330011367798\n",
      "Recompensa por acortar distancias: +  0.915697062264255\n",
      "Penalización por duración del episodio: -  0.2767438466098868\n",
      "Recompensa por acortar distancias: +  0.9156969591964816\n",
      "Penalización por parar muy lejos: -  0.16593261057696915\n",
      "Penalización por duración del episodio: -  0.2768248843161264\n",
      "Recompensa por acortar distancias: +  0.9156969591964816\n",
      "Penalización por duración del episodio: -  0.27690474798438\n",
      "Recompensa por acortar distancias: +  0.9156969591964816\n",
      "Penalización por parar muy lejos: -  0.16593261057696915\n",
      "Penalización por duración del episodio: -  0.2770638446179908\n",
      "Recompensa por acortar distancias: +  0.9156969591964816\n",
      "Penalización por parar muy lejos: -  0.16593261057696915\n",
      "Penalización por duración del episodio: -  0.2773779203117586\n",
      "Recompensa por acortar distancias: +  0.9156970401783131\n",
      "Penalización por duración del episodio: -  0.2776867014572981\n",
      "Recompensa por acortar distancias: +  0.9156971358840228\n",
      "Penalización por duración del episodio: -  0.27799905825088894\n",
      "Recompensa por acortar distancias: +  0.9156971800558555\n",
      "Penalización por parar muy lejos: -  0.1659330065400036\n",
      "Penalización por duración del episodio: -  0.2783158499192549\n",
      "Recompensa por acortar distancias: +  0.9156971800558555\n",
      "Penalización por duración del episodio: -  0.2786265712439068\n",
      "Recompensa por acortar distancias: +  0.9156969812824427\n",
      "Penalización por duración del episodio: -  0.27895042902851713\n",
      "Step: 2930, Mean Reward (últimos 10 pasos): 0.6367465257644653\n",
      "Recompensa por acortar distancias: +  0.9156969739204561\n",
      "Penalización por parar muy lejos: -  0.16593263697448127\n",
      "Penalización por duración del episodio: -  0.2790408903982057\n",
      "Recompensa por acortar distancias: +  0.9156969739204561\n",
      "Penalización por duración del episodio: -  0.27912115142492633\n",
      "Recompensa por acortar distancias: +  0.9156969739204561\n",
      "Penalización por parar muy lejos: -  0.16593263697448127\n",
      "Penalización por duración del episodio: -  0.2791979335747128\n",
      "Recompensa por acortar distancias: +  0.9156969665584692\n",
      "Penalización por duración del episodio: -  0.27958772411830984\n",
      "steer input from model: 0.25 , throttle:  0.3\n",
      "reward: 0.6361092424401593\n",
      "Recompensa por acortar distancias: +  0.915697025454349\n",
      "Penalización por parar muy lejos: -  0.16593272936580003\n",
      "Penalización por duración del episodio: -  0.2796764147583748\n",
      "Recompensa por acortar distancias: +  0.915697025454349\n",
      "Penalización por duración del episodio: -  0.27989473029751033\n",
      "Recompensa por acortar distancias: +  0.9156970990741461\n",
      "Penalización por parar muy lejos: -  0.16593286135346974\n",
      "Penalización por duración del episodio: -  0.2799853934059615\n",
      "Recompensa por acortar distancias: +  0.9156970990741461\n",
      "Penalización por duración del episodio: -  0.28021616182815395\n",
      "Recompensa por acortar distancias: +  0.9156970990741461\n",
      "Penalización por duración del episodio: -  0.2805136671203948\n",
      "Recompensa por acortar distancias: +  0.9156970990741461\n",
      "Penalización por duración del episodio: -  0.2808208073859899\n",
      "Step: 2940, Mean Reward (últimos 10 pasos): 0.6348763108253479\n",
      "Recompensa por acortar distancias: +  0.9156967604225958\n",
      "Penalización por duración del episodio: -  0.2811295546782033\n",
      "Recompensa por acortar distancias: +  0.9156967604225958\n",
      "Penalización por duración del episodio: -  0.28144064936052193\n",
      "Recompensa por acortar distancias: +  0.9156969665584692\n",
      "Penalización por duración del episodio: -  0.2817746064733268\n",
      "Recompensa por acortar distancias: +  0.9156970917121691\n",
      "Penalización por parar muy lejos: -  0.16593284815469897\n",
      "Penalización por duración del episodio: -  0.2820998812344929\n",
      "Recompensa por acortar distancias: +  0.9156971653319136\n",
      "Penalización por parar muy lejos: -  0.16593298014244443\n",
      "Penalización por duración del episodio: -  0.28241806851279955\n",
      "Recompensa por acortar distancias: +  0.9156971653319136\n",
      "Penalización por parar muy lejos: -  0.16593298014244443\n",
      "Penalización por duración del episodio: -  0.28274417563026283\n",
      "Recompensa por acortar distancias: +  0.915696892938567\n",
      "Penalización por duración del episodio: -  0.2830547955604608\n",
      "Recompensa por acortar distancias: +  0.9156968855765736\n",
      "Penalización por parar muy lejos: -  0.1659324785894592\n",
      "Penalización por duración del episodio: -  0.28337547942985036\n",
      "Recompensa por acortar distancias: +  0.9156969812824427\n",
      "Penalización por duración del episodio: -  0.2834659593648326\n",
      "Recompensa por acortar distancias: +  0.9156970033683983\n",
      "Penalización por duración del episodio: -  0.2835469877610772\n",
      "Step: 2950, Mean Reward (últimos 10 pasos): 0.6321499943733215\n",
      "Recompensa por acortar distancias: +  0.9156970033683983\n",
      "Penalización por parar muy lejos: -  0.16593268976951547\n",
      "Penalización por duración del episodio: -  0.2836992946857306\n",
      "Recompensa por acortar distancias: +  0.9156970401783131\n",
      "Penalización por duración del episodio: -  0.2840084394514236\n",
      "Recompensa por acortar distancias: +  0.9156970917121691\n",
      "Penalización por duración del episodio: -  0.2840904342588582\n",
      "Recompensa por acortar distancias: +  0.9156970917121691\n",
      "Penalización por duración del episodio: -  0.2843317595273811\n",
      "steer input from model: 0.9 , throttle:  1.0\n",
      "reward: 0.631365332184788\n",
      "Recompensa por acortar distancias: +  0.9156970917121691\n",
      "Penalización por parar muy lejos: -  0.16593284815469897\n",
      "Penalización por duración del episodio: -  0.2846398583552002\n",
      "Recompensa por acortar distancias: +  0.9156970917121691\n",
      "Penalización por duración del episodio: -  0.2847424100118806\n",
      "Recompensa por acortar distancias: +  0.915696870852585\n",
      "Penalización por parar muy lejos: -  0.1659324521919673\n",
      "Penalización por duración del episodio: -  0.28496099270511455\n",
      "Recompensa por acortar distancias: +  0.915696870852585\n",
      "Penalización por parar muy lejos: -  0.1659324521919673\n",
      "Penalización por duración del episodio: -  0.2850615731697925\n",
      "Recompensa por acortar distancias: +  0.915696870852585\n",
      "Penalización por duración del episodio: -  0.285276448195591\n",
      "Recompensa por acortar distancias: +  0.915696870852585\n",
      "Penalización por parar muy lejos: -  0.1659324521919673\n",
      "Penalización por duración del episodio: -  0.28560222182746176\n",
      "Step: 2960, Mean Reward (últimos 10 pasos): 0.4641622006893158\n",
      "Recompensa por acortar distancias: +  0.9156969960064137\n",
      "Penalización por parar muy lejos: -  0.16593267657075564\n",
      "Penalización por duración del episodio: -  0.28570972570650055\n",
      "Recompensa por acortar distancias: +  0.9156970328163313\n",
      "Penalización por duración del episodio: -  0.2859307402143634\n",
      "Recompensa por acortar distancias: +  0.9156970696262342\n",
      "Penalización por parar muy lejos: -  0.16593280855839176\n",
      "Penalización por duración del episodio: -  0.2860220755532184\n",
      "Recompensa por acortar distancias: +  0.9156970917121691\n",
      "Penalización por duración del episodio: -  0.2862409503235168\n",
      "Recompensa por acortar distancias: +  0.9156970917121691\n",
      "Penalización por duración del episodio: -  0.2865667744652684\n",
      "Recompensa por acortar distancias: +  0.9156970917121691\n",
      "Penalización por parar muy lejos: -  0.16593284815469897\n",
      "Penalización por duración del episodio: -  0.2868787289616731\n",
      "Recompensa por acortar distancias: +  0.9156970917121691\n",
      "Penalización por parar muy lejos: -  0.16593284815469897\n",
      "Penalización por duración del episodio: -  0.28698642761586685\n",
      "Recompensa por acortar distancias: +  0.9156967530605918\n",
      "Penalización por parar muy lejos: -  0.16593224101215326\n",
      "Penalización por duración del episodio: -  0.2871967969373322\n",
      "Recompensa por acortar distancias: +  0.9156967088885559\n",
      "Penalización por duración del episodio: -  0.28750788617434825\n",
      "Recompensa por acortar distancias: +  0.9156967088885559\n",
      "Penalización por parar muy lejos: -  0.16593216181977846\n",
      "Penalización por duración del episodio: -  0.28759332354397554\n",
      "Step: 2970, Mean Reward (últimos 10 pasos): 0.4621712267398834\n",
      "Recompensa por acortar distancias: +  0.9156968487665976\n",
      "Penalización por parar muy lejos: -  0.16593241259573577\n",
      "Penalización por duración del episodio: -  0.2878215270122771\n",
      "Recompensa por acortar distancias: +  0.9156969297485253\n",
      "Penalización por duración del episodio: -  0.28813768474240126\n",
      "Recompensa por acortar distancias: +  0.915697025454349\n",
      "Penalización por parar muy lejos: -  0.16593272936580003\n",
      "Penalización por duración del episodio: -  0.2884525957280449\n",
      "Recompensa por acortar distancias: +  0.915697025454349\n",
      "Penalización por parar muy lejos: -  0.16593272936580003\n",
      "Penalización por duración del episodio: -  0.2887665752475364\n",
      "steer input from model: -0.25 , throttle:  0.0\n",
      "reward: 0.4609977208410125\n",
      "Recompensa por acortar distancias: +  0.9156968782145795\n",
      "Penalización por parar muy lejos: -  0.16593246539071285\n",
      "Penalización por duración del episodio: -  0.2890780431941435\n",
      "Recompensa por acortar distancias: +  0.915696870852585\n",
      "Penalización por duración del episodio: -  0.2891555051711357\n",
      "Recompensa por acortar distancias: +  0.915696870852585\n",
      "Penalización por parar muy lejos: -  0.1659324521919673\n",
      "Penalización por duración del episodio: -  0.2894018354682989\n",
      "Recompensa por acortar distancias: +  0.9156969223865349\n",
      "Penalización por parar muy lejos: -  0.16593254458320367\n",
      "Penalización por duración del episodio: -  0.28972802591925\n",
      "Recompensa por acortar distancias: +  0.9156969812824427\n",
      "Penalización por duración del episodio: -  0.28983545162546587\n",
      "Recompensa por acortar distancias: +  0.9156970328163313\n",
      "Penalización por duración del episodio: -  0.29004388337330744\n",
      "Step: 2980, Mean Reward (últimos 10 pasos): 0.6256531476974487\n",
      "Recompensa por acortar distancias: +  0.9156970843501915\n",
      "Penalización por duración del episodio: -  0.2901434134979024\n",
      "Recompensa por acortar distancias: +  0.9156970843501915\n",
      "Penalización por duración del episodio: -  0.2903756945783434\n",
      "Recompensa por acortar distancias: +  0.9156971137980985\n",
      "Penalización por parar muy lejos: -  0.1659328877510138\n",
      "Penalización por duración del episodio: -  0.2907076807823299\n",
      "Recompensa por acortar distancias: +  0.9156971137980985\n",
      "Penalización por duración del episodio: -  0.29102653973508125\n",
      "Recompensa por acortar distancias: +  0.9156969518344935\n",
      "Penalización por parar muy lejos: -  0.1659325973782144\n",
      "Penalización por duración del episodio: -  0.29135295899247043\n",
      "Recompensa por acortar distancias: +  0.9156969518344935\n",
      "Penalización por parar muy lejos: -  0.1659325973782144\n",
      "Penalización por duración del episodio: -  0.2916760422598757\n",
      "Recompensa por acortar distancias: +  0.9156970696262342\n",
      "Penalización por duración del episodio: -  0.2920018400908951\n",
      "Recompensa por acortar distancias: +  0.9156971874178257\n",
      "Penalización por parar muy lejos: -  0.16593301973878447\n",
      "Penalización por duración del episodio: -  0.2923151414783346\n",
      "Recompensa por acortar distancias: +  0.9156972757614211\n",
      "Penalización por parar muy lejos: -  0.16593317812422026\n",
      "Penalización por duración del episodio: -  0.29263411817901397\n",
      "Recompensa por acortar distancias: +  0.9156972757614211\n",
      "Penalización por parar muy lejos: -  0.16593317812422026\n",
      "Penalización por duración del episodio: -  0.2929573533084699\n",
      "Step: 2990, Mean Reward (últimos 10 pasos): 0.4568067491054535\n",
      "Recompensa por acortar distancias: +  0.9156972757614211\n",
      "Penalización por duración del episodio: -  0.29327928036390394\n",
      "Recompensa por acortar distancias: +  0.9156970401783131\n",
      "Penalización por parar muy lejos: -  0.16593275576332722\n",
      "Penalización por duración del episodio: -  0.29336478261230625\n",
      "Recompensa por acortar distancias: +  0.9156970401783131\n",
      "Penalización por parar muy lejos: -  0.16593275576332722\n",
      "Penalización por duración del episodio: -  0.29360794144870417\n",
      "Recompensa por acortar distancias: +  0.9156970990741461\n",
      "Penalización por parar muy lejos: -  0.16593286135346974\n",
      "Penalización por duración del episodio: -  0.2939378617063372\n",
      "steer input from model: 0.9 , throttle:  0.0\n",
      "reward: 0.4558263760143392\n",
      "Recompensa por acortar distancias: +  0.9156970696262342\n",
      "Penalización por parar muy lejos: -  0.16593280855839176\n",
      "Penalización por duración del episodio: -  0.29424312332178854\n",
      "Recompensa por acortar distancias: +  0.9156970328163313\n",
      "Penalización por duración del episodio: -  0.29456742533513014\n",
      "Recompensa por acortar distancias: +  0.9156970328163313\n",
      "Penalización por duración del episodio: -  0.29490282211702185\n",
      "Recompensa por acortar distancias: +  0.9156970328163313\n",
      "Penalización por duración del episodio: -  0.2950515211488306\n",
      "Recompensa por acortar distancias: +  0.9156965837343402\n",
      "Penalización por duración del episodio: -  0.29522079555630965\n",
      "Recompensa por acortar distancias: +  0.9156966573544877\n",
      "Penalización por duración del episodio: -  0.2955457338067559\n",
      "Step: 3000, Mean Reward (últimos 10 pasos): 0.6201509237289429\n",
      "Recompensa por acortar distancias: +  0.9156966573544877\n",
      "Penalización por duración del episodio: -  0.2958615218095499\n",
      "Recompensa por acortar distancias: +  0.9156967162505635\n",
      "Penalización por parar muy lejos: -  0.16593217501850552\n",
      "Penalización por duración del episodio: -  0.2959594042398331\n",
      "Recompensa por acortar distancias: +  0.9156967604225958\n",
      "Penalización por parar muy lejos: -  0.1659322542108853\n",
      "Penalización por duración del episodio: -  0.2960546868768044\n",
      "Recompensa por acortar distancias: +  0.9156967972326069\n",
      "Penalización por parar muy lejos: -  0.16593232020455828\n",
      "Penalización por duración del episodio: -  0.2961949950527187\n",
      "Recompensa por acortar distancias: +  0.9156967972326069\n",
      "Penalización por duración del episodio: -  0.29653102835215045\n",
      "Recompensa por acortar distancias: +  0.9156968782145795\n",
      "Penalización por duración del episodio: -  0.2968510484029125\n",
      "Recompensa por acortar distancias: +  0.9156968782145795\n",
      "Penalización por parar muy lejos: -  0.16593246539071285\n",
      "Penalización por duración del episodio: -  0.2971719003389074\n",
      "Recompensa por acortar distancias: +  0.9156965690103038\n",
      "Penalización por parar muy lejos: -  0.16593191104412475\n",
      "Penalización por duración del episodio: -  0.29727428670062583\n",
      "Recompensa por acortar distancias: +  0.9156965690103038\n",
      "Penalización por parar muy lejos: -  0.16593191104412475\n",
      "Penalización por duración del episodio: -  0.29749165683610185\n",
      "Recompensa por acortar distancias: +  0.9156965248381803\n",
      "Penalización por parar muy lejos: -  0.16593183185187613\n",
      "Penalización por duración del episodio: -  0.2975815030746924\n",
      "Step: 3010, Mean Reward (últimos 10 pasos): 0.45218318700790405\n",
      "Recompensa por acortar distancias: +  0.9156965248381803\n",
      "Penalización por duración del episodio: -  0.2978254374267225\n",
      "Recompensa por acortar distancias: +  0.9156966499924755\n",
      "Penalización por duración del episodio: -  0.297915486339495\n",
      "Recompensa por acortar distancias: +  0.9156966499924755\n",
      "Penalización por parar muy lejos: -  0.16593205622999252\n",
      "Penalización por duración del episodio: -  0.29801091270199814\n",
      "Recompensa por acortar distancias: +  0.9156966426304628\n",
      "Penalización por duración del episodio: -  0.2981284368675973\n",
      "steer input from model: 0.1 , throttle:  0.7\n",
      "reward: 0.6175682057628655\n",
      "Recompensa por acortar distancias: +  0.915696701526548\n",
      "Penalización por parar muy lejos: -  0.16593214862105227\n",
      "Penalización por duración del episodio: -  0.2984743199406933\n",
      "Recompensa por acortar distancias: +  0.9156968193186064\n",
      "Penalización por duración del episodio: -  0.2988119361643275\n",
      "Recompensa por acortar distancias: +  0.9156968193186064\n",
      "Penalización por parar muy lejos: -  0.16593235980077214\n",
      "Penalización por duración del episodio: -  0.2991313266841603\n",
      "Recompensa por acortar distancias: +  0.9156968193186064\n",
      "Penalización por duración del episodio: -  0.29946115606459\n",
      "Recompensa por acortar distancias: +  0.9156967236125705\n",
      "Penalización por parar muy lejos: -  0.16593218821723335\n",
      "Penalización por duración del episodio: -  0.29979612831627267\n",
      "Recompensa por acortar distancias: +  0.9156968634905899\n",
      "Penalización por duración del episodio: -  0.30012710799381115\n",
      "Step: 3020, Mean Reward (últimos 10 pasos): 0.6155697703361511\n",
      "Recompensa por acortar distancias: +  0.9156969518344935\n",
      "Penalización por parar muy lejos: -  0.1659325973782144\n",
      "Penalización por duración del episodio: -  0.3004549338068594\n",
      "Recompensa por acortar distancias: +  0.9156970696262342\n",
      "Penalización por duración del episodio: -  0.3007840468865444\n",
      "Recompensa por acortar distancias: +  0.9156971211600738\n",
      "Penalización por parar muy lejos: -  0.16593290094978708\n",
      "Penalización por duración del episodio: -  0.3011146146233994\n",
      "Recompensa por acortar distancias: +  0.9156971211600738\n",
      "Penalización por duración del episodio: -  0.3014522973219406\n",
      "Recompensa por acortar distancias: +  0.915697025454349\n",
      "Penalización por duración del episodio: -  0.3017719239898457\n",
      "Recompensa por acortar distancias: +  0.915697025454349\n",
      "Penalización por parar muy lejos: -  0.16593272936580003\n",
      "Penalización por duración del episodio: -  0.30208918947220054\n",
      "Recompensa por acortar distancias: +  0.9156970990741461\n",
      "Penalización por duración del episodio: -  0.30218581973542036\n",
      "Recompensa por acortar distancias: +  0.9156971358840228\n",
      "Penalización por duración del episodio: -  0.3024156370516814\n",
      "Recompensa por acortar distancias: +  0.9156971432459964\n",
      "Penalización por duración del episodio: -  0.3027526771325503\n",
      "Recompensa por acortar distancias: +  0.9156971358840228\n",
      "Penalización por duración del episodio: -  0.3030767605793341\n",
      "Step: 3030, Mean Reward (últimos 10 pasos): 0.6126203536987305\n",
      "Recompensa por acortar distancias: +  0.9156971358840228\n",
      "Penalización por parar muy lejos: -  0.16593292734733617\n",
      "Penalización por duración del episodio: -  0.30340259702285827\n",
      "Recompensa por acortar distancias: +  0.9156967530605918\n",
      "Penalización por parar muy lejos: -  0.16593224101215326\n",
      "Penalización por duración del episodio: -  0.3037303958129344\n",
      "Recompensa por acortar distancias: +  0.9156967309745766\n",
      "Penalización por parar muy lejos: -  0.16593220141596207\n",
      "Penalización por duración del episodio: -  0.304059186255012\n",
      "Recompensa por acortar distancias: +  0.9156967530605918\n",
      "Penalización por parar muy lejos: -  0.16593224101215326\n",
      "Penalización por duración del episodio: -  0.30439046889705657\n",
      "steer input from model: 0.1 , throttle:  0.0\n",
      "reward: 0.44537404315138207\n",
      "Recompensa por acortar distancias: +  0.9156968414046006\n",
      "Penalización por parar muy lejos: -  0.1659323993969936\n",
      "Penalización por duración del episodio: -  0.30471488773171795\n",
      "Recompensa por acortar distancias: +  0.9156969223865349\n",
      "Penalización por parar muy lejos: -  0.16593254458320367\n",
      "Penalización por duración del episodio: -  0.30504196718332305\n",
      "Recompensa por acortar distancias: +  0.9156969518344935\n",
      "Penalización por duración del episodio: -  0.3053691980078756\n",
      "Recompensa por acortar distancias: +  0.9156969518344935\n",
      "Penalización por duración del episodio: -  0.30570996974356596\n",
      "Recompensa por acortar distancias: +  0.9156967604225958\n",
      "Penalización por parar muy lejos: -  0.1659322542108853\n",
      "Penalización por duración del episodio: -  0.3060421537018561\n",
      "Recompensa por acortar distancias: +  0.9156967604225958\n",
      "Penalización por duración del episodio: -  0.30613675390470924\n",
      "Step: 3040, Mean Reward (últimos 10 pasos): 0.6095600128173828\n",
      "Recompensa por acortar distancias: +  0.9156967972326069\n",
      "Penalización por parar muy lejos: -  0.16593232020455828\n",
      "Penalización por duración del episodio: -  0.3063706177863662\n",
      "Recompensa por acortar distancias: +  0.9156968561285941\n",
      "Penalización por parar muy lejos: -  0.16593242579447878\n",
      "Penalización por duración del episodio: -  0.3064712948472364\n",
      "Recompensa por acortar distancias: +  0.9156968561285941\n",
      "Penalización por parar muy lejos: -  0.16593242579447878\n",
      "Penalización por duración del episodio: -  0.30658504681508575\n",
      "Recompensa por acortar distancias: +  0.9156968855765736\n",
      "Penalización por duración del episodio: -  0.3067142240088447\n",
      "Recompensa por acortar distancias: +  0.9156968855765736\n",
      "Penalización por parar muy lejos: -  0.1659324785894592\n",
      "Penalización por duración del episodio: -  0.3068045591100572\n",
      "Recompensa por acortar distancias: +  0.9156969297485253\n",
      "Penalización por duración del episodio: -  0.3070456773793257\n",
      "Recompensa por acortar distancias: +  0.9156969518344935\n",
      "Penalización por duración del episodio: -  0.30737790877743887\n",
      "Recompensa por acortar distancias: +  0.9156969518344935\n",
      "Penalización por parar muy lejos: -  0.1659325973782144\n",
      "Penalización por duración del episodio: -  0.30771177735985067\n",
      "Recompensa por acortar distancias: +  0.9156969518344935\n",
      "Penalización por parar muy lejos: -  0.1659325973782144\n",
      "Penalización por duración del episodio: -  0.30781057619239066\n",
      "Recompensa por acortar distancias: +  0.9156969518344935\n",
      "Penalización por duración del episodio: -  0.3079248128631943\n",
      "Step: 3050, Mean Reward (últimos 10 pasos): 0.6077721118927002\n",
      "Recompensa por acortar distancias: +  0.9156969518344935\n",
      "Penalización por duración del episodio: -  0.30838291514016913\n",
      "Recompensa por acortar distancias: +  0.9156965690103038\n",
      "Penalización por parar muy lejos: -  0.16593191104412475\n",
      "Penalización por duración del episodio: -  0.3087250260942508\n",
      "Recompensa por acortar distancias: +  0.9156968045946072\n",
      "Penalización por duración del episodio: -  0.3090509277632864\n",
      "Recompensa por acortar distancias: +  0.9156969739204561\n",
      "Penalización por parar muy lejos: -  0.16593263697448127\n",
      "Penalización por duración del episodio: -  0.3093879057356187\n",
      "steer input from model: 0.25 , throttle:  0.0\n",
      "reward: 0.4403764312103562\n",
      "Recompensa por acortar distancias: +  0.9156969739204561\n",
      "Penalización por parar muy lejos: -  0.16593263697448127\n",
      "Penalización por duración del episodio: -  0.3097127358569841\n",
      "Recompensa por acortar distancias: +  0.9156969739204561\n",
      "Penalización por duración del episodio: -  0.310053350285295\n",
      "Recompensa por acortar distancias: +  0.915696892938567\n",
      "Penalización por parar muy lejos: -  0.1659324917882064\n",
      "Penalización por duración del episodio: -  0.3103713747075863\n",
      "Recompensa por acortar distancias: +  0.915696892938567\n",
      "Penalización por duración del episodio: -  0.3104607580857021\n",
      "Recompensa por acortar distancias: +  0.9156969150245438\n",
      "Penalización por duración del episodio: -  0.3107127397727736\n",
      "Recompensa por acortar distancias: +  0.9156969739204561\n",
      "Penalización por duración del episodio: -  0.3110575451401788\n",
      "Step: 3060, Mean Reward (últimos 10 pasos): 0.6046394109725952\n",
      "Recompensa por acortar distancias: +  0.915697062264255\n",
      "Penalización por duración del episodio: -  0.31138934990498174\n",
      "Recompensa por acortar distancias: +  0.9156970328163313\n",
      "Penalización por duración del episodio: -  0.3117247808378462\n",
      "Recompensa por acortar distancias: +  0.9156970328163313\n",
      "Penalización por parar muy lejos: -  0.1659327425645632\n",
      "Penalización por duración del episodio: -  0.31207049769052764\n",
      "Recompensa por acortar distancias: +  0.9156966426304628\n",
      "Penalización por parar muy lejos: -  0.1659320430312731\n",
      "Penalización por duración del episodio: -  0.3124119733323786\n",
      "Recompensa por acortar distancias: +  0.9156966426304628\n",
      "Penalización por parar muy lejos: -  0.1659320430312731\n",
      "Penalización por duración del episodio: -  0.312748149022349\n",
      "Recompensa por acortar distancias: +  0.9156967236125705\n",
      "Penalización por parar muy lejos: -  0.16593218821723335\n",
      "Penalización por duración del episodio: -  0.3130751231262482\n",
      "Recompensa por acortar distancias: +  0.9156967604225958\n",
      "Penalización por parar muy lejos: -  0.1659322542108853\n",
      "Penalización por duración del episodio: -  0.3131569418698474\n",
      "Recompensa por acortar distancias: +  0.9156967972326069\n",
      "Penalización por duración del episodio: -  0.31341646870156215\n",
      "Recompensa por acortar distancias: +  0.915696811956607\n",
      "Penalización por duración del episodio: -  0.31374425374815634\n",
      "Recompensa por acortar distancias: +  0.915696811956607\n",
      "Penalización por duración del episodio: -  0.3140868119864426\n",
      "Step: 3070, Mean Reward (últimos 10 pasos): 0.601610004901886\n",
      "Recompensa por acortar distancias: +  0.915696811956607\n",
      "Penalización por parar muy lejos: -  0.16593234660203335\n",
      "Penalización por duración del episodio: -  0.3141950255191065\n",
      "Recompensa por acortar distancias: +  0.9156966941645394\n",
      "Penalización por parar muy lejos: -  0.16593213542232693\n",
      "Penalización por duración del episodio: -  0.3144280104881369\n",
      "Recompensa por acortar distancias: +  0.9156966573544877\n",
      "Penalización por duración del episodio: -  0.3147752873869817\n",
      "Recompensa por acortar distancias: +  0.9156966573544877\n",
      "Penalización por duración del episodio: -  0.3148875228340571\n",
      "steer input from model: 0.05 , throttle:  0.7\n",
      "reward: 0.6008091345204306\n",
      "Recompensa por acortar distancias: +  0.9156967162505635\n",
      "Penalización por parar muy lejos: -  0.16593217501850552\n",
      "Penalización por duración del episodio: -  0.3151248812246126\n",
      "Recompensa por acortar distancias: +  0.9156967236125705\n",
      "Penalización por duración del episodio: -  0.31546276554690766\n",
      "Recompensa por acortar distancias: +  0.9156968045946072\n",
      "Penalización por parar muy lejos: -  0.1659323334032954\n",
      "Penalización por duración del episodio: -  0.3155651483508646\n",
      "Recompensa por acortar distancias: +  0.9156968487665976\n",
      "Penalización por parar muy lejos: -  0.16593241259573577\n",
      "Penalización por duración del episodio: -  0.3156413291892905\n",
      "Recompensa por acortar distancias: +  0.9156968487665976\n",
      "Penalización por parar muy lejos: -  0.16593241259573577\n",
      "Penalización por duración del episodio: -  0.31580104086137656\n",
      "Recompensa por acortar distancias: +  0.9156968487665976\n",
      "Penalización por parar muy lejos: -  0.16593241259573577\n",
      "Penalización por duración del episodio: -  0.31589834583934917\n",
      "Step: 3080, Mean Reward (últimos 10 pasos): 0.43386608362197876\n",
      "Recompensa por acortar distancias: +  0.9156968487665976\n",
      "Penalización por duración del episodio: -  0.3161389650139316\n",
      "Recompensa por acortar distancias: +  0.9156968487665976\n",
      "Penalización por duración del episodio: -  0.3162281909077331\n",
      "Recompensa por acortar distancias: +  0.9156968487665976\n",
      "Penalización por duración del episodio: -  0.3164686459704905\n",
      "Recompensa por acortar distancias: +  0.9156968487665976\n",
      "Penalización por duración del episodio: -  0.3165459343933891\n",
      "Recompensa por acortar distancias: +  0.9156968487665976\n",
      "Penalización por duración del episodio: -  0.3168056429930971\n",
      "Recompensa por acortar distancias: +  0.9156965027521107\n",
      "Penalización por duración del episodio: -  0.31713881019734486\n",
      "Recompensa por acortar distancias: +  0.9156965027521107\n",
      "Penalización por parar muy lejos: -  0.16593179225576318\n",
      "Penalización por duración del episodio: -  0.3172167698548377\n",
      "Recompensa por acortar distancias: +  0.9156966794405205\n",
      "Penalización por parar muy lejos: -  0.1659321090248788\n",
      "Penalización por duración del episodio: -  0.3174704188083694\n",
      "Recompensa por acortar distancias: +  0.9156967162505635\n",
      "Penalización por parar muy lejos: -  0.16593217501850552\n",
      "Penalización por duración del episodio: -  0.3178173736841664\n",
      "Recompensa por acortar distancias: +  0.9156968487665976\n",
      "Penalización por duración del episodio: -  0.3181524799849866\n",
      "Step: 3090, Mean Reward (últimos 10 pasos): 0.5975443720817566\n",
      "Recompensa por acortar distancias: +  0.9156968487665976\n",
      "Penalización por duración del episodio: -  0.31849302726275786\n",
      "Recompensa por acortar distancias: +  0.9156967972326069\n",
      "Penalización por parar muy lejos: -  0.16593232020455828\n",
      "Penalización por duración del episodio: -  0.31883928314701987\n",
      "Recompensa por acortar distancias: +  0.9156968414046006\n",
      "Penalización por parar muy lejos: -  0.1659323993969936\n",
      "Penalización por duración del episodio: -  0.31917649117930996\n",
      "Recompensa por acortar distancias: +  0.9156969371105153\n",
      "Penalización por duración del episodio: -  0.3195061284448191\n",
      "steer input from model: -0.05 , throttle:  0.7\n",
      "reward: 0.5961908086656962\n",
      "Recompensa por acortar distancias: +  0.9156970328163313\n",
      "Penalización por parar muy lejos: -  0.1659327425645632\n",
      "Penalización por duración del episodio: -  0.31961965275594856\n",
      "Recompensa por acortar distancias: +  0.9156970843501915\n",
      "Penalización por duración del episodio: -  0.31985812962783605\n",
      "Recompensa por acortar distancias: +  0.9156971506079694\n",
      "Penalización por duración del episodio: -  0.3201880204332579\n",
      "Recompensa por acortar distancias: +  0.9156971506079694\n",
      "Penalización por duración del episodio: -  0.32051410855925594\n",
      "Recompensa por acortar distancias: +  0.9156971506079694\n",
      "Penalización por parar muy lejos: -  0.16593295374488862\n",
      "Penalización por duración del episodio: -  0.3206368743767276\n",
      "Recompensa por acortar distancias: +  0.9156971285220487\n",
      "Penalización por parar muy lejos: -  0.1659329141485612\n",
      "Penalización por duración del episodio: -  0.32085014946319856\n",
      "Step: 3100, Mean Reward (últimos 10 pasos): 0.42891407012939453\n",
      "Recompensa por acortar distancias: +  0.9156971211600738\n",
      "Penalización por parar muy lejos: -  0.16593290094978708\n",
      "Penalización por duración del episodio: -  0.3211968452875904\n",
      "Recompensa por acortar distancias: +  0.9156971211600738\n",
      "Penalización por parar muy lejos: -  0.16593290094978708\n",
      "Penalización por duración del episodio: -  0.32153994151915\n",
      "Recompensa por acortar distancias: +  0.9156973125712279\n",
      "Penalización por parar muy lejos: -  0.16593324411818758\n",
      "Penalización por duración del episodio: -  0.3216557092549341\n",
      "Recompensa por acortar distancias: +  0.9156973641049325\n",
      "Penalización por parar muy lejos: -  0.16593333650977715\n",
      "Penalización por duración del episodio: -  0.3218924313139392\n",
      "Recompensa por acortar distancias: +  0.9156974303625111\n",
      "Penalización por parar muy lejos: -  0.1659334552990243\n",
      "Penalización por duración del episodio: -  0.32224733702959385\n",
      "Recompensa por acortar distancias: +  0.9156974598103085\n",
      "Penalización por parar muy lejos: -  0.16593350809426713\n",
      "Penalización por duración del episodio: -  0.322598832047922\n",
      "Recompensa por acortar distancias: +  0.9156974598103085\n",
      "Penalización por duración del episodio: -  0.3229394708765776\n",
      "Recompensa por acortar distancias: +  0.9156973052092677\n",
      "Penalización por duración del episodio: -  0.32328925347928855\n",
      "Recompensa por acortar distancias: +  0.9156973052092677\n",
      "Penalización por parar muy lejos: -  0.16593323091939247\n",
      "Penalización por duración del episodio: -  0.32364061163625496\n",
      "Recompensa por acortar distancias: +  0.9156973935527511\n",
      "Penalización por parar muy lejos: -  0.16593338930498974\n",
      "Penalización por duración del episodio: -  0.32372505950440467\n",
      "Step: 3110, Mean Reward (últimos 10 pasos): 0.4260389506816864\n",
      "Recompensa por acortar distancias: +  0.9156973935527511\n",
      "Penalización por duración del episodio: -  0.32398735428172554\n",
      "Recompensa por acortar distancias: +  0.9156974303625111\n",
      "Penalización por duración del episodio: -  0.3240915333467879\n",
      "Recompensa por acortar distancias: +  0.9156974598103085\n",
      "Penalización por duración del episodio: -  0.3241971506613568\n",
      "Recompensa por acortar distancias: +  0.9156974745342036\n",
      "Penalización por duración del episodio: -  0.3243406174732535\n",
      "steer input from model: 0.05 , throttle:  0.7\n",
      "reward: 0.5913568570609501\n",
      "Recompensa por acortar distancias: +  0.9156974745342036\n",
      "Penalización por parar muy lejos: -  0.16593353449189358\n",
      "Penalización por duración del episodio: -  0.32468448798978816\n",
      "Recompensa por acortar distancias: +  0.9156974745342036\n",
      "Penalización por duración del episodio: -  0.32504503459891565\n",
      "Recompensa por acortar distancias: +  0.915697194779795\n",
      "Penalización por duración del episodio: -  0.32537823388372233\n",
      "Recompensa por acortar distancias: +  0.9156972242276673\n",
      "Penalización por parar muy lejos: -  0.16593308573270132\n",
      "Penalización por duración del episodio: -  0.3257240094249173\n",
      "Recompensa por acortar distancias: +  0.9156972757614211\n",
      "Penalización por duración del episodio: -  0.3258287658091443\n",
      "Recompensa por acortar distancias: +  0.9156973052092677\n",
      "Penalización por parar muy lejos: -  0.16593323091939247\n",
      "Penalización por duración del episodio: -  0.3260682563563778\n",
      "Step: 3120, Mean Reward (últimos 10 pasos): 0.423695832490921\n",
      "Recompensa por acortar distancias: +  0.9156973567429766\n",
      "Penalización por parar muy lejos: -  0.16593332331097613\n",
      "Penalización por duración del episodio: -  0.32641713625920615\n",
      "Recompensa por acortar distancias: +  0.9156973861907973\n",
      "Penalización por parar muy lejos: -  0.1659333761061853\n",
      "Penalización por duración del episodio: -  0.32677668274996874\n",
      "Recompensa por acortar distancias: +  0.9156973861907973\n",
      "Penalización por parar muy lejos: -  0.1659333761061853\n",
      "Penalización por duración del episodio: -  0.326843392902521\n",
      "Recompensa por acortar distancias: +  0.9156973861907973\n",
      "Penalización por duración del episodio: -  0.32711221375478544\n",
      "Recompensa por acortar distancias: +  0.9156973861907973\n",
      "Penalización por duración del episodio: -  0.3274590478099741\n",
      "Recompensa por acortar distancias: +  0.915697062264255\n",
      "Penalización por parar muy lejos: -  0.16593279535962438\n",
      "Penalización por duración del episodio: -  0.327795132690886\n",
      "Recompensa por acortar distancias: +  0.915697062264255\n",
      "Penalización por duración del episodio: -  0.3281395256146167\n",
      "Recompensa por acortar distancias: +  0.9156971285220487\n",
      "Penalización por parar muy lejos: -  0.1659329141485612\n",
      "Penalización por duración del episodio: -  0.3282105207366306\n",
      "Recompensa por acortar distancias: +  0.9156971653319136\n",
      "Penalización por parar muy lejos: -  0.16593298014244443\n",
      "Penalización por duración del episodio: -  0.32848842654265525\n",
      "Recompensa por acortar distancias: +  0.9156972315896338\n",
      "Penalización por duración del episodio: -  0.32882986074069126\n",
      "Step: 3130, Mean Reward (últimos 10 pasos): 0.5868673920631409\n",
      "Recompensa por acortar distancias: +  0.9156972389515999\n",
      "Penalización por duración del episodio: -  0.32917209709874046\n",
      "Recompensa por acortar distancias: +  0.9156972389515999\n",
      "Penalización por duración del episodio: -  0.32925453187625814\n",
      "Recompensa por acortar distancias: +  0.9156972389515999\n",
      "Penalización por parar muy lejos: -  0.16593311213027395\n",
      "Penalización por duración del episodio: -  0.3293513378397217\n",
      "Recompensa por acortar distancias: +  0.9156972389515999\n",
      "Penalización por parar muy lejos: -  0.16593311213027395\n",
      "Penalización por duración del episodio: -  0.3295290163455985\n",
      "steer input from model: -0.05 , throttle:  0.0\n",
      "reward: 0.4202351104757275\n",
      "Recompensa por acortar distancias: +  0.9156972389515999\n",
      "Penalización por duración del episodio: -  0.3296641393972152\n",
      "Recompensa por acortar distancias: +  0.9156971579699418\n",
      "Penalización por duración del episodio: -  0.32988367623046044\n",
      "Recompensa por acortar distancias: +  0.9156970990741461\n",
      "Penalización por duración del episodio: -  0.3302202209408646\n",
      "Recompensa por acortar distancias: +  0.9156970990741461\n",
      "Penalización por duración del episodio: -  0.33029045345431257\n",
      "Recompensa por acortar distancias: +  0.9156972315896338\n",
      "Penalización por duración del episodio: -  0.3305699238501545\n",
      "Recompensa por acortar distancias: +  0.9156972757614211\n",
      "Penalización por parar muy lejos: -  0.16593317812422026\n",
      "Penalización por duración del episodio: -  0.33092293394220845\n",
      "Step: 3140, Mean Reward (últimos 10 pasos): 0.418841153383255\n",
      "Recompensa por acortar distancias: +  0.9156973567429766\n",
      "Penalización por duración del episodio: -  0.33127910808427674\n",
      "Recompensa por acortar distancias: +  0.9156973567429766\n",
      "Penalización por parar muy lejos: -  0.16593332331097613\n",
      "Penalización por duración del episodio: -  0.3316263067990604\n",
      "Recompensa por acortar distancias: +  0.9156972757614211\n",
      "Penalización por parar muy lejos: -  0.16593317812422026\n",
      "Penalización por duración del episodio: -  0.33196783569363575\n",
      "Recompensa por acortar distancias: +  0.9156972536755301\n",
      "Penalización por parar muy lejos: -  0.16593313852784994\n",
      "Penalización por duración del episodio: -  0.33230676947018\n",
      "Recompensa por acortar distancias: +  0.9156972757614211\n",
      "Penalización por parar muy lejos: -  0.16593317812422026\n",
      "Penalización por duración del episodio: -  0.33240864168849943\n",
      "Recompensa por acortar distancias: +  0.9156973052092677\n",
      "Penalización por parar muy lejos: -  0.16593323091939247\n",
      "Penalización por duración del episodio: -  0.33266616427000245\n",
      "Recompensa por acortar distancias: +  0.9156973493810199\n",
      "Penalización por duración del episodio: -  0.33302449880300183\n",
      "Recompensa por acortar distancias: +  0.9156974303625111\n",
      "Penalización por duración del episodio: -  0.3333717300032943\n",
      "Recompensa por acortar distancias: +  0.9156974303625111\n",
      "Penalización por parar muy lejos: -  0.1659334552990243\n",
      "Penalización por duración del episodio: -  0.33372259322472114\n",
      "Recompensa por acortar distancias: +  0.9156974303625111\n",
      "Penalización por duración del episodio: -  0.33384540866524287\n",
      "Step: 3150, Mean Reward (últimos 10 pasos): 0.5818520188331604\n",
      "Recompensa por acortar distancias: +  0.9156970401783131\n",
      "Penalización por duración del episodio: -  0.33407208126953436\n",
      "Recompensa por acortar distancias: +  0.915697025454349\n",
      "Penalización por parar muy lejos: -  0.16593272936580003\n",
      "Penalización por duración del episodio: -  0.3344129476646157\n",
      "Recompensa por acortar distancias: +  0.915697025454349\n",
      "Penalización por duración del episodio: -  0.33448147712822385\n",
      "Recompensa por acortar distancias: +  0.915697025454349\n",
      "Penalización por parar muy lejos: -  0.16593272936580003\n",
      "Penalización por duración del episodio: -  0.33476995267802534\n",
      "steer input from model: -0.25 , throttle:  0.0\n",
      "reward: 0.41499434341052355\n",
      "Recompensa por acortar distancias: +  0.9156966131824062\n",
      "Penalización por duración del episodio: -  0.33512049586249026\n",
      "Recompensa por acortar distancias: +  0.9155762988732401\n",
      "Penalización por duración del episodio: -  0.3354618771684852\n",
      "Recompensa por acortar distancias: +  0.9154941066136811\n",
      "Penalización por duración del episodio: -  0.33581884671162227\n",
      "Recompensa por acortar distancias: +  0.9154941066136811\n",
      "Penalización por duración del episodio: -  0.3361802391519976\n",
      "Recompensa por acortar distancias: +  0.9143659767538165\n",
      "Penalización por duración del episodio: -  0.3365357760370915\n",
      "Recompensa por acortar distancias: +  0.9143659767538165\n",
      "Penalización por parar muy lejos: -  0.16357684539378745\n",
      "Penalización por duración del episodio: -  0.33688645956944957\n",
      "Step: 3160, Mean Reward (últimos 10 pasos): 0.4139026701450348\n",
      "Recompensa por acortar distancias: +  0.9130347808812569\n",
      "Penalización por duración del episodio: -  0.3369861772580227\n",
      "Recompensa por acortar distancias: +  0.9130347808812569\n",
      "Penalización por parar muy lejos: -  0.16128008816884376\n",
      "Penalización por duración del episodio: -  0.337069372546386\n",
      "Recompensa por acortar distancias: +  0.9127381908730132\n",
      "Penalización por parar muy lejos: -  0.16077623556501203\n",
      "Penalización por duración del episodio: -  0.33722905778078427\n",
      "Recompensa por acortar distancias: +  0.9123781586032356\n",
      "Penalización por duración del episodio: -  0.3375716777546509\n",
      "Recompensa por acortar distancias: +  0.9117699315159321\n",
      "Penalización por duración del episodio: -  0.3379180902098852\n",
      "Recompensa por acortar distancias: +  0.9117699315159321\n",
      "Penalización por duración del episodio: -  0.338279710557478\n",
      "Recompensa por acortar distancias: +  0.9098179052597072\n",
      "Penalización por parar muy lejos: -  0.15596182935327924\n",
      "Penalización por duración del episodio: -  0.33836457808627196\n",
      "Recompensa por acortar distancias: +  0.9098179052597072\n",
      "Penalización por parar muy lejos: -  0.15596182935327924\n",
      "Penalización por duración del episodio: -  0.3386403825989912\n",
      "Recompensa por acortar distancias: +  0.9093274922083852\n",
      "Penalización por parar muy lejos: -  0.1551785527327789\n",
      "Penalización por duración del episodio: -  0.3390118417224103\n",
      "Recompensa por acortar distancias: +  0.9080883827458476\n",
      "Penalización por duración del episodio: -  0.33911550560684944\n",
      "Step: 3170, Mean Reward (últimos 10 pasos): 0.5689728856086731\n",
      "Recompensa por acortar distancias: +  0.9076818135216228\n",
      "Penalización por parar muy lejos: -  0.15260070504184758\n",
      "Penalización por duración del episodio: -  0.3393522774278736\n",
      "Recompensa por acortar distancias: +  0.9069892213423589\n",
      "Penalización por parar muy lejos: -  0.15153852206131962\n",
      "Penalización por duración del episodio: -  0.3397086500526258\n",
      "Recompensa por acortar distancias: +  0.9059587506689839\n",
      "Penalización por duración del episodio: -  0.3397820964534614\n",
      "Recompensa por acortar distancias: +  0.9059587506689839\n",
      "Penalización por duración del episodio: -  0.34005574981771025\n",
      "steer input from model: 0.1 , throttle:  0.3\n",
      "reward: 0.5659030008512737\n",
      "Recompensa por acortar distancias: +  0.9059587506689839\n",
      "Penalización por duración del episodio: -  0.3404066401608681\n",
      "Recompensa por acortar distancias: +  0.9059587506689839\n",
      "Penalización por parar muy lejos: -  0.14998231949552734\n",
      "Penalización por duración del episodio: -  0.34053905894989167\n",
      "Recompensa por acortar distancias: +  0.903526608566766\n",
      "Penalización por duración del episodio: -  0.34074138644396595\n",
      "Recompensa por acortar distancias: +  0.9029367182183402\n",
      "Penalización por parar muy lejos: -  0.14557831191699616\n",
      "Penalización por duración del episodio: -  0.3411054896496134\n",
      "Recompensa por acortar distancias: +  0.9029367182183402\n",
      "Penalización por duración del episodio: -  0.34145117165969396\n",
      "Recompensa por acortar distancias: +  0.900741975459968\n",
      "Penalización por duración del episodio: -  0.34153986644918854\n",
      "Step: 3180, Mean Reward (últimos 10 pasos): 0.5592021346092224\n",
      "Recompensa por acortar distancias: +  0.9004051567444462\n",
      "Penalización por duración del episodio: -  0.3416828480064455\n",
      "Recompensa por acortar distancias: +  0.9004051567444462\n",
      "Penalización por parar muy lejos: -  0.14206232923033532\n",
      "Penalización por duración del episodio: -  0.34182071432491984\n",
      "Recompensa por acortar distancias: +  0.8993634322888086\n",
      "Penalización por duración del episodio: -  0.34195138617025594\n",
      "Recompensa por acortar distancias: +  0.8993634322888086\n",
      "Penalización por duración del episodio: -  0.3420636503967369\n",
      "Recompensa por acortar distancias: +  0.8993634322888086\n",
      "Penalización por parar muy lejos: -  0.14065885770538503\n",
      "Penalización por duración del episodio: -  0.34249793124065836\n",
      "Recompensa por acortar distancias: +  0.8985614401492434\n",
      "Penalización por duración del episodio: -  0.34286328979333425\n",
      "Recompensa por acortar distancias: +  0.8985614401492434\n",
      "Penalización por parar muy lejos: -  0.1395949551650782\n",
      "Penalización por duración del episodio: -  0.34295539995069496\n",
      "Recompensa por acortar distancias: +  0.8985614401492434\n",
      "Penalización por duración del episodio: -  0.34322668484043245\n",
      "Recompensa por acortar distancias: +  0.8985614401492434\n",
      "Penalización por duración del episodio: -  0.34335866198845844\n",
      "Recompensa por acortar distancias: +  0.8947672361565486\n",
      "Penalización por duración del episodio: -  0.3434711685846533\n",
      "Step: 3190, Mean Reward (últimos 10 pasos): 0.551296055316925\n",
      "Recompensa por acortar distancias: +  0.8947672361565486\n",
      "Penalización por duración del episodio: -  0.3436261197031333\n",
      "Recompensa por acortar distancias: +  0.8937330451341282\n",
      "Penalización por duración del episodio: -  0.34374545551072067\n",
      "Recompensa por acortar distancias: +  0.8937330451341282\n",
      "Penalización por duración del episodio: -  0.3438533533534484\n",
      "Recompensa por acortar distancias: +  0.8937330451341282\n",
      "Penalización por duración del episodio: -  0.344298728706145\n",
      "steer input from model: -0.05 , throttle:  0.7\n",
      "reward: 0.5494343164279832\n",
      "Recompensa por acortar distancias: +  0.8919521652114495\n",
      "Penalización por parar muy lejos: -  0.1313400997772206\n",
      "Penalización por duración del episodio: -  0.34441132793467766\n",
      "Recompensa por acortar distancias: +  0.8912928605589708\n",
      "Penalización por duración del episodio: -  0.3445300072058798\n",
      "Recompensa por acortar distancias: +  0.8912928605589708\n",
      "Penalización por duración del episodio: -  0.34462011174327456\n",
      "Recompensa por acortar distancias: +  0.8912928605589708\n",
      "Penalización por duración del episodio: -  0.3447307627310284\n",
      "Recompensa por acortar distancias: +  0.8912928605589708\n",
      "Penalización por parar muy lejos: -  0.13056363519342779\n",
      "Penalización por duración del episodio: -  0.3448396045347266\n",
      "Recompensa por acortar distancias: +  0.8912928605589708\n",
      "Penalización por duración del episodio: -  0.3449115337245795\n",
      "Step: 3200, Mean Reward (últimos 10 pasos): 0.5463813543319702\n",
      "Recompensa por acortar distancias: +  0.8912928605589708\n",
      "Penalización por duración del episodio: -  0.345032703035907\n",
      "Recompensa por acortar distancias: +  0.8912928605589708\n",
      "Penalización por parar muy lejos: -  0.13056363519342779\n",
      "Penalización por duración del episodio: -  0.34533322685069434\n",
      "Recompensa por acortar distancias: +  0.8912928605589708\n",
      "Penalización por parar muy lejos: -  0.13056363519342779\n",
      "Penalización por duración del episodio: -  0.34545103211299605\n",
      "Recompensa por acortar distancias: +  0.8879118921606785\n",
      "Penalización por duración del episodio: -  0.345695484355747\n",
      "Recompensa por acortar distancias: +  0.8870307296461561\n",
      "Penalización por parar muy lejos: -  0.12573179064542173\n",
      "Penalización por duración del episodio: -  0.3457975716346196\n",
      "Recompensa por acortar distancias: +  0.8870307296461561\n",
      "Penalización por duración del episodio: -  0.34604819844965456\n",
      "Recompensa por acortar distancias: +  0.8870307296461561\n",
      "Penalización por parar muy lejos: -  0.12573179064542173\n",
      "Penalización por duración del episodio: -  0.34614641180492073\n",
      "Recompensa por acortar distancias: +  0.8870307296461561\n",
      "Penalización por parar muy lejos: -  0.12573179064542173\n",
      "Penalización por duración del episodio: -  0.3462486751129509\n",
      "Recompensa por acortar distancias: +  0.8848509286929809\n",
      "Penalización por duración del episodio: -  0.34635041286915813\n",
      "Recompensa por acortar distancias: +  0.8848509286929809\n",
      "Penalización por duración del episodio: -  0.3464979710695092\n",
      "Step: 3210, Mean Reward (últimos 10 pasos): 0.5383529663085938\n",
      "Recompensa por acortar distancias: +  0.8848509286929809\n",
      "Penalización por parar muy lejos: -  0.12337958974545025\n",
      "Penalización por duración del episodio: -  0.34663347962840646\n",
      "Recompensa por acortar distancias: +  0.883803098146548\n",
      "Penalización por duración del episodio: -  0.3471090143690045\n",
      "Recompensa por acortar distancias: +  0.882342808454049\n",
      "Penalización por parar muy lejos: -  0.12076618021393502\n",
      "Penalización por duración del episodio: -  0.3472336213746396\n",
      "Recompensa por acortar distancias: +  0.882342808454049\n",
      "Penalización por parar muy lejos: -  0.12076618021393502\n",
      "Penalización por duración del episodio: -  0.3473814045274592\n",
      "steer input from model: -0.05 , throttle:  0.0\n",
      "reward: 0.41419522371265477\n",
      "Recompensa por acortar distancias: +  0.882342808454049\n",
      "Penalización por parar muy lejos: -  0.12076618021393502\n",
      "Penalización por duración del episodio: -  0.347517123509551\n",
      "Recompensa por acortar distancias: +  0.882342808454049\n",
      "Penalización por parar muy lejos: -  0.12076618021393502\n",
      "Penalización por duración del episodio: -  0.34764184767463396\n",
      "Recompensa por acortar distancias: +  0.882342808454049\n",
      "Penalización por duración del episodio: -  0.3477775222498151\n",
      "Recompensa por acortar distancias: +  0.882342808454049\n",
      "Penalización por duración del episodio: -  0.3478800705542454\n",
      "Recompensa por acortar distancias: +  0.882342808454049\n",
      "Penalización por duración del episodio: -  0.3479931923752643\n",
      "Recompensa por acortar distancias: +  0.882342808454049\n",
      "Penalización por parar muy lejos: -  0.12076618021393502\n",
      "Penalización por duración del episodio: -  0.34811794213764774\n",
      "Step: 3220, Mean Reward (últimos 10 pasos): 0.4134586751461029\n",
      "Recompensa por acortar distancias: +  0.882342808454049\n",
      "Penalización por duración del episodio: -  0.34828837535297186\n",
      "Recompensa por acortar distancias: +  0.8773450822772709\n",
      "Penalización por duración del episodio: -  0.3484242595004445\n",
      "Recompensa por acortar distancias: +  0.8773450822772709\n",
      "Penalización por parar muy lejos: -  0.11583525214569053\n",
      "Penalización por duración del episodio: -  0.3488451387113167\n",
      "Recompensa por acortar distancias: +  0.8759706793478442\n",
      "Penalización por parar muy lejos: -  0.11453977705787473\n",
      "Penalización por duración del episodio: -  0.34897051791701444\n",
      "Recompensa por acortar distancias: +  0.8759706793478442\n",
      "Penalización por parar muy lejos: -  0.11453977705787473\n",
      "Penalización por duración del episodio: -  0.3490838803562512\n",
      "Recompensa por acortar distancias: +  0.8759706793478442\n",
      "Penalización por duración del episodio: -  0.3492087358427432\n",
      "Recompensa por acortar distancias: +  0.8759706793478442\n",
      "Penalización por duración del episodio: -  0.34934480826424985\n",
      "Recompensa por acortar distancias: +  0.8729916647926086\n",
      "Penalización por duración del episodio: -  0.3494702002110682\n",
      "Recompensa por acortar distancias: +  0.8729916647926086\n",
      "Penalización por duración del episodio: -  0.3496289265385515\n",
      "Recompensa por acortar distancias: +  0.8729916647926086\n",
      "Penalización por parar muy lejos: -  0.11181575744887245\n",
      "Penalización por duración del episodio: -  0.3497766243691357\n",
      "Step: 3230, Mean Reward (últimos 10 pasos): 0.4113992750644684\n",
      "Recompensa por acortar distancias: +  0.8729916647926086\n",
      "Penalización por parar muy lejos: -  0.11181575744887245\n",
      "Penalización por duración del episodio: -  0.34992492591249963\n",
      "Recompensa por acortar distancias: +  0.8729916647926086\n",
      "Penalización por duración del episodio: -  0.35009519366436104\n",
      "Recompensa por acortar distancias: +  0.8729916647926086\n",
      "Penalización por duración del episodio: -  0.35020877917525545\n",
      "Recompensa por acortar distancias: +  0.8729916647926086\n",
      "Penalización por parar muy lejos: -  0.11181575744887245\n",
      "Penalización por duración del episodio: -  0.3503802719233834\n",
      "steer input from model: -0.25 , throttle:  0.0\n",
      "reward: 0.4107956354203527\n",
      "Recompensa por acortar distancias: +  0.8729916647926086\n",
      "Penalización por parar muy lejos: -  0.11181575744887245\n",
      "Penalización por duración del episodio: -  0.3507096811238643\n",
      "Recompensa por acortar distancias: +  0.8729916647926086\n",
      "Penalización por duración del episodio: -  0.3508353965547959\n",
      "Recompensa por acortar distancias: +  0.8729916647926086\n",
      "Penalización por duración del episodio: -  0.35096054615695477\n",
      "Recompensa por acortar distancias: +  0.8729916647926086\n",
      "Penalización por parar muy lejos: -  0.11181575744887245\n",
      "Penalización por duración del episodio: -  0.3511089645450653\n",
      "Recompensa por acortar distancias: +  0.8729916647926086\n",
      "Penalización por parar muy lejos: -  0.11181575744887245\n",
      "Penalización por duración del episodio: -  0.351268614613969\n",
      "Recompensa por acortar distancias: +  0.8729916647926086\n",
      "Penalización por parar muy lejos: -  0.11181575744887245\n",
      "Penalización por duración del episodio: -  0.35138983572831745\n",
      "Step: 3240, Mean Reward (últimos 10 pasos): 0.40978607535362244\n",
      "Recompensa por acortar distancias: +  0.8645348987331156\n",
      "Penalización por parar muy lejos: -  0.10465664110255839\n",
      "Penalización por duración del episodio: -  0.3515090760135642\n",
      "Recompensa por acortar distancias: +  0.8645348987331156\n",
      "Penalización por duración del episodio: -  0.3516535727598756\n",
      "Recompensa por acortar distancias: +  0.863049031998642\n",
      "Penalización por parar muy lejos: -  0.10347914517673808\n",
      "Penalización por duración del episodio: -  0.35213228269964236\n",
      "Recompensa por acortar distancias: +  0.863049031998642\n",
      "Penalización por duración del episodio: -  0.3522576928514298\n",
      "Recompensa por acortar distancias: +  0.863049031998642\n",
      "Penalización por parar muy lejos: -  0.10347914517673808\n",
      "Penalización por duración del episodio: -  0.3524067972346797\n",
      "Recompensa por acortar distancias: +  0.863049031998642\n",
      "Penalización por parar muy lejos: -  0.10347914517673808\n",
      "Penalización por duración del episodio: -  0.35252059531691626\n",
      "Recompensa por acortar distancias: +  0.8594535491004981\n",
      "Penalización por duración del episodio: -  0.352650727522832\n",
      "Recompensa por acortar distancias: +  0.8594535491004981\n",
      "Penalización por duración del episodio: -  0.3527923516143474\n",
      "Recompensa por acortar distancias: +  0.8579872956333167\n",
      "Penalización por duración del episodio: -  0.3529355533435861\n",
      "Recompensa por acortar distancias: +  0.8579872956333167\n",
      "Penalización por duración del episodio: -  0.353084744682496\n",
      "Step: 3250, Mean Reward (últimos 10 pasos): 0.5049025416374207\n",
      "Recompensa por acortar distancias: +  0.8579872956333167\n",
      "Penalización por parar muy lejos: -  0.09963136685745175\n",
      "Penalización por duración del episodio: -  0.353210881020618\n",
      "Recompensa por acortar distancias: +  0.8579872956333167\n",
      "Penalización por duración del episodio: -  0.35331416356428863\n",
      "Recompensa por acortar distancias: +  0.8579872956333167\n",
      "Penalización por parar muy lejos: -  0.09963136685745175\n",
      "Penalización por duración del episodio: -  0.3534281601208153\n",
      "Recompensa por acortar distancias: +  0.8579872956333167\n",
      "Penalización por duración del episodio: -  0.35355906016715016\n",
      "steer input from model: -0.05 , throttle:  0.3\n",
      "reward: 0.5044282354661664\n",
      "Recompensa por acortar distancias: +  0.8579872956333167\n",
      "Penalización por duración del episodio: -  0.35369973244797065\n",
      "Recompensa por acortar distancias: +  0.8539897136294655\n",
      "Penalización por duración del episodio: -  0.35391752388205194\n",
      "Recompensa por acortar distancias: +  0.8527202445298687\n",
      "Penalización por duración del episodio: -  0.3540894941125041\n",
      "Recompensa por acortar distancias: +  0.8527202445298687\n",
      "Penalización por duración del episodio: -  0.354215094773419\n",
      "Recompensa por acortar distancias: +  0.8527202445298687\n",
      "Penalización por parar muy lejos: -  0.09587673506151503\n",
      "Penalización por duración del episodio: -  0.35431282111101314\n",
      "Recompensa por acortar distancias: +  0.8527202445298687\n",
      "Penalización por duración del episodio: -  0.3544163147713623\n",
      "Step: 3260, Mean Reward (últimos 10 pasos): 0.49830392003059387\n",
      "Recompensa por acortar distancias: +  0.8527202445298687\n",
      "Penalización por parar muy lejos: -  0.09587673506151503\n",
      "Penalización por duración del episodio: -  0.3546449404272413\n",
      "Recompensa por acortar distancias: +  0.8527202445298687\n",
      "Penalización por duración del episodio: -  0.35499529134688274\n",
      "Recompensa por acortar distancias: +  0.8477870069669662\n",
      "Penalización por parar muy lejos: -  0.09256999465539584\n",
      "Penalización por duración del episodio: -  0.3551216700203139\n",
      "Recompensa por acortar distancias: +  0.8477870069669662\n",
      "Penalización por duración del episodio: -  0.35521884269141313\n",
      "Recompensa por acortar distancias: +  0.8464885539430885\n",
      "Penalización por duración del episodio: -  0.35570914151125066\n",
      "Recompensa por acortar distancias: +  0.8464885539430885\n",
      "Penalización por duración del episodio: -  0.3558368746617976\n",
      "Recompensa por acortar distancias: +  0.8435713484710793\n",
      "Penalización por duración del episodio: -  0.3559769593621798\n",
      "Recompensa por acortar distancias: +  0.8435713484710793\n",
      "Penalización por parar muy lejos: -  0.0898919021048101\n",
      "Penalización por duración del episodio: -  0.35640656539672694\n",
      "Recompensa por acortar distancias: +  0.841985946420044\n",
      "Penalización por duración del episodio: -  0.3567580830219955\n",
      "Recompensa por acortar distancias: +  0.841985946420044\n",
      "Penalización por parar muy lejos: -  0.08891781003459628\n",
      "Penalización por duración del episodio: -  0.3571029293344144\n",
      "Step: 3270, Mean Reward (últimos 10 pasos): 0.39596521854400635\n",
      "Recompensa por acortar distancias: +  0.837547999304286\n",
      "Penalización por parar muy lejos: -  0.08628176232064182\n",
      "Penalización por duración del episodio: -  0.35718663635157016\n",
      "Recompensa por acortar distancias: +  0.8366471651910506\n",
      "Penalización por parar muy lejos: -  0.08576238074733258\n",
      "Penalización por duración del episodio: -  0.35746913246525347\n",
      "Recompensa por acortar distancias: +  0.8366471651910506\n",
      "Penalización por duración del episodio: -  0.3578264898576827\n",
      "Recompensa por acortar distancias: +  0.8336128875713699\n",
      "Penalización por parar muy lejos: -  0.08405015190458436\n",
      "Penalización por duración del episodio: -  0.3579156470833327\n",
      "steer input from model: 0.05 , throttle:  0.0\n",
      "reward: 0.3916470885834529\n",
      "Recompensa por acortar distancias: +  0.8336128875713699\n",
      "Penalización por parar muy lejos: -  0.08405015190458436\n",
      "Penalización por duración del episodio: -  0.3580546759188725\n",
      "Recompensa por acortar distancias: +  0.8336128875713699\n",
      "Penalización por parar muy lejos: -  0.08405015190458436\n",
      "Penalización por duración del episodio: -  0.3581878584720146\n",
      "Recompensa por acortar distancias: +  0.8320435019733208\n",
      "Penalización por duración del episodio: -  0.3583486866199061\n",
      "Recompensa por acortar distancias: +  0.8320435019733208\n",
      "Penalización por parar muy lejos: -  0.08318640206330433\n",
      "Penalización por duración del episodio: -  0.35845349421907663\n",
      "Recompensa por acortar distancias: +  0.8320435019733208\n",
      "Penalización por duración del episodio: -  0.35891498485656387\n",
      "Recompensa por acortar distancias: +  0.8320435019733208\n",
      "Penalización por parar muy lejos: -  0.08318640206330433\n",
      "Penalización por duración del episodio: -  0.35928344570101955\n",
      "Step: 3280, Mean Reward (últimos 10 pasos): 0.3895736634731293\n",
      "Recompensa por acortar distancias: +  0.8262163876503169\n",
      "Penalización por duración del episodio: -  0.35937529321148437\n",
      "Recompensa por acortar distancias: +  0.8251445746119246\n",
      "Penalización por duración del episodio: -  0.3596335961363443\n",
      "Recompensa por acortar distancias: +  0.8251445746119246\n",
      "Penalización por duración del episodio: -  0.36000862071062456\n",
      "Recompensa por acortar distancias: +  0.8219137592536606\n",
      "Penalización por duración del episodio: -  0.36038438782671844\n",
      "Recompensa por acortar distancias: +  0.8197650276114407\n",
      "Penalización por parar muy lejos: -  0.07689915102364044\n",
      "Penalización por duración del episodio: -  0.36075102862013836\n",
      "Recompensa por acortar distancias: +  0.8197650276114407\n",
      "Penalización por parar muy lejos: -  0.07689915102364044\n",
      "Penalización por duración del episodio: -  0.3611200650708441\n",
      "Recompensa por acortar distancias: +  0.8197650276114407\n",
      "Penalización por parar muy lejos: -  0.07689915102364044\n",
      "Penalización por duración del episodio: -  0.36148509975336013\n",
      "Recompensa por acortar distancias: +  0.8197650276114407\n",
      "Penalización por parar muy lejos: -  0.07689915102364044\n",
      "Penalización por duración del episodio: -  0.3616437285530103\n",
      "Recompensa por acortar distancias: +  0.8133617979597697\n",
      "Penalización por parar muy lejos: -  0.07391871501245172\n",
      "Penalización por duración del episodio: -  0.36179414089228756\n",
      "Recompensa por acortar distancias: +  0.8133617979597697\n",
      "Penalización por parar muy lejos: -  0.07391871501245172\n",
      "Penalización por duración del episodio: -  0.3619055818387359\n",
      "Step: 3290, Mean Reward (últimos 10 pasos): 0.37753748893737793\n",
      "Recompensa por acortar distancias: +  0.8115408925137064\n",
      "Penalización por parar muy lejos: -  0.07310481411129421\n",
      "Penalización por duración del episodio: -  0.3620299835976337\n",
      "Recompensa por acortar distancias: +  0.8115408925137064\n",
      "Penalización por parar muy lejos: -  0.07310481411129421\n",
      "Penalización por duración del episodio: -  0.36212437784784757\n",
      "Recompensa por acortar distancias: +  0.8115408925137064\n",
      "Penalización por duración del episodio: -  0.3625855099880107\n",
      "Recompensa por acortar distancias: +  0.8115408925137064\n",
      "Penalización por parar muy lejos: -  0.07310481411129421\n",
      "Penalización por duración del episodio: -  0.3629506827974328\n",
      "steer input from model: 0.1 , throttle:  0.0\n",
      "reward: 0.3754853956049794\n",
      "Recompensa por acortar distancias: +  0.8064299965657699\n",
      "Penalización por parar muy lejos: -  0.07089498161229169\n",
      "Penalización por duración del episodio: -  0.36304510882558805\n",
      "Recompensa por acortar distancias: +  0.8064299965657699\n",
      "Penalización por duración del episodio: -  0.36331996253445953\n",
      "Recompensa por acortar distancias: +  0.8064299965657699\n",
      "Penalización por parar muy lejos: -  0.07089498161229169\n",
      "Penalización por duración del episodio: -  0.36369779008803266\n",
      "Recompensa por acortar distancias: +  0.8064299965657699\n",
      "Penalización por parar muy lejos: -  0.07089498161229169\n",
      "Penalización por duración del episodio: -  0.3638013768738676\n",
      "Recompensa por acortar distancias: +  0.8011028212568405\n",
      "Penalización por parar muy lejos: -  0.06870214745222288\n",
      "Penalización por duración del episodio: -  0.36390922582958896\n",
      "Recompensa por acortar distancias: +  0.8011028212568405\n",
      "Penalización por duración del episodio: -  0.36407738666868456\n",
      "Step: 3300, Mean Reward (últimos 10 pasos): 0.43702542781829834\n",
      "Recompensa por acortar distancias: +  0.8000896461808203\n",
      "Penalización por parar muy lejos: -  0.06829719068034361\n",
      "Penalización por duración del episodio: -  0.3644303856401014\n",
      "Recompensa por acortar distancias: +  0.8000896461808203\n",
      "Penalización por parar muy lejos: -  0.06829719068034361\n",
      "Penalización por duración del episodio: -  0.3648013584551542\n",
      "Recompensa por acortar distancias: +  0.7956685272716074\n",
      "Penalización por duración del episodio: -  0.36517419426551373\n",
      "Recompensa por acortar distancias: +  0.7956685272716074\n",
      "Penalización por parar muy lejos: -  0.06657317425973493\n",
      "Penalización por duración del episodio: -  0.3655307639612978\n",
      "Recompensa por acortar distancias: +  0.7956685272716074\n",
      "Penalización por parar muy lejos: -  0.06657317425973493\n",
      "Penalización por duración del episodio: -  0.3656507261639284\n",
      "Recompensa por acortar distancias: +  0.7956685272716074\n",
      "Penalización por duración del episodio: -  0.36589788623431085\n",
      "Recompensa por acortar distancias: +  0.7905290158187342\n",
      "Penalización por duración del episodio: -  0.36600325507933384\n",
      "Recompensa por acortar distancias: +  0.7894902393609989\n",
      "Penalización por duración del episodio: -  0.36612831251169453\n",
      "Recompensa por acortar distancias: +  0.7894902393609989\n",
      "Penalización por parar muy lejos: -  0.064275380495189\n",
      "Penalización por duración del episodio: -  0.36663554338421034\n",
      "Recompensa por acortar distancias: +  0.7894902393609989\n",
      "Penalización por duración del episodio: -  0.3667631282551844\n",
      "Step: 3310, Mean Reward (últimos 10 pasos): 0.422727108001709\n",
      "Recompensa por acortar distancias: +  0.7859401571455802\n",
      "Penalización por duración del episodio: -  0.3670081847652131\n",
      "Recompensa por acortar distancias: +  0.7846791402145269\n",
      "Penalización por parar muy lejos: -  0.06257010365999191\n",
      "Penalización por duración del episodio: -  0.36712421878642265\n",
      "Recompensa por acortar distancias: +  0.7835995333896617\n",
      "Penalización por duración del episodio: -  0.367361375331693\n",
      "Recompensa por acortar distancias: +  0.7835995333896617\n",
      "Penalización por duración del episodio: -  0.3677373250781092\n",
      "steer input from model: 0.05 , throttle:  0.7\n",
      "reward: 0.4158622083115525\n",
      "Recompensa por acortar distancias: +  0.7835995333896617\n",
      "Penalización por duración del episodio: -  0.36809836800065304\n",
      "Recompensa por acortar distancias: +  0.7835995333896617\n",
      "Penalización por parar muy lejos: -  0.062197030677673376\n",
      "Penalización por duración del episodio: -  0.3684643078633118\n",
      "Recompensa por acortar distancias: +  0.7772945536278666\n",
      "Penalización por duración del episodio: -  0.36881639044837716\n",
      "Recompensa por acortar distancias: +  0.7772945536278666\n",
      "Penalización por duración del episodio: -  0.3689192798506185\n",
      "Recompensa por acortar distancias: +  0.7772945536278666\n",
      "Penalización por duración del episodio: -  0.3691879296947448\n",
      "Recompensa por acortar distancias: +  0.7728933578758337\n",
      "Penalización por parar muy lejos: -  0.05867478456843735\n",
      "Penalización por duración del episodio: -  0.36930296800731993\n",
      "Step: 3320, Mean Reward (últimos 10 pasos): 0.34491559863090515\n",
      "Recompensa por acortar distancias: +  0.7728933578758337\n",
      "Penalización por duración del episodio: -  0.36944747410487666\n",
      "Recompensa por acortar distancias: +  0.7718658083125731\n",
      "Penalización por duración del episodio: -  0.3695511308273117\n",
      "Recompensa por acortar distancias: +  0.7708772700552379\n",
      "Penalización por duración del episodio: -  0.3699131960726778\n",
      "Recompensa por acortar distancias: +  0.7708772700552379\n",
      "Penalización por duración del episodio: -  0.37001358887954966\n",
      "Recompensa por acortar distancias: +  0.7708772700552379\n",
      "Penalización por duración del episodio: -  0.3702925581350497\n",
      "Recompensa por acortar distancias: +  0.7708772700552379\n",
      "Penalización por duración del episodio: -  0.3704241964662924\n",
      "Recompensa por acortar distancias: +  0.7708772700552379\n",
      "Penalización por duración del episodio: -  0.3706634653547105\n",
      "Recompensa por acortar distancias: +  0.7708772700552379\n",
      "Penalización por parar muy lejos: -  0.058045563732557266\n",
      "Penalización por duración del episodio: -  0.3707706222622164\n",
      "Recompensa por acortar distancias: +  0.7646176036966816\n",
      "Penalización por parar muy lejos: -  0.056155565411554746\n",
      "Penalización por duración del episodio: -  0.37105124493703756\n",
      "Recompensa por acortar distancias: +  0.7632934348117623\n",
      "Penalización por duración del episodio: -  0.3711938955788004\n",
      "Step: 3330, Mean Reward (últimos 10 pasos): 0.392099529504776\n",
      "Recompensa por acortar distancias: +  0.7632934348117623\n",
      "Penalización por parar muy lejos: -  0.05576762906429138\n",
      "Penalización por duración del episodio: -  0.3714152443904006\n",
      "Recompensa por acortar distancias: +  0.7632934348117623\n",
      "Penalización por duración del episodio: -  0.37177545293483766\n",
      "Recompensa por acortar distancias: +  0.7584157252443916\n",
      "Penalización por parar muy lejos: -  0.05437268131575682\n",
      "Penalización por duración del episodio: -  0.3721491737032362\n",
      "Recompensa por acortar distancias: +  0.7584157252443916\n",
      "Penalización por duración del episodio: -  0.3722837562035569\n",
      "steer input from model: -0.05 , throttle:  1.0\n",
      "reward: 0.3861319690408347\n",
      "Recompensa por acortar distancias: +  0.7584157252443916\n",
      "Penalización por duración del episodio: -  0.37251297140578815\n",
      "Recompensa por acortar distancias: +  0.7584157252443916\n",
      "Penalización por parar muy lejos: -  0.05437268131575682\n",
      "Penalización por duración del episodio: -  0.37287132722647554\n",
      "Recompensa por acortar distancias: +  0.7523933242877715\n",
      "Penalización por parar muy lejos: -  0.05272087659081356\n",
      "Penalización por duración del episodio: -  0.37300030039360943\n",
      "Recompensa por acortar distancias: +  0.7509026577775239\n",
      "Penalización por duración del episodio: -  0.37311705084997643\n",
      "Recompensa por acortar distancias: +  0.7509026577775239\n",
      "Penalización por parar muy lejos: -  0.0523234936639742\n",
      "Penalización por duración del episodio: -  0.37325839573395464\n",
      "Recompensa por acortar distancias: +  0.7509026577775239\n",
      "Penalización por parar muy lejos: -  0.0523234936639742\n",
      "Penalización por duración del episodio: -  0.3735973903709811\n",
      "Step: 3340, Mean Reward (últimos 10 pasos): 0.32498177886009216\n",
      "Recompensa por acortar distancias: +  0.7509026577775239\n",
      "Penalización por duración del episodio: -  0.3736870577328482\n",
      "Recompensa por acortar distancias: +  0.7466379060255104\n",
      "Penalización por duración del episodio: -  0.3739739455359897\n",
      "Recompensa por acortar distancias: +  0.7452306645602456\n",
      "Penalización por duración del episodio: -  0.3740896019357731\n",
      "Recompensa por acortar distancias: +  0.744036579596133\n",
      "Penalización por duración del episodio: -  0.3742078354081774\n",
      "Recompensa por acortar distancias: +  0.744036579596133\n",
      "Penalización por duración del episodio: -  0.3743598559869329\n",
      "Recompensa por acortar distancias: +  0.7424719214266968\n",
      "Penalización por parar muy lejos: -  0.05015675790640652\n",
      "Penalización por duración del episodio: -  0.37469925849809277\n",
      "Recompensa por acortar distancias: +  0.7424719214266968\n",
      "Penalización por duración del episodio: -  0.374804552005558\n",
      "Recompensa por acortar distancias: +  0.7424719214266968\n",
      "Penalización por duración del episodio: -  0.3749134780020328\n",
      "Recompensa por acortar distancias: +  0.7424719214266968\n",
      "Penalización por parar muy lejos: -  0.05015675790640652\n",
      "Penalización por duración del episodio: -  0.37505937688279234\n",
      "Recompensa por acortar distancias: +  0.7424719214266968\n",
      "Penalización por parar muy lejos: -  0.05015675790640652\n",
      "Penalización por duración del episodio: -  0.3754245363991011\n",
      "Step: 3350, Mean Reward (últimos 10 pasos): 0.3168906271457672\n",
      "Recompensa por acortar distancias: +  0.7424719214266968\n",
      "Penalización por parar muy lejos: -  0.05015675790640652\n",
      "Penalización por duración del episodio: -  0.3755584095190746\n",
      "Recompensa por acortar distancias: +  0.7424719214266968\n",
      "Penalización por parar muy lejos: -  0.05015675790640652\n",
      "Penalización por duración del episodio: -  0.37578755586458135\n",
      "Recompensa por acortar distancias: +  0.7326172787155142\n",
      "Penalización por parar muy lejos: -  0.04778597635324088\n",
      "Penalización por duración del episodio: -  0.3758894867702453\n",
      "Recompensa por acortar distancias: +  0.7310582223727288\n",
      "Penalización por duración del episodio: -  0.3761564663833803\n",
      "steer input from model: 0.05 , throttle:  0.0\n",
      "reward: 0.3549017559893485\n",
      "Recompensa por acortar distancias: +  0.7310582223727288\n",
      "Penalización por duración del episodio: -  0.37626964468731416\n",
      "Recompensa por acortar distancias: +  0.7310582223727288\n",
      "Penalización por duración del episodio: -  0.37639078304015156\n",
      "Recompensa por acortar distancias: +  0.7310582223727288\n",
      "Penalización por duración del episodio: -  0.37688460056373446\n",
      "Recompensa por acortar distancias: +  0.7248635527512631\n",
      "Penalización por duración del episodio: -  0.3772418105389572\n",
      "Recompensa por acortar distancias: +  0.7248635527512631\n",
      "Penalización por duración del episodio: -  0.3773427322806529\n",
      "Recompensa por acortar distancias: +  0.7248635527512631\n",
      "Penalización por duración del episodio: -  0.3776169500520311\n",
      "Step: 3360, Mean Reward (últimos 10 pasos): 0.34724661707878113\n",
      "Recompensa por acortar distancias: +  0.7248635527512631\n",
      "Penalización por duración del episodio: -  0.3777826896312964\n",
      "Recompensa por acortar distancias: +  0.7248635527512631\n",
      "Penalización por duración del episodio: -  0.37792314456749615\n",
      "Recompensa por acortar distancias: +  0.7177209780256308\n",
      "Penalización por duración del episodio: -  0.37804037791334666\n",
      "Recompensa por acortar distancias: +  0.7177209780256308\n",
      "Penalización por duración del episodio: -  0.3781671454341987\n",
      "Recompensa por acortar distancias: +  0.7156568635371072\n",
      "Penalización por duración del episodio: -  0.37836724236181957\n",
      "Recompensa por acortar distancias: +  0.7156568635371072\n",
      "Penalización por duración del episodio: -  0.37874329162799564\n",
      "Recompensa por acortar distancias: +  0.7116479158538036\n",
      "Penalización por duración del episodio: -  0.3791220682633817\n",
      "Recompensa por acortar distancias: +  0.7100242259926629\n",
      "Penalización por duración del episodio: -  0.3792548259181508\n",
      "Recompensa por acortar distancias: +  0.7100242259926629\n",
      "Penalización por duración del episodio: -  0.3794920881006031\n",
      "Recompensa por acortar distancias: +  0.7100242259926629\n",
      "Penalización por duración del episodio: -  0.3798574405391414\n",
      "Step: 3370, Mean Reward (últimos 10 pasos): 0.3301667869091034\n",
      "Recompensa por acortar distancias: +  0.7100242259926629\n",
      "Penalización por duración del episodio: -  0.37992789987400327\n",
      "Recompensa por acortar distancias: +  0.7100242259926629\n",
      "Penalización por duración del episodio: -  0.38008609656235304\n",
      "Recompensa por acortar distancias: +  0.7028803880856124\n",
      "Penalización por duración del episodio: -  0.3801668477539444\n",
      "Recompensa por acortar distancias: +  0.7028803880856124\n",
      "Penalización por duración del episodio: -  0.38033131440124024\n",
      "steer input from model: -0.05 , throttle:  0.0\n",
      "reward: 0.32254907368437213\n",
      "Recompensa por acortar distancias: +  0.7009200402471312\n",
      "Penalización por duración del episodio: -  0.3804385482809125\n",
      "Recompensa por acortar distancias: +  0.7009200402471312\n",
      "Penalización por duración del episodio: -  0.3805941741917075\n",
      "Recompensa por acortar distancias: +  0.7009200402471312\n",
      "Penalización por duración del episodio: -  0.3809636977746548\n",
      "Recompensa por acortar distancias: +  0.6964172802464842\n",
      "Penalización por duración del episodio: -  0.38109121044710526\n",
      "Recompensa por acortar distancias: +  0.6964172802464842\n",
      "Penalización por duración del episodio: -  0.38122188900583803\n",
      "Recompensa por acortar distancias: +  0.694242743203032\n",
      "Penalización por duración del episodio: -  0.38171377049113986\n",
      "Step: 3380, Mean Reward (últimos 10 pasos): 0.31252896785736084\n",
      "Recompensa por acortar distancias: +  0.6928031020319957\n",
      "Penalización por duración del episodio: -  0.38182868358187133\n",
      "Recompensa por acortar distancias: +  0.6928031020319957\n",
      "Penalización por duración del episodio: -  0.3819652110579535\n",
      "Recompensa por acortar distancias: +  0.6928031020319957\n",
      "Penalización por duración del episodio: -  0.382053337149587\n",
      "Recompensa por acortar distancias: +  0.6928031020319957\n",
      "Penalización por duración del episodio: -  0.38220791003775023\n",
      "Recompensa por acortar distancias: +  0.6928031020319957\n",
      "Penalización por duración del episodio: -  0.38232740667594595\n",
      "Recompensa por acortar distancias: +  0.6928031020319957\n",
      "Penalización por duración del episodio: -  0.3824786825215408\n",
      "Recompensa por acortar distancias: +  0.6928031020319957\n",
      "Penalización por duración del episodio: -  0.3826289054275684\n",
      "Recompensa por acortar distancias: +  0.6928031020319957\n",
      "Penalización por duración del episodio: -  0.3828195279115903\n",
      "Recompensa por acortar distancias: +  0.6839728201613083\n",
      "Penalización por duración del episodio: -  0.3829489676265962\n",
      "Recompensa por acortar distancias: +  0.6823031946501816\n",
      "Penalización por duración del episodio: -  0.3830569566087782\n",
      "Step: 3390, Mean Reward (últimos 10 pasos): 0.29924625158309937\n",
      "Recompensa por acortar distancias: +  0.6823031946501816\n",
      "Penalización por duración del episodio: -  0.3831837219006077\n",
      "Recompensa por acortar distancias: +  0.6823031946501816\n",
      "Penalización por duración del episodio: -  0.3832903495753039\n",
      "Recompensa por acortar distancias: +  0.6823031946501816\n",
      "Penalización por duración del episodio: -  0.38355537536013357\n",
      "Recompensa por acortar distancias: +  0.6774652336275717\n",
      "Penalización por duración del episodio: -  0.38391881887201995\n",
      "steer input from model: -0.9 , throttle:  0.7\n",
      "reward: 0.29354641475555177\n",
      "Recompensa por acortar distancias: +  0.6758366973000308\n",
      "Penalización por duración del episodio: -  0.38403233663533237\n",
      "Recompensa por acortar distancias: +  0.6758366973000308\n",
      "Penalización por duración del episodio: -  0.3841503060824156\n",
      "Recompensa por acortar distancias: +  0.6758366973000308\n",
      "Penalización por duración del episodio: -  0.3842330101382097\n",
      "Recompensa por acortar distancias: +  0.6758366973000308\n",
      "Penalización por duración del episodio: -  0.38464809233765623\n",
      "Recompensa por acortar distancias: +  0.6758366973000308\n",
      "Penalización por duración del episodio: -  0.3850211940738549\n",
      "Recompensa por acortar distancias: +  0.666597734066569\n",
      "Penalización por duración del episodio: -  0.38516463913451626\n",
      "Step: 3400, Mean Reward (últimos 10 pasos): 0.28143310546875\n",
      "Recompensa por acortar distancias: +  0.666597734066569\n",
      "Penalización por duración del episodio: -  0.38529461958042915\n",
      "Recompensa por acortar distancias: +  0.666597734066569\n",
      "Penalización por duración del episodio: -  0.3857749380415212\n",
      "Recompensa por acortar distancias: +  0.6616204872266105\n",
      "Penalización por duración del episodio: -  0.3861387717111348\n",
      "Recompensa por acortar distancias: +  0.6583999554662365\n",
      "Penalización por duración del episodio: -  0.38627445297960766\n",
      "Recompensa por acortar distancias: +  0.6583999554662365\n",
      "Penalización por duración del episodio: -  0.38651053989428175\n",
      "Recompensa por acortar distancias: +  0.6583999554662365\n",
      "Penalización por duración del episodio: -  0.3868820897906654\n",
      "Recompensa por acortar distancias: +  0.6583999554662365\n",
      "Penalización por duración del episodio: -  0.38698152195284286\n",
      "Recompensa por acortar distancias: +  0.6583999554662365\n",
      "Penalización por duración del episodio: -  0.38712607480425487\n",
      "Recompensa por acortar distancias: +  0.6502903124923124\n",
      "Penalización por duración del episodio: -  0.3876404120385603\n",
      "Recompensa por acortar distancias: +  0.6482807819000618\n",
      "Penalización por duración del episodio: -  0.38800262346224046\n",
      "Step: 3410, Mean Reward (últimos 10 pasos): 0.2602781653404236\n",
      "Recompensa por acortar distancias: +  0.6482807819000618\n",
      "Penalización por duración del episodio: -  0.3883756567870447\n",
      "Recompensa por acortar distancias: +  0.6403980407525265\n",
      "Penalización por duración del episodio: -  0.3887586787427231\n",
      "Recompensa por acortar distancias: +  0.6403980407525265\n",
      "Penalización por duración del episodio: -  0.38913036722858185\n",
      "Recompensa por acortar distancias: +  0.6403980407525265\n",
      "Penalización por duración del episodio: -  0.3895055182201187\n",
      "steer input from model: 0.1 , throttle:  0.3\n",
      "reward: 0.2508925225324078\n",
      "Recompensa por acortar distancias: +  0.6323774211239567\n",
      "Penalización por duración del episodio: -  0.3896240771227738\n",
      "Recompensa por acortar distancias: +  0.6302386138226704\n",
      "Penalización por duración del episodio: -  0.3897310923994206\n",
      "Recompensa por acortar distancias: +  0.6302386138226704\n",
      "Penalización por duración del episodio: -  0.3898847643337756\n",
      "Recompensa por acortar distancias: +  0.6302386138226704\n",
      "Penalización por duración del episodio: -  0.3899851239441251\n",
      "Recompensa por acortar distancias: +  0.6302386138226704\n",
      "Penalización por duración del episodio: -  0.3902473165929386\n",
      "Recompensa por acortar distancias: +  0.6302386138226704\n",
      "Penalización por duración del episodio: -  0.39035101764902014\n",
      "Step: 3420, Mean Reward (últimos 10 pasos): 0.23988759517669678\n",
      "Recompensa por acortar distancias: +  0.6244529630277973\n",
      "Penalización por duración del episodio: -  0.39061906477824937\n",
      "Recompensa por acortar distancias: +  0.6213349747223528\n",
      "Penalización por duración del episodio: -  0.3907300436088151\n",
      "Recompensa por acortar distancias: +  0.6213349747223528\n",
      "Penalización por duración del episodio: -  0.39086561839345213\n",
      "Recompensa por acortar distancias: +  0.6213349747223528\n",
      "Penalización por duración del episodio: -  0.3909970202607946\n",
      "Recompensa por acortar distancias: +  0.6213349747223528\n",
      "Penalización por duración del episodio: -  0.39111048467149356\n",
      "Recompensa por acortar distancias: +  0.6213349747223528\n",
      "Penalización por duración del episodio: -  0.39137464088342544\n",
      "Recompensa por acortar distancias: +  0.6213349747223528\n",
      "Penalización por duración del episodio: -  0.3914957382596537\n",
      "Recompensa por acortar distancias: +  0.6213349747223528\n",
      "Penalización por duración del episodio: -  0.39158155725974697\n",
      "Recompensa por acortar distancias: +  0.6213349747223528\n",
      "Penalización por duración del episodio: -  0.3917486477705301\n",
      "Recompensa por acortar distancias: +  0.6117612809529311\n",
      "Penalización por duración del episodio: -  0.3918875247770864\n",
      "Step: 3430, Mean Reward (últimos 10 pasos): 0.21987375617027283\n",
      "Recompensa por acortar distancias: +  0.6117612809529311\n",
      "Penalización por duración del episodio: -  0.39200367243571915\n",
      "Recompensa por acortar distancias: +  0.6091253843161801\n",
      "Penalización por duración del episodio: -  0.39248243240022884\n",
      "Recompensa por acortar distancias: +  0.6091253843161801\n",
      "Penalización por duración del episodio: -  0.39261796186428893\n",
      "Recompensa por acortar distancias: +  0.6036684822866641\n",
      "Penalización por duración del episodio: -  0.3927196297712189\n",
      "steer input from model: 0.0 , throttle:  0.0\n",
      "reward: 0.21094885251544526\n",
      "Recompensa por acortar distancias: +  0.6036684822866641\n",
      "Penalización por duración del episodio: -  0.3932463694005842\n",
      "Recompensa por acortar distancias: +  0.5997296987762747\n",
      "Penalización por duración del episodio: -  0.39363066524534235\n",
      "Recompensa por acortar distancias: +  0.5997296987762747\n",
      "Penalización por duración del episodio: -  0.3937739493278399\n",
      "Recompensa por acortar distancias: +  0.5997296987762747\n",
      "Penalización por duración del episodio: -  0.393903892266467\n",
      "Recompensa por acortar distancias: +  0.5997296987762747\n",
      "Penalización por duración del episodio: -  0.39403591668371934\n",
      "Recompensa por acortar distancias: +  0.5997296987762747\n",
      "Penalización por duración del episodio: -  0.3941788026015881\n",
      "Step: 3440, Mean Reward (últimos 10 pasos): 0.2055508941411972\n",
      "Recompensa por acortar distancias: +  0.5889698682754253\n",
      "Penalización por duración del episodio: -  0.3943218831363755\n",
      "Recompensa por acortar distancias: +  0.5889698682754253\n",
      "Penalización por duración del episodio: -  0.39444334698678524\n",
      "Recompensa por acortar distancias: +  0.5889698682754253\n",
      "Penalización por duración del episodio: -  0.3947583823223535\n",
      "Recompensa por acortar distancias: +  0.585379502673114\n",
      "Penalización por duración del episodio: -  0.3951332043730886\n",
      "Recompensa por acortar distancias: +  0.585379502673114\n",
      "Penalización por duración del episodio: -  0.39551757783112895\n",
      "Recompensa por acortar distancias: +  0.576252754258056\n",
      "Penalización por duración del episodio: -  0.3958807148743948\n",
      "Recompensa por acortar distancias: +  0.576252754258056\n",
      "Penalización por duración del episodio: -  0.3959921658513468\n",
      "Recompensa por acortar distancias: +  0.576252754258056\n",
      "Penalización por duración del episodio: -  0.39625880815487846\n",
      "Recompensa por acortar distancias: +  0.576252754258056\n",
      "Penalización por duración del episodio: -  0.3963542550074883\n",
      "Recompensa por acortar distancias: +  0.576252754258056\n",
      "Penalización por duración del episodio: -  0.3964642799463382\n",
      "Step: 3450, Mean Reward (últimos 10 pasos): 0.1797884702682495\n",
      "Recompensa por acortar distancias: +  0.576252754258056\n",
      "Penalización por duración del episodio: -  0.3965866049261963\n",
      "Recompensa por acortar distancias: +  0.576252754258056\n",
      "Penalización por duración del episodio: -  0.39676393377925917\n",
      "Recompensa por acortar distancias: +  0.5656283777955848\n",
      "Penalización por duración del episodio: -  0.39692488157072675\n",
      "Recompensa por acortar distancias: +  0.5656283777955848\n",
      "Penalización por duración del episodio: -  0.3970720271068477\n",
      "steer input from model: 0.9 , throttle:  0.3\n",
      "reward: 0.16855635068873714\n",
      "Recompensa por acortar distancias: +  0.5622274546250584\n",
      "Penalización por duración del episodio: -  0.3973884807204459\n",
      "Recompensa por acortar distancias: +  0.5622274546250584\n",
      "Penalización por duración del episodio: -  0.3975440388104059\n",
      "Recompensa por acortar distancias: +  0.5622274546250584\n",
      "Penalización por duración del episodio: -  0.3976641417186318\n",
      "Recompensa por acortar distancias: +  0.5622274546250584\n",
      "Penalización por duración del episodio: -  0.397802013716986\n",
      "Recompensa por acortar distancias: +  0.5551458447198478\n",
      "Penalización por duración del episodio: -  0.39813855775622503\n",
      "Recompensa por acortar distancias: +  0.5522076625947604\n",
      "Penalización por duración del episodio: -  0.3985079896323194\n",
      "Step: 3460, Mean Reward (últimos 10 pasos): 0.15369966626167297\n",
      "Recompensa por acortar distancias: +  0.5522076625947604\n",
      "Penalización por duración del episodio: -  0.3988939955080879\n",
      "Recompensa por acortar distancias: +  0.5522076625947604\n",
      "Penalización por duración del episodio: -  0.3990064377362341\n",
      "Recompensa por acortar distancias: +  0.5522076625947604\n",
      "Penalización por duración del episodio: -  0.3992696392137375\n",
      "Recompensa por acortar distancias: +  0.5522076625947604\n",
      "Penalización por duración del episodio: -  0.3996403675789889\n",
      "Recompensa por acortar distancias: +  0.5384534794152611\n",
      "Penalización por duración del episodio: -  0.399734299053276\n",
      "Recompensa por acortar distancias: +  0.5384534794152611\n",
      "Penalización por duración del episodio: -  0.39986893939631474\n",
      "Recompensa por acortar distancias: +  0.5384534794152611\n",
      "Penalización por duración del episodio: -  0.40035810607796646\n",
      "Recompensa por acortar distancias: +  0.5314651771552635\n",
      "Penalización por duración del episodio: -  0.40048468201753223\n",
      "Recompensa por acortar distancias: +  0.5293706633328552\n",
      "Penalización por duración del episodio: -  0.4007306939087098\n",
      "Recompensa por acortar distancias: +  0.5293706633328552\n",
      "Penalización por duración del episodio: -  0.4008644379341821\n",
      "Step: 3470, Mean Reward (últimos 10 pasos): 0.12850622832775116\n",
      "Recompensa por acortar distancias: +  0.5293706633328552\n",
      "Penalización por duración del episodio: -  0.4010949660202684\n",
      "Recompensa por acortar distancias: +  0.5293706633328552\n",
      "Penalización por duración del episodio: -  0.40147465529386817\n",
      "Recompensa por acortar distancias: +  0.5293706633328552\n",
      "Penalización por duración del episodio: -  0.40184404999364887\n",
      "Recompensa por acortar distancias: +  0.516468669123534\n",
      "Penalización por duración del episodio: -  0.40220195941016934\n",
      "steer input from model: -0.9 , throttle:  0.7\n",
      "reward: 0.11426670971336461\n",
      "Recompensa por acortar distancias: +  0.516468669123534\n",
      "Penalización por duración del episodio: -  0.40230091086654296\n",
      "Recompensa por acortar distancias: +  0.516468669123534\n",
      "Penalización por duración del episodio: -  0.40242792389122495\n",
      "Recompensa por acortar distancias: +  0.5100520475960126\n",
      "Penalización por duración del episodio: -  0.40256976694241603\n",
      "Recompensa por acortar distancias: +  0.5100520475960126\n",
      "Penalización por duración del episodio: -  0.40272508021187065\n",
      "Recompensa por acortar distancias: +  0.5077805317764905\n",
      "Penalización por duración del episodio: -  0.4028604934746802\n",
      "Recompensa por acortar distancias: +  0.5077805317764905\n",
      "Penalización por duración del episodio: -  0.40299831351117343\n",
      "Step: 3480, Mean Reward (últimos 10 pasos): 0.10478221625089645\n",
      "Recompensa por acortar distancias: +  0.5048604626228846\n",
      "Penalización por duración del episodio: -  0.40331472426403325\n",
      "Recompensa por acortar distancias: +  0.5048604626228846\n",
      "Penalización por duración del episodio: -  0.4036970383416986\n",
      "Recompensa por acortar distancias: +  0.5048604626228846\n",
      "Penalización por duración del episodio: -  0.4038133688760775\n",
      "Recompensa por acortar distancias: +  0.5048604626228846\n",
      "Penalización por duración del episodio: -  0.4039596985171955\n",
      "Recompensa por acortar distancias: +  0.49505151574732875\n",
      "Penalización por duración del episodio: -  0.4044474819513739\n",
      "Recompensa por acortar distancias: +  0.4929557037529971\n",
      "Penalización por duración del episodio: -  0.40483383501787834\n",
      "Recompensa por acortar distancias: +  0.48643710822475406\n",
      "Penalización por duración del episodio: -  0.4049708726484794\n",
      "Recompensa por acortar distancias: +  0.48643710822475406\n",
      "Penalización por duración del episodio: -  0.40507262925441356\n",
      "Recompensa por acortar distancias: +  0.48643710822475406\n",
      "Penalización por duración del episodio: -  0.4052155825942239\n",
      "Recompensa por acortar distancias: +  0.48403563325811044\n",
      "Penalización por duración del episodio: -  0.40559897379467974\n",
      "Step: 3490, Mean Reward (últimos 10 pasos): 0.07843665778636932\n",
      "Recompensa por acortar distancias: +  0.48403563325811044\n",
      "Penalización por duración del episodio: -  0.405985251507805\n",
      "Recompensa por acortar distancias: +  0.48403563325811044\n",
      "Penalización por duración del episodio: -  0.4061118898477483\n",
      "Recompensa por acortar distancias: +  0.48403563325811044\n",
      "Penalización por duración del episodio: -  0.40625097410650907\n",
      "Recompensa por acortar distancias: +  0.47418060595712985\n",
      "Penalización por duración del episodio: -  0.4063744523086682\n",
      "steer input from model: 0.05 , throttle:  1.0\n",
      "reward: 0.06780615364846165\n",
      "Recompensa por acortar distancias: +  0.47233514826103157\n",
      "Penalización por duración del episodio: -  0.40673957871418803\n",
      "Recompensa por acortar distancias: +  0.47233514826103157\n",
      "Penalización por duración del episodio: -  0.4071259627255196\n",
      "Recompensa por acortar distancias: +  0.46645278594772216\n",
      "Penalización por duración del episodio: -  0.4072473259173986\n",
      "Recompensa por acortar distancias: +  0.46463449838260207\n",
      "Penalización por duración del episodio: -  0.40734511876917534\n",
      "Recompensa por acortar distancias: +  0.46463449838260207\n",
      "Penalización por duración del episodio: -  0.4078699272619349\n",
      "Recompensa por acortar distancias: +  0.460983663026374\n",
      "Penalización por duración del episodio: -  0.40825783840060964\n",
      "Step: 3500, Mean Reward (últimos 10 pasos): 0.05272582545876503\n",
      "Recompensa por acortar distancias: +  0.460983663026374\n",
      "Penalización por duración del episodio: -  0.4086255201937653\n",
      "Recompensa por acortar distancias: +  0.4515072564599437\n",
      "Penalización por duración del episodio: -  0.4090040638195095\n",
      "Recompensa por acortar distancias: +  0.44925567186634524\n",
      "Penalización por duración del episodio: -  0.40939193889514064\n",
      "Recompensa por acortar distancias: +  0.44925567186634524\n",
      "Penalización por duración del episodio: -  0.40951493501392366\n",
      "Recompensa por acortar distancias: +  0.44925567186634524\n",
      "Penalización por duración del episodio: -  0.4097687803556392\n",
      "Recompensa por acortar distancias: +  0.4408729483773103\n",
      "Penalización por duración del episodio: -  0.40992668389836734\n",
      "Recompensa por acortar distancias: +  0.4408729483773103\n",
      "Penalización por duración del episodio: -  0.4100354718027496\n",
      "Recompensa por acortar distancias: +  0.4385204636231164\n",
      "Penalización por duración del episodio: -  0.41017530051482604\n",
      "Recompensa por acortar distancias: +  0.4385204636231164\n",
      "Penalización por duración del episodio: -  0.4102777054328038\n",
      "Recompensa por acortar distancias: +  0.4385204636231164\n",
      "Penalización por duración del episodio: -  0.4105219730924531\n",
      "Step: 3510, Mean Reward (últimos 10 pasos): 0.027998490259051323\n",
      "Recompensa por acortar distancias: +  0.4385204636231164\n",
      "Penalización por duración del episodio: -  0.41088906037830203\n",
      "Recompensa por acortar distancias: +  0.4385204636231164\n",
      "Penalización por duración del episodio: -  0.41103476644047104\n",
      "Recompensa por acortar distancias: +  0.4297286316277885\n",
      "Penalización por duración del episodio: -  0.41127342656661214\n",
      "Recompensa por acortar distancias: +  0.4272937176179065\n",
      "Penalización por duración del episodio: -  0.41164134597080826\n",
      "steer input from model: -0.05 , throttle:  0.7\n",
      "reward: 0.015652371647098262\n",
      "Recompensa por acortar distancias: +  0.4272937176179065\n",
      "Penalización por duración del episodio: -  0.412031676547105\n",
      "Recompensa por acortar distancias: +  0.42163469230871337\n",
      "Penalización por duración del episodio: -  0.41214412764314784\n",
      "Recompensa por acortar distancias: +  0.4198503953081218\n",
      "Penalización por duración del episodio: -  0.41227509724883193\n",
      "Recompensa por acortar distancias: +  0.4198503953081218\n",
      "Penalización por duración del episodio: -  0.41278259449824733\n",
      "Recompensa por acortar distancias: +  0.4181804943217578\n",
      "Penalización por duración del episodio: -  0.4131496679205505\n",
      "Recompensa por acortar distancias: +  0.4181804943217578\n",
      "Penalización por duración del episodio: -  0.41325926132508023\n",
      "Step: 3520, Mean Reward (últimos 10 pasos): 0.0049212328158319\n",
      "Recompensa por acortar distancias: +  0.4181804943217578\n",
      "Penalización por duración del episodio: -  0.41338437526092525\n",
      "Recompensa por acortar distancias: +  0.40960640108111096\n",
      "Penalización por duración del episodio: -  0.41351446144170084\n",
      "Recompensa por acortar distancias: +  0.40960640108111096\n",
      "Penalización por duración del episodio: -  0.41363878281811245\n",
      "Recompensa por acortar distancias: +  0.4076132219596342\n",
      "Penalización por duración del episodio: -  0.4137487730450441\n",
      "Recompensa por acortar distancias: +  0.4076132219596342\n",
      "Penalización por duración del episodio: -  0.4138698185010373\n",
      "Recompensa por acortar distancias: +  0.4076132219596342\n",
      "Penalización por duración del episodio: -  0.41399916299165823\n",
      "Recompensa por acortar distancias: +  0.4076132219596342\n",
      "Penalización por duración del episodio: -  0.41428178634858637\n",
      "Recompensa por acortar distancias: +  0.4076132219596342\n",
      "Penalización por duración del episodio: -  0.4143991630497687\n",
      "Recompensa por acortar distancias: +  0.40259352372157275\n",
      "Penalización por duración del episodio: -  0.41466894990238734\n",
      "Recompensa por acortar distancias: +  0.40090989010274203\n",
      "Penalización por duración del episodio: -  0.41476770035360877\n",
      "Step: 3530, Mean Reward (últimos 10 pasos): -0.013857809826731682\n",
      "Recompensa por acortar distancias: +  0.39961240694300454\n",
      "Penalización por duración del episodio: -  0.41491577520293343\n",
      "Recompensa por acortar distancias: +  0.39961240694300454\n",
      "Penalización por duración del episodio: -  0.4150254363156908\n",
      "Recompensa por acortar distancias: +  0.39961240694300454\n",
      "Penalización por duración del episodio: -  0.4154136877931705\n",
      "Recompensa por acortar distancias: +  0.39961240694300454\n",
      "Penalización por duración del episodio: -  0.41554301057824994\n",
      "steer input from model: -0.9 , throttle:  0.3\n",
      "reward: -0.0159306036352454\n",
      "Recompensa por acortar distancias: +  0.39961240694300454\n",
      "Penalización por duración del episodio: -  0.4156764218105956\n",
      "Recompensa por acortar distancias: +  0.39961240694300454\n",
      "Penalización por duración del episodio: -  0.4157976022785901\n",
      "Recompensa por acortar distancias: +  0.39961240694300454\n",
      "Penalización por duración del episodio: -  0.415958746081848\n",
      "Recompensa por acortar distancias: +  0.3920634329286516\n",
      "Penalización por duración del episodio: -  0.41618443435684765\n",
      "Recompensa por acortar distancias: +  0.3904256904758633\n",
      "Penalización por duración del episodio: -  0.41629359547931327\n",
      "Recompensa por acortar distancias: +  0.3904256904758633\n",
      "Penalización por duración del episodio: -  0.41656672250499804\n",
      "Step: 3540, Mean Reward (últimos 10 pasos): -0.026141032576560974\n",
      "Recompensa por acortar distancias: +  0.3904256904758633\n",
      "Penalización por duración del episodio: -  0.41693062764000677\n",
      "Recompensa por acortar distancias: +  0.3868024253090548\n",
      "Penalización por duración del episodio: -  0.4170664097026663\n",
      "Recompensa por acortar distancias: +  0.3853999993207988\n",
      "Penalización por duración del episodio: -  0.4171858800350302\n",
      "Recompensa por acortar distancias: +  0.3853999993207988\n",
      "Penalización por duración del episodio: -  0.41731659554215705\n",
      "Recompensa por acortar distancias: +  0.38454061996089306\n",
      "Penalización por duración del episodio: -  0.41742376565155104\n",
      "Recompensa por acortar distancias: +  0.38454061996089306\n",
      "Penalización por duración del episodio: -  0.41751070758976816\n",
      "Recompensa por acortar distancias: +  0.38454061996089306\n",
      "Penalización por duración del episodio: -  0.41769816477377986\n",
      "Recompensa por acortar distancias: +  0.38454061996089306\n",
      "Penalización por duración del episodio: -  0.4178350383862681\n",
      "Recompensa por acortar distancias: +  0.38454061996089306\n",
      "Penalización por duración del episodio: -  0.41796239521774753\n",
      "Recompensa por acortar distancias: +  0.38454061996089306\n",
      "Penalización por duración del episodio: -  0.4180977387022178\n",
      "Step: 3550, Mean Reward (últimos 10 pasos): -0.033557116985321045\n",
      "Recompensa por acortar distancias: +  0.38454061996089306\n",
      "Penalización por duración del episodio: -  0.4182191198283349\n",
      "Recompensa por acortar distancias: +  0.38454061996089306\n",
      "Penalización por duración del episodio: -  0.41831624346429586\n",
      "Recompensa por acortar distancias: +  0.38454061996089306\n",
      "Penalización por duración del episodio: -  0.4188284254641987\n",
      "Recompensa por acortar distancias: +  0.37791604566482706\n",
      "Penalización por duración del episodio: -  0.4189341434622235\n",
      "steer input from model: -0.05 , throttle:  0.3\n",
      "reward: -0.04101809779739646\n",
      "Recompensa por acortar distancias: +  0.37791604566482706\n",
      "Penalización por duración del episodio: -  0.41900694788803583\n",
      "Recompensa por acortar distancias: +  0.37791604566482706\n",
      "Penalización por duración del episodio: -  0.41912130392292\n",
      "Recompensa por acortar distancias: +  0.37791604566482706\n",
      "Penalización por duración del episodio: -  0.41922083127579723\n",
      "Recompensa por acortar distancias: +  0.37791604566482706\n",
      "Penalización por duración del episodio: -  0.41960081494063917\n",
      "Recompensa por acortar distancias: +  0.374512649756931\n",
      "Penalización por duración del episodio: -  0.41998796788486636\n",
      "Recompensa por acortar distancias: +  0.37360214972088834\n",
      "Penalización por duración del episodio: -  0.42036166627038696\n",
      "Step: 3560, Mean Reward (últimos 10 pasos): -0.04675951600074768\n",
      "Recompensa por acortar distancias: +  0.37360214972088834\n",
      "Penalización por duración del episodio: -  0.42075109836750996\n",
      "Recompensa por acortar distancias: +  0.37000960407392475\n",
      "Penalización por duración del episodio: -  0.42112812713212905\n",
      "Recompensa por acortar distancias: +  0.3690091020479243\n",
      "Penalización por duración del episodio: -  0.4215106370852904\n",
      "Recompensa por acortar distancias: +  0.3690091020479243\n",
      "Penalización por duración del episodio: -  0.42163648303675344\n",
      "Recompensa por acortar distancias: +  0.3690091020479243\n",
      "Penalización por duración del episodio: -  0.42189257252907986\n",
      "Recompensa por acortar distancias: +  0.3690091020479243\n",
      "Penalización por duración del episodio: -  0.42208355496835426\n",
      "Recompensa por acortar distancias: +  0.3661818144756744\n",
      "Penalización por duración del episodio: -  0.42227064625939154\n",
      "Recompensa por acortar distancias: +  0.3653051902077448\n",
      "Penalización por duración del episodio: -  0.4223723030439649\n",
      "Recompensa por acortar distancias: +  0.3653051902077448\n",
      "Penalización por duración del episodio: -  0.42246141882362565\n",
      "Recompensa por acortar distancias: +  0.3653051902077448\n",
      "Penalización por duración del episodio: -  0.42256926031985426\n",
      "Step: 3570, Mean Reward (últimos 10 pasos): -0.057264070957899094\n",
      "Recompensa por acortar distancias: +  0.3653051902077448\n",
      "Penalización por duración del episodio: -  0.4226744504113051\n",
      "Recompensa por acortar distancias: +  0.3653051902077448\n",
      "Penalización por duración del episodio: -  0.4227726306665116\n",
      "Recompensa por acortar distancias: +  0.3653051902077448\n",
      "Penalización por duración del episodio: -  0.4230196122384231\n",
      "Recompensa por acortar distancias: +  0.3653051902077448\n",
      "Penalización por duración del episodio: -  0.42318644520783544\n",
      "steer input from model: 0.1 , throttle:  0.0\n",
      "reward: -0.057881255000090615\n",
      "Recompensa por acortar distancias: +  0.3653051902077448\n",
      "Penalización por duración del episodio: -  0.4233158942432034\n",
      "Recompensa por acortar distancias: +  0.3653051902077448\n",
      "Penalización por duración del episodio: -  0.42343471353613393\n",
      "Recompensa por acortar distancias: +  0.3653051902077448\n",
      "Penalización por duración del episodio: -  0.42354624782423256\n",
      "Recompensa por acortar distancias: +  0.3653051902077448\n",
      "Penalización por duración del episodio: -  0.4236547860068109\n",
      "Recompensa por acortar distancias: +  0.36221053200447945\n",
      "Penalización por duración del episodio: -  0.424164440385812\n",
      "Recompensa por acortar distancias: +  0.36171111213184465\n",
      "Penalización por duración del episodio: -  0.4245430024973357\n",
      "Step: 3580, Mean Reward (últimos 10 pasos): -0.06283189356327057\n",
      "Recompensa por acortar distancias: +  0.36047727632656634\n",
      "Penalización por duración del episodio: -  0.4249373137166656\n",
      "Recompensa por acortar distancias: +  0.36005625930711666\n",
      "Penalización por duración del episodio: -  0.4250615082334847\n",
      "Recompensa por acortar distancias: +  0.36005625930711666\n",
      "Penalización por duración del episodio: -  0.42514740002072793\n",
      "Recompensa por acortar distancias: +  0.36005625930711666\n",
      "Penalización por duración del episodio: -  0.42525697818698915\n",
      "Recompensa por acortar distancias: +  0.36005625930711666\n",
      "Penalización por duración del episodio: -  0.42535501331272335\n",
      "Recompensa por acortar distancias: +  0.36005625930711666\n",
      "Penalización por duración del episodio: -  0.4257005810031391\n",
      "Recompensa por acortar distancias: +  0.358355341886659\n",
      "Penalización por duración del episodio: -  0.4258247109968493\n",
      "Recompensa por acortar distancias: +  0.358355341886659\n",
      "Penalización por duración del episodio: -  0.42592772937843426\n",
      "Recompensa por acortar distancias: +  0.358355341886659\n",
      "Penalización por duración del episodio: -  0.4261068609572175\n",
      "Recompensa por acortar distancias: +  0.35796426500628165\n",
      "Penalización por duración del episodio: -  0.42622017055954947\n",
      "Step: 3590, Mean Reward (últimos 10 pasos): -0.06825590878725052\n",
      "Recompensa por acortar distancias: +  0.35796426500628165\n",
      "Penalización por duración del episodio: -  0.4264527902708306\n",
      "Recompensa por acortar distancias: +  0.35796426500628165\n",
      "Penalización por duración del episodio: -  0.42682132347607926\n",
      "Recompensa por acortar distancias: +  0.35700205130794166\n",
      "Penalización por duración del episodio: -  0.4269353058801235\n",
      "Recompensa por acortar distancias: +  0.3567690639388649\n",
      "Penalización por duración del episodio: -  0.42704458834976683\n",
      "steer input from model: 0.1 , throttle:  0.0\n",
      "reward: -0.0702755244109019\n",
      "Recompensa por acortar distancias: +  0.3567690639388649\n",
      "Penalización por duración del episodio: -  0.4271973939107322\n",
      "Recompensa por acortar distancias: +  0.3567690639388649\n",
      "Penalización por duración del episodio: -  0.4273403412062313\n",
      "Recompensa por acortar distancias: +  0.3567690639388649\n",
      "Penalización por duración del episodio: -  0.42758636310622056\n",
      "Recompensa por acortar distancias: +  0.3567690639388649\n",
      "Penalización por duración del episodio: -  0.4277131545533792\n",
      "Recompensa por acortar distancias: +  0.3567690639388649\n",
      "Penalización por duración del episodio: -  0.427954818125637\n",
      "Recompensa por acortar distancias: +  0.3567690639388649\n",
      "Penalización por duración del episodio: -  0.4281791669900101\n",
      "Step: 3600, Mean Reward (últimos 10 pasos): -0.07141010463237762\n",
      "Recompensa por acortar distancias: +  0.3567690639388649\n",
      "Penalización por duración del episodio: -  0.42871200790380903\n",
      "Recompensa por acortar distancias: +  0.35524493435291593\n",
      "Penalización por duración del episodio: -  0.42909145829412326\n",
      "Recompensa por acortar distancias: +  0.3548073276677391\n",
      "Penalización por duración del episodio: -  0.42920171457374934\n",
      "Recompensa por acortar distancias: +  0.3548073276677391\n",
      "Penalización por duración del episodio: -  0.4293073398688819\n",
      "Recompensa por acortar distancias: +  0.3546313914795727\n",
      "Penalización por duración del episodio: -  0.42947626726978966\n",
      "Recompensa por acortar distancias: +  0.3544972132887422\n",
      "Penalización por duración del episodio: -  0.4298810634732791\n",
      "Recompensa por acortar distancias: +  0.3544972132887422\n",
      "Penalización por duración del episodio: -  0.43027825614928045\n",
      "Recompensa por acortar distancias: +  0.3544972132887422\n",
      "Penalización por duración del episodio: -  0.4306649458771681\n",
      "Recompensa por acortar distancias: +  0.3538058705990853\n",
      "Penalización por duración del episodio: -  0.4307862747734448\n",
      "Recompensa por acortar distancias: +  0.3538058705990853\n",
      "Penalización por duración del episodio: -  0.43103841218722133\n",
      "Step: 3610, Mean Reward (últimos 10 pasos): -0.07723253965377808\n",
      "Recompensa por acortar distancias: +  0.3538058705990853\n",
      "Penalización por duración del episodio: -  0.43142596954750045\n",
      "Recompensa por acortar distancias: +  0.35348649140211486\n",
      "Penalización por duración del episodio: -  0.43181433040725714\n",
      "Recompensa por acortar distancias: +  0.3532625723271351\n",
      "Penalización por duración del episodio: -  0.4322055776883976\n",
      "Recompensa por acortar distancias: +  0.3532625723271351\n",
      "Penalización por duración del episodio: -  0.43229808254785185\n",
      "steer input from model: -0.1 , throttle:  0.0\n",
      "reward: -0.07903551022071675\n",
      "Recompensa por acortar distancias: +  0.3532625723271351\n",
      "Penalización por duración del episodio: -  0.4326014800957481\n",
      "Recompensa por acortar distancias: +  0.3532625723271351\n",
      "Penalización por duración del episodio: -  0.43270460980266295\n",
      "Recompensa por acortar distancias: +  0.3532625723271351\n",
      "Penalización por duración del episodio: -  0.43298575592092475\n",
      "Recompensa por acortar distancias: +  0.3528877820159696\n",
      "Penalización por duración del episodio: -  0.4331132940816224\n",
      "Recompensa por acortar distancias: +  0.3528541249773956\n",
      "Penalización por duración del episodio: -  0.43335343264807863\n",
      "Recompensa por acortar distancias: +  0.3528541249773956\n",
      "Penalización por duración del episodio: -  0.4334513762606584\n",
      "Step: 3620, Mean Reward (últimos 10 pasos): -0.08059725165367126\n",
      "Recompensa por acortar distancias: +  0.3528541249773956\n",
      "Penalización por duración del episodio: -  0.4337397396725541\n",
      "Recompensa por acortar distancias: +  0.3527337512223535\n",
      "Penalización por duración del episodio: -  0.4341089428575549\n",
      "Recompensa por acortar distancias: +  0.35268647675414877\n",
      "Penalización por duración del episodio: -  0.4342776072683288\n",
      "Recompensa por acortar distancias: +  0.3526695653333138\n",
      "Penalización por duración del episodio: -  0.43449207365908993\n",
      "Recompensa por acortar distancias: +  0.3526695653333138\n",
      "Penalización por duración del episodio: -  0.43486457775276555\n",
      "Recompensa por acortar distancias: +  0.3526695653333138\n",
      "Penalización por duración del episodio: -  0.43523870257811326\n",
      "Recompensa por acortar distancias: +  0.3526695653333138\n",
      "Penalización por duración del episodio: -  0.4356257205853446\n",
      "Recompensa por acortar distancias: +  0.3527151023658035\n",
      "Penalización por duración del episodio: -  0.4360152325406431\n",
      "Recompensa por acortar distancias: +  0.3527151023658035\n",
      "Penalización por duración del episodio: -  0.4363892075920795\n",
      "Recompensa por acortar distancias: +  0.3528263489480785\n",
      "Penalización por duración del episodio: -  0.4365033418427524\n",
      "Step: 3630, Mean Reward (últimos 10 pasos): -0.08367699384689331\n",
      "Recompensa por acortar distancias: +  0.3528699515524718\n",
      "Penalización por duración del episodio: -  0.4367793782915037\n",
      "Recompensa por acortar distancias: +  0.3529573492396583\n",
      "Penalización por duración del episodio: -  0.4368851243534683\n",
      "Recompensa por acortar distancias: +  0.3529573492396583\n",
      "Penalización por duración del episodio: -  0.4370025022208088\n",
      "Recompensa por acortar distancias: +  0.3529573492396583\n",
      "Penalización por duración del episodio: -  0.4371200807286718\n",
      "steer input from model: 0.9 , throttle:  0.0\n",
      "reward: -0.08416273148901349\n",
      "Recompensa por acortar distancias: +  0.3529573492396583\n",
      "Penalización por duración del episodio: -  0.4375392652708171\n",
      "Recompensa por acortar distancias: +  0.3529573492396583\n",
      "Penalización por duración del episodio: -  0.43792906079680444\n",
      "Recompensa por acortar distancias: +  0.3533977321681569\n",
      "Penalización por duración del episodio: -  0.4380414947464752\n",
      "Recompensa por acortar distancias: +  0.3535089783881559\n",
      "Penalización por duración del episodio: -  0.43832913463102\n",
      "Recompensa por acortar distancias: +  0.3535089783881559\n",
      "Penalización por duración del episodio: -  0.4387032276477299\n",
      "Recompensa por acortar distancias: +  0.3539128736153114\n",
      "Penalización por duración del episodio: -  0.439084272315356\n",
      "Step: 3640, Mean Reward (últimos 10 pasos): -0.0851714015007019\n",
      "Recompensa por acortar distancias: +  0.3542624620026272\n",
      "Penalización por duración del episodio: -  0.43925658744034946\n",
      "Recompensa por acortar distancias: +  0.3542624620026272\n",
      "Penalización por duración del episodio: -  0.4394661170840943\n",
      "Recompensa por acortar distancias: +  0.3542624620026272\n",
      "Penalización por duración del episodio: -  0.4398499015219396\n",
      "Recompensa por acortar distancias: +  0.3542624620026272\n",
      "Penalización por duración del episodio: -  0.44023663678999386\n",
      "Recompensa por acortar distancias: +  0.3550470676879431\n",
      "Penalización por duración del episodio: -  0.4403652924527999\n",
      "Recompensa por acortar distancias: +  0.3552626441898091\n",
      "Penalización por duración del episodio: -  0.44063500354286744\n",
      "Recompensa por acortar distancias: +  0.3552626441898091\n",
      "Penalización por duración del episodio: -  0.44102068072370193\n",
      "Recompensa por acortar distancias: +  0.35582430535550097\n",
      "Penalización por duración del episodio: -  0.4414066348433068\n",
      "Recompensa por acortar distancias: +  0.35623488329608444\n",
      "Penalización por duración del episodio: -  0.4414929287432888\n",
      "Recompensa por acortar distancias: +  0.3564363658112548\n",
      "Penalización por duración del episodio: -  0.44163346150250504\n",
      "Step: 3650, Mean Reward (últimos 10 pasos): -0.0851970985531807\n",
      "Recompensa por acortar distancias: +  0.3564363658112548\n",
      "Penalización por duración del episodio: -  0.4417874738962378\n",
      "Recompensa por acortar distancias: +  0.3566467066254937\n",
      "Penalización por duración del episodio: -  0.4418802277456538\n",
      "Recompensa por acortar distancias: +  0.3566467066254937\n",
      "Penalización por duración del episodio: -  0.4421648882859468\n",
      "Recompensa por acortar distancias: +  0.3566467066254937\n",
      "Penalización por duración del episodio: -  0.44254322822241526\n",
      "steer input from model: 0.1 , throttle:  0.0\n",
      "reward: -0.08589652159692157\n",
      "Recompensa por acortar distancias: +  0.3566467066254937\n",
      "Penalización por duración del episodio: -  0.4429344358335802\n",
      "Recompensa por acortar distancias: +  0.3581457546126723\n",
      "Penalización por duración del episodio: -  0.44332310768821553\n",
      "Recompensa por acortar distancias: +  0.3581457546126723\n",
      "Penalización por duración del episodio: -  0.4437201643570975\n",
      "Recompensa por acortar distancias: +  0.3593051469971584\n",
      "Penalización por duración del episodio: -  0.44381130054373785\n",
      "Recompensa por acortar distancias: +  0.35952020973208776\n",
      "Penalización por duración del episodio: -  0.44410074153568274\n",
      "Recompensa por acortar distancias: +  0.360047788312701\n",
      "Penalización por duración del episodio: -  0.44449515988378197\n",
      "Step: 3660, Mean Reward (últimos 10 pasos): -0.08444736897945404\n",
      "Recompensa por acortar distancias: +  0.360047788312701\n",
      "Penalización por duración del episodio: -  0.4448752342756452\n",
      "Recompensa por acortar distancias: +  0.360047788312701\n",
      "Penalización por duración del episodio: -  0.44500326693579006\n",
      "Recompensa por acortar distancias: +  0.360047788312701\n",
      "Penalización por duración del episodio: -  0.4451161553567236\n",
      "Recompensa por acortar distancias: +  0.36175797890640476\n",
      "Penalización por duración del episodio: -  0.44523550962058145\n",
      "Recompensa por acortar distancias: +  0.36175797890640476\n",
      "Penalización por duración del episodio: -  0.445348121107749\n",
      "Recompensa por acortar distancias: +  0.3621953361097292\n",
      "Penalización por duración del episodio: -  0.4454714159790194\n",
      "Recompensa por acortar distancias: +  0.3621953361097292\n",
      "Penalización por duración del episodio: -  0.4456091242886153\n",
      "Recompensa por acortar distancias: +  0.3621953361097292\n",
      "Penalización por duración del episodio: -  0.4460384583075187\n",
      "Recompensa por acortar distancias: +  0.363631356187928\n",
      "Penalización por duración del episodio: -  0.44613994551199937\n",
      "Recompensa por acortar distancias: +  0.363631356187928\n",
      "Penalización por duración del episodio: -  0.44624756443925345\n",
      "Step: 3670, Mean Reward (últimos 10 pasos): -0.08261620998382568\n",
      "Recompensa por acortar distancias: +  0.3641839622071296\n",
      "Penalización por duración del episodio: -  0.4463925607333172\n",
      "Recompensa por acortar distancias: +  0.3646079672244769\n",
      "Penalización por duración del episodio: -  0.44654619841245\n",
      "Recompensa por acortar distancias: +  0.3646079672244769\n",
      "Penalización por duración del episodio: -  0.44667247472447635\n",
      "Recompensa por acortar distancias: +  0.3652453913659877\n",
      "Penalización por duración del episodio: -  0.446829849505023\n",
      "steer input from model: -0.1 , throttle:  0.3\n",
      "reward: -0.08158445813903531\n",
      "Recompensa por acortar distancias: +  0.3652453913659877\n",
      "Penalización por duración del episodio: -  0.44721348406248146\n",
      "Recompensa por acortar distancias: +  0.3652453913659877\n",
      "Penalización por duración del episodio: -  0.4475965684025694\n",
      "Recompensa por acortar distancias: +  0.3652453913659877\n",
      "Penalización por duración del episodio: -  0.4477393199458762\n",
      "Recompensa por acortar distancias: +  0.3652453913659877\n",
      "Penalización por duración del episodio: -  0.4478580611296193\n",
      "Recompensa por acortar distancias: +  0.3652453913659877\n",
      "Penalización por duración del episodio: -  0.44801138229493237\n",
      "Recompensa por acortar distancias: +  0.3684207518918645\n",
      "Penalización por duración del episodio: -  0.44813968324160625\n",
      "Step: 3680, Mean Reward (últimos 10 pasos): -0.0797189325094223\n",
      "Recompensa por acortar distancias: +  0.3691259716442178\n",
      "Penalización por duración del episodio: -  0.44836882018759844\n",
      "Recompensa por acortar distancias: +  0.3691259716442178\n",
      "Penalización por duración del episodio: -  0.4485105919291581\n",
      "Recompensa por acortar distancias: +  0.3691259716442178\n",
      "Penalización por duración del episodio: -  0.44875166613751527\n",
      "Recompensa por acortar distancias: +  0.3691259716442178\n",
      "Penalización por duración del episodio: -  0.44914178704420943\n",
      "Recompensa por acortar distancias: +  0.372062705837468\n",
      "Penalización por duración del episodio: -  0.4495214159210685\n",
      "Recompensa por acortar distancias: +  0.372062705837468\n",
      "Penalización por duración del episodio: -  0.449904242739206\n",
      "Recompensa por acortar distancias: +  0.372062705837468\n",
      "Penalización por duración del episodio: -  0.4500161920512683\n",
      "Recompensa por acortar distancias: +  0.372062705837468\n",
      "Penalización por duración del episodio: -  0.4501583369691648\n",
      "Recompensa por acortar distancias: +  0.3750754796765566\n",
      "Penalización por duración del episodio: -  0.4502887282154523\n",
      "Recompensa por acortar distancias: +  0.3750754796765566\n",
      "Penalización por duración del episodio: -  0.45039353597933757\n",
      "Step: 3690, Mean Reward (últimos 10 pasos): -0.07531805336475372\n",
      "Recompensa por acortar distancias: +  0.3760034079147569\n",
      "Penalización por duración del episodio: -  0.45052141343278906\n",
      "Recompensa por acortar distancias: +  0.3760034079147569\n",
      "Penalización por duración del episodio: -  0.4506844051313496\n",
      "Recompensa por acortar distancias: +  0.3760034079147569\n",
      "Penalización por duración del episodio: -  0.45106157828295523\n",
      "Recompensa por acortar distancias: +  0.37828760458361627\n",
      "Penalización por duración del episodio: -  0.4514395870372548\n",
      "steer input from model: 0.9 , throttle:  0.0\n",
      "reward: -0.07315198245363852\n",
      "Recompensa por acortar distancias: +  0.3799185003229883\n",
      "Penalización por duración del episodio: -  0.45181711447369\n",
      "Recompensa por acortar distancias: +  0.3799185003229883\n",
      "Penalización por duración del episodio: -  0.45220092818593777\n",
      "Recompensa por acortar distancias: +  0.3799185003229883\n",
      "Penalización por duración del episodio: -  0.45257740337531743\n",
      "Recompensa por acortar distancias: +  0.383857773549913\n",
      "Penalización por duración del episodio: -  0.4526837051455011\n",
      "Recompensa por acortar distancias: +  0.3845251874790963\n",
      "Penalización por duración del episodio: -  0.4528074733461191\n",
      "Recompensa por acortar distancias: +  0.3845251874790963\n",
      "Penalización por duración del episodio: -  0.45296125838299583\n",
      "Step: 3700, Mean Reward (últimos 10 pasos): -0.06843607127666473\n",
      "Recompensa por acortar distancias: +  0.3845251874790963\n",
      "Penalización por duración del episodio: -  0.453349695308573\n",
      "Recompensa por acortar distancias: +  0.38736182184847845\n",
      "Penalización por duración del episodio: -  0.45373533478932215\n",
      "Recompensa por acortar distancias: +  0.38931900050480733\n",
      "Penalización por duración del episodio: -  0.45388372475514943\n",
      "Recompensa por acortar distancias: +  0.38931900050480733\n",
      "Penalización por duración del episodio: -  0.45399129635308183\n",
      "Recompensa por acortar distancias: +  0.3903676278731184\n",
      "Penalización por duración del episodio: -  0.4544955665022272\n",
      "Recompensa por acortar distancias: +  0.39124003925735273\n",
      "Penalización por duración del episodio: -  0.4546006559967351\n",
      "Recompensa por acortar distancias: +  0.39124003925735273\n",
      "Penalización por duración del episodio: -  0.45472733269451854\n",
      "Recompensa por acortar distancias: +  0.39124003925735273\n",
      "Penalización por duración del episodio: -  0.4548784136523395\n",
      "Recompensa por acortar distancias: +  0.39124003925735273\n",
      "Penalización por duración del episodio: -  0.4552840369203451\n",
      "Recompensa por acortar distancias: +  0.3962948115620255\n",
      "Penalización por duración del episodio: -  0.4556694771663831\n",
      "Step: 3710, Mean Reward (últimos 10 pasos): -0.05937466397881508\n",
      "Recompensa por acortar distancias: +  0.39743167621703585\n",
      "Penalización por duración del episodio: -  0.45580591931323194\n",
      "Recompensa por acortar distancias: +  0.39743167621703585\n",
      "Penalización por duración del episodio: -  0.45590873432133516\n",
      "Recompensa por acortar distancias: +  0.39743167621703585\n",
      "Penalización por duración del episodio: -  0.45602316294289236\n",
      "Recompensa por acortar distancias: +  0.39743167621703585\n",
      "Penalización por duración del episodio: -  0.45643316392364297\n",
      "steer input from model: 0.9 , throttle:  1.0\n",
      "reward: -0.059001487706607125\n",
      "Recompensa por acortar distancias: +  0.4025640930218919\n",
      "Penalización por duración del episodio: -  0.45681107626612344\n",
      "Recompensa por acortar distancias: +  0.4025640930218919\n",
      "Penalización por duración del episodio: -  0.45719513852508914\n",
      "Recompensa por acortar distancias: +  0.4025640930218919\n",
      "Penalización por duración del episodio: -  0.4573301034173385\n",
      "Recompensa por acortar distancias: +  0.4025640930218919\n",
      "Penalización por duración del episodio: -  0.457477879702266\n",
      "Recompensa por acortar distancias: +  0.4077163995091625\n",
      "Penalización por duración del episodio: -  0.45797603318049473\n",
      "Recompensa por acortar distancias: +  0.4093474676491974\n",
      "Penalización por duración del episodio: -  0.4583566199735865\n",
      "Step: 3720, Mean Reward (últimos 10 pasos): -0.04900915175676346\n",
      "Recompensa por acortar distancias: +  0.41280073810875023\n",
      "Penalización por duración del episodio: -  0.45846900247617206\n",
      "Recompensa por acortar distancias: +  0.41418259245805383\n",
      "Penalización por duración del episodio: -  0.45873316473699427\n",
      "Recompensa por acortar distancias: +  0.415453128995422\n",
      "Penalización por duración del episodio: -  0.458870384366046\n",
      "Recompensa por acortar distancias: +  0.415453128995422\n",
      "Penalización por duración del episodio: -  0.45903328712188063\n",
      "Recompensa por acortar distancias: +  0.4171746281928445\n",
      "Penalización por duración del episodio: -  0.45913480087961683\n",
      "Recompensa por acortar distancias: +  0.4181543442893219\n",
      "Penalización por duración del episodio: -  0.4592561174057421\n",
      "Recompensa por acortar distancias: +  0.4181543442893219\n",
      "Penalización por duración del episodio: -  0.45935605766887555\n",
      "Recompensa por acortar distancias: +  0.4181543442893219\n",
      "Penalización por duración del episodio: -  0.4595025427594598\n",
      "Recompensa por acortar distancias: +  0.4181543442893219\n",
      "Penalización por duración del episodio: -  0.4599121921412897\n",
      "Recompensa por acortar distancias: +  0.4181543442893219\n",
      "Penalización por duración del episodio: -  0.460121736720697\n",
      "Step: 3730, Mean Reward (últimos 10 pasos): -0.04196739196777344\n",
      "Recompensa por acortar distancias: +  0.4240127667574063\n",
      "Penalización por duración del episodio: -  0.4602900127319741\n",
      "Recompensa por acortar distancias: +  0.4256693853055255\n",
      "Penalización por duración del episodio: -  0.4606885878704941\n",
      "Recompensa por acortar distancias: +  0.4256693853055255\n",
      "Penalización por duración del episodio: -  0.46079977024033675\n",
      "Recompensa por acortar distancias: +  0.4256693853055255\n",
      "Penalización por duración del episodio: -  0.4609477686789339\n",
      "steer input from model: -0.25 , throttle:  0.0\n",
      "reward: -0.035278383373408384\n",
      "Recompensa por acortar distancias: +  0.4299140109040598\n",
      "Penalización por duración del episodio: -  0.46145574763988195\n",
      "Recompensa por acortar distancias: +  0.43332911587473066\n",
      "Penalización por duración del episodio: -  0.4618548120886651\n",
      "Recompensa por acortar distancias: +  0.43332911587473066\n",
      "Penalización por duración del episodio: -  0.4622422858092524\n",
      "Recompensa por acortar distancias: +  0.43332911587473066\n",
      "Penalización por duración del episodio: -  0.4626453462179078\n",
      "Recompensa por acortar distancias: +  0.44207851408187687\n",
      "Penalización por duración del episodio: -  0.4630301916109929\n",
      "Recompensa por acortar distancias: +  0.44207851408187687\n",
      "Penalización por duración del episodio: -  0.46342681368052857\n",
      "Step: 3740, Mean Reward (últimos 10 pasos): -0.021348299458622932\n",
      "Recompensa por acortar distancias: +  0.4485263995756573\n",
      "Penalización por duración del episodio: -  0.46356973680608216\n",
      "Recompensa por acortar distancias: +  0.4499752814605442\n",
      "Penalización por duración del episodio: -  0.46381559019117047\n",
      "Recompensa por acortar distancias: +  0.45243989265939233\n",
      "Penalización por duración del episodio: -  0.46394231834386723\n",
      "Recompensa por acortar distancias: +  0.45243989265939233\n",
      "Penalización por duración del episodio: -  0.46420570934221284\n",
      "Recompensa por acortar distancias: +  0.45243989265939233\n",
      "Penalización por duración del episodio: -  0.46458337066371536\n",
      "Recompensa por acortar distancias: +  0.45243989265939233\n",
      "Penalización por duración del episodio: -  0.46496262064637334\n",
      "Recompensa por acortar distancias: +  0.46162331518387667\n",
      "Penalización por duración del episodio: -  0.465099272092585\n",
      "Recompensa por acortar distancias: +  0.46162331518387667\n",
      "Penalización por duración del episodio: -  0.46534763536456236\n",
      "Recompensa por acortar distancias: +  0.46162331518387667\n",
      "Penalización por duración del episodio: -  0.4657359127110976\n",
      "Recompensa por acortar distancias: +  0.46734258649880983\n",
      "Penalización por duración del episodio: -  0.4658229668695629\n",
      "Step: 3750, Mean Reward (últimos 10 pasos): 0.0015196196036413312\n",
      "Recompensa por acortar distancias: +  0.4689006986706702\n",
      "Penalización por duración del episodio: -  0.46612742359361115\n",
      "Recompensa por acortar distancias: +  0.4713944579490453\n",
      "Penalización por duración del episodio: -  0.4665249158849353\n",
      "Recompensa por acortar distancias: +  0.4740487155755391\n",
      "Penalización por duración del episodio: -  0.4669211807270666\n",
      "Recompensa por acortar distancias: +  0.4740487155755391\n",
      "Penalización por duración del episodio: -  0.4673013975648484\n",
      "steer input from model: -0.1 , throttle:  0.0\n",
      "reward: 0.006747318010690728\n",
      "Recompensa por acortar distancias: +  0.4740487155755391\n",
      "Penalización por duración del episodio: -  0.4673903579106803\n",
      "Recompensa por acortar distancias: +  0.48294436705133\n",
      "Penalización por duración del episodio: -  0.4676979870873123\n",
      "Recompensa por acortar distancias: +  0.4845722906899007\n",
      "Penalización por duración del episodio: -  0.467802858471005\n",
      "Recompensa por acortar distancias: +  0.4845722906899007\n",
      "Penalización por duración del episodio: -  0.4679154731330159\n",
      "Recompensa por acortar distancias: +  0.4845722906899007\n",
      "Penalización por duración del episodio: -  0.46804325187546103\n",
      "Recompensa por acortar distancias: +  0.4845722906899007\n",
      "Penalización por duración del episodio: -  0.4681717768482389\n",
      "Step: 3760, Mean Reward (últimos 10 pasos): 0.016400514170527458\n",
      "Recompensa por acortar distancias: +  0.4897979116046795\n",
      "Penalización por duración del episodio: -  0.46849729613278085\n",
      "Recompensa por acortar distancias: +  0.49220448725127713\n",
      "Penalización por duración del episodio: -  0.46888287461925043\n",
      "Recompensa por acortar distancias: +  0.49613850045668645\n",
      "Penalización por duración del episodio: -  0.4692699331843828\n",
      "Recompensa por acortar distancias: +  0.49613850045668645\n",
      "Penalización por duración del episodio: -  0.4696621061552086\n",
      "Recompensa por acortar distancias: +  0.49613850045668645\n",
      "Penalización por duración del episodio: -  0.46980183004493165\n",
      "Recompensa por acortar distancias: +  0.49613850045668645\n",
      "Penalización por duración del episodio: -  0.47005094319661117\n",
      "Recompensa por acortar distancias: +  0.5069562595654469\n",
      "Penalización por duración del episodio: -  0.4701609720393297\n",
      "Recompensa por acortar distancias: +  0.5069562595654469\n",
      "Penalización por duración del episodio: -  0.47043441747540504\n",
      "Recompensa por acortar distancias: +  0.5069562595654469\n",
      "Penalización por duración del episodio: -  0.47054644026662606\n",
      "Recompensa por acortar distancias: +  0.5069562595654469\n",
      "Penalización por duración del episodio: -  0.4708164713217898\n",
      "Step: 3770, Mean Reward (últimos 10 pasos): 0.03613978996872902\n",
      "Recompensa por acortar distancias: +  0.513079096725452\n",
      "Penalización por duración del episodio: -  0.47100829523296134\n",
      "Recompensa por acortar distancias: +  0.5148919929455763\n",
      "Penalización por duración del episodio: -  0.4711309608159544\n",
      "Recompensa por acortar distancias: +  0.5169538745250015\n",
      "Penalización por duración del episodio: -  0.4716021349192239\n",
      "Recompensa por acortar distancias: +  0.5204688172268455\n",
      "Penalización por duración del episodio: -  0.47168572892611244\n",
      "steer input from model: 0.0 , throttle:  0.7\n",
      "reward: 0.048783088300733024\n",
      "Recompensa por acortar distancias: +  0.5204688172268455\n",
      "Penalización por duración del episodio: -  0.47198739941844464\n",
      "Recompensa por acortar distancias: +  0.5204688172268455\n",
      "Penalización por duración del episodio: -  0.472375103906967\n",
      "Recompensa por acortar distancias: +  0.5204688172268455\n",
      "Penalización por duración del episodio: -  0.472489743632964\n",
      "Recompensa por acortar distancias: +  0.5204688172268455\n",
      "Penalización por duración del episodio: -  0.4726296244279228\n",
      "Recompensa por acortar distancias: +  0.5204688172268455\n",
      "Penalización por duración del episodio: -  0.47275811721415933\n",
      "Recompensa por acortar distancias: +  0.5317782153414641\n",
      "Penalización por duración del episodio: -  0.47290795474740827\n",
      "Step: 3780, Mean Reward (últimos 10 pasos): 0.058870259672403336\n",
      "Recompensa por acortar distancias: +  0.5317782153414641\n",
      "Penalización por duración del episodio: -  0.4730118448911235\n",
      "Recompensa por acortar distancias: +  0.5342795769441054\n",
      "Penalización por duración del episodio: -  0.4731503568302293\n",
      "Recompensa por acortar distancias: +  0.5342795769441054\n",
      "Penalización por duración del episodio: -  0.4732825728457252\n",
      "Recompensa por acortar distancias: +  0.5342795769441054\n",
      "Penalización por duración del episodio: -  0.4734369682835265\n",
      "Recompensa por acortar distancias: +  0.5342795769441054\n",
      "Penalización por duración del episodio: -  0.47391301855604867\n",
      "Recompensa por acortar distancias: +  0.5411817360304213\n",
      "Penalización por duración del episodio: -  0.4743078511628921\n",
      "Recompensa por acortar distancias: +  0.5434620816797321\n",
      "Penalización por duración del episodio: -  0.47445049103001863\n",
      "Recompensa por acortar distancias: +  0.5434620816797321\n",
      "Penalización por duración del episodio: -  0.47469699066809956\n",
      "Recompensa por acortar distancias: +  0.5434620816797321\n",
      "Penalización por duración del episodio: -  0.474800247980586\n",
      "Recompensa por acortar distancias: +  0.5434620816797321\n",
      "Penalización por duración del episodio: -  0.47510066240744053\n",
      "Step: 3790, Mean Reward (últimos 10 pasos): 0.06836141645908356\n",
      "Recompensa por acortar distancias: +  0.5434620816797321\n",
      "Penalización por duración del episodio: -  0.4752758847458869\n",
      "Recompensa por acortar distancias: +  0.5529181377384663\n",
      "Penalización por duración del episodio: -  0.47541312965158955\n",
      "Recompensa por acortar distancias: +  0.5529181377384663\n",
      "Penalización por duración del episodio: -  0.4755766843819236\n",
      "Recompensa por acortar distancias: +  0.5559215426160258\n",
      "Penalización por duración del episodio: -  0.4757131405828161\n",
      "steer input from model: -0.05 , throttle:  0.3\n",
      "reward: 0.08020840203320967\n",
      "Recompensa por acortar distancias: +  0.5559215426160258\n",
      "Penalización por duración del episodio: -  0.47581264862540557\n",
      "Recompensa por acortar distancias: +  0.5559215426160258\n",
      "Penalización por duración del episodio: -  0.4762537383326724\n",
      "Recompensa por acortar distancias: +  0.5612814551585584\n",
      "Penalización por duración del episodio: -  0.4766475825498532\n",
      "Recompensa por acortar distancias: +  0.5632302229717271\n",
      "Penalización por duración del episodio: -  0.47704514350842137\n",
      "Recompensa por acortar distancias: +  0.5632302229717271\n",
      "Penalización por duración del episodio: -  0.47742662549306036\n",
      "Recompensa por acortar distancias: +  0.5632302229717271\n",
      "Penalización por duración del episodio: -  0.47783962049200923\n",
      "Step: 3800, Mean Reward (últimos 10 pasos): 0.085390605032444\n",
      "Recompensa por acortar distancias: +  0.5739851500138456\n",
      "Penalización por duración del episodio: -  0.47821755758435003\n",
      "Recompensa por acortar distancias: +  0.5739851500138456\n",
      "Penalización por duración del episodio: -  0.4786280101517536\n",
      "Recompensa por acortar distancias: +  0.5795681853904268\n",
      "Penalización por duración del episodio: -  0.4787498349062995\n",
      "Recompensa por acortar distancias: +  0.5824866136241741\n",
      "Penalización por duración del episodio: -  0.47886377273070796\n",
      "Recompensa por acortar distancias: +  0.5824866136241741\n",
      "Penalización por duración del episodio: -  0.47900607612816665\n",
      "Recompensa por acortar distancias: +  0.584422744583027\n",
      "Penalización por duración del episodio: -  0.47912416608180053\n",
      "Recompensa por acortar distancias: +  0.584422744583027\n",
      "Penalización por duración del episodio: -  0.4792500590744894\n",
      "Recompensa por acortar distancias: +  0.584422744583027\n",
      "Penalización por duración del episodio: -  0.47941351921032216\n",
      "Recompensa por acortar distancias: +  0.584422744583027\n",
      "Penalización por duración del episodio: -  0.4796189469655573\n",
      "Recompensa por acortar distancias: +  0.584422744583027\n",
      "Penalización por duración del episodio: -  0.479744344416225\n",
      "Step: 3810, Mean Reward (últimos 10 pasos): 0.10467839986085892\n",
      "Recompensa por acortar distancias: +  0.584422744583027\n",
      "Penalización por duración del episodio: -  0.4801704695607366\n",
      "Recompensa por acortar distancias: +  0.584422744583027\n",
      "Penalización por duración del episodio: -  0.4803380782740662\n",
      "Recompensa por acortar distancias: +  0.5961823147246469\n",
      "Penalización por duración del episodio: -  0.48056603893289135\n",
      "Recompensa por acortar distancias: +  0.5987767771581078\n",
      "Penalización por duración del episodio: -  0.48069984104523106\n",
      "steer input from model: 0.25 , throttle:  0.0\n",
      "reward: 0.11807693611287678\n",
      "Recompensa por acortar distancias: +  0.5987767771581078\n",
      "Penalización por duración del episodio: -  0.48094636031136845\n",
      "Recompensa por acortar distancias: +  0.5987767771581078\n",
      "Penalización por duración del episodio: -  0.48104945240305896\n",
      "Recompensa por acortar distancias: +  0.5987767771581078\n",
      "Penalización por duración del episodio: -  0.4811626942679603\n",
      "Recompensa por acortar distancias: +  0.5987767771581078\n",
      "Penalización por duración del episodio: -  0.48130516297140746\n",
      "Recompensa por acortar distancias: +  0.6053223954066754\n",
      "Penalización por duración del episodio: -  0.4814527238976188\n",
      "Recompensa por acortar distancias: +  0.6053223954066754\n",
      "Penalización por duración del episodio: -  0.4816004963929259\n",
      "Step: 3820, Mean Reward (últimos 10 pasos): 0.1237218976020813\n",
      "Recompensa por acortar distancias: +  0.6080900830472176\n",
      "Penalización por duración del episodio: -  0.4821225232956447\n",
      "Recompensa por acortar distancias: +  0.6080900830472176\n",
      "Penalización por duración del episodio: -  0.48222567494587704\n",
      "Recompensa por acortar distancias: +  0.6080900830472176\n",
      "Penalización por duración del episodio: -  0.4825038549945189\n",
      "Recompensa por acortar distancias: +  0.6080900830472176\n",
      "Penalización por duración del episodio: -  0.48265060204420657\n",
      "Recompensa por acortar distancias: +  0.6080900830472176\n",
      "Penalización por duración del episodio: -  0.4827999894471059\n",
      "Recompensa por acortar distancias: +  0.6177223416874257\n",
      "Penalización por duración del episodio: -  0.48325265318912325\n",
      "Recompensa por acortar distancias: +  0.6201286982715204\n",
      "Penalización por duración del episodio: -  0.48365507382745127\n",
      "Recompensa por acortar distancias: +  0.6255249143649002\n",
      "Penalización por duración del episodio: -  0.48377177497805407\n",
      "Recompensa por acortar distancias: +  0.6276224806221573\n",
      "Penalización por duración del episodio: -  0.48391001454335186\n",
      "Recompensa por acortar distancias: +  0.6276224806221573\n",
      "Penalización por duración del episodio: -  0.4844265008888484\n",
      "Step: 3830, Mean Reward (últimos 10 pasos): 0.1431959867477417\n",
      "Recompensa por acortar distancias: +  0.6300060515390421\n",
      "Penalización por duración del episodio: -  0.484826034192265\n",
      "Recompensa por acortar distancias: +  0.6300060515390421\n",
      "Penalización por duración del episodio: -  0.48493536825604705\n",
      "Recompensa por acortar distancias: +  0.6300060515390421\n",
      "Penalización por duración del episodio: -  0.48520903128473264\n",
      "Recompensa por acortar distancias: +  0.6398980276812294\n",
      "Penalización por duración del episodio: -  0.48530868700037116\n",
      "steer input from model: -0.9 , throttle:  0.7\n",
      "reward: 0.15458934068085822\n",
      "Recompensa por acortar distancias: +  0.6398980276812294\n",
      "Penalización por duración del episodio: -  0.485432707411853\n",
      "Recompensa por acortar distancias: +  0.641839315813006\n",
      "Penalización por duración del episodio: -  0.4855445327806615\n",
      "Recompensa por acortar distancias: +  0.641839315813006\n",
      "Penalización por duración del episodio: -  0.4856409108898201\n",
      "Recompensa por acortar distancias: +  0.641839315813006\n",
      "Penalización por duración del episodio: -  0.485791408902419\n",
      "Recompensa por acortar distancias: +  0.641839315813006\n",
      "Penalización por duración del episodio: -  0.48600806623764914\n",
      "Recompensa por acortar distancias: +  0.641839315813006\n",
      "Penalización por duración del episodio: -  0.4861218345922049\n",
      "Step: 3840, Mean Reward (últimos 10 pasos): 0.15571747720241547\n",
      "Recompensa por acortar distancias: +  0.6481173835182654\n",
      "Penalización por duración del episodio: -  0.48639440919550436\n",
      "Recompensa por acortar distancias: +  0.6501237483072084\n",
      "Penalización por duración del episodio: -  0.48679246063285886\n",
      "Recompensa por acortar distancias: +  0.6517014667977713\n",
      "Penalización por duración del episodio: -  0.4871838574874952\n",
      "Recompensa por acortar distancias: +  0.6517014667977713\n",
      "Penalización por duración del episodio: -  0.4875646372060143\n",
      "Recompensa por acortar distancias: +  0.6609407361831797\n",
      "Penalización por duración del episodio: -  0.48767725071610635\n",
      "Recompensa por acortar distancias: +  0.6609407361831797\n",
      "Penalización por duración del episodio: -  0.4877894008382033\n",
      "Recompensa por acortar distancias: +  0.6634760950347351\n",
      "Penalización por duración del episodio: -  0.4883549235335431\n",
      "Recompensa por acortar distancias: +  0.6634760950347351\n",
      "Penalización por duración del episodio: -  0.4884589968682644\n",
      "Recompensa por acortar distancias: +  0.6634760950347351\n",
      "Penalización por duración del episodio: -  0.48873447729734126\n",
      "Recompensa por acortar distancias: +  0.6708244597735341\n",
      "Penalización por duración del episodio: -  0.4891143419335234\n",
      "Step: 3850, Mean Reward (últimos 10 pasos): 0.1817101240158081\n",
      "Recompensa por acortar distancias: +  0.6721927632556962\n",
      "Penalización por duración del episodio: -  0.4895074574545652\n",
      "Recompensa por acortar distancias: +  0.6721927632556962\n",
      "Penalización por duración del episodio: -  0.4899088318738125\n",
      "Recompensa por acortar distancias: +  0.680388533861789\n",
      "Penalización por duración del episodio: -  0.4900107445082102\n",
      "Recompensa por acortar distancias: +  0.680388533861789\n",
      "Penalización por duración del episodio: -  0.49012752948343097\n",
      "steer input from model: -0.25 , throttle:  0.0\n",
      "reward: 0.19026100437835802\n",
      "Recompensa por acortar distancias: +  0.6828451422498636\n",
      "Penalización por duración del episodio: -  0.4902761382972123\n",
      "Recompensa por acortar distancias: +  0.6828451422498636\n",
      "Penalización por duración del episodio: -  0.49035633009710916\n",
      "Recompensa por acortar distancias: +  0.6828451422498636\n",
      "Penalización por duración del episodio: -  0.49065462122358533\n",
      "Recompensa por acortar distancias: +  0.6828451422498636\n",
      "Penalización por duración del episodio: -  0.490779265199679\n",
      "Recompensa por acortar distancias: +  0.6876451642461382\n",
      "Penalización por duración del episodio: -  0.4910458780782854\n",
      "Recompensa por acortar distancias: +  0.6902758412714821\n",
      "Penalización por duración del episodio: -  0.4914332727374221\n",
      "Step: 3860, Mean Reward (últimos 10 pasos): 0.19884257018566132\n",
      "Recompensa por acortar distancias: +  0.6931560005091679\n",
      "Penalización por duración del episodio: -  0.4918317015974522\n",
      "Recompensa por acortar distancias: +  0.6931560005091679\n",
      "Penalización por duración del episodio: -  0.4919665634186761\n",
      "Recompensa por acortar distancias: +  0.6931560005091679\n",
      "Penalización por duración del episodio: -  0.49210482302637054\n",
      "Recompensa por acortar distancias: +  0.6931560005091679\n",
      "Penalización por duración del episodio: -  0.49259865706181866\n",
      "Recompensa por acortar distancias: +  0.7027858557388017\n",
      "Penalización por duración del episodio: -  0.4929900769213233\n",
      "Recompensa por acortar distancias: +  0.7027858557388017\n",
      "Penalización por duración del episodio: -  0.4933711836618141\n",
      "Recompensa por acortar distancias: +  0.7076604391275841\n",
      "Penalización por duración del episodio: -  0.49373681524317437\n",
      "Recompensa por acortar distancias: +  0.711848426585317\n",
      "Penalización por duración del episodio: -  0.49413361647963533\n",
      "Recompensa por acortar distancias: +  0.7133518798720498\n",
      "Penalización por duración del episodio: -  0.4945328328462244\n",
      "Recompensa por acortar distancias: +  0.7133518798720498\n",
      "Penalización por duración del episodio: -  0.4949170790805201\n",
      "Step: 3870, Mean Reward (últimos 10 pasos): 0.21843479573726654\n",
      "Recompensa por acortar distancias: +  0.7133518798720498\n",
      "Penalización por duración del episodio: -  0.4950417713443467\n",
      "Recompensa por acortar distancias: +  0.7215172541925714\n",
      "Penalización por duración del episodio: -  0.49529917978170945\n",
      "Recompensa por acortar distancias: +  0.7241815617898256\n",
      "Penalización por duración del episodio: -  0.49569865347694647\n",
      "Recompensa por acortar distancias: +  0.7241815617898256\n",
      "Penalización por duración del episodio: -  0.49610825291784677\n",
      "steer input from model: -0.05 , throttle:  1.0\n",
      "reward: 0.22807330887197885\n",
      "Recompensa por acortar distancias: +  0.7310489970804397\n",
      "Penalización por duración del episodio: -  0.49624012643282206\n",
      "Recompensa por acortar distancias: +  0.7325750471800543\n",
      "Penalización por parar muy lejos: -  0.047776167972920495\n",
      "Penalización por duración del episodio: -  0.4964994108444543\n",
      "Recompensa por acortar distancias: +  0.7342878245810884\n",
      "Penalización por parar muy lejos: -  0.048176301713311755\n",
      "Penalización por duración del episodio: -  0.49687762146985737\n",
      "Recompensa por acortar distancias: +  0.7342878245810884\n",
      "Penalización por parar muy lejos: -  0.048176301713311755\n",
      "Penalización por duración del episodio: -  0.49726764299450554\n",
      "Recompensa por acortar distancias: +  0.7342878245810884\n",
      "Penalización por parar muy lejos: -  0.048176301713311755\n",
      "Penalización por duración del episodio: -  0.49765744135170176\n",
      "Recompensa por acortar distancias: +  0.7445461001794271\n",
      "Penalización por duración del episodio: -  0.4980713165097861\n",
      "Step: 3880, Mean Reward (últimos 10 pasos): 0.24647478759288788\n",
      "Recompensa por acortar distancias: +  0.7466669142654626\n",
      "Penalización por duración del episodio: -  0.49847362515633226\n",
      "Recompensa por acortar distancias: +  0.7515948166257898\n",
      "Penalización por parar muy lejos: -  0.05250745815965047\n",
      "Penalización por duración del episodio: -  0.49887626360317394\n",
      "Recompensa por acortar distancias: +  0.7546932396668139\n",
      "Penalización por duración del episodio: -  0.49927619746222573\n",
      "Recompensa por acortar distancias: +  0.7546932396668139\n",
      "Penalización por parar muy lejos: -  0.053342794086522205\n",
      "Penalización por duración del episodio: -  0.4996646822001571\n",
      "Recompensa por acortar distancias: +  0.7546932396668139\n",
      "Penalización por parar muy lejos: -  0.053342794086522205\n",
      "Penalización por duración del episodio: -  0.49979630113774964\n",
      "Penalización por duración del episodio\n",
      "Recompensa por acortar distancias: +  0.9156967383365824\n",
      "Penalización por parar muy lejos: -  0.1659322146146916\n",
      "Penalización por duración del episodio: -  0.2690377810812699\n",
      "Recompensa por acortar distancias: +  0.9156967383365824\n",
      "Penalización por parar muy lejos: -  0.1659322146146916\n",
      "Penalización por duración del episodio: -  0.2691463466649801\n",
      "Recompensa por acortar distancias: +  0.9156967383365824\n",
      "Penalización por duración del episodio: -  0.2692578389969339\n",
      "Recompensa por acortar distancias: +  0.9156967383365824\n",
      "Penalización por duración del episodio: -  0.26959788055820694\n",
      "Step: 3890, Mean Reward (últimos 10 pasos): 0.6460988521575928\n",
      "Recompensa por acortar distancias: +  0.9156963628735477\n",
      "Penalización por duración del episodio: -  0.26991451756849527\n",
      "Recompensa por acortar distancias: +  0.9156963113392873\n",
      "Penalización por duración del episodio: -  0.2702203774780848\n",
      "Recompensa por acortar distancias: +  0.9156963113392873\n",
      "Penalización por parar muy lejos: -  0.16593144908976795\n",
      "Penalización por duración del episodio: -  0.27052875159820744\n",
      "Recompensa por acortar distancias: +  0.9156963113392873\n",
      "Penalización por parar muy lejos: -  0.16593144908976795\n",
      "Penalización por duración del episodio: -  0.2706128668052843\n",
      "Recompensa por acortar distancias: +  0.9156960463054958\n",
      "Penalización por duración del episodio: -  0.2707270151711775\n",
      "Recompensa por acortar distancias: +  0.9156960463054958\n",
      "Penalización por duración del episodio: -  0.2708307223664045\n",
      "Recompensa por acortar distancias: +  0.9156959800469299\n",
      "Penalización por parar muy lejos: -  0.16593085514996583\n",
      "Penalización por duración del episodio: -  0.2711412869804717\n",
      "Recompensa por acortar distancias: +  0.9156959800469299\n",
      "Penalización por parar muy lejos: -  0.16593085514996583\n",
      "Penalización por duración del episodio: -  0.27146090191162003\n",
      "Recompensa por acortar distancias: +  0.9156960021331237\n",
      "Penalización por parar muy lejos: -  0.16593089474589964\n",
      "Penalización por duración del episodio: -  0.27177462830173166\n",
      "Recompensa por acortar distancias: +  0.9156960978399036\n",
      "Penalización por duración del episodio: -  0.27185702319719707\n",
      "Step: 3900, Mean Reward (últimos 10 pasos): 0.6438390612602234\n",
      "Recompensa por acortar distancias: +  0.9156960978399036\n",
      "Penalización por duración del episodio: -  0.2719755416681131\n",
      "Recompensa por acortar distancias: +  0.91569608311579\n",
      "Penalización por duración del episodio: -  0.2720766447204058\n",
      "Recompensa por acortar distancias: +  0.91569608311579\n",
      "Penalización por duración del episodio: -  0.2723774395002149\n",
      "Recompensa por acortar distancias: +  0.91569608311579\n",
      "Penalización por parar muy lejos: -  0.1659310399310551\n",
      "Penalización por duración del episodio: -  0.2726846791033336\n",
      "Recompensa por acortar distancias: +  0.9156961788224862\n",
      "Penalización por duración del episodio: -  0.27300051066850467\n",
      "Recompensa por acortar distancias: +  0.9156963849596507\n",
      "Penalización por duración del episodio: -  0.2730813535807485\n",
      "steer input from model: -0.1 , throttle:  1.0\n",
      "reward: 0.6426150313789022\n",
      "Recompensa por acortar distancias: +  0.9156963849596507\n",
      "Penalización por duración del episodio: -  0.2733190234876326\n",
      "Recompensa por acortar distancias: +  0.9156963849596507\n",
      "Penalización por duración del episodio: -  0.27363780595731035\n",
      "Recompensa por acortar distancias: +  0.9156966499924755\n",
      "Penalización por duración del episodio: -  0.2739567204772047\n",
      "Recompensa por acortar distancias: +  0.915696811956607\n",
      "Penalización por duración del episodio: -  0.27426112646867173\n",
      "Step: 3910, Mean Reward (últimos 10 pasos): 0.6414356827735901\n",
      "Recompensa por acortar distancias: +  0.915696811956607\n",
      "Penalización por parar muy lejos: -  0.16593234660203335\n",
      "Penalización por duración del episodio: -  0.2743248018442218\n",
      "Recompensa por acortar distancias: +  0.915696811956607\n",
      "Penalización por duración del episodio: -  0.27457787615673357\n",
      "Recompensa por acortar distancias: +  0.9156966499924755\n",
      "Penalización por parar muy lejos: -  0.16593205622999252\n",
      "Penalización por duración del episodio: -  0.27489357947427967\n",
      "Recompensa por acortar distancias: +  0.9156967236125705\n",
      "Penalización por parar muy lejos: -  0.16593218821723335\n",
      "Penalización por duración del episodio: -  0.2752094700245219\n",
      "Recompensa por acortar distancias: +  0.9156967236125705\n",
      "Penalización por parar muy lejos: -  0.16593218821723335\n",
      "Penalización por duración del episodio: -  0.2753256626381433\n",
      "Recompensa por acortar distancias: +  0.915696811956607\n",
      "Penalización por duración del episodio: -  0.27551852794988924\n",
      "Recompensa por acortar distancias: +  0.915696811956607\n",
      "Penalización por parar muy lejos: -  0.16593234660203335\n",
      "Penalización por duración del episodio: -  0.27582427198666204\n",
      "Recompensa por acortar distancias: +  0.9156969150245438\n",
      "Penalización por duración del episodio: -  0.275952224719413\n",
      "Recompensa por acortar distancias: +  0.9156970769882131\n",
      "Penalización por parar muy lejos: -  0.16593282175715998\n",
      "Penalización por duración del episodio: -  0.2760457833866222\n",
      "Recompensa por acortar distancias: +  0.9156970769882131\n",
      "Penalización por duración del episodio: -  0.2761614653708408\n",
      "Step: 3920, Mean Reward (últimos 10 pasos): 0.6395356059074402\n",
      "Recompensa por acortar distancias: +  0.9156970769882131\n",
      "Penalización por parar muy lejos: -  0.16593282175715998\n",
      "Penalización por duración del episodio: -  0.2762731014520407\n",
      "Recompensa por acortar distancias: +  0.9156970769882131\n",
      "Penalización por parar muy lejos: -  0.16593282175715998\n",
      "Penalización por duración del episodio: -  0.27635961345174476\n",
      "Recompensa por acortar distancias: +  0.9156970769882131\n",
      "Penalización por parar muy lejos: -  0.16593282175715998\n",
      "Penalización por duración del episodio: -  0.276433409316054\n",
      "Recompensa por acortar distancias: +  0.9156970769882131\n",
      "Penalización por duración del episodio: -  0.2767605397522444\n",
      "Recompensa por acortar distancias: +  0.9156970769882131\n",
      "Penalización por duración del episodio: -  0.2768951908992127\n",
      "Recompensa por acortar distancias: +  0.9156970696262342\n",
      "Penalización por parar muy lejos: -  0.16593280855839176\n",
      "Penalización por duración del episodio: -  0.27697857162862083\n",
      "steer input from model: -0.9 , throttle:  0.0\n",
      "reward: 0.4727856894392216\n",
      "Recompensa por acortar distancias: +  0.9156970696262342\n",
      "Penalización por parar muy lejos: -  0.16593280855839176\n",
      "Penalización por duración del episodio: -  0.277090960790709\n",
      "Recompensa por acortar distancias: +  0.9156970696262342\n",
      "Penalización por parar muy lejos: -  0.16593280855839176\n",
      "Penalización por duración del episodio: -  0.2771908386370712\n",
      "Recompensa por acortar distancias: +  0.9156970696262342\n",
      "Penalización por duración del episodio: -  0.27737803978297254\n",
      "Recompensa por acortar distancias: +  0.9156970696262342\n",
      "Penalización por duración del episodio: -  0.2776971935582697\n",
      "Step: 3930, Mean Reward (últimos 10 pasos): 0.6379998922348022\n",
      "Recompensa por acortar distancias: +  0.9156969960064137\n",
      "Penalización por parar muy lejos: -  0.16593267657075564\n",
      "Penalización por duración del episodio: -  0.2777919921898666\n",
      "Recompensa por acortar distancias: +  0.9156969591964816\n",
      "Penalización por duración del episodio: -  0.27789789596193104\n",
      "Recompensa por acortar distancias: +  0.9156969960064137\n",
      "Penalización por duración del episodio: -  0.27801517587446806\n",
      "Recompensa por acortar distancias: +  0.9156969960064137\n",
      "Penalización por duración del episodio: -  0.2783152800543776\n",
      "Recompensa por acortar distancias: +  0.9156969960064137\n",
      "Penalización por parar muy lejos: -  0.16593267657075564\n",
      "Penalización por duración del episodio: -  0.2786313441664747\n",
      "Recompensa por acortar distancias: +  0.9156969960064137\n",
      "Penalización por duración del episodio: -  0.2787121656052293\n",
      "Recompensa por acortar distancias: +  0.915696701526548\n",
      "Penalización por parar muy lejos: -  0.16593214862105227\n",
      "Penalización por duración del episodio: -  0.27895368037683105\n",
      "Recompensa por acortar distancias: +  0.9156967530605918\n",
      "Penalización por parar muy lejos: -  0.16593224101215326\n",
      "Penalización por duración del episodio: -  0.2792682453988543\n",
      "Recompensa por acortar distancias: +  0.9156967530605918\n",
      "Penalización por parar muy lejos: -  0.16593224101215326\n",
      "Penalización por duración del episodio: -  0.27938882232760653\n",
      "Recompensa por acortar distancias: +  0.9156967530605918\n",
      "Penalización por parar muy lejos: -  0.16593224101215326\n",
      "Penalización por duración del episodio: -  0.2795359978607777\n",
      "Step: 3940, Mean Reward (últimos 10 pasos): 0.47022852301597595\n",
      "Recompensa por acortar distancias: +  0.9156966499924755\n",
      "Penalización por duración del episodio: -  0.2798933078971855\n",
      "Recompensa por acortar distancias: +  0.9156969150245438\n",
      "Penalización por duración del episodio: -  0.2802261930634537\n",
      "Recompensa por acortar distancias: +  0.9156969150245438\n",
      "Penalización por parar muy lejos: -  0.1659325313844531\n",
      "Penalización por duración del episodio: -  0.2803322653924073\n",
      "Recompensa por acortar distancias: +  0.9156969150245438\n",
      "Penalización por duración del episodio: -  0.28054422370608567\n",
      "Recompensa por acortar distancias: +  0.9156969150245438\n",
      "Penalización por duración del episodio: -  0.28065517802137274\n",
      "Recompensa por acortar distancias: +  0.9156970401783131\n",
      "Penalización por duración del episodio: -  0.2808544855178336\n",
      "steer input from model: -0.9 , throttle:  1.0\n",
      "reward: 0.6348425546604795\n",
      "Recompensa por acortar distancias: +  0.9156971653319136\n",
      "Penalización por duración del episodio: -  0.2809552890388173\n",
      "Recompensa por acortar distancias: +  0.9156971653319136\n",
      "Penalización por duración del episodio: -  0.28107625248638\n",
      "Recompensa por acortar distancias: +  0.9156971653319136\n",
      "Penalización por parar muy lejos: -  0.16593298014244443\n",
      "Penalización por duración del episodio: -  0.28148118617679857\n",
      "Recompensa por acortar distancias: +  0.9156971358840228\n",
      "Penalización por duración del episodio: -  0.28160222466909934\n",
      "Step: 3950, Mean Reward (últimos 10 pasos): 0.6340948939323425\n",
      "Recompensa por acortar distancias: +  0.9156971358840228\n",
      "Penalización por duración del episodio: -  0.28180289183671414\n",
      "Recompensa por acortar distancias: +  0.915697194779795\n",
      "Penalización por duración del episodio: -  0.2821158974527765\n",
      "Recompensa por acortar distancias: +  0.915697194779795\n",
      "Penalización por parar muy lejos: -  0.16593303293756617\n",
      "Penalización por duración del episodio: -  0.28242298725589565\n",
      "Recompensa por acortar distancias: +  0.915697194779795\n",
      "Penalización por duración del episodio: -  0.28274630792594724\n",
      "Recompensa por acortar distancias: +  0.9156970769882131\n",
      "Penalización por duración del episodio: -  0.2830588065633007\n",
      "Recompensa por acortar distancias: +  0.9156972389515999\n",
      "Penalización por parar muy lejos: -  0.16593311213027395\n",
      "Penalización por duración del episodio: -  0.2833669775571034\n",
      "Recompensa por acortar distancias: +  0.9156972389515999\n",
      "Penalización por duración del episodio: -  0.2834312150578408\n",
      "Recompensa por acortar distancias: +  0.9156972389515999\n",
      "Penalización por parar muy lejos: -  0.16593311213027395\n",
      "Penalización por duración del episodio: -  0.2836838878402128\n",
      "Recompensa por acortar distancias: +  0.9156972683994581\n",
      "Penalización por parar muy lejos: -  0.16593316492542934\n",
      "Penalización por duración del episodio: -  0.28400803220400295\n",
      "Recompensa por acortar distancias: +  0.9156974230005601\n",
      "Penalización por duración del episodio: -  0.2841011410387989\n",
      "Step: 3960, Mean Reward (últimos 10 pasos): 0.6315962672233582\n",
      "Recompensa por acortar distancias: +  0.9156974230005601\n",
      "Penalización por duración del episodio: -  0.2843278201151526\n",
      "Recompensa por acortar distancias: +  0.9156974230005601\n",
      "Penalización por duración del episodio: -  0.28441025383576646\n",
      "Recompensa por acortar distancias: +  0.9156974230005601\n",
      "Penalización por parar muy lejos: -  0.1659334421002157\n",
      "Penalización por duración del episodio: -  0.28464827644410934\n",
      "Recompensa por acortar distancias: +  0.9156974230005601\n",
      "Penalización por parar muy lejos: -  0.1659334421002157\n",
      "Penalización por duración del episodio: -  0.2847270952804207\n",
      "Recompensa por acortar distancias: +  0.9156974230005601\n",
      "Penalización por parar muy lejos: -  0.1659334421002157\n",
      "Penalización por duración del episodio: -  0.2849630282008683\n",
      "Recompensa por acortar distancias: +  0.9156973125712279\n",
      "Penalización por parar muy lejos: -  0.16593324411818758\n",
      "Penalización por duración del episodio: -  0.2850443337308347\n",
      "steer input from model: -0.1 , throttle:  0.0\n",
      "reward: 0.4647197347222056\n",
      "Recompensa por acortar distancias: +  0.9156973125712279\n",
      "Penalización por duración del episodio: -  0.2852911049606764\n",
      "Recompensa por acortar distancias: +  0.9156973125712279\n",
      "Penalización por parar muy lejos: -  0.16593324411818758\n",
      "Penalización por duración del episodio: -  0.2856026839589792\n",
      "Recompensa por acortar distancias: +  0.9156973125712279\n",
      "Penalización por duración del episodio: -  0.28570497686681595\n",
      "Recompensa por acortar distancias: +  0.9156973125712279\n",
      "Penalización por duración del episodio: -  0.2858075545532054\n",
      "Step: 3970, Mean Reward (últimos 10 pasos): 0.6298897862434387\n",
      "Recompensa por acortar distancias: +  0.9156972389515999\n",
      "Penalización por parar muy lejos: -  0.16593311213027395\n",
      "Penalización por duración del episodio: -  0.2859111035266549\n",
      "Recompensa por acortar distancias: +  0.9156972389515999\n",
      "Penalización por duración del episodio: -  0.2860291159304524\n",
      "Recompensa por acortar distancias: +  0.9156971506079694\n",
      "Penalización por parar muy lejos: -  0.16593295374488862\n",
      "Penalización por duración del episodio: -  0.28611633563298244\n",
      "Recompensa por acortar distancias: +  0.9156971506079694\n",
      "Penalización por duración del episodio: -  0.2862573612067619\n",
      "Recompensa por acortar distancias: +  0.915697025454349\n",
      "Penalización por duración del episodio: -  0.2865794480174033\n",
      "Recompensa por acortar distancias: +  0.915697025454349\n",
      "Penalización por duración del episodio: -  0.28689154245963167\n",
      "Recompensa por acortar distancias: +  0.9156965763723223\n",
      "Penalización por duración del episodio: -  0.2870087625736453\n",
      "Recompensa por acortar distancias: +  0.9156965763723223\n",
      "Penalización por duración del episodio: -  0.28710370016905723\n",
      "Recompensa por acortar distancias: +  0.9156964880280614\n",
      "Penalización por duración del episodio: -  0.28750760779010576\n",
      "Recompensa por acortar distancias: +  0.9156964880280614\n",
      "Penalización por parar muy lejos: -  0.16593176585835873\n",
      "Penalización por duración del episodio: -  0.287819752994212\n",
      "Step: 3980, Mean Reward (últimos 10 pasos): 0.46194496750831604\n",
      "Recompensa por acortar distancias: +  0.9156965322002024\n",
      "Penalización por duración del episodio: -  0.28793703791509245\n",
      "Recompensa por acortar distancias: +  0.9156964438558993\n",
      "Penalización por duración del episodio: -  0.2881386383532858\n",
      "Recompensa por acortar distancias: +  0.9156964733040096\n",
      "Penalización por duración del episodio: -  0.2882242998336637\n",
      "Recompensa por acortar distancias: +  0.9156964733040096\n",
      "Penalización por duración del episodio: -  0.28846125727629307\n",
      "Recompensa por acortar distancias: +  0.9156964733040096\n",
      "Penalización por duración del episodio: -  0.2885537546359643\n",
      "Recompensa por acortar distancias: +  0.9156964733040096\n",
      "Penalización por parar muy lejos: -  0.16593173946095768\n",
      "Penalización por duración del episodio: -  0.2887720595278977\n",
      "steer input from model: 0.1 , throttle:  0.0\n",
      "reward: 0.4609926743151543\n",
      "Recompensa por acortar distancias: +  0.9156964733040096\n",
      "Penalización por parar muy lejos: -  0.16593173946095768\n",
      "Penalización por duración del episodio: -  0.28907998351333847\n",
      "Recompensa por acortar distancias: +  0.9156966058203905\n",
      "Penalización por parar muy lejos: -  0.16593197703768842\n",
      "Penalización por duración del episodio: -  0.2891819591394736\n",
      "Recompensa por acortar distancias: +  0.9156966058203905\n",
      "Penalización por parar muy lejos: -  0.16593197703768842\n",
      "Penalización por duración del episodio: -  0.28926944192039916\n",
      "Recompensa por acortar distancias: +  0.9156966058203905\n",
      "Penalización por duración del episodio: -  0.2893937798396339\n",
      "Step: 3990, Mean Reward (últimos 10 pasos): 0.6263028383255005\n",
      "Recompensa por acortar distancias: +  0.9156966058203905\n",
      "Penalización por duración del episodio: -  0.28949945985362857\n",
      "Recompensa por acortar distancias: +  0.9156966058203905\n",
      "Penalización por parar muy lejos: -  0.16593197703768842\n",
      "Penalización por duración del episodio: -  0.28971825264066725\n",
      "Recompensa por acortar distancias: +  0.9156966205444212\n",
      "Penalización por parar muy lejos: -  0.16593200343511977\n",
      "Penalización por duración del episodio: -  0.28981284380081734\n",
      "Recompensa por acortar distancias: +  0.9156966720785101\n",
      "Penalización por parar muy lejos: -  0.16593209582615595\n",
      "Penalización por duración del episodio: -  0.2900262439363813\n",
      "Recompensa por acortar distancias: +  0.9156967972326069\n",
      "Penalización por duración del episodio: -  0.29034221991810405\n",
      "Recompensa por acortar distancias: +  0.9156967972326069\n",
      "Penalización por parar muy lejos: -  0.16593232020455828\n",
      "Penalización por duración del episodio: -  0.29066575795460947\n",
      "Recompensa por acortar distancias: +  0.9156967972326069\n",
      "Penalización por parar muy lejos: -  0.16593232020455828\n",
      "Penalización por duración del episodio: -  0.29098775263557447\n",
      "Recompensa por acortar distancias: +  0.9156966868025304\n",
      "Penalización por parar muy lejos: -  0.16593212222360243\n",
      "Penalización por duración del episodio: -  0.29131573612365613\n",
      "Recompensa por acortar distancias: +  0.9156966868025304\n",
      "Penalización por duración del episodio: -  0.2916485129808046\n",
      "Recompensa por acortar distancias: +  0.9156969150245438\n",
      "Penalización por parar muy lejos: -  0.1659325313844531\n",
      "Penalización por duración del episodio: -  0.2919849930934711\n",
      "Step: 4000, Mean Reward (últimos 10 pasos): 0.4577793776988983\n",
      "Recompensa por acortar distancias: +  0.9156969886444285\n",
      "Penalización por duración del episodio: -  0.2921060843423626\n",
      "Recompensa por acortar distancias: +  0.9156970107303826\n",
      "Penalización por duración del episodio: -  0.29220928041129424\n",
      "Recompensa por acortar distancias: +  0.9156970107303826\n",
      "Penalización por duración del episodio: -  0.2926313643170727\n",
      "Recompensa por acortar distancias: +  0.9156970107303826\n",
      "Penalización por parar muy lejos: -  0.16593270296827617\n",
      "Penalización por duración del episodio: -  0.29273211718716996\n",
      "Recompensa por acortar distancias: +  0.9156970107303826\n",
      "Penalización por parar muy lejos: -  0.16593270296827617\n",
      "Penalización por duración del episodio: -  0.29294333326323485\n",
      "Recompensa por acortar distancias: +  0.9156970107303826\n",
      "Penalización por duración del episodio: -  0.293087962558935\n",
      "steer input from model: 0.05 , throttle:  1.0\n",
      "reward: 0.6226090481714476\n",
      "Recompensa por acortar distancias: +  0.9156969960064137\n",
      "Penalización por duración del episodio: -  0.29327139854277307\n",
      "Recompensa por acortar distancias: +  0.9156971506079694\n",
      "Penalización por parar muy lejos: -  0.16593295374488862\n",
      "Penalización por duración del episodio: -  0.2935870894211377\n",
      "Recompensa por acortar distancias: +  0.9156971506079694\n",
      "Penalización por parar muy lejos: -  0.16593295374488862\n",
      "Penalización por duración del episodio: -  0.2939205288070928\n",
      "Recompensa por acortar distancias: +  0.915697194779795\n",
      "Penalización por parar muy lejos: -  0.16593303293756617\n",
      "Penalización por duración del episodio: -  0.2940348637205297\n",
      "Step: 4010, Mean Reward (últimos 10 pasos): 0.45572930574417114\n",
      "Recompensa por acortar distancias: +  0.915697194779795\n",
      "Penalización por parar muy lejos: -  0.16593303293756617\n",
      "Penalización por duración del episodio: -  0.29424905972338555\n",
      "Recompensa por acortar distancias: +  0.9156971800558555\n",
      "Penalización por duración del episodio: -  0.29435321804366893\n",
      "Recompensa por acortar distancias: +  0.9156971800558555\n",
      "Penalización por parar muy lejos: -  0.1659330065400036\n",
      "Penalización por duración del episodio: -  0.2945772249908643\n",
      "Recompensa por acortar distancias: +  0.9156971800558555\n",
      "Penalización por duración del episodio: -  0.2949103527069673\n",
      "Recompensa por acortar distancias: +  0.9156971800558555\n",
      "Penalización por duración del episodio: -  0.2952356976201808\n",
      "Recompensa por acortar distancias: +  0.9156967530605918\n",
      "Penalización por duración del episodio: -  0.29531871368552876\n",
      "Recompensa por acortar distancias: +  0.9156967530605918\n",
      "Penalización por duración del episodio: -  0.29539158530936366\n",
      "Recompensa por acortar distancias: +  0.9156967530605918\n",
      "Penalización por duración del episodio: -  0.29548494034976364\n",
      "Recompensa por acortar distancias: +  0.9156967530605918\n",
      "Penalización por duración del episodio: -  0.29562073299277253\n",
      "Recompensa por acortar distancias: +  0.9156967972326069\n",
      "Penalización por parar muy lejos: -  0.16593232020455828\n",
      "Penalización por duración del episodio: -  0.2958788914041914\n",
      "Step: 4020, Mean Reward (últimos 10 pasos): 0.45388558506965637\n",
      "Recompensa por acortar distancias: +  0.915696811956607\n",
      "Penalización por parar muy lejos: -  0.16593234660203335\n",
      "Penalización por duración del episodio: -  0.2961942644400701\n",
      "Recompensa por acortar distancias: +  0.9156969150245438\n",
      "Penalización por duración del episodio: -  0.29629997555300025\n",
      "Recompensa por acortar distancias: +  0.9156968414046006\n",
      "Penalización por parar muy lejos: -  0.1659323993969936\n",
      "Penalización por duración del episodio: -  0.2964138679572121\n",
      "Recompensa por acortar distancias: +  0.9156968414046006\n",
      "Penalización por parar muy lejos: -  0.1659323993969936\n",
      "Penalización por duración del episodio: -  0.2965285267277119\n",
      "Recompensa por acortar distancias: +  0.9156968414046006\n",
      "Penalización por parar muy lejos: -  0.1659323993969936\n",
      "Penalización por duración del episodio: -  0.2968505607038895\n",
      "Recompensa por acortar distancias: +  0.9156968414046006\n",
      "Penalización por duración del episodio: -  0.29719132623656114\n",
      "steer input from model: 0.25 , throttle:  0.7\n",
      "reward: 0.6185055151680394\n",
      "Recompensa por acortar distancias: +  0.9156968855765736\n",
      "Penalización por duración del episodio: -  0.29727792754568616\n",
      "Recompensa por acortar distancias: +  0.9156968855765736\n",
      "Penalización por parar muy lejos: -  0.1659324785894592\n",
      "Penalización por duración del episodio: -  0.29751509607732324\n",
      "Recompensa por acortar distancias: +  0.9156968266806051\n",
      "Penalización por duración del episodio: -  0.29783004944102265\n",
      "Recompensa por acortar distancias: +  0.9156968266806051\n",
      "Penalización por duración del episodio: -  0.2979241335352349\n",
      "Step: 4030, Mean Reward (últimos 10 pasos): 0.6177726984024048\n",
      "Recompensa por acortar distancias: +  0.9156969444725047\n",
      "Penalización por duración del episodio: -  0.2981646821884788\n",
      "Recompensa por acortar distancias: +  0.9156970328163313\n",
      "Penalización por parar muy lejos: -  0.1659327425645632\n",
      "Penalización por duración del episodio: -  0.2982892377290428\n",
      "Recompensa por acortar distancias: +  0.9156970328163313\n",
      "Penalización por duración del episodio: -  0.29849456364382837\n",
      "Recompensa por acortar distancias: +  0.9156971064361227\n",
      "Penalización por duración del episodio: -  0.2986069692309362\n",
      "Recompensa por acortar distancias: +  0.9156971064361227\n",
      "Penalización por duración del episodio: -  0.2988222967814364\n",
      "Recompensa por acortar distancias: +  0.9156971064361227\n",
      "Penalización por parar muy lejos: -  0.16593287455224134\n",
      "Penalización por duración del episodio: -  0.2991506112066011\n",
      "Recompensa por acortar distancias: +  0.9156971064361227\n",
      "Penalización por parar muy lejos: -  0.16593287455224134\n",
      "Penalización por duración del episodio: -  0.2992466445388022\n",
      "Recompensa por acortar distancias: +  0.9156969812824427\n",
      "Penalización por duración del episodio: -  0.2994826435703655\n",
      "Recompensa por acortar distancias: +  0.9156970328163313\n",
      "Penalización por parar muy lejos: -  0.1659327425645632\n",
      "Penalización por duración del episodio: -  0.299620397640496\n",
      "Recompensa por acortar distancias: +  0.9156970328163313\n",
      "Penalización por parar muy lejos: -  0.1659327425645632\n",
      "Penalización por duración del episodio: -  0.2997250493236061\n",
      "Step: 4040, Mean Reward (últimos 10 pasos): 0.45003923773765564\n",
      "Recompensa por acortar distancias: +  0.9156970328163313\n",
      "Penalización por duración del episodio: -  0.2998437365622977\n",
      "Recompensa por acortar distancias: +  0.9156970328163313\n",
      "Penalización por duración del episodio: -  0.29995016002104374\n",
      "Recompensa por acortar distancias: +  0.9156970328163313\n",
      "Penalización por parar muy lejos: -  0.1659327425645632\n",
      "Penalización por duración del episodio: -  0.30015194326245287\n",
      "Recompensa por acortar distancias: +  0.9156969960064137\n",
      "Penalización por duración del episodio: -  0.30048047612428413\n",
      "Recompensa por acortar distancias: +  0.9156971064361227\n",
      "Penalización por parar muy lejos: -  0.16593287455224134\n",
      "Penalización por duración del episodio: -  0.30082773787877903\n",
      "Recompensa por acortar distancias: +  0.9156971064361227\n",
      "Penalización por duración del episodio: -  0.30115967772487967\n",
      "steer input from model: 0.25 , throttle:  1.0\n",
      "reward: 0.6145374287112431\n",
      "Recompensa por acortar distancias: +  0.9156971064361227\n",
      "Penalización por parar muy lejos: -  0.16593287455224134\n",
      "Penalización por duración del episodio: -  0.30125848275716727\n",
      "Recompensa por acortar distancias: +  0.9156969665584692\n",
      "Penalización por parar muy lejos: -  0.1659326237757248\n",
      "Penalización por duración del episodio: -  0.30147828955363587\n",
      "Recompensa por acortar distancias: +  0.9156969591964816\n",
      "Penalización por duración del episodio: -  0.30182246394622303\n",
      "Recompensa por acortar distancias: +  0.9156969591964816\n",
      "Penalización por duración del episodio: -  0.3019256838715822\n",
      "Step: 4050, Mean Reward (últimos 10 pasos): 0.6137712597846985\n",
      "Recompensa por acortar distancias: +  0.9156971064361227\n",
      "Penalización por parar muy lejos: -  0.16593287455224134\n",
      "Penalización por duración del episodio: -  0.30214124759061245\n",
      "Recompensa por acortar distancias: +  0.9156971211600738\n",
      "Penalización por duración del episodio: -  0.3022537760520379\n",
      "Recompensa por acortar distancias: +  0.9156971506079694\n",
      "Penalización por duración del episodio: -  0.302349249294193\n",
      "Recompensa por acortar distancias: +  0.9156971506079694\n",
      "Penalización por parar muy lejos: -  0.16593295374488862\n",
      "Penalización por duración del episodio: -  0.30247047352996154\n",
      "Recompensa por acortar distancias: +  0.9156971506079694\n",
      "Penalización por duración del episodio: -  0.3026070711161278\n",
      "Recompensa por acortar distancias: +  0.9156972978473069\n",
      "Penalización por parar muy lejos: -  0.16593321772059813\n",
      "Penalización por duración del episodio: -  0.3026924371768407\n",
      "Recompensa por acortar distancias: +  0.9156972978473069\n",
      "Penalización por duración del episodio: -  0.303151770618781\n",
      "Recompensa por acortar distancias: +  0.9156972978473069\n",
      "Penalización por duración del episodio: -  0.303245570584235\n",
      "Recompensa por acortar distancias: +  0.9156972978473069\n",
      "Penalización por parar muy lejos: -  0.16593321772059813\n",
      "Penalización por duración del episodio: -  0.30348969752871807\n",
      "Recompensa por acortar distancias: +  0.9156972978473069\n",
      "Penalización por parar muy lejos: -  0.16593321772059813\n",
      "Penalización por duración del episodio: -  0.30362204331315357\n",
      "Step: 4060, Mean Reward (últimos 10 pasos): 0.4461420476436615\n",
      "Recompensa por acortar distancias: +  0.9156969297485253\n",
      "Penalización por parar muy lejos: -  0.16593255778195506\n",
      "Penalización por duración del episodio: -  0.3038076856561333\n",
      "Recompensa por acortar distancias: +  0.9156969591964816\n",
      "Penalización por parar muy lejos: -  0.16593261057696915\n",
      "Penalización por duración del episodio: -  0.30413662918112255\n",
      "Recompensa por acortar distancias: +  0.9156969591964816\n",
      "Penalización por parar muy lejos: -  0.16593261057696915\n",
      "Penalización por duración del episodio: -  0.3044587147848583\n",
      "Recompensa por acortar distancias: +  0.9156969591964816\n",
      "Penalización por parar muy lejos: -  0.16593261057696915\n",
      "Penalización por duración del episodio: -  0.3045220864557117\n",
      "Recompensa por acortar distancias: +  0.9156969591964816\n",
      "Penalización por duración del episodio: -  0.30462775605188613\n",
      "Recompensa por acortar distancias: +  0.9156969591964816\n",
      "Penalización por duración del episodio: -  0.3047894337776162\n",
      "steer input from model: -0.9 , throttle:  0.7\n",
      "reward: 0.6109075254188654\n",
      "Recompensa por acortar distancias: +  0.9156968414046006\n",
      "Penalización por duración del episodio: -  0.3051154561515851\n",
      "Recompensa por acortar distancias: +  0.9156967972326069\n",
      "Penalización por parar muy lejos: -  0.16593232020455828\n",
      "Penalización por duración del episodio: -  0.3054278457011235\n",
      "Recompensa por acortar distancias: +  0.9156967972326069\n",
      "Penalización por duración del episodio: -  0.305753284000689\n",
      "Recompensa por acortar distancias: +  0.9156967236125705\n",
      "Penalización por duración del episodio: -  0.30584011009816814\n",
      "Step: 4070, Mean Reward (últimos 10 pasos): 0.6098566055297852\n",
      "Recompensa por acortar distancias: +  0.9156967972326069\n",
      "Penalización por duración del episodio: -  0.306094128365863\n",
      "Recompensa por acortar distancias: +  0.9156967972326069\n",
      "Penalización por duración del episodio: -  0.3064359855951824\n",
      "Recompensa por acortar distancias: +  0.915696870852585\n",
      "Penalización por parar muy lejos: -  0.1659324521919673\n",
      "Penalización por duración del episodio: -  0.3065362945356039\n",
      "Recompensa por acortar distancias: +  0.9156969003005598\n",
      "Penalización por parar muy lejos: -  0.1659325049869545\n",
      "Penalización por duración del episodio: -  0.30675805371918663\n",
      "Recompensa por acortar distancias: +  0.9156970328163313\n",
      "Penalización por parar muy lejos: -  0.1659327425645632\n",
      "Penalización por duración del episodio: -  0.30710260727322186\n",
      "Recompensa por acortar distancias: +  0.9156969591964816\n",
      "Penalización por duración del episodio: -  0.3074336393836133\n",
      "Recompensa por acortar distancias: +  0.9156969591964816\n",
      "Penalización por parar muy lejos: -  0.16593261057696915\n",
      "Penalización por duración del episodio: -  0.30776568761307177\n",
      "Recompensa por acortar distancias: +  0.915696870852585\n",
      "Penalización por parar muy lejos: -  0.1659324521919673\n",
      "Penalización por duración del episodio: -  0.3078519224148125\n",
      "Recompensa por acortar distancias: +  0.915696870852585\n",
      "Penalización por duración del episodio: -  0.30796343897949024\n",
      "Recompensa por acortar distancias: +  0.9156968561285941\n",
      "Penalización por duración del episodio: -  0.30805168652159676\n",
      "Step: 4080, Mean Reward (últimos 10 pasos): 0.6076451539993286\n",
      "Recompensa por acortar distancias: +  0.9156968561285941\n",
      "Penalización por duración del episodio: -  0.30843331037033106\n",
      "Recompensa por acortar distancias: +  0.9156970107303826\n",
      "Penalización por parar muy lejos: -  0.16593270296827617\n",
      "Penalización por duración del episodio: -  0.308762573063738\n",
      "Recompensa por acortar distancias: +  0.9156971211600738\n",
      "Penalización por duración del episodio: -  0.3088816420037742\n",
      "Recompensa por acortar distancias: +  0.9156971800558555\n",
      "Penalización por duración del episodio: -  0.3090937358197637\n",
      "Recompensa por acortar distancias: +  0.915697194779795\n",
      "Penalización por parar muy lejos: -  0.16593303293756617\n",
      "Penalización por duración del episodio: -  0.30918271761262484\n",
      "Recompensa por acortar distancias: +  0.915697194779795\n",
      "Penalización por duración del episodio: -  0.30941965380726255\n",
      "steer input from model: -0.9 , throttle:  0.7\n",
      "reward: 0.6062775409725325\n",
      "Recompensa por acortar distancias: +  0.915697194779795\n",
      "Penalización por duración del episodio: -  0.3095049015866454\n",
      "Recompensa por acortar distancias: +  0.915697194779795\n",
      "Penalización por parar muy lejos: -  0.16593303293756617\n",
      "Penalización por duración del episodio: -  0.3097342463213517\n",
      "Recompensa por acortar distancias: +  0.915697194779795\n",
      "Penalización por duración del episodio: -  0.3098365240421866\n",
      "Recompensa por acortar distancias: +  0.9156970549022747\n",
      "Penalización por parar muy lejos: -  0.1659327821608578\n",
      "Penalización por duración del episodio: -  0.31007230315808393\n",
      "Step: 4090, Mean Reward (últimos 10 pasos): 0.439691960811615\n",
      "Recompensa por acortar distancias: +  0.915697018092366\n",
      "Penalización por parar muy lejos: -  0.16593271616703767\n",
      "Penalización por duración del episodio: -  0.31040957296364907\n",
      "Recompensa por acortar distancias: +  0.915697018092366\n",
      "Penalización por duración del episodio: -  0.31049502699711984\n",
      "Recompensa por acortar distancias: +  0.915697018092366\n",
      "Penalización por duración del episodio: -  0.31059217948240836\n",
      "Recompensa por acortar distancias: +  0.9156969960064137\n",
      "Penalización por duración del episodio: -  0.31073972167551167\n",
      "Recompensa por acortar distancias: +  0.9156969960064137\n",
      "Penalización por duración del episodio: -  0.31107288355025836\n",
      "Recompensa por acortar distancias: +  0.915697194779795\n",
      "Penalización por duración del episodio: -  0.3114136850441271\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 777          |\n",
      "|    ep_rew_mean          | 270          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 52           |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 78           |\n",
      "|    total_timesteps      | 4096         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0006492736 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.5          |\n",
      "|    entropy_loss         | -3.99        |\n",
      "|    explained_variance   | 0.116        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 16.7         |\n",
      "|    n_updates            | 60           |\n",
      "|    policy_gradient_loss | -0.0015      |\n",
      "|    value_loss           | 34.7         |\n",
      "------------------------------------------\n",
      "Recompensa por acortar distancias: +  0.4447682398190926\n",
      "Penalización por duración del episodio: -  0.3504919624122777\n",
      "Recompensa por acortar distancias: +  0.4369536696830981\n",
      "Penalización por duración del episodio: -  0.3505827813549251\n",
      "Recompensa por acortar distancias: +  0.4369536696830981\n",
      "Penalización por duración del episodio: -  0.35084559955775746\n",
      "Recompensa por acortar distancias: +  0.4328878166444362\n",
      "Penalización por duración del episodio: -  0.3509708268649823\n",
      "Step: 4100, Mean Reward (últimos 10 pasos): 0.08191698789596558\n",
      "Recompensa por acortar distancias: +  0.4312879216392449\n",
      "Penalización por duración del episodio: -  0.3511909366877591\n",
      "Recompensa por acortar distancias: +  0.4312879216392449\n",
      "Penalización por duración del episodio: -  0.3515437234040602\n",
      "Recompensa por acortar distancias: +  0.4312879216392449\n",
      "Penalización por duración del episodio: -  0.3519095103501173\n",
      "Recompensa por acortar distancias: +  0.4229851339831591\n",
      "Penalización por duración del episodio: -  0.3522602061583547\n",
      "Recompensa por acortar distancias: +  0.42147813657951083\n",
      "Penalización por duración del episodio: -  0.35235260578500244\n",
      "Recompensa por acortar distancias: +  0.42147813657951083\n",
      "Penalización por duración del episodio: -  0.3526206946539182\n",
      "steer input from model: -0.1 , throttle:  1.0\n",
      "reward: 0.06885744192559262\n",
      "Recompensa por acortar distancias: +  0.41827465100840083\n",
      "Penalización por duración del episodio: -  0.35297815473635713\n",
      "Recompensa por acortar distancias: +  0.41657066276940247\n",
      "Penalización por duración del episodio: -  0.3533510165405467\n",
      "Recompensa por acortar distancias: +  0.4160061607530036\n",
      "Penalización por duración del episodio: -  0.3537045994550061\n",
      "Recompensa por acortar distancias: +  0.4160061607530036\n",
      "Penalización por duración del episodio: -  0.3540650056366994\n",
      "Step: 4110, Mean Reward (últimos 10 pasos): 0.061941154301166534\n",
      "Recompensa por acortar distancias: +  0.4133529237292992\n",
      "Penalización por duración del episodio: -  0.3544347915667564\n",
      "Recompensa por acortar distancias: +  0.41301079529774753\n",
      "Penalización por duración del episodio: -  0.35478199270561944\n",
      "Recompensa por acortar distancias: +  0.41301079529774753\n",
      "Penalización por duración del episodio: -  0.3551517062177103\n",
      "Recompensa por acortar distancias: +  0.41261076929782453\n",
      "Penalización por duración del episodio: -  0.35551463861343924\n",
      "Recompensa por acortar distancias: +  0.41285730296292233\n",
      "Penalización por duración del episodio: -  0.35586573563402496\n",
      "Recompensa por acortar distancias: +  0.41285730296292233\n",
      "Penalización por duración del episodio: -  0.3562335655835908\n",
      "Recompensa por acortar distancias: +  0.41285730296292233\n",
      "Penalización por duración del episodio: -  0.356585871392867\n",
      "Recompensa por acortar distancias: +  0.4152204230501137\n",
      "Penalización por duración del episodio: -  0.35667474895266493\n",
      "Recompensa por acortar distancias: +  0.4152204230501137\n",
      "Penalización por duración del episodio: -  0.35678576266196643\n",
      "Recompensa por acortar distancias: +  0.4152204230501137\n",
      "Penalización por duración del episodio: -  0.35694633327761666\n",
      "Step: 4120, Mean Reward (últimos 10 pasos): 0.05827409029006958\n",
      "Recompensa por acortar distancias: +  0.4152204230501137\n",
      "Penalización por duración del episodio: -  0.3572910031612042\n",
      "Recompensa por acortar distancias: +  0.41816770058714736\n",
      "Penalización por duración del episodio: -  0.35739552587706125\n",
      "Recompensa por acortar distancias: +  0.41904139540784346\n",
      "Penalización por duración del episodio: -  0.3575453471751202\n",
      "Recompensa por acortar distancias: +  0.41904139540784346\n",
      "Penalización por duración del episodio: -  0.35765990458399627\n",
      "Recompensa por acortar distancias: +  0.42001527654966725\n",
      "Penalización por duración del episodio: -  0.3580252264648261\n",
      "Recompensa por acortar distancias: +  0.42107877114513687\n",
      "Penalización por duración del episodio: -  0.3581210753799419\n",
      "steer input from model: -0.25 , throttle:  0.0\n",
      "reward: 0.06295769576519494\n",
      "Recompensa por acortar distancias: +  0.42107877114513687\n",
      "Penalización por duración del episodio: -  0.35838884929745934\n",
      "Recompensa por acortar distancias: +  0.42107877114513687\n",
      "Penalización por duración del episodio: -  0.35849462709840757\n",
      "Recompensa por acortar distancias: +  0.42107877114513687\n",
      "Penalización por duración del episodio: -  0.35874463825990754\n",
      "Recompensa por acortar distancias: +  0.42636522095284735\n",
      "Penalización por duración del episodio: -  0.35887749512748596\n",
      "Step: 4130, Mean Reward (últimos 10 pasos): 0.06748772412538528\n",
      "Recompensa por acortar distancias: +  0.4274225117855073\n",
      "Penalización por duración del episodio: -  0.35910783128965235\n",
      "Recompensa por acortar distancias: +  0.4274225117855073\n",
      "Penalización por duración del episodio: -  0.3594698738749304\n",
      "Recompensa por acortar distancias: +  0.43135767966193805\n",
      "Penalización por duración del episodio: -  0.35958057950718547\n",
      "Recompensa por acortar distancias: +  0.43135767966193805\n",
      "Penalización por duración del episodio: -  0.359829522733996\n",
      "Recompensa por acortar distancias: +  0.4340926196040322\n",
      "Penalización por duración del episodio: -  0.35997164666669557\n",
      "Recompensa por acortar distancias: +  0.43504711001690016\n",
      "Penalización por duración del episodio: -  0.36007780525119554\n",
      "Recompensa por acortar distancias: +  0.43504711001690016\n",
      "Penalización por duración del episodio: -  0.3605589505500251\n",
      "Recompensa por acortar distancias: +  0.4368745489023691\n",
      "Penalización por duración del episodio: -  0.36093145403153853\n",
      "Recompensa por acortar distancias: +  0.44388720905703344\n",
      "Penalización por duración del episodio: -  0.3613035857289544\n",
      "Recompensa por acortar distancias: +  0.4453717960286086\n",
      "Penalización por duración del episodio: -  0.3616679248075229\n",
      "Step: 4140, Mean Reward (últimos 10 pasos): 0.08370386809110641\n",
      "Recompensa por acortar distancias: +  0.4510887339029125\n",
      "Penalización por duración del episodio: -  0.36177084928912956\n",
      "Recompensa por acortar distancias: +  0.4529769315867802\n",
      "Penalización por duración del episodio: -  0.3618855629946237\n",
      "Recompensa por acortar distancias: +  0.4529769315867802\n",
      "Penalización por duración del episodio: -  0.3623785699199887\n",
      "Recompensa por acortar distancias: +  0.45809492357528525\n",
      "Penalización por duración del episodio: -  0.36248317406815805\n",
      "Recompensa por acortar distancias: +  0.4613399447448243\n",
      "Penalización por duración del episodio: -  0.36273463096921776\n",
      "Recompensa por acortar distancias: +  0.4613399447448243\n",
      "Penalización por duración del episodio: -  0.3630999070069609\n",
      "steer input from model: -0.9 , throttle:  0.0\n",
      "reward: 0.09824003773786344\n",
      "Recompensa por acortar distancias: +  0.4613399447448243\n",
      "Penalización por duración del episodio: -  0.36321526000118937\n",
      "Recompensa por acortar distancias: +  0.4613399447448243\n",
      "Penalización por duración del episodio: -  0.36334240914431865\n",
      "Recompensa por acortar distancias: +  0.4613399447448243\n",
      "Penalización por duración del episodio: -  0.3638202162054422\n",
      "Recompensa por acortar distancias: +  0.47613199829115543\n",
      "Penalización por duración del episodio: -  0.3641712592224879\n",
      "Step: 4150, Mean Reward (últimos 10 pasos): 0.11196073889732361\n",
      "Recompensa por acortar distancias: +  0.4841272539636354\n",
      "Penalización por duración del episodio: -  0.364299203098544\n",
      "Recompensa por acortar distancias: +  0.4877562506895518\n",
      "Penalización por duración del episodio: -  0.36453903220575495\n",
      "Recompensa por acortar distancias: +  0.490066208448053\n",
      "Penalización por duración del episodio: -  0.3646519071533541\n",
      "Recompensa por acortar distancias: +  0.4922877885461092\n",
      "Penalización por duración del episodio: -  0.36489912301185395\n",
      "Recompensa por acortar distancias: +  0.4922877885461092\n",
      "Penalización por duración del episodio: -  0.3652650087753142\n",
      "Recompensa por acortar distancias: +  0.4922877885461092\n",
      "Penalización por duración del episodio: -  0.3656230262100545\n",
      "Recompensa por acortar distancias: +  0.5077540498646016\n",
      "Penalización por duración del episodio: -  0.36597869718891657\n",
      "Recompensa por acortar distancias: +  0.5114971693116167\n",
      "Penalización por duración del episodio: -  0.36634268884573457\n",
      "Recompensa por acortar distancias: +  0.5100103113479026\n",
      "Penalización por duración del episodio: -  0.36644717630656404\n",
      "Recompensa por acortar distancias: +  0.5097740773996188\n",
      "Penalización por duración del episodio: -  0.3667090755676111\n",
      "Step: 4160, Mean Reward (últimos 10 pasos): 0.14306500554084778\n",
      "Recompensa por acortar distancias: +  0.5096658107304652\n",
      "Penalización por duración del episodio: -  0.367062344613053\n",
      "Recompensa por acortar distancias: +  0.5091526833163758\n",
      "Penalización por duración del episodio: -  0.36721538176823687\n",
      "Recompensa por acortar distancias: +  0.5091526833163758\n",
      "Penalización por duración del episodio: -  0.3672893451042193\n",
      "Recompensa por acortar distancias: +  0.5091526833163758\n",
      "Penalización por duración del episodio: -  0.36777885712927816\n",
      "Recompensa por acortar distancias: +  0.5091526833163758\n",
      "Penalización por duración del episodio: -  0.3678716960061603\n",
      "Recompensa por acortar distancias: +  0.5091526833163758\n",
      "Penalización por duración del episodio: -  0.36814478087456154\n",
      "steer input from model: 0.1 , throttle:  0.7\n",
      "reward: 0.14100790244181421\n",
      "Recompensa por acortar distancias: +  0.5081114506418625\n",
      "Penalización por duración del episodio: -  0.3682396051578697\n",
      "Recompensa por acortar distancias: +  0.5079852168790281\n",
      "Penalización por duración del episodio: -  0.36851641030188487\n",
      "Recompensa por acortar distancias: +  0.5079852168790281\n",
      "Penalización por duración del episodio: -  0.36888106889690564\n",
      "Recompensa por acortar distancias: +  0.5077823016056807\n",
      "Penalización por duración del episodio: -  0.36898993892111764\n",
      "Step: 4170, Mean Reward (últimos 10 pasos): 0.13879236578941345\n",
      "Recompensa por acortar distancias: +  0.5077823016056807\n",
      "Penalización por duración del episodio: -  0.3692483539133158\n",
      "Recompensa por acortar distancias: +  0.507738020063302\n",
      "Penalización por duración del episodio: -  0.36945687725378024\n",
      "Recompensa por acortar distancias: +  0.507738020063302\n",
      "Penalización por duración del episodio: -  0.36959018157204465\n",
      "Recompensa por acortar distancias: +  0.5077619098245455\n",
      "Penalización por duración del episodio: -  0.3697346452766715\n",
      "Recompensa por acortar distancias: +  0.5077619098245455\n",
      "Penalización por duración del episodio: -  0.3698623954301435\n",
      "Recompensa por acortar distancias: +  0.5077619098245455\n",
      "Penalización por duración del episodio: -  0.37032952300369143\n",
      "Recompensa por acortar distancias: +  0.5077619098245455\n",
      "Penalización por duración del episodio: -  0.3704171684485478\n",
      "Recompensa por acortar distancias: +  0.5077619098245455\n",
      "Penalización por duración del episodio: -  0.37052480210519617\n",
      "Recompensa por acortar distancias: +  0.5078991873655331\n",
      "Penalización por duración del episodio: -  0.3706942384301091\n",
      "Recompensa por acortar distancias: +  0.5078991873655331\n",
      "Penalización por duración del episodio: -  0.3707985398771835\n",
      "Step: 4180, Mean Reward (últimos 10 pasos): 0.13710065186023712\n",
      "Recompensa por acortar distancias: +  0.5079200258937129\n",
      "Penalización por duración del episodio: -  0.3709066084846038\n",
      "Recompensa por acortar distancias: +  0.5079200258937129\n",
      "Penalización por duración del episodio: -  0.37103954942728784\n",
      "Recompensa por acortar distancias: +  0.5079200258937129\n",
      "Penalización por duración del episodio: -  0.37142103332160775\n",
      "Recompensa por acortar distancias: +  0.5079200258937129\n",
      "Penalización por duración del episodio: -  0.37177828172084715\n",
      "Recompensa por acortar distancias: +  0.5080167515800946\n",
      "Penalización por duración del episodio: -  0.3721411797127705\n",
      "Recompensa por acortar distancias: +  0.5080167515800946\n",
      "Penalización por duración del episodio: -  0.3724979914005947\n",
      "steer input from model: 0.9 , throttle:  0.3\n",
      "reward: 0.13551876017949993\n",
      "Recompensa por acortar distancias: +  0.5080167515800946\n",
      "Penalización por duración del episodio: -  0.3726271796981032\n",
      "Recompensa por acortar distancias: +  0.5080500143041071\n",
      "Penalización por duración del episodio: -  0.3727278287600162\n",
      "Recompensa por acortar distancias: +  0.5080500143041071\n",
      "Penalización por duración del episodio: -  0.37281908965280536\n",
      "Recompensa por acortar distancias: +  0.5080847845601614\n",
      "Penalización por duración del episodio: -  0.3729345403304853\n",
      "Step: 4190, Mean Reward (últimos 10 pasos): 0.1351502388715744\n",
      "Recompensa por acortar distancias: +  0.5080847845601614\n",
      "Penalización por duración del episodio: -  0.37303971742254954\n",
      "Recompensa por acortar distancias: +  0.5080847845601614\n",
      "Penalización por duración del episodio: -  0.3732069839338141\n",
      "Recompensa por acortar distancias: +  0.5080847845601614\n",
      "Penalización por duración del episodio: -  0.37329043892633523\n",
      "Recompensa por acortar distancias: +  0.5080847845601614\n",
      "Penalización por duración del episodio: -  0.373389676692054\n",
      "Recompensa por acortar distancias: +  0.5080847845601614\n",
      "Penalización por duración del episodio: -  0.37349775651753103\n",
      "Recompensa por acortar distancias: +  0.5081538719624675\n",
      "Penalización por duración del episodio: -  0.37394503787170635\n",
      "Recompensa por acortar distancias: +  0.5081865087097981\n",
      "Penalización por duración del episodio: -  0.37431769132523696\n",
      "Recompensa por acortar distancias: +  0.5082013581981927\n",
      "Penalización por duración del episodio: -  0.37469708549187314\n",
      "Recompensa por acortar distancias: +  0.5082013581981927\n",
      "Penalización por duración del episodio: -  0.37488121120985984\n",
      "Recompensa por acortar distancias: +  0.5082013581981927\n",
      "Penalización por duración del episodio: -  0.3750249536525546\n",
      "Step: 4200, Mean Reward (últimos 10 pasos): 0.13317640125751495\n",
      "Recompensa por acortar distancias: +  0.5082696823427447\n",
      "Penalización por duración del episodio: -  0.3754400836011807\n",
      "Recompensa por acortar distancias: +  0.5082910030357036\n",
      "Penalización por duración del episodio: -  0.37554824466978076\n",
      "Recompensa por acortar distancias: +  0.5082910030357036\n",
      "Penalización por duración del episodio: -  0.3757953464092171\n",
      "Recompensa por acortar distancias: +  0.5082993811421269\n",
      "Penalización por duración del episodio: -  0.3761692282004595\n",
      "Recompensa por acortar distancias: +  0.5083381193957095\n",
      "Penalización por duración del episodio: -  0.3762862633630294\n",
      "Recompensa por acortar distancias: +  0.508346807333637\n",
      "Penalización por duración del episodio: -  0.376390206633885\n",
      "steer input from model: 0.9 , throttle:  0.7\n",
      "reward: 0.131956600699752\n",
      "Recompensa por acortar distancias: +  0.5083572233184157\n",
      "Penalización por duración del episodio: -  0.3764886036911702\n",
      "Recompensa por acortar distancias: +  0.5083572233184157\n",
      "Penalización por duración del episodio: -  0.37659982892076616\n",
      "Recompensa por acortar distancias: +  0.5083572233184157\n",
      "Penalización por duración del episodio: -  0.3767062136472675\n",
      "Recompensa por acortar distancias: +  0.5083572233184157\n",
      "Penalización por duración del episodio: -  0.37692682418965423\n",
      "Step: 4210, Mean Reward (últimos 10 pasos): 0.13143040239810944\n",
      "Recompensa por acortar distancias: +  0.5083572233184157\n",
      "Penalización por duración del episodio: -  0.3773125784362558\n",
      "Recompensa por acortar distancias: +  0.5083572233184157\n",
      "Penalización por duración del episodio: -  0.37766386821854814\n",
      "Recompensa por acortar distancias: +  0.5084096368248853\n",
      "Penalización por duración del episodio: -  0.3777704330244875\n",
      "Recompensa por acortar distancias: +  0.5084096368248853\n",
      "Penalización por duración del episodio: -  0.3779110711392696\n",
      "Recompensa por acortar distancias: +  0.5084096368248853\n",
      "Penalización por duración del episodio: -  0.37802449670761384\n",
      "Recompensa por acortar distancias: +  0.5084096368248853\n",
      "Penalización por duración del episodio: -  0.37837376978791604\n",
      "Recompensa por acortar distancias: +  0.5084377264793724\n",
      "Penalización por duración del episodio: -  0.37847245480902036\n",
      "Recompensa por acortar distancias: +  0.5084467480499388\n",
      "Penalización por duración del episodio: -  0.3787415974357105\n",
      "Recompensa por acortar distancias: +  0.5084546076568005\n",
      "Penalización por duración del episodio: -  0.37889779532083173\n",
      "Recompensa por acortar distancias: +  0.5084546076568005\n",
      "Penalización por duración del episodio: -  0.37910559688985346\n",
      "Step: 4220, Mean Reward (últimos 10 pasos): 0.1293490082025528\n",
      "Recompensa por acortar distancias: +  0.5084546076568005\n",
      "Penalización por duración del episodio: -  0.37920504669347754\n",
      "Recompensa por acortar distancias: +  0.5084546076568005\n",
      "Penalización por duración del episodio: -  0.3794835545093693\n",
      "Recompensa por acortar distancias: +  0.5084546076568005\n",
      "Penalización por duración del episodio: -  0.37961252073809393\n",
      "Recompensa por acortar distancias: +  0.5084546076568005\n",
      "Penalización por duración del episodio: -  0.37975349348303516\n",
      "Recompensa por acortar distancias: +  0.5084949722435452\n",
      "Penalización por duración del episodio: -  0.38024099255880206\n",
      "Recompensa por acortar distancias: +  0.5084963308371009\n",
      "Penalización por duración del episodio: -  0.3806183090562748\n",
      "steer input from model: 0.0 , throttle:  0.3\n",
      "reward: 0.12787802178082608\n",
      "Recompensa por acortar distancias: +  0.5084942631529992\n",
      "Penalización por duración del episodio: -  0.380729239219648\n",
      "Recompensa por acortar distancias: +  0.5084942631529992\n",
      "Penalización por duración del episodio: -  0.3808682244307647\n",
      "Recompensa por acortar distancias: +  0.5085142666437615\n",
      "Penalización por duración del episodio: -  0.38095860368143597\n",
      "Recompensa por acortar distancias: +  0.5085025696401068\n",
      "Penalización por duración del episodio: -  0.38135611716853923\n",
      "Step: 4230, Mean Reward (últimos 10 pasos): 0.12714645266532898\n",
      "Recompensa por acortar distancias: +  0.5085025696401068\n",
      "Penalización por duración del episodio: -  0.3817211529823558\n",
      "Recompensa por acortar distancias: +  0.5085025696401068\n",
      "Penalización por duración del episodio: -  0.38184097980145076\n",
      "Recompensa por acortar distancias: +  0.5085025696401068\n",
      "Penalización por duración del episodio: -  0.38208380625626565\n",
      "Recompensa por acortar distancias: +  0.5085450256073223\n",
      "Penalización por duración del episodio: -  0.3821944777607657\n",
      "Recompensa por acortar distancias: +  0.5085493158876889\n",
      "Penalización por duración del episodio: -  0.3822941657576629\n",
      "Recompensa por acortar distancias: +  0.5085493158876889\n",
      "Penalización por duración del episodio: -  0.38245017790091923\n",
      "Recompensa por acortar distancias: +  0.5085493158876889\n",
      "Penalización por duración del episodio: -  0.3828025274024331\n",
      "Recompensa por acortar distancias: +  0.5085625859552375\n",
      "Penalización por duración del episodio: -  0.38315544527639633\n",
      "Recompensa por acortar distancias: +  0.5085708745274555\n",
      "Penalización por duración del episodio: -  0.38327968123032474\n",
      "Recompensa por acortar distancias: +  0.5085464318660257\n",
      "Penalización por duración del episodio: -  0.383401057898183\n",
      "Step: 4240, Mean Reward (últimos 10 pasos): 0.12514537572860718\n",
      "Recompensa por acortar distancias: +  0.5085464318660257\n",
      "Penalización por duración del episodio: -  0.3835162371435734\n",
      "Recompensa por acortar distancias: +  0.5085443284366438\n",
      "Penalización por duración del episodio: -  0.3836477504643\n",
      "Recompensa por acortar distancias: +  0.5085443284366438\n",
      "Penalización por duración del episodio: -  0.38388380004664857\n",
      "Recompensa por acortar distancias: +  0.5085443284366438\n",
      "Penalización por duración del episodio: -  0.38398203061690084\n",
      "Recompensa por acortar distancias: +  0.5085443284366438\n",
      "Penalización por duración del episodio: -  0.38406506507808164\n",
      "Recompensa por acortar distancias: +  0.5085443284366438\n",
      "Penalización por duración del episodio: -  0.3842414377313367\n",
      "steer input from model: 0.9 , throttle:  1.0\n",
      "reward: 0.12430289070530709\n",
      "Recompensa por acortar distancias: +  0.5085443284366438\n",
      "Penalización por duración del episodio: -  0.384602778256031\n",
      "Recompensa por acortar distancias: +  0.5084386977583698\n",
      "Penalización por duración del episodio: -  0.3849700209539692\n",
      "Recompensa por acortar distancias: +  0.5084386977583698\n",
      "Penalización por duración del episodio: -  0.3853345373650725\n",
      "Recompensa por acortar distancias: +  0.5083797773566897\n",
      "Penalización por duración del episodio: -  0.38542905532201815\n",
      "Step: 4250, Mean Reward (últimos 10 pasos): 0.1229507252573967\n",
      "Recompensa por acortar distancias: +  0.5083876787105155\n",
      "Penalización por duración del episodio: -  0.38569293472346017\n",
      "Recompensa por acortar distancias: +  0.5083670851279813\n",
      "Penalización por duración del episodio: -  0.3860709913916608\n",
      "Recompensa por acortar distancias: +  0.5083779956782877\n",
      "Penalización por duración del episodio: -  0.3864326391578132\n",
      "Recompensa por acortar distancias: +  0.5083779956782877\n",
      "Penalización por duración del episodio: -  0.3868056656074518\n",
      "Recompensa por acortar distancias: +  0.508355256914522\n",
      "Penalización por duración del episodio: -  0.38716581957719604\n",
      "Recompensa por acortar distancias: +  0.508355256914522\n",
      "Penalización por duración del episodio: -  0.38753703558374825\n",
      "Recompensa por acortar distancias: +  0.5083672221802739\n",
      "Penalización por duración del episodio: -  0.3876805554128818\n",
      "Recompensa por acortar distancias: +  0.5083672221802739\n",
      "Penalización por duración del episodio: -  0.38779562870627465\n",
      "Recompensa por acortar distancias: +  0.5084028855274998\n",
      "Penalización por duración del episodio: -  0.3879230384017753\n",
      "Recompensa por acortar distancias: +  0.5084066812705378\n",
      "Penalización por duración del episodio: -  0.38830498562751675\n",
      "Step: 4260, Mean Reward (últimos 10 pasos): 0.120101697742939\n",
      "Recompensa por acortar distancias: +  0.508411192065949\n",
      "Penalización por duración del episodio: -  0.3883941762500844\n",
      "Recompensa por acortar distancias: +  0.508411192065949\n",
      "Penalización por duración del episodio: -  0.38868275901066546\n",
      "Recompensa por acortar distancias: +  0.508411192065949\n",
      "Penalización por duración del episodio: -  0.38904558063266736\n",
      "Recompensa por acortar distancias: +  0.508411192065949\n",
      "Penalización por duración del episodio: -  0.3892011100309933\n",
      "Recompensa por acortar distancias: +  0.5084604829932412\n",
      "Penalización por duración del episodio: -  0.3893060653054159\n",
      "Recompensa por acortar distancias: +  0.5085097499210907\n",
      "Penalización por duración del episodio: -  0.38976325065745454\n",
      "steer input from model: -0.9 , throttle:  0.0\n",
      "reward: 0.11874649926363612\n",
      "Recompensa por acortar distancias: +  0.5085097499210907\n",
      "Penalización por duración del episodio: -  0.3901402388410273\n",
      "Recompensa por acortar distancias: +  0.5085197010100929\n",
      "Penalización por duración del episodio: -  0.39052108658708856\n",
      "Recompensa por acortar distancias: +  0.5085244143678576\n",
      "Penalización por duración del episodio: -  0.3906398192410213\n",
      "Recompensa por acortar distancias: +  0.5085244143678576\n",
      "Penalización por duración del episodio: -  0.3908893577767639\n",
      "Step: 4270, Mean Reward (últimos 10 pasos): 0.11763505637645721\n",
      "Recompensa por acortar distancias: +  0.5085244143678576\n",
      "Penalización por duración del episodio: -  0.39126766808296587\n",
      "Recompensa por acortar distancias: +  0.5085244143678576\n",
      "Penalización por duración del episodio: -  0.39137799158304665\n",
      "Recompensa por acortar distancias: +  0.5085236039802841\n",
      "Penalización por duración del episodio: -  0.3916388607521562\n",
      "Recompensa por acortar distancias: +  0.5085640577581249\n",
      "Penalización por duración del episodio: -  0.39200780922481954\n",
      "Recompensa por acortar distancias: +  0.5085640577581249\n",
      "Penalización por duración del episodio: -  0.39210290850714746\n",
      "Recompensa por acortar distancias: +  0.5085661611846655\n",
      "Penalización por duración del episodio: -  0.39223439596768284\n",
      "Recompensa por acortar distancias: +  0.5085661611846655\n",
      "Penalización por duración del episodio: -  0.392342224395859\n",
      "Recompensa por acortar distancias: +  0.5085684493310395\n",
      "Penalización por duración del episodio: -  0.39247818582395533\n",
      "Recompensa por acortar distancias: +  0.5085684493310395\n",
      "Penalización por duración del episodio: -  0.39263321060429274\n",
      "Recompensa por acortar distancias: +  0.5085814691154205\n",
      "Penalización por duración del episodio: -  0.3931178905776949\n",
      "Step: 4280, Mean Reward (últimos 10 pasos): 0.11546357721090317\n",
      "Recompensa por acortar distancias: +  0.5085850205053872\n",
      "Penalización por duración del episodio: -  0.39323686353205317\n",
      "Recompensa por acortar distancias: +  0.5085850205053872\n",
      "Penalización por duración del episodio: -  0.39334831084227123\n",
      "Recompensa por acortar distancias: +  0.5085850205053872\n",
      "Penalización por duración del episodio: -  0.39348824157641915\n",
      "Recompensa por acortar distancias: +  0.5085850205053872\n",
      "Penalización por duración del episodio: -  0.3935896929008956\n",
      "Recompensa por acortar distancias: +  0.5085850205053872\n",
      "Penalización por duración del episodio: -  0.39385426401655865\n",
      "Recompensa por acortar distancias: +  0.5085850205053872\n",
      "Penalización por duración del episodio: -  0.39397088448369477\n",
      "steer input from model: 0.25 , throttle:  0.0\n",
      "reward: 0.11461413602169246\n",
      "Recompensa por acortar distancias: +  0.5085670192395978\n",
      "Penalización por duración del episodio: -  0.3940788124382743\n",
      "Recompensa por acortar distancias: +  0.5085670192395978\n",
      "Penalización por duración del episodio: -  0.3941855437024625\n",
      "Recompensa por acortar distancias: +  0.5085673648450424\n",
      "Penalización por duración del episodio: -  0.3945983704261639\n",
      "Recompensa por acortar distancias: +  0.5085673648450424\n",
      "Penalización por duración del episodio: -  0.3949772133950606\n",
      "Step: 4290, Mean Reward (últimos 10 pasos): 0.11359015107154846\n",
      "Recompensa por acortar distancias: +  0.5085896504202004\n",
      "Penalización por duración del episodio: -  0.3953439403357984\n",
      "Recompensa por acortar distancias: +  0.5085927966162984\n",
      "Penalización por duración del episodio: -  0.39544660122987646\n",
      "Recompensa por acortar distancias: +  0.5085927966162984\n",
      "Penalización por duración del episodio: -  0.3957164064263292\n",
      "Recompensa por acortar distancias: +  0.5085927966162984\n",
      "Penalización por duración del episodio: -  0.39609272334778056\n",
      "Recompensa por acortar distancias: +  0.5085927966162984\n",
      "Penalización por duración del episodio: -  0.3964618154372568\n",
      "Recompensa por acortar distancias: +  0.5086151059872714\n",
      "Penalización por duración del episodio: -  0.3968357106655647\n",
      "Recompensa por acortar distancias: +  0.5086151059872714\n",
      "Penalización por duración del episodio: -  0.3972013862705842\n",
      "Recompensa por acortar distancias: +  0.5085936546696616\n",
      "Penalización por duración del episodio: -  0.3975685757593279\n",
      "Recompensa por acortar distancias: +  0.5085944471772367\n",
      "Penalización por duración del episodio: -  0.3979462195592996\n",
      "Recompensa por acortar distancias: +  0.5085914678252265\n",
      "Penalización por duración del episodio: -  0.39834361260396617\n",
      "Step: 4300, Mean Reward (últimos 10 pasos): 0.11024785786867142\n",
      "Recompensa por acortar distancias: +  0.5085914678252265\n",
      "Penalización por duración del episodio: -  0.3984513565460424\n",
      "Recompensa por acortar distancias: +  0.5085914678252265\n",
      "Penalización por duración del episodio: -  0.39871245709351166\n",
      "Recompensa por acortar distancias: +  0.5086048451109678\n",
      "Penalización por duración del episodio: -  0.3988245848479363\n",
      "Recompensa por acortar distancias: +  0.5086048451109678\n",
      "Penalización por duración del episodio: -  0.3991031495444232\n",
      "Recompensa por acortar distancias: +  0.5086277443737169\n",
      "Penalización por duración del episodio: -  0.39947456965868877\n",
      "Recompensa por acortar distancias: +  0.5086367002816232\n",
      "Penalización por duración del episodio: -  0.39984762729432793\n",
      "steer input from model: 0.05 , throttle:  0.0\n",
      "reward: 0.10878907298729529\n",
      "Recompensa por acortar distancias: +  0.5086593730642697\n",
      "Penalización por duración del episodio: -  0.40022925417915\n",
      "Recompensa por acortar distancias: +  0.5086579846925313\n",
      "Penalización por duración del episodio: -  0.40060255789450316\n",
      "Recompensa por acortar distancias: +  0.5086579846925313\n",
      "Penalización por duración del episodio: -  0.4009731480425944\n",
      "Recompensa por acortar distancias: +  0.5086726072791533\n",
      "Penalización por duración del episodio: -  0.40134555280691975\n",
      "Step: 4310, Mean Reward (últimos 10 pasos): 0.10732705146074295\n",
      "Recompensa por acortar distancias: +  0.5086814261098788\n",
      "Penalización por duración del episodio: -  0.4014256272772263\n",
      "Recompensa por acortar distancias: +  0.5086814261098788\n",
      "Penalización por duración del episodio: -  0.401709040783961\n",
      "Recompensa por acortar distancias: +  0.5086814261098788\n",
      "Penalización por duración del episodio: -  0.40207533082321545\n",
      "Recompensa por acortar distancias: +  0.5086508402367106\n",
      "Penalización por duración del episodio: -  0.4024554965174702\n",
      "Recompensa por acortar distancias: +  0.5086515671956795\n",
      "Penalización por duración del episodio: -  0.40282500850218583\n",
      "Recompensa por acortar distancias: +  0.5086515671956795\n",
      "Penalización por duración del episodio: -  0.40319041411790585\n",
      "Recompensa por acortar distancias: +  0.5086515671956795\n",
      "Penalización por duración del episodio: -  0.40328817098185676\n",
      "Recompensa por acortar distancias: +  0.5086758964652985\n",
      "Penalización por duración del episodio: -  0.40357010761123807\n",
      "Recompensa por acortar distancias: +  0.5087007679318533\n",
      "Penalización por duración del episodio: -  0.4039529993092903\n",
      "Recompensa por acortar distancias: +  0.5087007679318533\n",
      "Penalización por duración del episodio: -  0.40406760834202027\n",
      "Step: 4320, Mean Reward (últimos 10 pasos): 0.1046331599354744\n",
      "Recompensa por acortar distancias: +  0.5087007679318533\n",
      "Penalización por duración del episodio: -  0.40431773622649186\n",
      "Recompensa por acortar distancias: +  0.5087081268745347\n",
      "Penalización por duración del episodio: -  0.40446145995917276\n",
      "Recompensa por acortar distancias: +  0.5086909420988646\n",
      "Penalización por duración del episodio: -  0.40469591616972556\n",
      "Recompensa por acortar distancias: +  0.50868895190507\n",
      "Penalización por duración del episodio: -  0.40477959050485823\n",
      "Recompensa por acortar distancias: +  0.5086629363524975\n",
      "Penalización por duración del episodio: -  0.40508369536790767\n",
      "Recompensa por acortar distancias: +  0.5086602907004526\n",
      "Penalización por duración del episodio: -  0.4052054002495554\n",
      "steer input from model: -0.05 , throttle:  0.0\n",
      "reward: 0.10345489045089717\n",
      "Recompensa por acortar distancias: +  0.5086602907004526\n",
      "Penalización por duración del episodio: -  0.40532545596823616\n",
      "Recompensa por acortar distancias: +  0.5086602907004526\n",
      "Penalización por duración del episodio: -  0.40545314970735574\n",
      "Recompensa por acortar distancias: +  0.5086602907004526\n",
      "Penalización por duración del episodio: -  0.4055640724370882\n",
      "Recompensa por acortar distancias: +  0.5086602907004526\n",
      "Penalización por duración del episodio: -  0.40582706315106465\n",
      "Step: 4330, Mean Reward (últimos 10 pasos): 0.10283322632312775\n",
      "Recompensa por acortar distancias: +  0.5086602907004526\n",
      "Penalización por duración del episodio: -  0.40619674981303444\n",
      "Recompensa por acortar distancias: +  0.5086612857993643\n",
      "Penalización por duración del episodio: -  0.40657795547865044\n",
      "Recompensa por acortar distancias: +  0.5086626443774083\n",
      "Penalización por duración del episodio: -  0.4069492271361661\n",
      "Recompensa por acortar distancias: +  0.508665754805606\n",
      "Penalización por duración del episodio: -  0.40705847776913556\n",
      "Recompensa por acortar distancias: +  0.5086663804663694\n",
      "Penalización por duración del episodio: -  0.4073413660034989\n",
      "Recompensa por acortar distancias: +  0.508668561340818\n",
      "Penalización por duración del episodio: -  0.4074858034745117\n",
      "Recompensa por acortar distancias: +  0.508668561340818\n",
      "Penalización por duración del episodio: -  0.4076018462430125\n",
      "Recompensa por acortar distancias: +  0.508668561340818\n",
      "Penalización por duración del episodio: -  0.40771173888520684\n",
      "Recompensa por acortar distancias: +  0.508668561340818\n",
      "Penalización por duración del episodio: -  0.4081077236269963\n",
      "Recompensa por acortar distancias: +  0.508668561340818\n",
      "Penalización por duración del episodio: -  0.4081846794983686\n",
      "Step: 4340, Mean Reward (últimos 10 pasos): 0.10048387944698334\n",
      "Recompensa por acortar distancias: +  0.508668561340818\n",
      "Penalización por duración del episodio: -  0.4084762564653346\n",
      "Recompensa por acortar distancias: +  0.508668561340818\n",
      "Penalización por duración del episodio: -  0.4086147060868854\n",
      "Recompensa por acortar distancias: +  0.508668561340818\n",
      "Penalización por duración del episodio: -  0.40884474816444916\n",
      "Recompensa por acortar distancias: +  0.5087283445818345\n",
      "Penalización por duración del episodio: -  0.40921606867068233\n",
      "Recompensa por acortar distancias: +  0.5087192933924961\n",
      "Penalización por duración del episodio: -  0.4095949476612744\n",
      "Recompensa por acortar distancias: +  0.5087192933924961\n",
      "Penalización por duración del episodio: -  0.40967955479808615\n",
      "steer input from model: 0.05 , throttle:  0.3\n",
      "reward: 0.09903973859440995\n",
      "Recompensa por acortar distancias: +  0.5087537939452688\n",
      "Penalización por duración del episodio: -  0.4099616440932981\n",
      "Recompensa por acortar distancias: +  0.5087291787925455\n",
      "Penalización por duración del episodio: -  0.4100822412543296\n",
      "Recompensa por acortar distancias: +  0.5087291787925455\n",
      "Penalización por duración del episodio: -  0.4103487468168868\n",
      "Recompensa por acortar distancias: +  0.5087291787925455\n",
      "Penalización por duración del episodio: -  0.4104702728835851\n",
      "Step: 4350, Mean Reward (últimos 10 pasos): 0.09825890511274338\n",
      "Recompensa por acortar distancias: +  0.5087291787925455\n",
      "Penalización por duración del episodio: -  0.4107317539338062\n",
      "Recompensa por acortar distancias: +  0.5087291787925455\n",
      "Penalización por duración del episodio: -  0.4111164623924107\n",
      "Recompensa por acortar distancias: +  0.5086393399793033\n",
      "Penalización por duración del episodio: -  0.4115058177172683\n",
      "Recompensa por acortar distancias: +  0.5086393399793033\n",
      "Penalización por duración del episodio: -  0.41160242757237103\n",
      "Recompensa por acortar distancias: +  0.5086393399793033\n",
      "Penalización por duración del episodio: -  0.41189516836045076\n",
      "Recompensa por acortar distancias: +  0.5086723331802739\n",
      "Penalización por duración del episodio: -  0.4120159775609443\n",
      "Recompensa por acortar distancias: +  0.5087005117094895\n",
      "Penalización por duración del episodio: -  0.41228362410601727\n",
      "Recompensa por acortar distancias: +  0.5087390403511941\n",
      "Penalización por duración del episodio: -  0.41266235391895595\n",
      "Recompensa por acortar distancias: +  0.5087390403511941\n",
      "Penalización por duración del episodio: -  0.41305327931449315\n",
      "Recompensa por acortar distancias: +  0.5088209714659957\n",
      "Penalización por duración del episodio: -  0.41317945580318394\n",
      "Step: 4360, Mean Reward (últimos 10 pasos): 0.09564151614904404\n",
      "Recompensa por acortar distancias: +  0.5088432506888351\n",
      "Penalización por duración del episodio: -  0.41342780728752365\n",
      "Recompensa por acortar distancias: +  0.5088432506888351\n",
      "Penalización por duración del episodio: -  0.41380727608477874\n",
      "Recompensa por acortar distancias: +  0.5088432506888351\n",
      "Penalización por duración del episodio: -  0.4141767873448233\n",
      "Recompensa por acortar distancias: +  0.5089218324861011\n",
      "Penalización por duración del episodio: -  0.414292066835148\n",
      "Recompensa por acortar distancias: +  0.5089445405653222\n",
      "Penalización por duración del episodio: -  0.4145550400749582\n",
      "Recompensa por acortar distancias: +  0.5089777356469631\n",
      "Penalización por duración del episodio: -  0.41493896158058\n",
      "steer input from model: -0.05 , throttle:  0.7\n",
      "reward: 0.09403877406638311\n",
      "Recompensa por acortar distancias: +  0.5090173777758761\n",
      "Penalización por duración del episodio: -  0.4153113147923978\n",
      "Recompensa por acortar distancias: +  0.5090173777758761\n",
      "Penalización por duración del episodio: -  0.41568648070461245\n",
      "Recompensa por acortar distancias: +  0.5090910666682608\n",
      "Penalización por duración del episodio: -  0.4158024091690682\n",
      "Recompensa por acortar distancias: +  0.5090910666682608\n",
      "Penalización por duración del episodio: -  0.41592605600259186\n",
      "Step: 4370, Mean Reward (últimos 10 pasos): 0.09316501021385193\n",
      "Recompensa por acortar distancias: +  0.5090910666682608\n",
      "Penalización por duración del episodio: -  0.4160681450659603\n",
      "Recompensa por acortar distancias: +  0.5090910666682608\n",
      "Penalización por duración del episodio: -  0.41645932543418657\n",
      "Recompensa por acortar distancias: +  0.5091033947868318\n",
      "Penalización por duración del episodio: -  0.4168302975077223\n",
      "Recompensa por acortar distancias: +  0.5091039846771964\n",
      "Penalización por duración del episodio: -  0.41690535754568986\n",
      "Recompensa por acortar distancias: +  0.5091050989144826\n",
      "Penalización por duración del episodio: -  0.4172064535645317\n",
      "Recompensa por acortar distancias: +  0.5091050989144826\n",
      "Penalización por duración del episodio: -  0.4173061079589804\n",
      "Recompensa por acortar distancias: +  0.5091050989144826\n",
      "Penalización por duración del episodio: -  0.41741049433933247\n",
      "Recompensa por acortar distancias: +  0.5091050989144826\n",
      "Penalización por duración del episodio: -  0.4174972789434203\n",
      "Recompensa por acortar distancias: +  0.5091050989144826\n",
      "Penalización por duración del episodio: -  0.41797530028448454\n",
      "Recompensa por acortar distancias: +  0.5091750156331865\n",
      "Penalización por duración del episodio: -  0.4183439801488576\n",
      "Step: 4380, Mean Reward (últimos 10 pasos): 0.09083103388547897\n",
      "Recompensa por acortar distancias: +  0.5091750156331865\n",
      "Penalización por duración del episodio: -  0.4187243107359711\n",
      "Recompensa por acortar distancias: +  0.5091750156331865\n",
      "Penalización por duración del episodio: -  0.4188533685759371\n",
      "Recompensa por acortar distancias: +  0.5091869682935803\n",
      "Penalización por duración del episodio: -  0.41909034880962664\n",
      "Recompensa por acortar distancias: +  0.5091889584164747\n",
      "Penalización por duración del episodio: -  0.41923027005620084\n",
      "Recompensa por acortar distancias: +  0.5091912226277967\n",
      "Penalización por duración del episodio: -  0.41934218738093976\n",
      "Recompensa por acortar distancias: +  0.5091912226277967\n",
      "Penalización por duración del episodio: -  0.41984165824233244\n",
      "steer input from model: -0.25 , throttle:  0.7\n",
      "reward: 0.08934956438546426\n",
      "Recompensa por acortar distancias: +  0.5091874807204612\n",
      "Penalización por duración del episodio: -  0.4202112314443059\n",
      "Recompensa por acortar distancias: +  0.5091874807204612\n",
      "Penalización por duración del episodio: -  0.42059685451431894\n",
      "Recompensa por acortar distancias: +  0.5091874807204612\n",
      "Penalización por duración del episodio: -  0.42075810031111244\n",
      "Recompensa por acortar distancias: +  0.5091874807204612\n",
      "Penalización por duración del episodio: -  0.4209713116706862\n",
      "Step: 4390, Mean Reward (últimos 10 pasos): 0.08821617066860199\n",
      "Recompensa por acortar distancias: +  0.5092246912021745\n",
      "Penalización por duración del episodio: -  0.4211176420496271\n",
      "Recompensa por acortar distancias: +  0.5092274618744713\n",
      "Penalización por duración del episodio: -  0.4212166545188795\n",
      "Recompensa por acortar distancias: +  0.5092274618744713\n",
      "Penalización por duración del episodio: -  0.42132700843182375\n",
      "Recompensa por acortar distancias: +  0.5092274618744713\n",
      "Penalización por duración del episodio: -  0.42174350021933144\n",
      "Recompensa por acortar distancias: +  0.5092340578597868\n",
      "Penalización por duración del episodio: -  0.4221181123652169\n",
      "Recompensa por acortar distancias: +  0.5092363876063162\n",
      "Penalización por duración del episodio: -  0.42250479769807714\n",
      "Recompensa por acortar distancias: +  0.5092363876063162\n",
      "Penalización por duración del episodio: -  0.42289583733582103\n",
      "Recompensa por acortar distancias: +  0.5092448783671252\n",
      "Penalización por duración del episodio: -  0.42327535080359163\n",
      "Recompensa por acortar distancias: +  0.5092464752254043\n",
      "Penalización por duración del episodio: -  0.42365876209626924\n",
      "Recompensa por acortar distancias: +  0.5092524038580363\n",
      "Penalización por duración del episodio: -  0.42375886034770743\n",
      "Step: 4400, Mean Reward (últimos 10 pasos): 0.0854935422539711\n",
      "Recompensa por acortar distancias: +  0.5092524038580363\n",
      "Penalización por duración del episodio: -  0.4238939802038616\n",
      "Recompensa por acortar distancias: +  0.5092608231077435\n",
      "Penalización por duración del episodio: -  0.4240371935897368\n",
      "Recompensa por acortar distancias: +  0.5092429001692937\n",
      "Penalización por duración del episodio: -  0.42442507379671435\n",
      "Recompensa por acortar distancias: +  0.5092192749830803\n",
      "Penalización por duración del episodio: -  0.4245449188296052\n",
      "Recompensa por acortar distancias: +  0.5092192749830803\n",
      "Penalización por duración del episodio: -  0.4246554641682465\n",
      "Recompensa por acortar distancias: +  0.5092192749830803\n",
      "Penalización por duración del episodio: -  0.42482215851165755\n",
      "steer input from model: 0.0 , throttle:  0.0\n",
      "reward: 0.08439711647142273\n",
      "Recompensa por acortar distancias: +  0.5092192749830803\n",
      "Penalización por duración del episodio: -  0.42519548414783775\n",
      "Recompensa por acortar distancias: +  0.5091716252704764\n",
      "Penalización por duración del episodio: -  0.425573866734748\n",
      "Recompensa por acortar distancias: +  0.5091752897222263\n",
      "Penalización por duración del episodio: -  0.42568402132989097\n",
      "Recompensa por acortar distancias: +  0.5091752897222263\n",
      "Penalización por duración del episodio: -  0.42579568723144035\n",
      "Step: 4410, Mean Reward (últimos 10 pasos): 0.0833796039223671\n",
      "Recompensa por acortar distancias: +  0.5091752897222263\n",
      "Penalización por duración del episodio: -  0.42589429083721314\n",
      "Recompensa por acortar distancias: +  0.5091752897222263\n",
      "Penalización por duración del episodio: -  0.42634256109534113\n",
      "Recompensa por acortar distancias: +  0.5092478992891584\n",
      "Penalización por duración del episodio: -  0.4267150417846617\n",
      "Recompensa por acortar distancias: +  0.5092672879916035\n",
      "Penalización por duración del episodio: -  0.42709233677020536\n",
      "Recompensa por acortar distancias: +  0.5092672879916035\n",
      "Penalización por duración del episodio: -  0.4274924500795284\n",
      "Recompensa por acortar distancias: +  0.5092672879916035\n",
      "Penalización por duración del episodio: -  0.4278865474644232\n",
      "Recompensa por acortar distancias: +  0.509277989304065\n",
      "Penalización por duración del episodio: -  0.42827661487192653\n",
      "Recompensa por acortar distancias: +  0.509277989304065\n",
      "Penalización por duración del episodio: -  0.4283674537071098\n",
      "Recompensa por acortar distancias: +  0.5093172968915403\n",
      "Penalización por duración del episodio: -  0.42865071969748914\n",
      "Recompensa por acortar distancias: +  0.5093388007208233\n",
      "Penalización por duración del episodio: -  0.4288109460230795\n",
      "Step: 4420, Mean Reward (últimos 10 pasos): 0.08052785694599152\n",
      "Recompensa por acortar distancias: +  0.5093388007208233\n",
      "Penalización por duración del episodio: -  0.4290490561522527\n",
      "Recompensa por acortar distancias: +  0.5093789542180328\n",
      "Penalización por duración del episodio: -  0.42917773760068645\n",
      "Recompensa por acortar distancias: +  0.509396251346877\n",
      "Penalización por duración del episodio: -  0.42943648449068617\n",
      "Recompensa por acortar distancias: +  0.509396251346877\n",
      "Penalización por duración del episodio: -  0.4298017082054878\n",
      "Recompensa por acortar distancias: +  0.509396251346877\n",
      "Penalización por duración del episodio: -  0.430189830085964\n",
      "Recompensa por acortar distancias: +  0.5094037290859352\n",
      "Penalización por duración del episodio: -  0.4302989460357484\n",
      "steer input from model: 0.0 , throttle:  0.7\n",
      "reward: 0.07910478305018681\n",
      "Recompensa por acortar distancias: +  0.5094035145851125\n",
      "Penalización por duración del episodio: -  0.4305823985806124\n",
      "Recompensa por acortar distancias: +  0.5094035145851125\n",
      "Penalización por duración del episodio: -  0.4309598876409067\n",
      "Recompensa por acortar distancias: +  0.5094108612363193\n",
      "Penalización por duración del episodio: -  0.43106599892340014\n",
      "Recompensa por acortar distancias: +  0.5094225515196388\n",
      "Penalización por duración del episodio: -  0.4313474279244198\n",
      "Step: 4430, Mean Reward (últimos 10 pasos): 0.07807512581348419\n",
      "Recompensa por acortar distancias: +  0.509407018098117\n",
      "Penalización por duración del episodio: -  0.43173753827646877\n",
      "Recompensa por acortar distancias: +  0.5094050458825767\n",
      "Penalización por duración del episodio: -  0.43213196334715\n",
      "Recompensa por acortar distancias: +  0.5094050458825767\n",
      "Penalización por duración del episodio: -  0.4325209210247157\n",
      "Recompensa por acortar distancias: +  0.5094050458825767\n",
      "Penalización por duración del episodio: -  0.4329036697794294\n",
      "Recompensa por acortar distancias: +  0.5094372030885121\n",
      "Penalización por duración del episodio: -  0.4330193254365553\n",
      "Recompensa por acortar distancias: +  0.5094372030885121\n",
      "Penalización por duración del episodio: -  0.43327621256074045\n",
      "Recompensa por acortar distancias: +  0.5094372030885121\n",
      "Penalización por duración del episodio: -  0.4336579126889942\n",
      "Recompensa por acortar distancias: +  0.5094243092320911\n",
      "Penalización por duración del episodio: -  0.4337877753292462\n",
      "Recompensa por acortar distancias: +  0.509423576355402\n",
      "Penalización por duración del episodio: -  0.4339043239140574\n",
      "Recompensa por acortar distancias: +  0.509423576355402\n",
      "Penalización por duración del episodio: -  0.4340065134411476\n",
      "Step: 4440, Mean Reward (últimos 10 pasos): 0.07541706413030624\n",
      "Recompensa por acortar distancias: +  0.5094205078062235\n",
      "Penalización por duración del episodio: -  0.4341447818907907\n",
      "Recompensa por acortar distancias: +  0.5094472250144525\n",
      "Penalización por duración del episodio: -  0.4342514596553003\n",
      "Recompensa por acortar distancias: +  0.5094472250144525\n",
      "Penalización por duración del episodio: -  0.43443038247338667\n",
      "Recompensa por acortar distancias: +  0.5094472250144525\n",
      "Penalización por duración del episodio: -  0.43481625662194306\n",
      "Recompensa por acortar distancias: +  0.5094472250144525\n",
      "Penalización por duración del episodio: -  0.4349286504221733\n",
      "Recompensa por acortar distancias: +  0.5094472250144525\n",
      "Penalización por duración del episodio: -  0.4351897448340855\n",
      "steer input from model: 0.1 , throttle:  0.0\n",
      "reward: 0.07425748018036699\n",
      "Recompensa por acortar distancias: +  0.5094766710810702\n",
      "Penalización por duración del episodio: -  0.43557435552632134\n",
      "Recompensa por acortar distancias: +  0.5094834933594888\n",
      "Penalización por duración del episodio: -  0.43595218443578754\n",
      "Recompensa por acortar distancias: +  0.5094929670852328\n",
      "Penalización por duración del episodio: -  0.43633967508313265\n",
      "Recompensa por acortar distancias: +  0.5094962918251045\n",
      "Penalización por duración del episodio: -  0.4364681385401315\n",
      "Step: 4450, Mean Reward (últimos 10 pasos): 0.07302815467119217\n",
      "Recompensa por acortar distancias: +  0.5095010644340966\n",
      "Penalización por duración del episodio: -  0.4367298944629474\n",
      "Recompensa por acortar distancias: +  0.5095091200698147\n",
      "Penalización por duración del episodio: -  0.4371261053217847\n",
      "Recompensa por acortar distancias: +  0.5095091200698147\n",
      "Penalización por duración del episodio: -  0.43720231479906324\n",
      "Recompensa por acortar distancias: +  0.5095091200698147\n",
      "Penalización por duración del episodio: -  0.4375118820757285\n",
      "Recompensa por acortar distancias: +  0.5095090306951852\n",
      "Penalización por duración del episodio: -  0.4376193223736662\n",
      "Recompensa por acortar distancias: +  0.5095090306951852\n",
      "Penalización por duración del episodio: -  0.43790053957422376\n",
      "Recompensa por acortar distancias: +  0.5095095848178786\n",
      "Penalización por duración del episodio: -  0.43828063904140174\n",
      "Recompensa por acortar distancias: +  0.5095095848178786\n",
      "Penalización por duración del episodio: -  0.43838304935108746\n",
      "Recompensa por acortar distancias: +  0.5095127844291029\n",
      "Penalización por duración del episodio: -  0.43867222962155067\n",
      "Recompensa por acortar distancias: +  0.509513833091085\n",
      "Penalización por duración del episodio: -  0.43906209391615203\n",
      "Step: 4460, Mean Reward (últimos 10 pasos): 0.07045173645019531\n",
      "Recompensa por acortar distancias: +  0.5095173663663517\n",
      "Penalización por duración del episodio: -  0.43944034021350803\n",
      "Recompensa por acortar distancias: +  0.5095173663663517\n",
      "Penalización por duración del episodio: -  0.43981431590443754\n",
      "Recompensa por acortar distancias: +  0.5095173663663517\n",
      "Penalización por duración del episodio: -  0.4399156760378596\n",
      "Recompensa por acortar distancias: +  0.5095179204886935\n",
      "Penalización por duración del episodio: -  0.44020467535422464\n",
      "Recompensa por acortar distancias: +  0.5095255649913002\n",
      "Penalización por duración del episodio: -  0.4405804885163397\n",
      "Recompensa por acortar distancias: +  0.5095255649913002\n",
      "Penalización por duración del episodio: -  0.44065424897612915\n",
      "steer input from model: -0.05 , throttle:  0.7\n",
      "reward: 0.06887131601517105\n",
      "Recompensa por acortar distancias: +  0.5095255649913002\n",
      "Penalización por duración del episodio: -  0.44096563251098686\n",
      "Recompensa por acortar distancias: +  0.50952875268203\n",
      "Penalización por duración del episodio: -  0.4411132479790521\n",
      "Recompensa por acortar distancias: +  0.5095108360625842\n",
      "Penalización por duración del episodio: -  0.4413482845596058\n",
      "Recompensa por acortar distancias: +  0.5095214716377693\n",
      "Penalización por duración del episodio: -  0.4417359392016196\n",
      "Step: 4470, Mean Reward (últimos 10 pasos): 0.06778553128242493\n",
      "Recompensa por acortar distancias: +  0.5095113365604331\n",
      "Penalización por duración del episodio: -  0.44212539376417187\n",
      "Recompensa por acortar distancias: +  0.5095113365604331\n",
      "Penalización por duración del episodio: -  0.44223625196633204\n",
      "Recompensa por acortar distancias: +  0.5095113365604331\n",
      "Penalización por duración del episodio: -  0.4423453809662451\n",
      "Recompensa por acortar distancias: +  0.5095113365604331\n",
      "Penalización por duración del episodio: -  0.4424573857134548\n",
      "Recompensa por acortar distancias: +  0.5095716404530708\n",
      "Penalización por duración del episodio: -  0.4429069338064441\n",
      "Recompensa por acortar distancias: +  0.5095722422393546\n",
      "Penalización por duración del episodio: -  0.4432970893352384\n",
      "Recompensa por acortar distancias: +  0.5096533401344476\n",
      "Penalización por duración del episodio: -  0.4436785169806224\n",
      "Recompensa por acortar distancias: +  0.5096567065411506\n",
      "Penalización por duración del episodio: -  0.4438028553099125\n",
      "Recompensa por acortar distancias: +  0.5096528873079925\n",
      "Penalización por duración del episodio: -  0.4440643783422812\n",
      "Recompensa por acortar distancias: +  0.5096732823574821\n",
      "Penalización por duración del episodio: -  0.44421549140617295\n",
      "Step: 4480, Mean Reward (últimos 10 pasos): 0.0654577910900116\n",
      "Recompensa por acortar distancias: +  0.5096732823574821\n",
      "Penalización por duración del episodio: -  0.44445745388656244\n",
      "Recompensa por acortar distancias: +  0.5096732823574821\n",
      "Penalización por duración del episodio: -  0.4448405129187258\n",
      "Recompensa por acortar distancias: +  0.5096732823574821\n",
      "Penalización por duración del episodio: -  0.4452168770307084\n",
      "Recompensa por acortar distancias: +  0.5098035763484128\n",
      "Penalización por duración del episodio: -  0.4453348997735507\n",
      "Recompensa por acortar distancias: +  0.5098035763484128\n",
      "Penalización por duración del episodio: -  0.44562344864720305\n",
      "Recompensa por acortar distancias: +  0.5098035763484128\n",
      "Penalización por duración del episodio: -  0.4457605535813789\n",
      "steer input from model: 0.05 , throttle:  0.0\n",
      "reward: 0.06404302276703389\n",
      "Recompensa por acortar distancias: +  0.5098035763484128\n",
      "Penalización por duración del episodio: -  0.44587643097486057\n",
      "Recompensa por acortar distancias: +  0.5098162851251553\n",
      "Penalización por duración del episodio: -  0.446012437729027\n",
      "Recompensa por acortar distancias: +  0.5098162851251553\n",
      "Penalización por duración del episodio: -  0.44615538077385886\n",
      "Recompensa por acortar distancias: +  0.5098155582287498\n",
      "Penalización por duración del episodio: -  0.44640152240479936\n",
      "Step: 4490, Mean Reward (últimos 10 pasos): 0.06341403722763062\n",
      "Recompensa por acortar distancias: +  0.5098151173243524\n",
      "Penalización por duración del episodio: -  0.4465432817055324\n",
      "Recompensa por acortar distancias: +  0.5098160706311383\n",
      "Penalización por duración del episodio: -  0.44677624683138145\n",
      "Recompensa por acortar distancias: +  0.5098160706311383\n",
      "Penalización por duración del episodio: -  0.44716128121079024\n",
      "Recompensa por acortar distancias: +  0.5098160706311383\n",
      "Penalización por duración del episodio: -  0.4475514839355706\n",
      "Recompensa por acortar distancias: +  0.5098524273153449\n",
      "Penalización por duración del episodio: -  0.44792715907971004\n",
      "Recompensa por acortar distancias: +  0.5098631519810618\n",
      "Penalización por duración del episodio: -  0.44802804451800166\n",
      "Recompensa por acortar distancias: +  0.5098631519810618\n",
      "Penalización por duración del episodio: -  0.448306307888773\n",
      "Recompensa por acortar distancias: +  0.5099022313944139\n",
      "Penalización por duración del episodio: -  0.4487044897252352\n",
      "Recompensa por acortar distancias: +  0.5099254323183738\n",
      "Penalización por duración del episodio: -  0.4488428662587573\n",
      "Recompensa por acortar distancias: +  0.5099254323183738\n",
      "Penalización por duración del episodio: -  0.44909528138021454\n",
      "Step: 4500, Mean Reward (últimos 10 pasos): 0.06083014979958534\n",
      "Recompensa por acortar distancias: +  0.5099229358676415\n",
      "Penalización por duración del episodio: -  0.4494915871519701\n",
      "Recompensa por acortar distancias: +  0.5099229358676415\n",
      "Penalización por duración del episodio: -  0.4495824905141475\n",
      "Recompensa por acortar distancias: +  0.5099229358676415\n",
      "Penalización por duración del episodio: -  0.44968834808830127\n",
      "Recompensa por acortar distancias: +  0.5099229358676415\n",
      "Penalización por duración del episodio: -  0.4498275475246935\n",
      "Recompensa por acortar distancias: +  0.5099229358676415\n",
      "Penalización por duración del episodio: -  0.44997624329127545\n",
      "Recompensa por acortar distancias: +  0.5099824334821327\n",
      "Penalización por duración del episodio: -  0.4500878890048253\n",
      "steer input from model: -0.1 , throttle:  0.0\n",
      "reward: 0.059894544477307354\n",
      "Recompensa por acortar distancias: +  0.5099824334821327\n",
      "Penalización por duración del episodio: -  0.4502574325125512\n",
      "Recompensa por acortar distancias: +  0.5099916029772219\n",
      "Penalización por duración del episodio: -  0.45036906135800786\n",
      "Recompensa por acortar distancias: +  0.5099916029772219\n",
      "Penalización por duración del episodio: -  0.4506378054811916\n",
      "Recompensa por acortar distancias: +  0.5099916029772219\n",
      "Penalización por duración del episodio: -  0.4510211287565491\n",
      "Step: 4510, Mean Reward (últimos 10 pasos): 0.05897047370672226\n",
      "Recompensa por acortar distancias: +  0.5100068079990921\n",
      "Penalización por duración del episodio: -  0.4511482293423252\n",
      "Recompensa por acortar distancias: +  0.5100118366151047\n",
      "Penalización por duración del episodio: -  0.4514084128265904\n",
      "Recompensa por acortar distancias: +  0.5100170260970408\n",
      "Penalización por duración del episodio: -  0.4517850321926074\n",
      "Recompensa por acortar distancias: +  0.510019057799484\n",
      "Penalización por duración del episodio: -  0.45217858591543697\n",
      "Recompensa por acortar distancias: +  0.510019057799484\n",
      "Penalización por duración del episodio: -  0.4525778345751446\n",
      "Recompensa por acortar distancias: +  0.510044004218609\n",
      "Penalización por duración del episodio: -  0.4529755019126115\n",
      "Recompensa por acortar distancias: +  0.510044004218609\n",
      "Penalización por duración del episodio: -  0.4533520410153177\n",
      "Recompensa por acortar distancias: +  0.510049896737824\n",
      "Penalización por duración del episodio: -  0.45351233981701417\n",
      "Recompensa por acortar distancias: +  0.5100514339162904\n",
      "Penalización por duración del episodio: -  0.4537389099986161\n",
      "Recompensa por acortar distancias: +  0.5100529889687316\n",
      "Penalización por duración del episodio: -  0.4541057754062304\n",
      "Step: 4520, Mean Reward (últimos 10 pasos): 0.05594721436500549\n",
      "Recompensa por acortar distancias: +  0.5100544725243275\n",
      "Penalización por duración del episodio: -  0.4544956965463479\n",
      "Recompensa por acortar distancias: +  0.5100544725243275\n",
      "Penalización por duración del episodio: -  0.4545948156148555\n",
      "Recompensa por acortar distancias: +  0.5100544725243275\n",
      "Penalización por duración del episodio: -  0.4548903439397931\n",
      "Recompensa por acortar distancias: +  0.5100698562108653\n",
      "Penalización por duración del episodio: -  0.4550324767799826\n",
      "Recompensa por acortar distancias: +  0.5100698562108653\n",
      "Penalización por duración del episodio: -  0.4552581094474778\n",
      "Recompensa por acortar distancias: +  0.5100698562108653\n",
      "Penalización por duración del episodio: -  0.4553493976959706\n",
      "steer input from model: -0.1 , throttle:  0.7\n",
      "reward: 0.05472045851489471\n",
      "Recompensa por acortar distancias: +  0.5100698562108653\n",
      "Penalización por duración del episodio: -  0.455652286353277\n",
      "Recompensa por acortar distancias: +  0.510101433819029\n",
      "Penalización por duración del episodio: -  0.45605240366667\n",
      "Recompensa por acortar distancias: +  0.5101022143211543\n",
      "Penalización por duración del episodio: -  0.45642794079713733\n",
      "Recompensa por acortar distancias: +  0.5101097333543727\n",
      "Penalización por duración del episodio: -  0.45657458238052256\n",
      "Step: 4530, Mean Reward (últimos 10 pasos): 0.05353515222668648\n",
      "Recompensa por acortar distancias: +  0.5101097333543727\n",
      "Penalización por duración del episodio: -  0.4568189977912193\n",
      "Recompensa por acortar distancias: +  0.5101097333543727\n",
      "Penalización por duración del episodio: -  0.457211575386763\n",
      "Recompensa por acortar distancias: +  0.5101097333543727\n",
      "Penalización por duración del episodio: -  0.4573391920282165\n",
      "Recompensa por acortar distancias: +  0.5101188789234764\n",
      "Penalización por duración del episodio: -  0.4575957025394322\n",
      "Recompensa por acortar distancias: +  0.5101508258028743\n",
      "Penalización por duración del episodio: -  0.45797458910114747\n",
      "Recompensa por acortar distancias: +  0.5101508258028743\n",
      "Penalización por duración del episodio: -  0.4580865902019677\n",
      "Recompensa por acortar distancias: +  0.5101508258028743\n",
      "Penalización por duración del episodio: -  0.45818560971080735\n",
      "Recompensa por acortar distancias: +  0.5102001341767554\n",
      "Penalización por duración del episodio: -  0.4583812199320439\n",
      "Recompensa por acortar distancias: +  0.5102001341767554\n",
      "Penalización por duración del episodio: -  0.45852228294344705\n",
      "Recompensa por acortar distancias: +  0.5102104772324471\n",
      "Penalización por duración del episodio: -  0.4586610675906055\n",
      "Step: 4540, Mean Reward (últimos 10 pasos): 0.051549408584833145\n",
      "Recompensa por acortar distancias: +  0.5102095954515422\n",
      "Penalización por duración del episodio: -  0.45917589638506956\n",
      "Recompensa por acortar distancias: +  0.5102089519897607\n",
      "Penalización por duración del episodio: -  0.4595663520283415\n",
      "Recompensa por acortar distancias: +  0.5102089519897607\n",
      "Penalización por duración del episodio: -  0.45969374359374204\n",
      "Recompensa por acortar distancias: +  0.5102089519897607\n",
      "Penalización por duración del episodio: -  0.4599520188548719\n",
      "Recompensa por acortar distancias: +  0.5102350777024632\n",
      "Penalización por duración del episodio: -  0.4600302524455751\n",
      "Recompensa por acortar distancias: +  0.5102350777024632\n",
      "Penalización por duración del episodio: -  0.4603493959765048\n",
      "steer input from model: -0.1 , throttle:  1.0\n",
      "reward: 0.04988568172595842\n",
      "Recompensa por acortar distancias: +  0.5102350777024632\n",
      "Penalización por duración del episodio: -  0.4607252612120299\n",
      "Recompensa por acortar distancias: +  0.5102408092652564\n",
      "Penalización por duración del episodio: -  0.46083869002719846\n",
      "Recompensa por acortar distancias: +  0.5102424655791589\n",
      "Penalización por duración del episodio: -  0.4609594628813537\n",
      "Recompensa por acortar distancias: +  0.5102424655791589\n",
      "Penalización por duración del episodio: -  0.46110339276326195\n",
      "Step: 4550, Mean Reward (últimos 10 pasos): 0.04913907125592232\n",
      "Recompensa por acortar distancias: +  0.5102439967756242\n",
      "Penalización por duración del episodio: -  0.4612719343362157\n",
      "Recompensa por acortar distancias: +  0.5102452539056522\n",
      "Penalización por duración del episodio: -  0.4614856099978874\n",
      "Recompensa por acortar distancias: +  0.5102463918763243\n",
      "Penalización por duración del episodio: -  0.4615982006814799\n",
      "Recompensa por acortar distancias: +  0.5102463918763243\n",
      "Penalización por duración del episodio: -  0.46187398794734097\n",
      "Recompensa por acortar distancias: +  0.5102463918763243\n",
      "Penalización por duración del episodio: -  0.46226144615691195\n",
      "Recompensa por acortar distancias: +  0.5102463918763243\n",
      "Penalización por duración del episodio: -  0.4623795932295816\n",
      "Recompensa por acortar distancias: +  0.5102463918763243\n",
      "Penalización por duración del episodio: -  0.46249305039990746\n",
      "Recompensa por acortar distancias: +  0.5102521293917596\n",
      "Penalización por duración del episodio: -  0.4626499990702251\n",
      "Recompensa por acortar distancias: +  0.5102550070854002\n",
      "Penalización por duración del episodio: -  0.46303269317653195\n",
      "Recompensa por acortar distancias: +  0.5102550070854002\n",
      "Penalización por duración del episodio: -  0.4634272701807308\n",
      "Step: 4560, Mean Reward (últimos 10 pasos): 0.046827737241983414\n",
      "Recompensa por acortar distancias: +  0.5102593266035641\n",
      "Penalización por duración del episodio: -  0.46381524629480037\n",
      "Recompensa por acortar distancias: +  0.510257658376041\n",
      "Penalización por duración del episodio: -  0.46422525440540535\n",
      "Recompensa por acortar distancias: +  0.510257658376041\n",
      "Penalización por duración del episodio: -  0.464335594751061\n",
      "Recompensa por acortar distancias: +  0.510257658376041\n",
      "Penalización por duración del episodio: -  0.4646036354413818\n",
      "Recompensa por acortar distancias: +  0.510257658376041\n",
      "Penalización por duración del episodio: -  0.4647621103839213\n",
      "Recompensa por acortar distancias: +  0.5102766225347332\n",
      "Penalización por duración del episodio: -  0.4649851355369519\n",
      "steer input from model: 0.9 , throttle:  0.3\n",
      "reward: 0.04529148699778124\n",
      "Recompensa por acortar distancias: +  0.5102779154090686\n",
      "Penalización por duración del episodio: -  0.4651093258698416\n",
      "Recompensa por acortar distancias: +  0.5102779154090686\n",
      "Penalización por duración del episodio: -  0.46522108188760364\n",
      "Recompensa por acortar distancias: +  0.5102779154090686\n",
      "Penalización por duración del episodio: -  0.46536725793001255\n",
      "Recompensa por acortar distancias: +  0.5102779154090686\n",
      "Penalización por duración del episodio: -  0.46574485889212003\n",
      "Step: 4570, Mean Reward (últimos 10 pasos): 0.044533055275678635\n",
      "Recompensa por acortar distancias: +  0.510283301390996\n",
      "Penalización por duración del episodio: -  0.46612878227593507\n",
      "Recompensa por acortar distancias: +  0.5102898491689065\n",
      "Penalización por duración del episodio: -  0.4662078715053629\n",
      "Recompensa por acortar distancias: +  0.5102936205443901\n",
      "Penalización por duración del episodio: -  0.4663399003094865\n",
      "Recompensa por acortar distancias: +  0.5102936205443901\n",
      "Penalización por duración del episodio: -  0.4665028305414731\n",
      "Recompensa por acortar distancias: +  0.5102936205443901\n",
      "Penalización por duración del episodio: -  0.46688903434684237\n",
      "Recompensa por acortar distancias: +  0.5102936205443901\n",
      "Penalización por duración del episodio: -  0.46727168720701406\n",
      "Recompensa por acortar distancias: +  0.5102955747479713\n",
      "Penalización por duración del episodio: -  0.46765396308711304\n",
      "Recompensa por acortar distancias: +  0.5102932392363376\n",
      "Penalización por duración del episodio: -  0.468058852020506\n",
      "Recompensa por acortar distancias: +  0.510300823689569\n",
      "Penalización por duración del episodio: -  0.4684552994092413\n",
      "Recompensa por acortar distancias: +  0.5103038384041475\n",
      "Penalización por duración del episodio: -  0.468545521080323\n",
      "Step: 4580, Mean Reward (últimos 10 pasos): 0.04175831750035286\n",
      "Recompensa por acortar distancias: +  0.5103047440099615\n",
      "Penalización por duración del episodio: -  0.4688435337395294\n",
      "Recompensa por acortar distancias: +  0.5103054708777369\n",
      "Penalización por duración del episodio: -  0.46898803291873425\n",
      "Recompensa por acortar distancias: +  0.5103054708777369\n",
      "Penalización por duración del episodio: -  0.4692208266378267\n",
      "Recompensa por acortar distancias: +  0.5103054708777369\n",
      "Penalización por duración del episodio: -  0.4696342902184143\n",
      "Recompensa por acortar distancias: +  0.5103054708777369\n",
      "Penalización por duración del episodio: -  0.46974903514104954\n",
      "Recompensa por acortar distancias: +  0.5103092005428501\n",
      "Penalización por duración del episodio: -  0.4700229048962791\n",
      "steer input from model: 0.9 , throttle:  1.0\n",
      "reward: 0.04028629564657099\n",
      "Recompensa por acortar distancias: +  0.510310654277823\n",
      "Penalización por duración del episodio: -  0.4701449183140547\n",
      "Recompensa por acortar distancias: +  0.510310654277823\n",
      "Penalización por duración del episodio: -  0.4704129160923265\n",
      "Recompensa por acortar distancias: +  0.510310654277823\n",
      "Penalización por duración del episodio: -  0.470526025287323\n",
      "Recompensa por acortar distancias: +  0.510310654277823\n",
      "Penalización por duración del episodio: -  0.4707977539221936\n",
      "Step: 4590, Mean Reward (últimos 10 pasos): 0.03951289877295494\n",
      "Recompensa por acortar distancias: +  0.5103176369696059\n",
      "Penalización por duración del episodio: -  0.4709149840521649\n",
      "Recompensa por acortar distancias: +  0.5103176369696059\n",
      "Penalización por duración del episodio: -  0.47107614730195246\n",
      "Recompensa por acortar distancias: +  0.5102893665757506\n",
      "Penalización por duración del episodio: -  0.4711538975109533\n",
      "Recompensa por acortar distancias: +  0.5102949729962923\n",
      "Penalización por duración del episodio: -  0.47158254076177863\n",
      "Recompensa por acortar distancias: +  0.5102949729962923\n",
      "Penalización por duración del episodio: -  0.4719817428706782\n",
      "Recompensa por acortar distancias: +  0.5102949729962923\n",
      "Penalización por duración del episodio: -  0.4720967112381806\n",
      "Recompensa por acortar distancias: +  0.5102380268957127\n",
      "Penalización por duración del episodio: -  0.4723728577294949\n",
      "Recompensa por acortar distancias: +  0.5102370319154436\n",
      "Penalización por duración del episodio: -  0.472765004890879\n",
      "Recompensa por acortar distancias: +  0.5102370319154436\n",
      "Penalización por duración del episodio: -  0.47314493062168017\n",
      "Recompensa por acortar distancias: +  0.5101931395016539\n",
      "Penalización por duración del episodio: -  0.4735194013748049\n",
      "Step: 4600, Mean Reward (últimos 10 pasos): 0.036673739552497864\n",
      "Recompensa por acortar distancias: +  0.510187032563144\n",
      "Penalización por duración del episodio: -  0.47364373429389195\n",
      "Recompensa por acortar distancias: +  0.5101777261788071\n",
      "Penalización por duración del episodio: -  0.47390172451460605\n",
      "Recompensa por acortar distancias: +  0.5101860733266724\n",
      "Penalización por duración del episodio: -  0.47429652647157644\n",
      "Recompensa por acortar distancias: +  0.5101860733266724\n",
      "Penalización por duración del episodio: -  0.47468927380465703\n",
      "Recompensa por acortar distancias: +  0.5101860733266724\n",
      "Penalización por duración del episodio: -  0.47508466259985455\n",
      "Recompensa por acortar distancias: +  0.51019523075502\n",
      "Penalización por duración del episodio: -  0.4752100344401846\n",
      "steer input from model: 0.0 , throttle:  1.0\n",
      "reward: 0.03498519631483543\n",
      "Recompensa por acortar distancias: +  0.51019523075502\n",
      "Penalización por duración del episodio: -  0.4754844530431826\n",
      "Recompensa por acortar distancias: +  0.51019523075502\n",
      "Penalización por duración del episodio: -  0.47556297236433\n",
      "Recompensa por acortar distancias: +  0.51019523075502\n",
      "Penalización por duración del episodio: -  0.4758587819053066\n",
      "Recompensa por acortar distancias: +  0.5101963151084767\n",
      "Penalización por duración del episodio: -  0.4759788683228541\n",
      "Step: 4610, Mean Reward (últimos 10 pasos): 0.03421744704246521\n",
      "Recompensa por acortar distancias: +  0.5101969764448786\n",
      "Penalización por duración del episodio: -  0.4762446215582931\n",
      "Recompensa por acortar distancias: +  0.510197816520797\n",
      "Penalización por duración del episodio: -  0.47635188292626957\n",
      "Recompensa por acortar distancias: +  0.5101979714284068\n",
      "Penalización por duración del episodio: -  0.47662400091244866\n",
      "Recompensa por acortar distancias: +  0.5101979714284068\n",
      "Penalización por duración del episodio: -  0.4770021700894186\n",
      "Recompensa por acortar distancias: +  0.5101979714284068\n",
      "Penalización por duración del episodio: -  0.47738395244119086\n",
      "Recompensa por acortar distancias: +  0.5101984480671942\n",
      "Penalización por duración del episodio: -  0.4777581885586115\n",
      "Recompensa por acortar distancias: +  0.5101984480671942\n",
      "Penalización por duración del episodio: -  0.47814331859675735\n",
      "Recompensa por acortar distancias: +  0.5101991034454965\n",
      "Penalización por duración del episodio: -  0.47827751940210916\n",
      "Recompensa por acortar distancias: +  0.5101987757563496\n",
      "Penalización por duración del episodio: -  0.4783827560166005\n",
      "Recompensa por acortar distancias: +  0.5101994132606816\n",
      "Penalización por duración del episodio: -  0.4785379878361892\n",
      "Step: 4620, Mean Reward (últimos 10 pasos): 0.03166142478585243\n",
      "Recompensa por acortar distancias: +  0.510199931605301\n",
      "Penalización por duración del episodio: -  0.4789300302237536\n",
      "Recompensa por acortar distancias: +  0.5102003724961093\n",
      "Penalización por duración del episodio: -  0.479330155237629\n",
      "Recompensa por acortar distancias: +  0.5102003724961093\n",
      "Penalización por duración del episodio: -  0.4797360967759899\n",
      "Recompensa por acortar distancias: +  0.5101998839414288\n",
      "Penalización por duración del episodio: -  0.4801341799209565\n",
      "Recompensa por acortar distancias: +  0.5101993834707603\n",
      "Penalización por duración del episodio: -  0.4805175942320719\n",
      "Recompensa por acortar distancias: +  0.5102003724961093\n",
      "Penalización por duración del episodio: -  0.48090438233778454\n",
      "steer input from model: -0.05 , throttle:  0.3\n",
      "reward: 0.029295990158324736\n",
      "Recompensa por acortar distancias: +  0.5102111326101054\n",
      "Penalización por duración del episodio: -  0.48103032301681636\n",
      "Recompensa por acortar distancias: +  0.5102058061761199\n",
      "Penalización por duración del episodio: -  0.48128380080448646\n",
      "Recompensa por acortar distancias: +  0.510207230133531\n",
      "Penalización por duración del episodio: -  0.4816737231264317\n",
      "Recompensa por acortar distancias: +  0.510207230133531\n",
      "Penalización por duración del episodio: -  0.4817516590928778\n",
      "Step: 4630, Mean Reward (últimos 10 pasos): 0.028455570340156555\n",
      "Recompensa por acortar distancias: +  0.510207230133531\n",
      "Penalización por duración del episodio: -  0.4820665013008191\n",
      "Recompensa por acortar distancias: +  0.510207230133531\n",
      "Penalización por duración del episodio: -  0.48247076142081835\n",
      "Recompensa por acortar distancias: +  0.5100900360991778\n",
      "Penalización por duración del episodio: -  0.4825924029359351\n",
      "Recompensa por acortar distancias: +  0.5100900360991778\n",
      "Penalización por duración del episodio: -  0.4828694125053989\n",
      "Recompensa por acortar distancias: +  0.5100900360991778\n",
      "Penalización por duración del episodio: -  0.48300690318683065\n",
      "Recompensa por acortar distancias: +  0.5100203387847253\n",
      "Penalización por duración del episodio: -  0.4832539927891733\n",
      "Recompensa por acortar distancias: +  0.5099824573144873\n",
      "Penalización por duración del episodio: -  0.4834161933363422\n",
      "Recompensa por acortar distancias: +  0.5099824573144873\n",
      "Penalización por duración del episodio: -  0.4836624985874832\n",
      "Recompensa por acortar distancias: +  0.5099252237843221\n",
      "Penalización por duración del episodio: -  0.4840489413268712\n",
      "Recompensa por acortar distancias: +  0.5098893141691554\n",
      "Penalización por duración del episodio: -  0.4844411970575352\n",
      "Step: 4640, Mean Reward (últimos 10 pasos): 0.025448117405176163\n",
      "Recompensa por acortar distancias: +  0.5098893141691554\n",
      "Penalización por duración del episodio: -  0.48482066280665115\n",
      "Recompensa por acortar distancias: +  0.5097449656657852\n",
      "Penalización por duración del episodio: -  0.4852148852960652\n",
      "Recompensa por acortar distancias: +  0.5097315775826107\n",
      "Penalización por duración del episodio: -  0.48558687040917164\n",
      "Recompensa por acortar distancias: +  0.5096772207492501\n",
      "Penalización por duración del episodio: -  0.4856992456845015\n",
      "Recompensa por acortar distancias: +  0.5096765951349043\n",
      "Penalización por duración del episodio: -  0.4859798358052177\n",
      "Recompensa por acortar distancias: +  0.5096936773747702\n",
      "Penalización por duración del episodio: -  0.48636354499082607\n",
      "steer input from model: -0.25 , throttle:  0.0\n",
      "reward: 0.023330132383944158\n",
      "Recompensa por acortar distancias: +  0.5096832087707409\n",
      "Penalización por duración del episodio: -  0.4864898554087493\n",
      "Recompensa por acortar distancias: +  0.5096832087707409\n",
      "Penalización por duración del episodio: -  0.4867623039060992\n",
      "Recompensa por acortar distancias: +  0.5096832087707409\n",
      "Penalización por duración del episodio: -  0.48717016339241886\n",
      "Recompensa por acortar distancias: +  0.5096832087707409\n",
      "Penalización por duración del episodio: -  0.48727518371391776\n",
      "Step: 4650, Mean Reward (últimos 10 pasos): 0.022408025339245796\n",
      "Recompensa por acortar distancias: +  0.5096832087707409\n",
      "Penalización por duración del episodio: -  0.48755191949386056\n",
      "Recompensa por acortar distancias: +  0.509789973832121\n",
      "Penalización por duración del episodio: -  0.48769251216214204\n",
      "Recompensa por acortar distancias: +  0.509789973832121\n",
      "Penalización por duración del episodio: -  0.48793169452556434\n",
      "Recompensa por acortar distancias: +  0.509789973832121\n",
      "Penalización por duración del episodio: -  0.4880418875492905\n",
      "Recompensa por acortar distancias: +  0.5097918923657397\n",
      "Penalización por duración del episodio: -  0.48830961888501945\n",
      "Recompensa por acortar distancias: +  0.509792142609234\n",
      "Penalización por duración del episodio: -  0.48845227109122313\n",
      "Recompensa por acortar distancias: +  0.509792845674263\n",
      "Penalización por duración del episodio: -  0.4885762846047137\n",
      "Recompensa por acortar distancias: +  0.509792845674263\n",
      "Penalización por duración del episodio: -  0.4886939489162831\n",
      "Recompensa por acortar distancias: +  0.5097938347317805\n",
      "Penalización por duración del episodio: -  0.4890910058842205\n",
      "Recompensa por acortar distancias: +  0.5097941981806081\n",
      "Penalización por duración del episodio: -  0.48949395103975263\n",
      "Step: 4660, Mean Reward (últimos 10 pasos): 0.0203002467751503\n",
      "Recompensa por acortar distancias: +  0.5097941981806081\n",
      "Penalización por duración del episodio: -  0.4896260488409987\n",
      "Recompensa por acortar distancias: +  0.5097941981806081\n",
      "Penalización por duración del episodio: -  0.4897794597453767\n",
      "Recompensa por acortar distancias: +  0.5098633664742835\n",
      "Penalización por duración del episodio: -  0.48988893800552613\n",
      "Recompensa por acortar distancias: +  0.5098612751652164\n",
      "Penalización por duración del episodio: -  0.49028499220053967\n",
      "Recompensa por acortar distancias: +  0.5098612751652164\n",
      "Penalización por duración del episodio: -  0.4906841152480821\n",
      "Recompensa por acortar distancias: +  0.5098690028781981\n",
      "Penalización por duración del episodio: -  0.49106877085738626\n",
      "steer input from model: 0.0 , throttle:  0.0\n",
      "reward: 0.01880023202081188\n",
      "Recompensa por acortar distancias: +  0.5098677933752439\n",
      "Penalización por duración del episodio: -  0.4911810544613293\n",
      "Recompensa por acortar distancias: +  0.5098681389475284\n",
      "Penalización por duración del episodio: -  0.4913115664987481\n",
      "Recompensa por acortar distancias: +  0.5098681389475284\n",
      "Penalización por duración del episodio: -  0.4914368718015762\n",
      "Recompensa por acortar distancias: +  0.5098681389475284\n",
      "Penalización por duración del episodio: -  0.49183405535275365\n",
      "Step: 4670, Mean Reward (últimos 10 pasos): 0.018034083768725395\n",
      "Recompensa por acortar distancias: +  0.5098681389475284\n",
      "Penalización por duración del episodio: -  0.49222316281706024\n",
      "Recompensa por acortar distancias: +  0.5099397615785114\n",
      "Penalización por duración del episodio: -  0.49234588339340546\n",
      "Recompensa por acortar distancias: +  0.5099336783478232\n",
      "Penalización por duración del episodio: -  0.49259785257545075\n",
      "Recompensa por acortar distancias: +  0.5099336783478232\n",
      "Penalización por duración del episodio: -  0.49298037519510357\n",
      "Recompensa por acortar distancias: +  0.5099336783478232\n",
      "Penalización por duración del episodio: -  0.49310143857392635\n",
      "Recompensa por acortar distancias: +  0.51001699630668\n",
      "Penalización por duración del episodio: -  0.49337178556292416\n",
      "Recompensa por acortar distancias: +  0.5100689088813776\n",
      "Penalización por duración del episodio: -  0.49353483591199915\n",
      "Recompensa por acortar distancias: +  0.5101112705254185\n",
      "Penalización por duración del episodio: -  0.49373561737783667\n",
      "Recompensa por acortar distancias: +  0.5101112705254185\n",
      "Penalización por duración del episodio: -  0.49388523190647904\n",
      "Recompensa por acortar distancias: +  0.5101119378244177\n",
      "Penalización por duración del episodio: -  0.4940126300932317\n",
      "Step: 4680, Mean Reward (últimos 10 pasos): 0.01609930768609047\n",
      "Recompensa por acortar distancias: +  0.5101119378244177\n",
      "Penalización por duración del episodio: -  0.49411759696266416\n",
      "Recompensa por acortar distancias: +  0.5101119378244177\n",
      "Penalización por duración del episodio: -  0.49455215436986577\n",
      "Recompensa por acortar distancias: +  0.5101119378244177\n",
      "Penalización por duración del episodio: -  0.49494204489852833\n",
      "Recompensa por acortar distancias: +  0.5101912865674616\n",
      "Penalización por duración del episodio: -  0.49504327919361396\n",
      "Recompensa por acortar distancias: +  0.5102295070021593\n",
      "Penalización por duración del episodio: -  0.49533745452862404\n",
      "Recompensa por acortar distancias: +  0.5102295070021593\n",
      "Penalización por duración del episodio: -  0.49545050898401855\n",
      "steer input from model: 0.9 , throttle:  0.7\n",
      "reward: 0.014778998018140754\n",
      "Recompensa por acortar distancias: +  0.5102295070021593\n",
      "Penalización por duración del episodio: -  0.4955505293981067\n",
      "Recompensa por acortar distancias: +  0.5102295070021593\n",
      "Penalización por duración del episodio: -  0.4956610934340425\n",
      "Recompensa por acortar distancias: +  0.5102295070021593\n",
      "Penalización por duración del episodio: -  0.4957977509531206\n",
      "Recompensa por acortar distancias: +  0.5102617931966975\n",
      "Penalización por duración del episodio: -  0.4959200512938468\n",
      "Step: 4690, Mean Reward (últimos 10 pasos): 0.014341741800308228\n",
      "Recompensa por acortar distancias: +  0.5102617931966975\n",
      "Penalización por duración del episodio: -  0.4960278571847236\n",
      "Recompensa por acortar distancias: +  0.5102730537242179\n",
      "Penalización por duración del episodio: -  0.49649022622009703\n",
      "Recompensa por acortar distancias: +  0.5102780881894994\n",
      "Penalización por duración del episodio: -  0.49689229556381864\n",
      "Recompensa por acortar distancias: +  0.5102780881894994\n",
      "Penalización por duración del episodio: -  0.49728874837378584\n",
      "Recompensa por acortar distancias: +  0.5102686150519157\n",
      "Penalización por duración del episodio: -  0.4976917252017787\n",
      "Recompensa por acortar distancias: +  0.5102686150519157\n",
      "Penalización por duración del episodio: -  0.49809290499448006\n",
      "Recompensa por acortar distancias: +  0.510283813774108\n",
      "Penalización por duración del episodio: -  0.4982171491841803\n",
      "Recompensa por acortar distancias: +  0.5102951696082303\n",
      "Penalización por duración del episodio: -  0.4984958753658771\n",
      "Recompensa por acortar distancias: +  0.5102961645837465\n",
      "Penalización por duración del episodio: -  0.49888552611857023\n",
      "Recompensa por acortar distancias: +  0.5102963611956652\n",
      "Penalización por duración del episodio: -  0.4992762511062937\n",
      "Step: 4700, Mean Reward (últimos 10 pasos): 0.011020109988749027\n",
      "Recompensa por acortar distancias: +  0.5102963611956652\n",
      "Penalización por duración del episodio: -  0.499656707102359\n",
      "Penalización por duración del episodio\n",
      "Recompensa por acortar distancias: +  0.9156967677845992\n",
      "Penalización por duración del episodio: -  0.269181231201675\n",
      "Recompensa por acortar distancias: +  0.9156967677845992\n",
      "Penalización por duración del episodio: -  0.26947391783891766\n",
      "Recompensa por acortar distancias: +  0.9156963555115124\n",
      "Penalización por duración del episodio: -  0.2697644334347824\n",
      "Recompensa por acortar distancias: +  0.9156962229947743\n",
      "Penalización por parar muy lejos: -  0.16593129070565418\n",
      "Penalización por duración del episodio: -  0.27007850996562766\n",
      "Recompensa por acortar distancias: +  0.9156962229947743\n",
      "Penalización por parar muy lejos: -  0.16593129070565418\n",
      "Penalización por duración del episodio: -  0.2703775634719439\n",
      "Recompensa por acortar distancias: +  0.9156962229947743\n",
      "Penalización por duración del episodio: -  0.27068542444091037\n",
      "Recompensa por acortar distancias: +  0.9156958622538067\n",
      "Penalización por parar muy lejos: -  0.16593064397177992\n",
      "Penalización por duración del episodio: -  0.2707644389654687\n",
      "Recompensa por acortar distancias: +  0.9156960021331237\n",
      "Penalización por parar muy lejos: -  0.16593089474589964\n",
      "Penalización por duración del episodio: -  0.2709905383997187\n",
      "Step: 4710, Mean Reward (últimos 10 pasos): 0.4787745773792267\n",
      "Recompensa por acortar distancias: +  0.9156960021331237\n",
      "Penalización por parar muy lejos: -  0.16593089474589964\n",
      "Penalización por duración del episodio: -  0.27130063362149354\n",
      "Recompensa por acortar distancias: +  0.9156960463054958\n",
      "Penalización por parar muy lejos: -  0.16593097393779\n",
      "Penalización por duración del episodio: -  0.2716107722406695\n",
      "Recompensa por acortar distancias: +  0.9156961272881236\n",
      "Penalización por duración del episodio: -  0.2719118532605284\n",
      "Recompensa por acortar distancias: +  0.9156963260633646\n",
      "Penalización por duración del episodio: -  0.27222423867496587\n",
      "Recompensa por acortar distancias: +  0.9156963260633646\n",
      "Penalización por parar muy lejos: -  0.165931475487132\n",
      "Penalización por duración del episodio: -  0.272306898437072\n",
      "Recompensa por acortar distancias: +  0.9156963260633646\n",
      "Penalización por parar muy lejos: -  0.165931475487132\n",
      "Penalización por duración del episodio: -  0.2723870931283684\n",
      "Recompensa por acortar distancias: +  0.9156963260633646\n",
      "Penalización por duración del episodio: -  0.2725355581945843\n",
      "Recompensa por acortar distancias: +  0.9156963260633646\n",
      "Penalización por duración del episodio: -  0.27285391662672237\n",
      "Recompensa por acortar distancias: +  0.9156962082706805\n",
      "Penalización por duración del episodio: -  0.2731682374443283\n",
      "Recompensa por acortar distancias: +  0.9156962082706805\n",
      "Penalización por parar muy lejos: -  0.16593126430831365\n",
      "Penalización por duración del episodio: -  0.2732810143366785\n",
      "Step: 4720, Mean Reward (últimos 10 pasos): 0.47648394107818604\n",
      "Recompensa por acortar distancias: +  0.9156963996837164\n",
      "Penalización por parar muy lejos: -  0.1659316074740028\n",
      "Penalización por duración del episodio: -  0.2734780707415335\n",
      "Recompensa por acortar distancias: +  0.9156964512179278\n",
      "Penalización por parar muy lejos: -  0.16593169986486236\n",
      "Penalización por duración del episodio: -  0.27379752346304065\n",
      "steer input from model: 0.0 , throttle:  0.0\n",
      "reward: 0.47596722789002477\n",
      "Recompensa por acortar distancias: +  0.9156966720785101\n",
      "Penalización por duración del episodio: -  0.2740947368862677\n",
      "Recompensa por acortar distancias: +  0.9156966720785101\n",
      "Penalización por duración del episodio: -  0.2743995705662276\n",
      "Recompensa por acortar distancias: +  0.9156966720785101\n",
      "Penalización por duración del episodio: -  0.2744676101000411\n",
      "Recompensa por acortar distancias: +  0.9156966426304628\n",
      "Penalización por parar muy lejos: -  0.1659320430312731\n",
      "Penalización por duración del episodio: -  0.2747121015055777\n",
      "Recompensa por acortar distancias: +  0.9156967088885559\n",
      "Penalización por duración del episodio: -  0.27479153023443786\n",
      "Recompensa por acortar distancias: +  0.9156967088885559\n",
      "Penalización por duración del episodio: -  0.27502613224298256\n",
      "Recompensa por acortar distancias: +  0.9156967088885559\n",
      "Penalización por duración del episodio: -  0.27535216446356586\n",
      "Recompensa por acortar distancias: +  0.9156966868025304\n",
      "Penalización por parar muy lejos: -  0.16593212222360243\n",
      "Penalización por duración del episodio: -  0.2756581130847141\n",
      "Step: 4730, Mean Reward (últimos 10 pasos): 0.47410646080970764\n",
      "Recompensa por acortar distancias: +  0.9156967236125705\n",
      "Penalización por duración del episodio: -  0.2759656918039151\n",
      "Recompensa por acortar distancias: +  0.9156967825086042\n",
      "Penalización por parar muy lejos: -  0.16593229380708657\n",
      "Penalización por duración del episodio: -  0.2760556320565997\n",
      "Recompensa por acortar distancias: +  0.9156967825086042\n",
      "Penalización por parar muy lejos: -  0.16593229380708657\n",
      "Penalización por duración del episodio: -  0.2762687681876278\n",
      "Recompensa por acortar distancias: +  0.9156967825086042\n",
      "Penalización por parar muy lejos: -  0.16593229380708657\n",
      "Penalización por duración del episodio: -  0.2765860321794971\n",
      "Recompensa por acortar distancias: +  0.9156968045946072\n",
      "Penalización por duración del episodio: -  0.27667528621538046\n",
      "Recompensa por acortar distancias: +  0.9156968045946072\n",
      "Penalización por duración del episodio: -  0.27675687465229587\n",
      "Recompensa por acortar distancias: +  0.9156968561285941\n",
      "Penalización por duración del episodio: -  0.2768969476308679\n",
      "Recompensa por acortar distancias: +  0.9156968561285941\n",
      "Penalización por duración del episodio: -  0.27720745764408383\n",
      "Recompensa por acortar distancias: +  0.9156968561285941\n",
      "Penalización por duración del episodio: -  0.27729655344435555\n",
      "Recompensa por acortar distancias: +  0.915696892938567\n",
      "Penalización por duración del episodio: -  0.2775171448926748\n",
      "Step: 4740, Mean Reward (últimos 10 pasos): 0.6381797194480896\n",
      "Recompensa por acortar distancias: +  0.9156969960064137\n",
      "Penalización por parar muy lejos: -  0.16593267657075564\n",
      "Penalización por duración del episodio: -  0.2778302166739934\n",
      "Recompensa por acortar distancias: +  0.915697025454349\n",
      "Penalización por parar muy lejos: -  0.16593272936580003\n",
      "Penalización por duración del episodio: -  0.2781356503332494\n",
      "steer input from model: -0.9 , throttle:  0.0\n",
      "reward: 0.4716286457552995\n",
      "Recompensa por acortar distancias: +  0.9156969665584692\n",
      "Penalización por parar muy lejos: -  0.1659326237757248\n",
      "Penalización por duración del episodio: -  0.278452456190053\n",
      "Recompensa por acortar distancias: +  0.9156969665584692\n",
      "Penalización por duración del episodio: -  0.2787714153597541\n",
      "Recompensa por acortar distancias: +  0.9156969739204561\n",
      "Penalización por duración del episodio: -  0.2788643726566471\n",
      "Recompensa por acortar distancias: +  0.9156969739204561\n",
      "Penalización por parar muy lejos: -  0.16593263697448127\n",
      "Penalización por duración del episodio: -  0.2790823142967084\n",
      "Recompensa por acortar distancias: +  0.9156969739204561\n",
      "Penalización por duración del episodio: -  0.2793950000957315\n",
      "Recompensa por acortar distancias: +  0.9156970696262342\n",
      "Penalización por parar muy lejos: -  0.16593280855839176\n",
      "Penalización por duración del episodio: -  0.2794800957197005\n",
      "Recompensa por acortar distancias: +  0.9156970696262342\n",
      "Penalización por parar muy lejos: -  0.16593280855839176\n",
      "Penalización por duración del episodio: -  0.2797052007717651\n",
      "Recompensa por acortar distancias: +  0.9156971874178257\n",
      "Penalización por duración del episodio: -  0.2797993575716629\n",
      "Step: 4750, Mean Reward (últimos 10 pasos): 0.6358978152275085\n",
      "Recompensa por acortar distancias: +  0.9156971874178257\n",
      "Penalización por parar muy lejos: -  0.16593301973878447\n",
      "Penalización por duración del episodio: -  0.28002396130451057\n",
      "Recompensa por acortar distancias: +  0.9156971874178257\n",
      "Penalización por parar muy lejos: -  0.16593301973878447\n",
      "Penalización por duración del episodio: -  0.2801087076853764\n",
      "Recompensa por acortar distancias: +  0.9156971874178257\n",
      "Penalización por parar muy lejos: -  0.16593301973878447\n",
      "Penalización por duración del episodio: -  0.2802007499308502\n",
      "Recompensa por acortar distancias: +  0.9156971874178257\n",
      "Penalización por duración del episodio: -  0.2803331552435516\n",
      "Recompensa por acortar distancias: +  0.9156971874178257\n",
      "Penalización por duración del episodio: -  0.28064954639957956\n",
      "Recompensa por acortar distancias: +  0.9156971579699418\n",
      "Penalización por duración del episodio: -  0.2807405320004243\n",
      "Recompensa por acortar distancias: +  0.9156971579699418\n",
      "Penalización por parar muy lejos: -  0.1659329669436661\n",
      "Penalización por duración del episodio: -  0.28083187746400634\n",
      "Recompensa por acortar distancias: +  0.9156971579699418\n",
      "Penalización por parar muy lejos: -  0.1659329669436661\n",
      "Penalización por duración del episodio: -  0.28096622266469595\n",
      "Recompensa por acortar distancias: +  0.9156972831233836\n",
      "Penalización por duración del episodio: -  0.28105837886397156\n",
      "Recompensa por acortar distancias: +  0.9156972831233836\n",
      "Penalización por parar muy lejos: -  0.16593319132301204\n",
      "Penalización por duración del episodio: -  0.28115915949374365\n",
      "Step: 4760, Mean Reward (últimos 10 pasos): 0.4686049222946167\n",
      "Recompensa por acortar distancias: +  0.9156972831233836\n",
      "Penalización por duración del episodio: -  0.281251325304979\n",
      "Recompensa por acortar distancias: +  0.9156972831233836\n",
      "Penalización por parar muy lejos: -  0.16593319132301204\n",
      "Penalización por duración del episodio: -  0.28161478462238165\n",
      "steer input from model: -0.9 , throttle:  0.0\n",
      "reward: 0.46814930717798997\n",
      "Recompensa por acortar distancias: +  0.9156973272951463\n",
      "Penalización por duración del episodio: -  0.2817562909079456\n",
      "Recompensa por acortar distancias: +  0.9156973272951463\n",
      "Penalización por duración del episodio: -  0.2819276778003821\n",
      "Recompensa por acortar distancias: +  0.9156972904853456\n",
      "Penalización por parar muy lejos: -  0.16593320452180466\n",
      "Penalización por duración del episodio: -  0.282241303670301\n",
      "Recompensa por acortar distancias: +  0.9156972904853456\n",
      "Penalización por parar muy lejos: -  0.16593320452180466\n",
      "Penalización por duración del episodio: -  0.28255984867267986\n",
      "Recompensa por acortar distancias: +  0.9156971358840228\n",
      "Penalización por parar muy lejos: -  0.16593292734733617\n",
      "Penalización por duración del episodio: -  0.2828795497878385\n",
      "Recompensa por acortar distancias: +  0.9156971579699418\n",
      "Penalización por duración del episodio: -  0.2831866105681014\n",
      "Recompensa por acortar distancias: +  0.9156972463135653\n",
      "Penalización por duración del episodio: -  0.28351262974090374\n",
      "Recompensa por acortar distancias: +  0.9156973125712279\n",
      "Penalización por duración del episodio: -  0.2838428206408185\n",
      "Step: 4770, Mean Reward (últimos 10 pasos): 0.6318544745445251\n",
      "Recompensa por acortar distancias: +  0.9156974230005601\n",
      "Penalización por parar muy lejos: -  0.1659334421002157\n",
      "Penalización por duración del episodio: -  0.2839709644680037\n",
      "Recompensa por acortar distancias: +  0.9156974230005601\n",
      "Penalización por parar muy lejos: -  0.1659334421002157\n",
      "Penalización por duración del episodio: -  0.28416133726229487\n",
      "Recompensa por acortar distancias: +  0.9156974230005601\n",
      "Penalización por duración del episodio: -  0.2844783950339576\n",
      "Recompensa por acortar distancias: +  0.9156974230005601\n",
      "Penalización por parar muy lejos: -  0.1659334421002157\n",
      "Penalización por duración del episodio: -  0.2845693396892521\n",
      "Recompensa por acortar distancias: +  0.9156974230005601\n",
      "Penalización por duración del episodio: -  0.28469120423179345\n",
      "Recompensa por acortar distancias: +  0.9156974230005601\n",
      "Penalización por parar muy lejos: -  0.1659334421002157\n",
      "Penalización por duración del episodio: -  0.28479804055036506\n",
      "Recompensa por acortar distancias: +  0.9156970107303826\n",
      "Penalización por duración del episodio: -  0.28489896043053686\n",
      "Recompensa por acortar distancias: +  0.9156970107303826\n",
      "Penalización por parar muy lejos: -  0.16593270296827617\n",
      "Penalización por duración del episodio: -  0.2849822856864968\n",
      "Recompensa por acortar distancias: +  0.9156971579699418\n",
      "Penalización por duración del episodio: -  0.2851109675360284\n",
      "Recompensa por acortar distancias: +  0.9156971579699418\n",
      "Penalización por parar muy lejos: -  0.1659329669436661\n",
      "Penalización por duración del episodio: -  0.2854345269200514\n",
      "Step: 4780, Mean Reward (últimos 10 pasos): 0.46432965993881226\n",
      "Recompensa por acortar distancias: +  0.9156971579699418\n",
      "Penalización por duración del episodio: -  0.2855219880074467\n",
      "Recompensa por acortar distancias: +  0.9156971579699418\n",
      "Penalización por duración del episodio: -  0.28564482251036166\n",
      "steer input from model: -0.05 , throttle:  0.3\n",
      "reward: 0.6300523354595802\n",
      "Recompensa por acortar distancias: +  0.9156971579699418\n",
      "Penalización por duración del episodio: -  0.2860624447136123\n",
      "Recompensa por acortar distancias: +  0.9156972831233836\n",
      "Penalización por duración del episodio: -  0.2863884785270684\n",
      "Recompensa por acortar distancias: +  0.9156972831233836\n",
      "Penalización por parar muy lejos: -  0.16593319132301204\n",
      "Penalización por duración del episodio: -  0.2864999757651459\n",
      "Recompensa por acortar distancias: +  0.9156972831233836\n",
      "Penalización por duración del episodio: -  0.2867035007965407\n",
      "Recompensa por acortar distancias: +  0.9156968855765736\n",
      "Penalización por parar muy lejos: -  0.1659324785894592\n",
      "Penalización por duración del episodio: -  0.28702047200968417\n",
      "Recompensa por acortar distancias: +  0.9156969518344935\n",
      "Penalización por duración del episodio: -  0.2873413483385844\n",
      "Recompensa por acortar distancias: +  0.9156970033683983\n",
      "Penalización por parar muy lejos: -  0.16593268976951547\n",
      "Penalización por duración del episodio: -  0.28765824203280943\n",
      "Recompensa por acortar distancias: +  0.9156971211600738\n",
      "Penalización por parar muy lejos: -  0.16593290094978708\n",
      "Penalización por duración del episodio: -  0.28775211547464\n",
      "Step: 4790, Mean Reward (últimos 10 pasos): 0.4620121121406555\n",
      "Recompensa por acortar distancias: +  0.9156971506079694\n",
      "Penalización por duración del episodio: -  0.28785075770802104\n",
      "Recompensa por acortar distancias: +  0.9156971506079694\n",
      "Penalización por duración del episodio: -  0.2879534921437058\n",
      "Recompensa por acortar distancias: +  0.9156971506079694\n",
      "Penalización por duración del episodio: -  0.2880602969246186\n",
      "Recompensa por acortar distancias: +  0.9156972389515999\n",
      "Penalización por parar muy lejos: -  0.16593311213027395\n",
      "Penalización por duración del episodio: -  0.28817534646468335\n",
      "Recompensa por acortar distancias: +  0.9156972389515999\n",
      "Penalización por duración del episodio: -  0.28825724306631945\n",
      "Recompensa por acortar distancias: +  0.9156972389515999\n",
      "Penalización por parar muy lejos: -  0.16593311213027395\n",
      "Penalización por duración del episodio: -  0.28862280145521924\n",
      "Recompensa por acortar distancias: +  0.9156972389515999\n",
      "Penalización por duración del episodio: -  0.28895219374755715\n",
      "Recompensa por acortar distancias: +  0.9156972389515999\n",
      "Penalización por duración del episodio: -  0.2890932817675092\n",
      "Recompensa por acortar distancias: +  0.9156968855765736\n",
      "Penalización por duración del episodio: -  0.28925288912551494\n",
      "Recompensa por acortar distancias: +  0.915697025454349\n",
      "Penalización por duración del episodio: -  0.28934740494998173\n",
      "Step: 4800, Mean Reward (últimos 10 pasos): 0.6263496279716492\n",
      "Recompensa por acortar distancias: +  0.915697025454349\n",
      "Penalización por parar muy lejos: -  0.16593272936580003\n",
      "Penalización por duración del episodio: -  0.28957157879485323\n",
      "Recompensa por acortar distancias: +  0.915697025454349\n",
      "Penalización por parar muy lejos: -  0.16593272936580003\n",
      "Penalización por duración del episodio: -  0.289889504603671\n",
      "steer input from model: -0.05 , throttle:  0.0\n",
      "reward: 0.45987479148487787\n",
      "Recompensa por acortar distancias: +  0.9156969960064137\n",
      "Penalización por parar muy lejos: -  0.16593267657075564\n",
      "Penalización por duración del episodio: -  0.28998653420614245\n",
      "Recompensa por acortar distancias: +  0.9156969591964816\n",
      "Penalización por duración del episodio: -  0.29021774897396446\n",
      "Recompensa por acortar distancias: +  0.9156969591964816\n",
      "Penalización por duración del episodio: -  0.29054543154039736\n",
      "Recompensa por acortar distancias: +  0.9156969591964816\n",
      "Penalización por parar muy lejos: -  0.16593261057696915\n",
      "Penalización por duración del episodio: -  0.2908590367316608\n",
      "Recompensa por acortar distancias: +  0.9156968561285941\n",
      "Penalización por duración del episodio: -  0.29118203846110374\n",
      "Recompensa por acortar distancias: +  0.9156969076625522\n",
      "Penalización por duración del episodio: -  0.2915150947270544\n",
      "Recompensa por acortar distancias: +  0.9156969960064137\n",
      "Penalización por duración del episodio: -  0.29163118544052224\n",
      "Recompensa por acortar distancias: +  0.9156969960064137\n",
      "Penalización por duración del episodio: -  0.29184368416678896\n",
      "Step: 4810, Mean Reward (últimos 10 pasos): 0.623853325843811\n",
      "Recompensa por acortar distancias: +  0.9156969739204561\n",
      "Penalización por duración del episodio: -  0.29217076550946\n",
      "Recompensa por acortar distancias: +  0.9156970696262342\n",
      "Penalización por duración del episodio: -  0.29225779439609234\n",
      "Recompensa por acortar distancias: +  0.9156970696262342\n",
      "Penalización por parar muy lejos: -  0.16593280855839176\n",
      "Penalización por duración del episodio: -  0.2923528043690792\n",
      "Recompensa por acortar distancias: +  0.9156970696262342\n",
      "Penalización por duración del episodio: -  0.2924565301388971\n",
      "Recompensa por acortar distancias: +  0.9156970696262342\n",
      "Penalización por parar muy lejos: -  0.16593280855839176\n",
      "Penalización por duración del episodio: -  0.292816992807889\n",
      "Recompensa por acortar distancias: +  0.9156970696262342\n",
      "Penalización por parar muy lejos: -  0.16593280855839176\n",
      "Penalización por duración del episodio: -  0.29314854710646504\n",
      "Recompensa por acortar distancias: +  0.9156969076625522\n",
      "Penalización por duración del episodio: -  0.29328794803942404\n",
      "Recompensa por acortar distancias: +  0.9156969076625522\n",
      "Penalización por parar muy lejos: -  0.16593251818570337\n",
      "Penalización por duración del episodio: -  0.2934008095124187\n",
      "Recompensa por acortar distancias: +  0.9156970769882131\n",
      "Penalización por duración del episodio: -  0.29349680820136453\n",
      "Recompensa por acortar distancias: +  0.9156970769882131\n",
      "Penalización por duración del episodio: -  0.29379341767610573\n",
      "Step: 4820, Mean Reward (últimos 10 pasos): 0.621903657913208\n",
      "Recompensa por acortar distancias: +  0.9156970769882131\n",
      "Penalización por duración del episodio: -  0.29412163800157914\n",
      "Recompensa por acortar distancias: +  0.9156970769882131\n",
      "Penalización por parar muy lejos: -  0.16593282175715998\n",
      "Penalización por duración del episodio: -  0.29422146273228916\n",
      "steer input from model: 0.05 , throttle:  0.0\n",
      "reward: 0.455542792498764\n",
      "Recompensa por acortar distancias: +  0.9156972242276673\n",
      "Penalización por duración del episodio: -  0.29444089406006646\n",
      "Recompensa por acortar distancias: +  0.9156972242276673\n",
      "Penalización por parar muy lejos: -  0.16593308573270132\n",
      "Penalización por duración del episodio: -  0.2945344061538873\n",
      "Recompensa por acortar distancias: +  0.9156972242276673\n",
      "Penalización por duración del episodio: -  0.29474501284680055\n",
      "Recompensa por acortar distancias: +  0.9156972242276673\n",
      "Penalización por parar muy lejos: -  0.16593308573270132\n",
      "Penalización por duración del episodio: -  0.29488222387272944\n",
      "Recompensa por acortar distancias: +  0.9156972242276673\n",
      "Penalización por parar muy lejos: -  0.16593308573270132\n",
      "Penalización por duración del episodio: -  0.29502345390609064\n",
      "Recompensa por acortar distancias: +  0.9156972242276673\n",
      "Penalización por duración del episodio: -  0.29514798809634607\n",
      "Recompensa por acortar distancias: +  0.9156972242276673\n",
      "Penalización por parar muy lejos: -  0.16593308573270132\n",
      "Penalización por duración del episodio: -  0.295387933044246\n",
      "Recompensa por acortar distancias: +  0.9156972021417641\n",
      "Penalización por duración del episodio: -  0.29547724241473483\n",
      "Step: 4830, Mean Reward (últimos 10 pasos): 0.6202199459075928\n",
      "Recompensa por acortar distancias: +  0.9156971874178257\n",
      "Penalización por duración del episodio: -  0.2957161410821522\n",
      "Recompensa por acortar distancias: +  0.9156971874178257\n",
      "Penalización por duración del episodio: -  0.29583148279663574\n",
      "Recompensa por acortar distancias: +  0.9156971874178257\n",
      "Penalización por duración del episodio: -  0.295960417685663\n",
      "Recompensa por acortar distancias: +  0.9156971874178257\n",
      "Penalización por duración del episodio: -  0.29635926525044615\n",
      "Recompensa por acortar distancias: +  0.9156972242276673\n",
      "Penalización por duración del episodio: -  0.29668207845936256\n",
      "Recompensa por acortar distancias: +  0.9156973493810199\n",
      "Penalización por parar muy lejos: -  0.16593331011217594\n",
      "Penalización por duración del episodio: -  0.296780167699974\n",
      "Recompensa por acortar distancias: +  0.9156973493810199\n",
      "Penalización por duración del episodio: -  0.297010535874044\n",
      "Recompensa por acortar distancias: +  0.9156973493810199\n",
      "Penalización por duración del episodio: -  0.2973341522328864\n",
      "Recompensa por acortar distancias: +  0.9156972978473069\n",
      "Penalización por parar muy lejos: -  0.16593321772059813\n",
      "Penalización por duración del episodio: -  0.2976580566314388\n",
      "Recompensa por acortar distancias: +  0.9156972757614211\n",
      "Penalización por duración del episodio: -  0.2979772266935184\n",
      "Step: 4840, Mean Reward (últimos 10 pasos): 0.6177200675010681\n",
      "Recompensa por acortar distancias: +  0.9156972757614211\n",
      "Penalización por duración del episodio: -  0.2980654513741146\n",
      "Recompensa por acortar distancias: +  0.9156972757614211\n",
      "Penalización por duración del episodio: -  0.2981899581267755\n",
      "steer input from model: -0.25 , throttle:  0.3\n",
      "reward: 0.6175073176346456\n",
      "Recompensa por acortar distancias: +  0.9156973493810199\n",
      "Penalización por parar muy lejos: -  0.16593331011217594\n",
      "Penalización por duración del episodio: -  0.29828775059039986\n",
      "Recompensa por acortar distancias: +  0.9156973493810199\n",
      "Penalización por parar muy lejos: -  0.16593331011217594\n",
      "Penalización por duración del episodio: -  0.29843459365438413\n",
      "Recompensa por acortar distancias: +  0.9156974450864109\n",
      "Penalización por duración del episodio: -  0.29855524955598917\n",
      "Recompensa por acortar distancias: +  0.9156974450864109\n",
      "Penalización por parar muy lejos: -  0.16593348169664404\n",
      "Penalización por duración del episodio: -  0.29866613509770623\n",
      "Recompensa por acortar distancias: +  0.9156974450864109\n",
      "Penalización por parar muy lejos: -  0.16593348169664404\n",
      "Penalización por duración del episodio: -  0.29895827275280495\n",
      "Recompensa por acortar distancias: +  0.9156974450864109\n",
      "Penalización por duración del episodio: -  0.29908587741344955\n",
      "Recompensa por acortar distancias: +  0.9156974450864109\n",
      "Penalización por duración del episodio: -  0.29931096325090806\n",
      "Recompensa por acortar distancias: +  0.9156974450864109\n",
      "Penalización por duración del episodio: -  0.2996130880651788\n",
      "Step: 4850, Mean Reward (últimos 10 pasos): 0.6160843372344971\n",
      "Recompensa por acortar distancias: +  0.9156971285220487\n",
      "Penalización por parar muy lejos: -  0.1659329141485612\n",
      "Penalización por duración del episodio: -  0.29994392218988547\n",
      "Recompensa por acortar distancias: +  0.9156971137980985\n",
      "Penalización por parar muy lejos: -  0.1659328877510138\n",
      "Penalización por duración del episodio: -  0.30026540212743785\n",
      "Recompensa por acortar distancias: +  0.9156970917121691\n",
      "Penalización por parar muy lejos: -  0.16593284815469897\n",
      "Penalización por duración del episodio: -  0.30060168496046785\n",
      "Recompensa por acortar distancias: +  0.9156970475402941\n",
      "Penalización por parar muy lejos: -  0.16593276896209214\n",
      "Penalización por duración del episodio: -  0.30069236923831344\n",
      "Recompensa por acortar distancias: +  0.9156970475402941\n",
      "Penalización por duración del episodio: -  0.3009359654971126\n",
      "Recompensa por acortar distancias: +  0.9156970475402941\n",
      "Penalización por parar muy lejos: -  0.16593276896209214\n",
      "Penalización por duración del episodio: -  0.3010516200214063\n",
      "Recompensa por acortar distancias: +  0.9156970475402941\n",
      "Penalización por duración del episodio: -  0.30115660682939\n",
      "Recompensa por acortar distancias: +  0.9156970475402941\n",
      "Penalización por parar muy lejos: -  0.16593276896209214\n",
      "Penalización por duración del episodio: -  0.30125164223933426\n",
      "Recompensa por acortar distancias: +  0.9156970475402941\n",
      "Penalización por parar muy lejos: -  0.16593276896209214\n",
      "Penalización por duración del episodio: -  0.3013413840078264\n",
      "Recompensa por acortar distancias: +  0.9156970475402941\n",
      "Penalización por duración del episodio: -  0.30145963747540866\n",
      "Step: 4860, Mean Reward (últimos 10 pasos): 0.6142374277114868\n",
      "Recompensa por acortar distancias: +  0.9156970033683983\n",
      "Penalización por duración del episodio: -  0.3015737492572039\n",
      "Recompensa por acortar distancias: +  0.9156970033683983\n",
      "Penalización por parar muy lejos: -  0.16593268976951547\n",
      "Penalización por duración del episodio: -  0.30168988968733607\n",
      "steer input from model: -0.9 , throttle:  0.0\n",
      "reward: 0.4480744239115468\n",
      "Recompensa por acortar distancias: +  0.9156971579699418\n",
      "Penalización por duración del episodio: -  0.30190435791678377\n",
      "Recompensa por acortar distancias: +  0.9156971579699418\n",
      "Penalización por parar muy lejos: -  0.1659329669436661\n",
      "Penalización por duración del episodio: -  0.30201102639394906\n",
      "Recompensa por acortar distancias: +  0.9156971579699418\n",
      "Penalización por duración del episodio: -  0.3021058227849248\n",
      "Recompensa por acortar distancias: +  0.9156971579699418\n",
      "Penalización por duración del episodio: -  0.3022320548314232\n",
      "Recompensa por acortar distancias: +  0.9156971579699418\n",
      "Penalización por parar muy lejos: -  0.1659329669436661\n",
      "Penalización por duración del episodio: -  0.30232777059942995\n",
      "Recompensa por acortar distancias: +  0.9156971579699418\n",
      "Penalización por duración del episodio: -  0.3024215419384569\n",
      "Recompensa por acortar distancias: +  0.9156972315896338\n",
      "Penalización por duración del episodio: -  0.30254365293362473\n",
      "Recompensa por acortar distancias: +  0.9156972315896338\n",
      "Penalización por duración del episodio: -  0.3026735110524332\n",
      "Step: 4870, Mean Reward (últimos 10 pasos): 0.6130236983299255\n",
      "Recompensa por acortar distancias: +  0.9156972315896338\n",
      "Penalización por parar muy lejos: -  0.16593309893148722\n",
      "Penalización por duración del episodio: -  0.3028324337917253\n",
      "Recompensa por acortar distancias: +  0.9156972389515999\n",
      "Penalización por duración del episodio: -  0.30293261705621966\n",
      "Recompensa por acortar distancias: +  0.9156972389515999\n",
      "Penalización por duración del episodio: -  0.30305903951631424\n",
      "Recompensa por acortar distancias: +  0.9156972389515999\n",
      "Penalización por duración del episodio: -  0.3031714439817892\n",
      "Recompensa por acortar distancias: +  0.9156972389515999\n",
      "Penalización por parar muy lejos: -  0.16593311213027395\n",
      "Penalización por duración del episodio: -  0.3032676906636651\n",
      "Recompensa por acortar distancias: +  0.9156972389515999\n",
      "Penalización por duración del episodio: -  0.303364010023095\n",
      "Recompensa por acortar distancias: +  0.9156972389515999\n",
      "Penalización por duración del episodio: -  0.30356711916290696\n",
      "Recompensa por acortar distancias: +  0.9156972389515999\n",
      "Penalización por duración del episodio: -  0.30375594944828377\n",
      "Recompensa por acortar distancias: +  0.9156972389515999\n",
      "Penalización por duración del episodio: -  0.3039051810569051\n",
      "Recompensa por acortar distancias: +  0.9156972389515999\n",
      "Penalización por parar muy lejos: -  0.16593311213027395\n",
      "Penalización por duración del episodio: -  0.3042274062800395\n",
      "Step: 4880, Mean Reward (últimos 10 pasos): 0.445536732673645\n",
      "Recompensa por acortar distancias: +  0.9156967825086042\n",
      "Penalización por parar muy lejos: -  0.16593229380708657\n",
      "Penalización por duración del episodio: -  0.3045549592331323\n",
      "Recompensa por acortar distancias: +  0.915696701526548\n",
      "Penalización por parar muy lejos: -  0.16593214862105227\n",
      "Penalización por duración del episodio: -  0.3048864797090566\n",
      "steer input from model: -0.25 , throttle:  0.0\n",
      "reward: 0.4448780731964391\n",
      "Recompensa por acortar distancias: +  0.9156967383365824\n",
      "Penalización por parar muy lejos: -  0.1659322146146916\n",
      "Penalización por duración del episodio: -  0.30520186223599494\n",
      "Recompensa por acortar distancias: +  0.9156968855765736\n",
      "Penalización por parar muy lejos: -  0.1659324785894592\n",
      "Penalización por duración del episodio: -  0.30552480322252346\n",
      "Recompensa por acortar distancias: +  0.9156968855765736\n",
      "Penalización por parar muy lejos: -  0.1659324785894592\n",
      "Penalización por duración del episodio: -  0.3058628627900086\n",
      "Recompensa por acortar distancias: +  0.9156968855765736\n",
      "Penalización por duración del episodio: -  0.305979642778925\n",
      "Recompensa por acortar distancias: +  0.9156968855765736\n",
      "Penalización por parar muy lejos: -  0.1659324785894592\n",
      "Penalización por duración del episodio: -  0.3060643831034533\n",
      "Recompensa por acortar distancias: +  0.9156968487665976\n",
      "Penalización por parar muy lejos: -  0.16593241259573577\n",
      "Penalización por duración del episodio: -  0.306520563358188\n",
      "Recompensa por acortar distancias: +  0.9156969739204561\n",
      "Penalización por duración del episodio: -  0.30683848233263755\n",
      "Recompensa por acortar distancias: +  0.9156969739204561\n",
      "Penalización por parar muy lejos: -  0.16593263697448127\n",
      "Penalización por duración del episodio: -  0.30717369925784455\n",
      "Step: 4890, Mean Reward (últimos 10 pasos): 0.4425906240940094\n",
      "Recompensa por acortar distancias: +  0.9156969223865349\n",
      "Penalización por duración del episodio: -  0.3072612931979299\n",
      "Recompensa por acortar distancias: +  0.9156969223865349\n",
      "Penalización por parar muy lejos: -  0.16593254458320367\n",
      "Penalización por duración del episodio: -  0.30749910806744013\n",
      "Recompensa por acortar distancias: +  0.9156969223865349\n",
      "Penalización por duración del episodio: -  0.3078357676077608\n",
      "Recompensa por acortar distancias: +  0.9156969223865349\n",
      "Penalización por duración del episodio: -  0.3081651849604473\n",
      "Recompensa por acortar distancias: +  0.9156968855765736\n",
      "Penalización por duración del episodio: -  0.3085002652773588\n",
      "Recompensa por acortar distancias: +  0.9156968855765736\n",
      "Penalización por parar muy lejos: -  0.1659324785894592\n",
      "Penalización por duración del episodio: -  0.30882770999656933\n",
      "Recompensa por acortar distancias: +  0.9156969223865349\n",
      "Penalización por duración del episodio: -  0.3089053702760107\n",
      "Recompensa por acortar distancias: +  0.9156969223865349\n",
      "Penalización por duración del episodio: -  0.3090118137997281\n",
      "Recompensa por acortar distancias: +  0.9156970843501915\n",
      "Penalización por duración del episodio: -  0.30916491502976357\n",
      "Recompensa por acortar distancias: +  0.9156970843501915\n",
      "Penalización por duración del episodio: -  0.3095000407086621\n",
      "Step: 4900, Mean Reward (últimos 10 pasos): 0.6061970591545105\n",
      "Recompensa por acortar distancias: +  0.9156970843501915\n",
      "Penalización por duración del episodio: -  0.3098241914098413\n",
      "Recompensa por acortar distancias: +  0.9156970843501915\n",
      "Penalización por duración del episodio: -  0.3099543579065436\n",
      "steer input from model: -0.9 , throttle:  0.3\n",
      "reward: 0.6057427264436479\n",
      "Recompensa por acortar distancias: +  0.9156964144077797\n",
      "Penalización por duración del episodio: -  0.31016335826334085\n",
      "Recompensa por acortar distancias: +  0.9156345527495172\n",
      "Penalización por duración del episodio: -  0.3104900605813071\n",
      "Recompensa por acortar distancias: +  0.9156345527495172\n",
      "Penalización por parar muy lejos: -  0.16582079451896772\n",
      "Penalización por duración del episodio: -  0.31082323891988645\n",
      "Recompensa por acortar distancias: +  0.9151093964283961\n",
      "Penalización por duración del episodio: -  0.31093335098046077\n",
      "Recompensa por acortar distancias: +  0.9149066052790141\n",
      "Penalización por duración del episodio: -  0.31115779901448193\n",
      "Recompensa por acortar distancias: +  0.9147086501347496\n",
      "Penalización por duración del episodio: -  0.3114916820933646\n",
      "Recompensa por acortar distancias: +  0.9147086501347496\n",
      "Penalización por parar muy lejos: -  0.16417759177410332\n",
      "Penalización por duración del episodio: -  0.3118181841652652\n",
      "Recompensa por acortar distancias: +  0.9147086501347496\n",
      "Penalización por duración del episodio: -  0.31214529820070874\n",
      "Step: 4910, Mean Reward (últimos 10 pasos): 0.6025633811950684\n",
      "Recompensa por acortar distancias: +  0.9132347864805456\n",
      "Penalización por parar muy lejos: -  0.16162146189842205\n",
      "Penalización por duración del episodio: -  0.3124829103201509\n",
      "Recompensa por acortar distancias: +  0.9132347864805456\n",
      "Penalización por duración del episodio: -  0.3126454326638538\n",
      "Recompensa por acortar distancias: +  0.9123326169133293\n",
      "Penalización por parar muy lejos: -  0.16009178910749391\n",
      "Penalización por duración del episodio: -  0.31282014751599757\n",
      "Recompensa por acortar distancias: +  0.9119336425630175\n",
      "Penalización por duración del episodio: -  0.31316764439207645\n",
      "Recompensa por acortar distancias: +  0.9114052063141341\n",
      "Penalización por parar muy lejos: -  0.1585461431735199\n",
      "Penalización por duración del episodio: -  0.31326023182177815\n",
      "Recompensa por acortar distancias: +  0.9114052063141341\n",
      "Penalización por duración del episodio: -  0.3135139657143235\n",
      "Recompensa por acortar distancias: +  0.9114052063141341\n",
      "Penalización por parar muy lejos: -  0.1585461431735199\n",
      "Penalización por duración del episodio: -  0.3135891803021114\n",
      "Recompensa por acortar distancias: +  0.9114052063141341\n",
      "Penalización por parar muy lejos: -  0.1585461431735199\n",
      "Penalización por duración del episodio: -  0.31384731003652183\n",
      "Recompensa por acortar distancias: +  0.9114052063141341\n",
      "Penalización por duración del episodio: -  0.3141946042557092\n",
      "Recompensa por acortar distancias: +  0.9092647169294271\n",
      "Penalización por parar muy lejos: -  0.15507879650059592\n",
      "Penalización por duración del episodio: -  0.3145268757071473\n",
      "Step: 4920, Mean Reward (últimos 10 pasos): 0.439659059047699\n",
      "Recompensa por acortar distancias: +  0.9092647169294271\n",
      "Penalización por duración del episodio: -  0.3148692946105608\n",
      "Recompensa por acortar distancias: +  0.9076361726943457\n",
      "Penalización por parar muy lejos: -  0.1525303008248953\n",
      "Penalización por duración del episodio: -  0.3149742998752003\n",
      "steer input from model: -0.9 , throttle:  0.0\n",
      "reward: 0.4401315719942501\n",
      "Recompensa por acortar distancias: +  0.9072531364858797\n",
      "Penalización por duración del episodio: -  0.3150623812334982\n",
      "Recompensa por acortar distancias: +  0.9072531364858797\n",
      "Penalización por parar muy lejos: -  0.15194171387194672\n",
      "Penalización por duración del episodio: -  0.3151587452567049\n",
      "Recompensa por acortar distancias: +  0.9068944662335291\n",
      "Penalización por parar muy lejos: -  0.15139422614372472\n",
      "Penalización por duración del episodio: -  0.31527774033912725\n",
      "Recompensa por acortar distancias: +  0.9068944662335291\n",
      "Penalización por duración del episodio: -  0.31540175836234574\n",
      "Recompensa por acortar distancias: +  0.9062824646985448\n",
      "Penalización por duración del episodio: -  0.31550304922049566\n",
      "Recompensa por acortar distancias: +  0.9062824646985448\n",
      "Penalización por parar muy lejos: -  0.15046811331974352\n",
      "Penalización por duración del episodio: -  0.315870327852684\n",
      "Recompensa por acortar distancias: +  0.9062824646985448\n",
      "Penalización por parar muy lejos: -  0.15046811331974352\n",
      "Penalización por duración del episodio: -  0.3162110292462638\n",
      "Recompensa por acortar distancias: +  0.9042088218029887\n",
      "Penalización por duración del episodio: -  0.3165581333252106\n",
      "Step: 4930, Mean Reward (últimos 10 pasos): 0.587650716304779\n",
      "Recompensa por acortar distancias: +  0.903717787874648\n",
      "Penalización por parar muy lejos: -  0.14669437227222293\n",
      "Penalización por duración del episodio: -  0.31690564312280184\n",
      "Recompensa por acortar distancias: +  0.90239635679267\n",
      "Penalización por parar muy lejos: -  0.14481497236810567\n",
      "Penalización por duración del episodio: -  0.31707141315982507\n",
      "Recompensa por acortar distancias: +  0.9019228825687718\n",
      "Penalización por duración del episodio: -  0.31724830155842626\n",
      "Recompensa por acortar distancias: +  0.9013720209385162\n",
      "Penalización por duración del episodio: -  0.3173377727337234\n",
      "Recompensa por acortar distancias: +  0.901020653403553\n",
      "Penalización por parar muy lejos: -  0.14290324389510317\n",
      "Penalización por duración del episodio: -  0.3176042675063715\n",
      "Recompensa por acortar distancias: +  0.9006016876012812\n",
      "Penalización por duración del episodio: -  0.31794687475467936\n",
      "Recompensa por acortar distancias: +  0.9006016876012812\n",
      "Penalización por duración del episodio: -  0.31828323855161617\n",
      "Recompensa por acortar distancias: +  0.8984993362180501\n",
      "Penalización por parar muy lejos: -  0.13951316211809156\n",
      "Penalización por duración del episodio: -  0.31838088001524045\n",
      "Recompensa por acortar distancias: +  0.8984993362180501\n",
      "Penalización por duración del episodio: -  0.31848899077662746\n",
      "Recompensa por acortar distancias: +  0.89791682438453\n",
      "Penalización por parar muy lejos: -  0.13875006958820915\n",
      "Penalización por duración del episodio: -  0.31858710580623906\n",
      "Step: 4940, Mean Reward (últimos 10 pasos): 0.4405796527862549\n",
      "Recompensa por acortar distancias: +  0.89791682438453\n",
      "Penalización por parar muy lejos: -  0.13875006958820915\n",
      "Penalización por duración del episodio: -  0.31896394076757567\n",
      "Recompensa por acortar distancias: +  0.89791682438453\n",
      "Penalización por duración del episodio: -  0.3193189207387258\n",
      "steer input from model: 0.0 , throttle:  0.7\n",
      "reward: 0.5785979036458042\n",
      "Recompensa por acortar distancias: +  0.8953188173472612\n",
      "Penalización por duración del episodio: -  0.31965672983087506\n",
      "Recompensa por acortar distancias: +  0.8942036191791599\n",
      "Penalización por duración del episodio: -  0.31978707505872483\n",
      "Recompensa por acortar distancias: +  0.8942036191791599\n",
      "Penalización por parar muy lejos: -  0.13405365722890056\n",
      "Penalización por duración del episodio: -  0.3199924871026785\n",
      "Recompensa por acortar distancias: +  0.8942036191791599\n",
      "Penalización por parar muy lejos: -  0.13405365722890056\n",
      "Penalización por duración del episodio: -  0.3203334609055556\n",
      "Recompensa por acortar distancias: +  0.8942036191791599\n",
      "Penalización por duración del episodio: -  0.3204440983506667\n",
      "Recompensa por acortar distancias: +  0.8942036191791599\n",
      "Penalización por duración del episodio: -  0.3206746630578545\n",
      "Recompensa por acortar distancias: +  0.8916620023831515\n",
      "Penalización por parar muy lejos: -  0.13099738105140182\n",
      "Penalización por duración del episodio: -  0.3210087037230103\n",
      "Recompensa por acortar distancias: +  0.8910641594294978\n",
      "Penalización por duración del episodio: -  0.3211174319526138\n",
      "Step: 4950, Mean Reward (últimos 10 pasos): 0.5699467062950134\n",
      "Recompensa por acortar distancias: +  0.8910641594294978\n",
      "Penalización por duración del episodio: -  0.321356191750277\n",
      "Recompensa por acortar distancias: +  0.8894271243618062\n",
      "Penalización por duración del episodio: -  0.32149672149787367\n",
      "Recompensa por acortar distancias: +  0.8887669113042095\n",
      "Penalización por parar muy lejos: -  0.1276617693114367\n",
      "Penalización por duración del episodio: -  0.32168416038729325\n",
      "Recompensa por acortar distancias: +  0.8881122220321642\n",
      "Penalización por parar muy lejos: -  0.1269279728199119\n",
      "Penalización por duración del episodio: -  0.3220258801368445\n",
      "Recompensa por acortar distancias: +  0.8876358234683709\n",
      "Penalización por duración del episodio: -  0.3223693840776941\n",
      "Recompensa por acortar distancias: +  0.8876358234683709\n",
      "Penalización por duración del episodio: -  0.3226907091776536\n",
      "Recompensa por acortar distancias: +  0.8876358234683709\n",
      "Penalización por duración del episodio: -  0.3230285885325982\n",
      "Recompensa por acortar distancias: +  0.8840405038005238\n",
      "Penalización por duración del episodio: -  0.32312540007477475\n",
      "Recompensa por acortar distancias: +  0.8840405038005238\n",
      "Penalización por parar muy lejos: -  0.1225244941581965\n",
      "Penalización por duración del episodio: -  0.32336840554933666\n",
      "Recompensa por acortar distancias: +  0.8832083120514632\n",
      "Penalización por parar muy lejos: -  0.12165708035267937\n",
      "Penalización por duración del episodio: -  0.32371492828543097\n",
      "Step: 4960, Mean Reward (últimos 10 pasos): 0.43783628940582275\n",
      "Recompensa por acortar distancias: +  0.8832083120514632\n",
      "Penalización por duración del episodio: -  0.32405529403718114\n",
      "Recompensa por acortar distancias: +  0.8809668183596231\n",
      "Penalización por parar muy lejos: -  0.1193728716542307\n",
      "Penalización por duración del episodio: -  0.3241534098313859\n",
      "steer input from model: -0.25 , throttle:  0.0\n",
      "reward: 0.43744053687400647\n",
      "Recompensa por acortar distancias: +  0.8801400240603064\n",
      "Penalización por duración del episodio: -  0.32428229581477463\n",
      "Recompensa por acortar distancias: +  0.8801400240603064\n",
      "Penalización por parar muy lejos: -  0.1185489848252505\n",
      "Penalización por duración del episodio: -  0.32443532406829634\n",
      "Recompensa por acortar distancias: +  0.8801400240603064\n",
      "Penalización por duración del episodio: -  0.3247241411417625\n",
      "Recompensa por acortar distancias: +  0.8801400240603064\n",
      "Penalización por duración del episodio: -  0.3247995125846814\n",
      "Recompensa por acortar distancias: +  0.8801400240603064\n",
      "Penalización por duración del episodio: -  0.3249318005332602\n",
      "Recompensa por acortar distancias: +  0.8801400240603064\n",
      "Penalización por parar muy lejos: -  0.1185489848252505\n",
      "Penalización por duración del episodio: -  0.32507781614822556\n",
      "Recompensa por acortar distancias: +  0.8801400240603064\n",
      "Penalización por duración del episodio: -  0.32525504506927516\n",
      "Recompensa por acortar distancias: +  0.8762062272742002\n",
      "Penalización por duración del episodio: -  0.32533230671348934\n",
      "Step: 4970, Mean Reward (últimos 10 pasos): 0.5508739352226257\n",
      "Recompensa por acortar distancias: +  0.8762062272742002\n",
      "Penalización por parar muy lejos: -  0.11476002317902344\n",
      "Penalización por duración del episodio: -  0.32546286463470436\n",
      "Recompensa por acortar distancias: +  0.875199573673374\n",
      "Penalización por parar muy lejos: -  0.11382382380877937\n",
      "Penalización por duración del episodio: -  0.3257803758737001\n",
      "Recompensa por acortar distancias: +  0.875199573673374\n",
      "Penalización por duración del episodio: -  0.3258962246423498\n",
      "Recompensa por acortar distancias: +  0.875199573673374\n",
      "Penalización por parar muy lejos: -  0.11382382380877937\n",
      "Penalización por duración del episodio: -  0.3259956348160902\n",
      "Recompensa por acortar distancias: +  0.8730599893328423\n",
      "Penalización por duración del episodio: -  0.3261141009724074\n",
      "Recompensa por acortar distancias: +  0.8730599893328423\n",
      "Penalización por parar muy lejos: -  0.11187698462436542\n",
      "Penalización por duración del episodio: -  0.326265149759753\n",
      "Recompensa por acortar distancias: +  0.8718808452018569\n",
      "Penalización por parar muy lejos: -  0.11082832362696399\n",
      "Penalización por duración del episodio: -  0.3264481072557989\n",
      "Recompensa por acortar distancias: +  0.8718808452018569\n",
      "Penalización por duración del episodio: -  0.3267922397828998\n",
      "Recompensa por acortar distancias: +  0.8718808452018569\n",
      "Penalización por parar muy lejos: -  0.11082832362696399\n",
      "Penalización por duración del episodio: -  0.32686960050575103\n",
      "Recompensa por acortar distancias: +  0.8718808452018569\n",
      "Penalización por duración del episodio: -  0.327139545023945\n",
      "Step: 4980, Mean Reward (últimos 10 pasos): 0.5447412729263306\n",
      "Recompensa por acortar distancias: +  0.8718808452018569\n",
      "Penalización por duración del episodio: -  0.32749392380132447\n",
      "Recompensa por acortar distancias: +  0.8676145736750545\n",
      "Penalización por parar muy lejos: -  0.10717094217334525\n",
      "Penalización por duración del episodio: -  0.32783952584714315\n",
      "steer input from model: 0.05 , throttle:  0.0\n",
      "reward: 0.4326041056545661\n",
      "Recompensa por acortar distancias: +  0.8676145736750545\n",
      "Penalización por duración del episodio: -  0.3279749308542226\n",
      "Recompensa por acortar distancias: +  0.8652570693978536\n",
      "Penalización por duración del episodio: -  0.32817353984491804\n",
      "Recompensa por acortar distancias: +  0.8652570693978536\n",
      "Penalización por parar muy lejos: -  0.10523717295063834\n",
      "Penalización por duración del episodio: -  0.3282715294093762\n",
      "Recompensa por acortar distancias: +  0.864167324016955\n",
      "Penalización por duración del episodio: -  0.3283385536326255\n",
      "Recompensa por acortar distancias: +  0.8634883723759597\n",
      "Penalización por parar muy lejos: -  0.10382495846793922\n",
      "Penalización por duración del episodio: -  0.3285206026874308\n",
      "Recompensa por acortar distancias: +  0.8634883723759597\n",
      "Penalización por parar muy lejos: -  0.10382495846793922\n",
      "Penalización por duración del episodio: -  0.32861260652019686\n",
      "Recompensa por acortar distancias: +  0.8634883723759597\n",
      "Penalización por duración del episodio: -  0.32872768767888294\n",
      "Recompensa por acortar distancias: +  0.8634883723759597\n",
      "Penalización por parar muy lejos: -  0.10382495846793922\n",
      "Penalización por duración del episodio: -  0.3288655954074091\n",
      "Step: 4990, Mean Reward (últimos 10 pasos): 0.430797815322876\n",
      "Recompensa por acortar distancias: +  0.8634883723759597\n",
      "Penalización por parar muy lejos: -  0.10382495846793922\n",
      "Penalización por duración del episodio: -  0.3292006377069549\n",
      "Recompensa por acortar distancias: +  0.8634883723759597\n",
      "Penalización por duración del episodio: -  0.3293005687196997\n",
      "Recompensa por acortar distancias: +  0.8634883723759597\n",
      "Penalización por parar muy lejos: -  0.10382495846793922\n",
      "Penalización por duración del episodio: -  0.3295492390220231\n",
      "Recompensa por acortar distancias: +  0.8591070071113062\n",
      "Penalización por duración del episodio: -  0.32965943445666734\n",
      "Recompensa por acortar distancias: +  0.8581882038578942\n",
      "Penalización por duración del episodio: -  0.3297683944593028\n",
      "Recompensa por acortar distancias: +  0.8581882038578942\n",
      "Penalización por parar muy lejos: -  0.09977946496359894\n",
      "Penalización por duración del episodio: -  0.3298876396521674\n",
      "Recompensa por acortar distancias: +  0.8581882038578942\n",
      "Penalización por parar muy lejos: -  0.09977946496359894\n",
      "Penalización por duración del episodio: -  0.3299714621954862\n",
      "Recompensa por acortar distancias: +  0.8581882038578942\n",
      "Penalización por duración del episodio: -  0.3300848451221337\n",
      "Recompensa por acortar distancias: +  0.8581882038578942\n",
      "Penalización por parar muy lejos: -  0.09977946496359894\n",
      "Penalización por duración del episodio: -  0.3302294016794758\n",
      "Recompensa por acortar distancias: +  0.8581882038578942\n",
      "Penalización por parar muy lejos: -  0.09977946496359894\n",
      "Penalización por duración del episodio: -  0.3303232572365649\n",
      "Step: 5000, Mean Reward (últimos 10 pasos): 0.42808547616004944\n",
      "Recompensa por acortar distancias: +  0.855405558107247\n",
      "Penalización por duración del episodio: -  0.3304340797750337\n",
      "Recompensa por acortar distancias: +  0.855405558107247\n",
      "Penalización por duración del episodio: -  0.33053918632391593\n",
      "steer input from model: 0.05 , throttle:  0.3\n",
      "reward: 0.5248663717833311\n",
      "Recompensa por acortar distancias: +  0.855405558107247\n",
      "Penalización por duración del episodio: -  0.33066297884256796\n",
      "Recompensa por acortar distancias: +  0.8541753191567156\n",
      "Penalización por duración del episodio: -  0.3307733524022377\n",
      "Recompensa por acortar distancias: +  0.8541753191567156\n",
      "Penalización por duración del episodio: -  0.33093255216134654\n",
      "Recompensa por acortar distancias: +  0.853006307709482\n",
      "Penalización por parar muy lejos: -  0.09607452425142066\n",
      "Penalización por duración del episodio: -  0.33107903893887586\n",
      "Recompensa por acortar distancias: +  0.853006307709482\n",
      "Penalización por duración del episodio: -  0.331167439955432\n",
      "Recompensa por acortar distancias: +  0.853006307709482\n",
      "Penalización por parar muy lejos: -  0.09607452425142066\n",
      "Penalización por duración del episodio: -  0.33126707105328335\n",
      "Recompensa por acortar distancias: +  0.853006307709482\n",
      "Penalización por duración del episodio: -  0.331355803784051\n",
      "Recompensa por acortar distancias: +  0.853006307709482\n",
      "Penalización por parar muy lejos: -  0.09607452425142066\n",
      "Penalización por duración del episodio: -  0.33146629936403893\n",
      "Step: 5010, Mean Reward (últimos 10 pasos): 0.42546549439430237\n",
      "Recompensa por acortar distancias: +  0.853006307709482\n",
      "Penalización por duración del episodio: -  0.3316356076814751\n",
      "Recompensa por acortar distancias: +  0.853006307709482\n",
      "Penalización por duración del episodio: -  0.3317801634518055\n",
      "Recompensa por acortar distancias: +  0.853006307709482\n",
      "Penalización por duración del episodio: -  0.33189071972756495\n",
      "Recompensa por acortar distancias: +  0.8483516221743117\n",
      "Penalización por parar muy lejos: -  0.09293874709312511\n",
      "Penalización por duración del episodio: -  0.3323398963241048\n",
      "Recompensa por acortar distancias: +  0.8474230146607445\n",
      "Penalización por parar muy lejos: -  0.09233355901917971\n",
      "Penalización por duración del episodio: -  0.3326834510342994\n",
      "Recompensa por acortar distancias: +  0.8448621322849624\n",
      "Penalización por duración del episodio: -  0.3330419749547046\n",
      "Recompensa por acortar distancias: +  0.8436340722814626\n",
      "Penalización por parar muy lejos: -  0.08993080334721576\n",
      "Penalización por duración del episodio: -  0.3333898299104343\n",
      "Recompensa por acortar distancias: +  0.8436340722814626\n",
      "Penalización por duración del episodio: -  0.3337356981187718\n",
      "Recompensa por acortar distancias: +  0.8436340722814626\n",
      "Penalización por duración del episodio: -  0.33407495076600946\n",
      "Recompensa por acortar distancias: +  0.8386025174051666\n",
      "Penalización por duración del episodio: -  0.33441874265280275\n",
      "Step: 5020, Mean Reward (últimos 10 pasos): 0.5041837692260742\n",
      "Recompensa por acortar distancias: +  0.8386025174051666\n",
      "Penalización por parar muy lejos: -  0.08689635397806628\n",
      "Penalización por duración del episodio: -  0.3345122335414115\n",
      "Recompensa por acortar distancias: +  0.8386025174051666\n",
      "Penalización por duración del episodio: -  0.3347694535796957\n",
      "steer input from model: -0.25 , throttle:  0.3\n",
      "reward: 0.5038330638254709\n",
      "Recompensa por acortar distancias: +  0.834727743325976\n",
      "Penalización por duración del episodio: -  0.334892428773974\n",
      "Recompensa por acortar distancias: +  0.834727743325976\n",
      "Penalización por duración del episodio: -  0.33498371222290135\n",
      "Recompensa por acortar distancias: +  0.8337608461833648\n",
      "Penalización por duración del episodio: -  0.33512071366754653\n",
      "Recompensa por acortar distancias: +  0.8337608461833648\n",
      "Penalización por duración del episodio: -  0.3352318299591258\n",
      "Recompensa por acortar distancias: +  0.8337608461833648\n",
      "Penalización por parar muy lejos: -  0.08413234091190043\n",
      "Penalización por duración del episodio: -  0.33535492657837207\n",
      "Recompensa por acortar distancias: +  0.8323694820268659\n",
      "Penalización por parar muy lejos: -  0.08336461567240008\n",
      "Penalización por duración del episodio: -  0.3355307364765474\n",
      "Recompensa por acortar distancias: +  0.8323694820268659\n",
      "Penalización por duración del episodio: -  0.3358087589266801\n",
      "Recompensa por acortar distancias: +  0.8323694820268659\n",
      "Penalización por duración del episodio: -  0.3361557594074149\n",
      "Step: 5030, Mean Reward (últimos 10 pasos): 0.49621373414993286\n",
      "Recompensa por acortar distancias: +  0.8323694820268659\n",
      "Penalización por duración del episodio: -  0.33624677678675047\n",
      "Recompensa por acortar distancias: +  0.8323694820268659\n",
      "Penalización por parar muy lejos: -  0.08336461567240008\n",
      "Penalización por duración del episodio: -  0.3365058538788745\n",
      "Recompensa por acortar distancias: +  0.8260753237730899\n",
      "Penalización por parar muy lejos: -  0.08003023166700378\n",
      "Penalización por duración del episodio: -  0.3368557657854252\n",
      "Recompensa por acortar distancias: +  0.8260753237730899\n",
      "Penalización por duración del episodio: -  0.33721518708250586\n",
      "Recompensa por acortar distancias: +  0.8226129521511092\n",
      "Penalización por duración del episodio: -  0.33731940268743155\n",
      "Recompensa por acortar distancias: +  0.8216427079989986\n",
      "Penalización por parar muy lejos: -  0.07780986799408889\n",
      "Penalización por duración del episodio: -  0.3375673219772978\n",
      "Recompensa por acortar distancias: +  0.8216427079989986\n",
      "Penalización por parar muy lejos: -  0.07780986799408889\n",
      "Penalización por duración del episodio: -  0.3379083715009884\n",
      "Recompensa por acortar distancias: +  0.8216427079989986\n",
      "Penalización por duración del episodio: -  0.33825599370211046\n",
      "Recompensa por acortar distancias: +  0.8171252321375133\n",
      "Penalización por parar muy lejos: -  0.07564749130821488\n",
      "Penalización por duración del episodio: -  0.3383676311841107\n",
      "Recompensa por acortar distancias: +  0.8159259944422921\n",
      "Penalización por duración del episodio: -  0.3385994336802717\n",
      "Step: 5040, Mean Reward (últimos 10 pasos): 0.47732657194137573\n",
      "Recompensa por acortar distancias: +  0.8159259944422921\n",
      "Penalización por parar muy lejos: -  0.07508964012197515\n",
      "Penalización por duración del episodio: -  0.3389536958312467\n",
      "Recompensa por acortar distancias: +  0.8128390208228468\n",
      "Penalización por parar muy lejos: -  0.07368357243117987\n",
      "Penalización por duración del episodio: -  0.33908818561405235\n",
      "steer input from model: 0.9 , throttle:  0.0\n",
      "reward: 0.40006726277761456\n",
      "Recompensa por acortar distancias: +  0.8128390208228468\n",
      "Penalización por parar muy lejos: -  0.07368357243117987\n",
      "Penalización por duración del episodio: -  0.33919880266550934\n",
      "Recompensa por acortar distancias: +  0.8128390208228468\n",
      "Penalización por parar muy lejos: -  0.07368357243117987\n",
      "Penalización por duración del episodio: -  0.33965130165162905\n",
      "Recompensa por acortar distancias: +  0.8095620445547531\n",
      "Penalización por parar muy lejos: -  0.07223639010587576\n",
      "Penalización por duración del episodio: -  0.3397407488130178\n",
      "Recompensa por acortar distancias: +  0.8095620445547531\n",
      "Penalización por parar muy lejos: -  0.07223639010587576\n",
      "Penalización por duración del episodio: -  0.34001131500553616\n",
      "Recompensa por acortar distancias: +  0.8095620445547531\n",
      "Penalización por duración del episodio: -  0.3401146563651544\n",
      "Recompensa por acortar distancias: +  0.8095620445547531\n",
      "Penalización por parar muy lejos: -  0.07223639010587576\n",
      "Penalización por duración del episodio: -  0.3403552940314402\n",
      "Recompensa por acortar distancias: +  0.8044450830318209\n",
      "Penalización por parar muy lejos: -  0.07006518017514217\n",
      "Penalización por duración del episodio: -  0.3406947125738611\n",
      "Recompensa por acortar distancias: +  0.8030823656562407\n",
      "Penalización por parar muy lejos: -  0.06950433707846466\n",
      "Penalización por duración del episodio: -  0.3407843087796387\n",
      "Step: 5050, Mean Reward (últimos 10 pasos): 0.3927937150001526\n",
      "Recompensa por acortar distancias: +  0.8030823656562407\n",
      "Penalización por duración del episodio: -  0.3410476789621522\n",
      "Recompensa por acortar distancias: +  0.8030823656562407\n",
      "Penalización por duración del episodio: -  0.3413980716131854\n",
      "Recompensa por acortar distancias: +  0.7991275681320024\n",
      "Penalización por duración del episodio: -  0.3417648780598375\n",
      "Recompensa por acortar distancias: +  0.7963531035134721\n",
      "Penalización por duración del episodio: -  0.34212307862002556\n",
      "Recompensa por acortar distancias: +  0.7963531035134721\n",
      "Penalización por parar muy lejos: -  0.06683563796560976\n",
      "Penalización por duración del episodio: -  0.342485260461379\n",
      "Recompensa por acortar distancias: +  0.7963531035134721\n",
      "Penalización por duración del episodio: -  0.342582815145262\n",
      "Recompensa por acortar distancias: +  0.7914063060454811\n",
      "Penalización por parar muy lejos: -  0.06497462768807587\n",
      "Penalización por duración del episodio: -  0.3428398316897982\n",
      "Recompensa por acortar distancias: +  0.790314801458101\n",
      "Penalización por duración del episodio: -  0.34318852702856617\n",
      "Recompensa por acortar distancias: +  0.790314801458101\n",
      "Penalización por duración del episodio: -  0.34326248515853625\n",
      "Recompensa por acortar distancias: +  0.790314801458101\n",
      "Penalización por duración del episodio: -  0.34352557350521556\n",
      "Step: 5060, Mean Reward (últimos 10 pasos): 0.4467892348766327\n",
      "Recompensa por acortar distancias: +  0.785937630134235\n",
      "Penalización por parar muy lejos: -  0.0630093614082565\n",
      "Penalización por duración del episodio: -  0.3436564815068866\n",
      "Recompensa por acortar distancias: +  0.7851892436550308\n",
      "Penalización por duración del episodio: -  0.3438742194073054\n",
      "steer input from model: -0.05 , throttle:  1.0\n",
      "reward: 0.44131502424772545\n",
      "Recompensa por acortar distancias: +  0.7839662817313123\n",
      "Penalización por parar muy lejos: -  0.06232338066081895\n",
      "Penalización por duración del episodio: -  0.343964253197425\n",
      "Recompensa por acortar distancias: +  0.7829204388857757\n",
      "Penalización por parar muy lejos: -  0.061964110979617425\n",
      "Penalización por duración del episodio: -  0.3442344379647332\n",
      "Recompensa por acortar distancias: +  0.7829204388857757\n",
      "Penalización por duración del episodio: -  0.3445887348842141\n",
      "Recompensa por acortar distancias: +  0.7829204388857757\n",
      "Penalización por duración del episodio: -  0.3449310403482365\n",
      "Recompensa por acortar distancias: +  0.7776177200335151\n",
      "Penalización por duración del episodio: -  0.3450456395118238\n",
      "Recompensa por acortar distancias: +  0.7760741967839268\n",
      "Penalización por parar muy lejos: -  0.059688791854914595\n",
      "Penalización por duración del episodio: -  0.3452777537994147\n",
      "Recompensa por acortar distancias: +  0.7760741967839268\n",
      "Penalización por duración del episodio: -  0.34563072517071025\n",
      "Recompensa por acortar distancias: +  0.7760741967839268\n",
      "Penalización por parar muy lejos: -  0.059688791854914595\n",
      "Penalización por duración del episodio: -  0.34596541093287964\n",
      "Step: 5070, Mean Reward (últimos 10 pasos): 0.370419979095459\n",
      "Recompensa por acortar distancias: +  0.770621034706089\n",
      "Penalización por duración del episodio: -  0.3463157502895745\n",
      "Recompensa por acortar distancias: +  0.7685330115847375\n",
      "Penalización por parar muy lejos: -  0.05732667538601001\n",
      "Penalización por duración del episodio: -  0.34640609122949484\n",
      "Recompensa por acortar distancias: +  0.7669416657704758\n",
      "Penalización por parar muy lejos: -  0.056846304555591594\n",
      "Penalización por duración del episodio: -  0.3465531962528727\n",
      "Recompensa por acortar distancias: +  0.7669416657704758\n",
      "Penalización por parar muy lejos: -  0.056846304555591594\n",
      "Penalización por duración del episodio: -  0.34669005957201704\n",
      "Recompensa por acortar distancias: +  0.7669416657704758\n",
      "Penalización por duración del episodio: -  0.3467821745965983\n",
      "Recompensa por acortar distancias: +  0.7669416657704758\n",
      "Penalización por duración del episodio: -  0.347021504789625\n",
      "Recompensa por acortar distancias: +  0.7669416657704758\n",
      "Penalización por parar muy lejos: -  0.056846304555591594\n",
      "Penalización por duración del episodio: -  0.34736040589607337\n",
      "Recompensa por acortar distancias: +  0.7669416657704758\n",
      "Penalización por parar muy lejos: -  0.056846304555591594\n",
      "Penalización por duración del episodio: -  0.34747374609399984\n",
      "Recompensa por acortar distancias: +  0.7600959952242516\n",
      "Penalización por parar muy lejos: -  0.05484726956909404\n",
      "Penalización por duración del episodio: -  0.347709681872274\n",
      "Recompensa por acortar distancias: +  0.7581691430624751\n",
      "Penalización por duración del episodio: -  0.34806262747207184\n",
      "Step: 5080, Mean Reward (últimos 10 pasos): 0.41010650992393494\n",
      "Recompensa por acortar distancias: +  0.7581691430624751\n",
      "Penalización por parar muy lejos: -  0.054303549946939644\n",
      "Penalización por duración del episodio: -  0.3484209902410679\n",
      "Recompensa por acortar distancias: +  0.7526611847414771\n",
      "Penalización por parar muy lejos: -  0.05279275509391845\n",
      "Penalización por duración del episodio: -  0.3487713746654729\n",
      "steer input from model: 0.9 , throttle:  0.0\n",
      "reward: 0.35109705498208577\n",
      "Recompensa por acortar distancias: +  0.7511888075412592\n",
      "Penalización por parar muy lejos: -  0.05239943214120989\n",
      "Penalización por duración del episodio: -  0.3491187370368528\n",
      "Recompensa por acortar distancias: +  0.7511888075412592\n",
      "Penalización por duración del episodio: -  0.34924416725439716\n",
      "Recompensa por acortar distancias: +  0.7511888075412592\n",
      "Penalización por parar muy lejos: -  0.05239943214120989\n",
      "Penalización por duración del episodio: -  0.34947138724161764\n",
      "Recompensa por acortar distancias: +  0.7511888075412592\n",
      "Penalización por duración del episodio: -  0.3498174671667228\n",
      "Recompensa por acortar distancias: +  0.7428723033947967\n",
      "Penalización por parar muy lejos: -  0.05025666155024018\n",
      "Penalización por duración del episodio: -  0.34997751385276826\n",
      "Recompensa por acortar distancias: +  0.7428723033947967\n",
      "Penalización por duración del episodio: -  0.3500682333677005\n",
      "Recompensa por acortar distancias: +  0.7428723033947967\n",
      "Penalización por duración del episodio: -  0.35017049770658515\n",
      "Recompensa por acortar distancias: +  0.7428723033947967\n",
      "Penalización por parar muy lejos: -  0.05025666155024018\n",
      "Penalización por duración del episodio: -  0.3502840185163432\n",
      "Step: 5090, Mean Reward (últimos 10 pasos): 0.3423316180706024\n",
      "Recompensa por acortar distancias: +  0.7428723033947967\n",
      "Penalización por duración del episodio: -  0.35043408537199583\n",
      "Recompensa por acortar distancias: +  0.7428723033947967\n",
      "Penalización por parar muy lejos: -  0.05025666155024018\n",
      "Penalización por duración del episodio: -  0.3508847566799133\n",
      "Recompensa por acortar distancias: +  0.7355529897374132\n",
      "Penalización por duración del episodio: -  0.3509983513852809\n",
      "Recompensa por acortar distancias: +  0.7355529897374132\n",
      "Penalización por parar muy lejos: -  0.048474974673896706\n",
      "Penalización por duración del episodio: -  0.35111055610082953\n",
      "Recompensa por acortar distancias: +  0.7355529897374132\n",
      "Penalización por parar muy lejos: -  0.048474974673896706\n",
      "Penalización por duración del episodio: -  0.3512014595263292\n",
      "Recompensa por acortar distancias: +  0.7355529897374132\n",
      "Penalización por duración del episodio: -  0.35132641909998513\n",
      "Recompensa por acortar distancias: +  0.7355529897374132\n",
      "Penalización por parar muy lejos: -  0.048474974673896706\n",
      "Penalización por duración del episodio: -  0.3514411173222362\n",
      "Recompensa por acortar distancias: +  0.7355529897374132\n",
      "Penalización por parar muy lejos: -  0.048474974673896706\n",
      "Penalización por duración del episodio: -  0.35157526883516116\n",
      "Recompensa por acortar distancias: +  0.7355529897374132\n",
      "Penalización por parar muy lejos: -  0.048474974673896706\n",
      "Penalización por duración del episodio: -  0.35193217457385423\n",
      "Recompensa por acortar distancias: +  0.7283005422012844\n",
      "Penalización por duración del episodio: -  0.35227917046522933\n",
      "Step: 5100, Mean Reward (últimos 10 pasos): 0.3760213851928711\n",
      "Recompensa por acortar distancias: +  0.7267892799315544\n",
      "Penalización por duración del episodio: -  0.35263925959728715\n",
      "Recompensa por acortar distancias: +  0.7267892799315544\n",
      "Penalización por duración del episodio: -  0.3527419054751565\n",
      "steer input from model: -0.9 , throttle:  0.7\n",
      "reward: 0.3740473744563979\n",
      "Recompensa por acortar distancias: +  0.7228329590552567\n",
      "Penalización por duración del episodio: -  0.3530104558160942\n",
      "Recompensa por acortar distancias: +  0.7210651368392814\n",
      "Penalización por duración del episodio: -  0.35313606815748705\n",
      "Recompensa por acortar distancias: +  0.7210651368392814\n",
      "Penalización por duración del episodio: -  0.35327287831730747\n",
      "Recompensa por acortar distancias: +  0.7192156608371851\n",
      "Penalización por duración del episodio: -  0.35341470302837635\n",
      "Recompensa por acortar distancias: +  0.7192156608371851\n",
      "Penalización por duración del episodio: -  0.3535072511118203\n",
      "Recompensa por acortar distancias: +  0.7192156608371851\n",
      "Penalización por duración del episodio: -  0.3537346087929919\n",
      "Recompensa por acortar distancias: +  0.7192156608371851\n",
      "Penalización por duración del episodio: -  0.35408058416656973\n",
      "Recompensa por acortar distancias: +  0.7192156608371851\n",
      "Penalización por duración del episodio: -  0.3542016568539726\n",
      "Step: 5110, Mean Reward (últimos 10 pasos): 0.3650140166282654\n",
      "Recompensa por acortar distancias: +  0.7192156608371851\n",
      "Penalización por duración del episodio: -  0.354336635500012\n",
      "Recompensa por acortar distancias: +  0.7192156608371851\n",
      "Penalización por duración del episodio: -  0.3544777639336517\n",
      "Recompensa por acortar distancias: +  0.7110194625901372\n",
      "Penalización por duración del episodio: -  0.3547939505752866\n",
      "Recompensa por acortar distancias: +  0.7094696409793089\n",
      "Penalización por duración del episodio: -  0.35514983881859374\n",
      "Recompensa por acortar distancias: +  0.7094696409793089\n",
      "Penalización por duración del episodio: -  0.3555013424124001\n",
      "Recompensa por acortar distancias: +  0.7042472271188482\n",
      "Penalización por duración del episodio: -  0.3555848707264351\n",
      "Recompensa por acortar distancias: +  0.7042472271188482\n",
      "Penalización por duración del episodio: -  0.35585465783721854\n",
      "Recompensa por acortar distancias: +  0.7042472271188482\n",
      "Penalización por duración del episodio: -  0.3562044999147851\n",
      "Recompensa por acortar distancias: +  0.7042472271188482\n",
      "Penalización por duración del episodio: -  0.3565584448098446\n",
      "Recompensa por acortar distancias: +  0.6970668593500405\n",
      "Penalización por duración del episodio: -  0.3569242353995702\n",
      "Step: 5120, Mean Reward (últimos 10 pasos): 0.3401426374912262\n",
      "Recompensa por acortar distancias: +  0.6970668593500405\n",
      "Penalización por duración del episodio: -  0.3570349881143906\n",
      "Recompensa por acortar distancias: +  0.6970668593500405\n",
      "Penalización por duración del episodio: -  0.3572926182596794\n",
      "steer input from model: 0.1 , throttle:  0.7\n",
      "reward: 0.33977424109036114\n",
      "Recompensa por acortar distancias: +  0.6925469381012341\n",
      "Penalización por duración del episodio: -  0.3576470984970973\n",
      "Recompensa por acortar distancias: +  0.6907925482824377\n",
      "Penalización por duración del episodio: -  0.3577513058498339\n",
      "Recompensa por acortar distancias: +  0.6892847837057603\n",
      "Penalización por duración del episodio: -  0.35789624018133936\n",
      "Recompensa por acortar distancias: +  0.6892847837057603\n",
      "Penalización por duración del episodio: -  0.3580228865560108\n",
      "Recompensa por acortar distancias: +  0.6892847837057603\n",
      "Penalización por duración del episodio: -  0.3581516957172262\n",
      "Recompensa por acortar distancias: +  0.6892847837057603\n",
      "Penalización por duración del episodio: -  0.35837181034308685\n",
      "Recompensa por acortar distancias: +  0.6892847837057603\n",
      "Penalización por duración del episodio: -  0.35846625823817746\n",
      "Recompensa por acortar distancias: +  0.6892847837057603\n",
      "Penalización por duración del episodio: -  0.3585588307906351\n",
      "Step: 5130, Mean Reward (últimos 10 pasos): 0.33072593808174133\n",
      "Recompensa por acortar distancias: +  0.6892847837057603\n",
      "Penalización por duración del episodio: -  0.3587339979220998\n",
      "Recompensa por acortar distancias: +  0.6892847837057603\n",
      "Penalización por duración del episodio: -  0.3588633806966933\n",
      "Recompensa por acortar distancias: +  0.6892847837057603\n",
      "Penalización por duración del episodio: -  0.35900113986615073\n",
      "Recompensa por acortar distancias: +  0.6807203637169319\n",
      "Penalización por duración del episodio: -  0.3591509562480523\n",
      "Recompensa por acortar distancias: +  0.678789010173398\n",
      "Penalización por duración del episodio: -  0.35945305934637445\n",
      "Recompensa por acortar distancias: +  0.678789010173398\n",
      "Penalización por duración del episodio: -  0.35982954470209755\n",
      "Recompensa por acortar distancias: +  0.6740343816034603\n",
      "Penalización por duración del episodio: -  0.3601804611212861\n",
      "Recompensa por acortar distancias: +  0.6722250980086728\n",
      "Penalización por duración del episodio: -  0.3605470058986703\n",
      "Recompensa por acortar distancias: +  0.6722250980086728\n",
      "Penalización por duración del episodio: -  0.36089591241983415\n",
      "Recompensa por acortar distancias: +  0.6722250980086728\n",
      "Penalización por duración del episodio: -  0.360997883479166\n",
      "Step: 5140, Mean Reward (últimos 10 pasos): 0.3112272024154663\n",
      "Recompensa por acortar distancias: +  0.6651794028487364\n",
      "Penalización por duración del episodio: -  0.3612607111045449\n",
      "Recompensa por acortar distancias: +  0.6637267713018269\n",
      "Penalización por duración del episodio: -  0.36137160758317116\n",
      "steer input from model: -0.1 , throttle:  0.3\n",
      "reward: 0.30235516371865573\n",
      "Recompensa por acortar distancias: +  0.6637267713018269\n",
      "Penalización por duración del episodio: -  0.3616286365221311\n",
      "Recompensa por acortar distancias: +  0.6637267713018269\n",
      "Penalización por duración del episodio: -  0.36200632199706717\n",
      "Recompensa por acortar distancias: +  0.6572966365920776\n",
      "Penalización por duración del episodio: -  0.3623618119896052\n",
      "Recompensa por acortar distancias: +  0.6551685074555691\n",
      "Penalización por duración del episodio: -  0.3627435812728184\n",
      "Recompensa por acortar distancias: +  0.6551685074555691\n",
      "Penalización por duración del episodio: -  0.3628160965682517\n",
      "Recompensa por acortar distancias: +  0.6551685074555691\n",
      "Penalización por duración del episodio: -  0.3630957993632938\n",
      "Recompensa por acortar distancias: +  0.6551685074555691\n",
      "Penalización por duración del episodio: -  0.36321045698831605\n",
      "Recompensa por acortar distancias: +  0.6479683026682712\n",
      "Penalización por duración del episodio: -  0.3633039965736068\n",
      "Step: 5150, Mean Reward (últimos 10 pasos): 0.2846643030643463\n",
      "Recompensa por acortar distancias: +  0.6463544566020948\n",
      "Penalización por duración del episodio: -  0.3634540057569172\n",
      "Recompensa por acortar distancias: +  0.6463544566020948\n",
      "Penalización por duración del episodio: -  0.3635242927489193\n",
      "Recompensa por acortar distancias: +  0.6463544566020948\n",
      "Penalización por duración del episodio: -  0.36382613738215075\n",
      "Recompensa por acortar distancias: +  0.6463544566020948\n",
      "Penalización por duración del episodio: -  0.3639581191398672\n",
      "Recompensa por acortar distancias: +  0.6411676504435064\n",
      "Penalización por duración del episodio: -  0.3641895491512284\n",
      "Recompensa por acortar distancias: +  0.6392253289359997\n",
      "Penalización por duración del episodio: -  0.3643050723920873\n",
      "Recompensa por acortar distancias: +  0.6392253289359997\n",
      "Penalización por duración del episodio: -  0.3644096497600445\n",
      "Recompensa por acortar distancias: +  0.637661175909072\n",
      "Penalización por duración del episodio: -  0.36454834399089553\n",
      "Recompensa por acortar distancias: +  0.637661175909072\n",
      "Penalización por duración del episodio: -  0.3646971861439764\n",
      "Recompensa por acortar distancias: +  0.6355111591100705\n",
      "Penalización por duración del episodio: -  0.3647913809647078\n",
      "Step: 5160, Mean Reward (últimos 10 pasos): 0.2707197666168213\n",
      "Recompensa por acortar distancias: +  0.6355111591100705\n",
      "Penalización por duración del episodio: -  0.36487589497782824\n",
      "Recompensa por acortar distancias: +  0.6355111591100705\n",
      "Penalización por duración del episodio: -  0.36526630224659334\n",
      "steer input from model: -0.25 , throttle:  1.0\n",
      "reward: 0.27024485686347716\n",
      "Recompensa por acortar distancias: +  0.6355111591100705\n",
      "Penalización por duración del episodio: -  0.36563878670566996\n",
      "Recompensa por acortar distancias: +  0.6265954236143654\n",
      "Penalización por duración del episodio: -  0.3660103476206641\n",
      "Recompensa por acortar distancias: +  0.6247727973735032\n",
      "Penalización por duración del episodio: -  0.36638041867167537\n",
      "Recompensa por acortar distancias: +  0.6198801464938953\n",
      "Penalización por duración del episodio: -  0.3664849715597999\n",
      "Recompensa por acortar distancias: +  0.6198801464938953\n",
      "Penalización por duración del episodio: -  0.36662397236143596\n",
      "Recompensa por acortar distancias: +  0.617431946704661\n",
      "Penalización por duración del episodio: -  0.36711562150409544\n",
      "Recompensa por acortar distancias: +  0.6144583781434707\n",
      "Penalización por duración del episodio: -  0.36724599684490417\n",
      "Recompensa por acortar distancias: +  0.6144583781434707\n",
      "Penalización por duración del episodio: -  0.36748050415893374\n",
      "Step: 5170, Mean Reward (últimos 10 pasos): 0.24697788059711456\n",
      "Recompensa por acortar distancias: +  0.6144583781434707\n",
      "Penalización por duración del episodio: -  0.36758000115620465\n",
      "Recompensa por acortar distancias: +  0.6144583781434707\n",
      "Penalización por duración del episodio: -  0.3677144256366429\n",
      "Recompensa por acortar distancias: +  0.6144583781434707\n",
      "Penalización por duración del episodio: -  0.367846553255228\n",
      "Recompensa por acortar distancias: +  0.6144583781434707\n",
      "Penalización por duración del episodio: -  0.36794250983662485\n",
      "Recompensa por acortar distancias: +  0.6144583781434707\n",
      "Penalización por duración del episodio: -  0.36804734937854655\n",
      "Recompensa por acortar distancias: +  0.6144583781434707\n",
      "Penalización por duración del episodio: -  0.3681533716002744\n",
      "Recompensa por acortar distancias: +  0.6144583781434707\n",
      "Penalización por duración del episodio: -  0.36856328902869506\n",
      "Recompensa por acortar distancias: +  0.6009818074682555\n",
      "Penalización por duración del episodio: -  0.3687060488991836\n",
      "Recompensa por acortar distancias: +  0.6009818074682555\n",
      "Penalización por duración del episodio: -  0.36881995366250253\n",
      "Recompensa por acortar distancias: +  0.6009818074682555\n",
      "Penalización por duración del episodio: -  0.36893609341318634\n",
      "Step: 5180, Mean Reward (últimos 10 pasos): 0.2320457100868225\n",
      "Recompensa por acortar distancias: +  0.6009818074682555\n",
      "Penalización por duración del episodio: -  0.36901959420143754\n",
      "Recompensa por acortar distancias: +  0.6009818074682555\n",
      "Penalización por duración del episodio: -  0.36929706497030335\n",
      "steer input from model: -0.05 , throttle:  0.7\n",
      "reward: 0.23168474249795212\n",
      "Recompensa por acortar distancias: +  0.5947985071748264\n",
      "Penalización por duración del episodio: -  0.3693995212532752\n",
      "Recompensa por acortar distancias: +  0.5947985071748264\n",
      "Penalización por duración del episodio: -  0.36955153076938596\n",
      "Recompensa por acortar distancias: +  0.591533208414418\n",
      "Penalización por duración del episodio: -  0.36967943254131663\n",
      "Recompensa por acortar distancias: +  0.591533208414418\n",
      "Penalización por duración del episodio: -  0.37001601200571504\n",
      "Recompensa por acortar distancias: +  0.591533208414418\n",
      "Penalización por duración del episodio: -  0.37011920101732093\n",
      "Recompensa por acortar distancias: +  0.591533208414418\n",
      "Penalización por duración del episodio: -  0.37039033571480046\n",
      "Recompensa por acortar distancias: +  0.591533208414418\n",
      "Penalización por duración del episodio: -  0.3705094878370866\n",
      "Recompensa por acortar distancias: +  0.591533208414418\n",
      "Penalización por duración del episodio: -  0.3706323707653603\n",
      "Step: 5190, Mean Reward (últimos 10 pasos): 0.22090083360671997\n",
      "Recompensa por acortar distancias: +  0.5822354703298861\n",
      "Penalización por duración del episodio: -  0.37074333959346556\n",
      "Recompensa por acortar distancias: +  0.5822354703298861\n",
      "Penalización por duración del episodio: -  0.3711065363649716\n",
      "Recompensa por acortar distancias: +  0.5801081080249383\n",
      "Penalización por duración del episodio: -  0.3712045858222829\n",
      "Recompensa por acortar distancias: +  0.5801081080249383\n",
      "Penalización por duración del episodio: -  0.37133975231499167\n",
      "Recompensa por acortar distancias: +  0.5801081080249383\n",
      "Penalización por duración del episodio: -  0.3714399310991508\n",
      "Recompensa por acortar distancias: +  0.5740795518400099\n",
      "Penalización por duración del episodio: -  0.37153735412833444\n",
      "Recompensa por acortar distancias: +  0.5740795518400099\n",
      "Penalización por duración del episodio: -  0.371644402910673\n",
      "Recompensa por acortar distancias: +  0.5740795518400099\n",
      "Penalización por duración del episodio: -  0.3718326540315342\n",
      "Recompensa por acortar distancias: +  0.571505410522282\n",
      "Penalización por duración del episodio: -  0.3721933675270084\n",
      "Recompensa por acortar distancias: +  0.571505410522282\n",
      "Penalización por duración del episodio: -  0.37232869758655074\n",
      "Step: 5200, Mean Reward (últimos 10 pasos): 0.19917671382427216\n",
      "Recompensa por acortar distancias: +  0.571505410522282\n",
      "Penalización por duración del episodio: -  0.37244622087207674\n",
      "Recompensa por acortar distancias: +  0.571505410522282\n",
      "Penalización por duración del episodio: -  0.37290644570083376\n",
      "steer input from model: 0.05 , throttle:  0.7\n",
      "reward: 0.19859896482144823\n",
      "Recompensa por acortar distancias: +  0.5614120790652088\n",
      "Penalización por duración del episodio: -  0.37304530475145076\n",
      "Recompensa por acortar distancias: +  0.5592224702466074\n",
      "Penalización por duración del episodio: -  0.3731619605264837\n",
      "Recompensa por acortar distancias: +  0.5592224702466074\n",
      "Penalización por duración del episodio: -  0.3732905783682455\n",
      "Recompensa por acortar distancias: +  0.5592224702466074\n",
      "Penalización por duración del episodio: -  0.3734254954922517\n",
      "Recompensa por acortar distancias: +  0.5592224702466074\n",
      "Penalización por duración del episodio: -  0.3735264940198848\n",
      "Recompensa por acortar distancias: +  0.5592224702466074\n",
      "Penalización por duración del episodio: -  0.37398681166161585\n",
      "Recompensa por acortar distancias: +  0.5492162954778284\n",
      "Penalización por duración del episodio: -  0.37434911780502567\n",
      "Recompensa por acortar distancias: +  0.5492162954778284\n",
      "Penalización por duración del episodio: -  0.37472386018552767\n",
      "Step: 5210, Mean Reward (últimos 10 pasos): 0.17449243366718292\n",
      "Recompensa por acortar distancias: +  0.5492162954778284\n",
      "Penalización por duración del episodio: -  0.375080752332815\n",
      "Recompensa por acortar distancias: +  0.538974275084495\n",
      "Penalización por duración del episodio: -  0.37543874745973904\n",
      "Recompensa por acortar distancias: +  0.5365318698386792\n",
      "Penalización por duración del episodio: -  0.37581242655037134\n",
      "Recompensa por acortar distancias: +  0.5304915561261214\n",
      "Penalización por duración del episodio: -  0.37590969528413865\n",
      "Recompensa por acortar distancias: +  0.5304915561261214\n",
      "Penalización por duración del episodio: -  0.37616944640049255\n",
      "Recompensa por acortar distancias: +  0.5276860000405186\n",
      "Penalización por duración del episodio: -  0.3763094012970961\n",
      "Recompensa por acortar distancias: +  0.5253427885038595\n",
      "Penalización por duración del episodio: -  0.37654731546847886\n",
      "Recompensa por acortar distancias: +  0.5253427885038595\n",
      "Penalización por duración del episodio: -  0.37662113849986756\n",
      "Recompensa por acortar distancias: +  0.5253427885038595\n",
      "Penalización por duración del episodio: -  0.37691451133870124\n",
      "Recompensa por acortar distancias: +  0.5253427885038595\n",
      "Penalización por duración del episodio: -  0.37701305779357364\n",
      "Step: 5220, Mean Reward (últimos 10 pasos): 0.1483297348022461\n",
      "Recompensa por acortar distancias: +  0.5253427885038595\n",
      "Penalización por duración del episodio: -  0.37728720916227726\n",
      "Recompensa por acortar distancias: +  0.5253427885038595\n",
      "Penalización por duración del episodio: -  0.3773916929873902\n",
      "steer input from model: -0.9 , throttle:  0.0\n",
      "reward: 0.1479510955164693\n",
      "Recompensa por acortar distancias: +  0.514152613754082\n",
      "Penalización por duración del episodio: -  0.3776700210395326\n",
      "Recompensa por acortar distancias: +  0.5120447038450294\n",
      "Penalización por duración del episodio: -  0.37776870130800067\n",
      "Recompensa por acortar distancias: +  0.5120447038450294\n",
      "Penalización por duración del episodio: -  0.37804136454118475\n",
      "Recompensa por acortar distancias: +  0.5120447038450294\n",
      "Penalización por duración del episodio: -  0.37841679358176716\n",
      "Recompensa por acortar distancias: +  0.5053175768974779\n",
      "Penalización por duración del episodio: -  0.37851277404389416\n",
      "Recompensa por acortar distancias: +  0.5032518643588444\n",
      "Penalización por duración del episodio: -  0.37864652545360217\n",
      "Recompensa por acortar distancias: +  0.5017231217355508\n",
      "Penalización por duración del episodio: -  0.3787772321959903\n",
      "Recompensa por acortar distancias: +  0.5017231217355508\n",
      "Penalización por duración del episodio: -  0.3789081080367904\n",
      "Step: 5230, Mean Reward (últimos 10 pasos): 0.12281501293182373\n",
      "Recompensa por acortar distancias: +  0.5017231217355508\n",
      "Penalización por duración del episodio: -  0.37914068938850815\n",
      "Recompensa por acortar distancias: +  0.5017231217355508\n",
      "Penalización por duración del episodio: -  0.37923923911786844\n",
      "Recompensa por acortar distancias: +  0.5017231217355508\n",
      "Penalización por duración del episodio: -  0.3793432044755722\n",
      "Recompensa por acortar distancias: +  0.5017231217355508\n",
      "Penalización por duración del episodio: -  0.37944693951208014\n",
      "Recompensa por acortar distancias: +  0.5017231217355508\n",
      "Penalización por duración del episodio: -  0.37988166405029644\n",
      "Recompensa por acortar distancias: +  0.48987875574151246\n",
      "Penalización por duración del episodio: -  0.3802551344735338\n",
      "Recompensa por acortar distancias: +  0.48987875574151246\n",
      "Penalización por duración del episodio: -  0.3803507058816097\n",
      "Recompensa por acortar distancias: +  0.48987875574151246\n",
      "Penalización por duración del episodio: -  0.3804447186721167\n",
      "Recompensa por acortar distancias: +  0.4847208640539356\n",
      "Penalización por duración del episodio: -  0.38057429456597097\n",
      "Recompensa por acortar distancias: +  0.4847208640539356\n",
      "Penalización por duración del episodio: -  0.38066839050123\n",
      "Step: 5240, Mean Reward (últimos 10 pasos): 0.10405247658491135\n",
      "Recompensa por acortar distancias: +  0.48268030305949555\n",
      "Penalización por duración del episodio: -  0.3809855250799335\n",
      "Recompensa por acortar distancias: +  0.4790780650849242\n",
      "Penalización por duración del episodio: -  0.3811096271132144\n",
      "steer input from model: -0.1 , throttle:  0.7\n",
      "reward: 0.09796843797170979\n",
      "Recompensa por acortar distancias: +  0.4790780650849242\n",
      "Penalización por duración del episodio: -  0.38120481439162734\n",
      "Recompensa por acortar distancias: +  0.4790780650849242\n",
      "Penalización por duración del episodio: -  0.3813599758283691\n",
      "Recompensa por acortar distancias: +  0.4790780650849242\n",
      "Penalización por duración del episodio: -  0.3817335660442366\n",
      "Recompensa por acortar distancias: +  0.4790780650849242\n",
      "Penalización por duración del episodio: -  0.3821078140663184\n",
      "Recompensa por acortar distancias: +  0.4709261815242701\n",
      "Penalización por duración del episodio: -  0.38247530945135394\n",
      "Recompensa por acortar distancias: +  0.4688869239137709\n",
      "Penalización por duración del episodio: -  0.38257464801307794\n",
      "Recompensa por acortar distancias: +  0.4688869239137709\n",
      "Penalización por duración del episodio: -  0.3828489950132577\n",
      "Recompensa por acortar distancias: +  0.46401475939437753\n",
      "Penalización por duración del episodio: -  0.3829712495851814\n",
      "Step: 5250, Mean Reward (últimos 10 pasos): 0.08104351162910461\n",
      "Recompensa por acortar distancias: +  0.46260441917950756\n",
      "Penalización por duración del episodio: -  0.383115832283918\n",
      "Recompensa por acortar distancias: +  0.4606528627228247\n",
      "Penalización por duración del episodio: -  0.3832284769933239\n",
      "Recompensa por acortar distancias: +  0.459583749403193\n",
      "Penalización por duración del episodio: -  0.3833468547912466\n",
      "Recompensa por acortar distancias: +  0.459583749403193\n",
      "Penalización por duración del episodio: -  0.3835853656238725\n",
      "Recompensa por acortar distancias: +  0.459583749403193\n",
      "Penalización por duración del episodio: -  0.3836891545550422\n",
      "Recompensa por acortar distancias: +  0.459583749403193\n",
      "Penalización por duración del episodio: -  0.383951267341142\n",
      "Recompensa por acortar distancias: +  0.459583749403193\n",
      "Penalización por duración del episodio: -  0.38405835913033376\n",
      "Recompensa por acortar distancias: +  0.459583749403193\n",
      "Penalización por duración del episodio: -  0.3843121668170638\n",
      "Recompensa por acortar distancias: +  0.4517347217471687\n",
      "Penalización por duración del episodio: -  0.38467726821652437\n",
      "Recompensa por acortar distancias: +  0.45045462620077636\n",
      "Penalización por duración del episodio: -  0.38506838963018797\n",
      "Step: 5260, Mean Reward (últimos 10 pasos): 0.06538623571395874\n",
      "Recompensa por acortar distancias: +  0.44600302986346013\n",
      "Penalización por duración del episodio: -  0.3854577168036193\n",
      "Recompensa por acortar distancias: +  0.44272818799260544\n",
      "Penalización por duración del episodio: -  0.3858296764356118\n",
      "steer input from model: 0.05 , throttle:  0.3\n",
      "reward: 0.05689851155699366\n",
      "Recompensa por acortar distancias: +  0.441383485000443\n",
      "Penalización por duración del episodio: -  0.38619284541962523\n",
      "Recompensa por acortar distancias: +  0.441383485000443\n",
      "Penalización por duración del episodio: -  0.3865505100889557\n",
      "Recompensa por acortar distancias: +  0.441383485000443\n",
      "Penalización por duración del episodio: -  0.38692409322925336\n",
      "Recompensa por acortar distancias: +  0.4336703528042008\n",
      "Penalización por duración del episodio: -  0.38705312844631096\n",
      "Recompensa por acortar distancias: +  0.4336703528042008\n",
      "Penalización por duración del episodio: -  0.3871366302720334\n",
      "Recompensa por acortar distancias: +  0.4336703528042008\n",
      "Penalización por duración del episodio: -  0.38728803313313853\n",
      "Recompensa por acortar distancias: +  0.4336703528042008\n",
      "Penalización por duración del episodio: -  0.387651963077376\n",
      "Recompensa por acortar distancias: +  0.42949078149292436\n",
      "Penalización por duración del episodio: -  0.38777808758276144\n",
      "Step: 5270, Mean Reward (últimos 10 pasos): 0.041712693870067596\n",
      "Recompensa por acortar distancias: +  0.4282062618810103\n",
      "Penalización por duración del episodio: -  0.3879034912145745\n",
      "Recompensa por acortar distancias: +  0.4282062618810103\n",
      "Penalización por duración del episodio: -  0.3880692829543904\n",
      "Recompensa por acortar distancias: +  0.42664440104095763\n",
      "Penalización por duración del episodio: -  0.38839607352214356\n",
      "Recompensa por acortar distancias: +  0.4248139850508936\n",
      "Penalización por duración del episodio: -  0.388495098826846\n",
      "Recompensa por acortar distancias: +  0.4248139850508936\n",
      "Penalización por duración del episodio: -  0.3887767062939745\n",
      "Recompensa por acortar distancias: +  0.4248139850508936\n",
      "Penalización por duración del episodio: -  0.38895513426129286\n",
      "Recompensa por acortar distancias: +  0.4248139850508936\n",
      "Penalización por duración del episodio: -  0.38909197695823\n",
      "Recompensa por acortar distancias: +  0.4248139850508936\n",
      "Penalización por duración del episodio: -  0.38950697525138145\n",
      "Recompensa por acortar distancias: +  0.4186223879150058\n",
      "Penalización por duración del episodio: -  0.38961147278021274\n",
      "Recompensa por acortar distancias: +  0.41753779428383275\n",
      "Penalización por duración del episodio: -  0.38988552996943504\n",
      "Step: 5280, Mean Reward (últimos 10 pasos): 0.027652263641357422\n",
      "Recompensa por acortar distancias: +  0.41753779428383275\n",
      "Penalización por duración del episodio: -  0.3902580731733629\n",
      "Recompensa por acortar distancias: +  0.41419780098431985\n",
      "Penalización por duración del episodio: -  0.39063622109141255\n",
      "steer input from model: -0.05 , throttle:  0.0\n",
      "reward: 0.023561579892907303\n",
      "Recompensa por acortar distancias: +  0.4131859938457861\n",
      "Penalización por duración del episodio: -  0.39099847362083373\n",
      "Recompensa por acortar distancias: +  0.4131859938457861\n",
      "Penalización por duración del episodio: -  0.39137046672110243\n",
      "Recompensa por acortar distancias: +  0.4131859938457861\n",
      "Penalización por duración del episodio: -  0.39173756972590834\n",
      "Recompensa por acortar distancias: +  0.40639954622918817\n",
      "Penalización por duración del episodio: -  0.3918941440864089\n",
      "Recompensa por acortar distancias: +  0.40639954622918817\n",
      "Penalización por duración del episodio: -  0.39202278816783453\n",
      "Recompensa por acortar distancias: +  0.40639954622918817\n",
      "Penalización por duración del episodio: -  0.39216100066641796\n",
      "Recompensa por acortar distancias: +  0.40639954622918817\n",
      "Penalización por duración del episodio: -  0.3922629222177014\n",
      "Recompensa por acortar distancias: +  0.40639954622918817\n",
      "Penalización por duración del episodio: -  0.3924718017780463\n",
      "Step: 5290, Mean Reward (últimos 10 pasos): 0.013927744701504707\n",
      "Recompensa por acortar distancias: +  0.40639954622918817\n",
      "Penalización por duración del episodio: -  0.39260277018837636\n",
      "Recompensa por acortar distancias: +  0.4023097624825023\n",
      "Penalización por duración del episodio: -  0.3927064211168084\n",
      "Recompensa por acortar distancias: +  0.4023097624825023\n",
      "Penalización por duración del episodio: -  0.3928435929341242\n",
      "Recompensa por acortar distancias: +  0.4023097624825023\n",
      "Penalización por duración del episodio: -  0.39300687576132926\n",
      "Recompensa por acortar distancias: +  0.4023097624825023\n",
      "Penalización por duración del episodio: -  0.3931274693795548\n",
      "Recompensa por acortar distancias: +  0.39987160558125395\n",
      "Penalización por duración del episodio: -  0.3935925324637218\n",
      "Recompensa por acortar distancias: +  0.39987160558125395\n",
      "Penalización por duración del episodio: -  0.39398130737159326\n",
      "Recompensa por acortar distancias: +  0.39987160558125395\n",
      "Penalización por duración del episodio: -  0.3940899536465228\n",
      "Recompensa por acortar distancias: +  0.39987160558125395\n",
      "Penalización por duración del episodio: -  0.3941858169911852\n",
      "Recompensa por acortar distancias: +  0.39987160558125395\n",
      "Penalización por duración del episodio: -  0.3943493921602826\n",
      "Step: 5300, Mean Reward (últimos 10 pasos): 0.005522213410586119\n",
      "Recompensa por acortar distancias: +  0.39432212513997966\n",
      "Penalización por duración del episodio: -  0.3944685069528213\n",
      "Recompensa por acortar distancias: +  0.39432212513997966\n",
      "Penalización por duración del episodio: -  0.3945936373980379\n",
      "steer input from model: 0.1 , throttle:  0.0\n",
      "reward: -0.0002715122580582152\n",
      "Recompensa por acortar distancias: +  0.39334589574836626\n",
      "Penalización por duración del episodio: -  0.3947131310477097\n",
      "Recompensa por acortar distancias: +  0.39334589574836626\n",
      "Penalización por duración del episodio: -  0.3948132855229133\n",
      "Recompensa por acortar distancias: +  0.39334589574836626\n",
      "Penalización por duración del episodio: -  0.3949324319745263\n",
      "Recompensa por acortar distancias: +  0.39334589574836626\n",
      "Penalización por duración del episodio: -  0.3950887131144869\n",
      "Recompensa por acortar distancias: +  0.39334589574836626\n",
      "Penalización por duración del episodio: -  0.39547876017531697\n",
      "Recompensa por acortar distancias: +  0.38984623938246044\n",
      "Penalización por duración del episodio: -  0.39558814839643386\n",
      "Recompensa por acortar distancias: +  0.38984623938246044\n",
      "Penalización por duración del episodio: -  0.39584907491751675\n",
      "Recompensa por acortar distancias: +  0.38984623938246044\n",
      "Penalización por duración del episodio: -  0.3962158131634223\n",
      "Step: 5310, Mean Reward (últimos 10 pasos): -0.006369573995471001\n",
      "Recompensa por acortar distancias: +  0.38984623938246044\n",
      "Penalización por duración del episodio: -  0.3963027459240764\n",
      "Recompensa por acortar distancias: +  0.38984623938246044\n",
      "Penalización por duración del episodio: -  0.39644160894297864\n",
      "Recompensa por acortar distancias: +  0.38984623938246044\n",
      "Penalización por duración del episodio: -  0.39657053837291584\n",
      "Recompensa por acortar distancias: +  0.38580232665095604\n",
      "Penalización por duración del episodio: -  0.3966620111619724\n",
      "Recompensa por acortar distancias: +  0.38580232665095604\n",
      "Penalización por duración del episodio: -  0.39676917223458513\n",
      "Recompensa por acortar distancias: +  0.38466625239070035\n",
      "Penalización por duración del episodio: -  0.396931775837011\n",
      "Recompensa por acortar distancias: +  0.38466625239070035\n",
      "Penalización por duración del episodio: -  0.3970400577113314\n",
      "Recompensa por acortar distancias: +  0.38466625239070035\n",
      "Penalización por duración del episodio: -  0.3973437596076639\n",
      "Recompensa por acortar distancias: +  0.38466625239070035\n",
      "Penalización por duración del episodio: -  0.3977265393374262\n",
      "Recompensa por acortar distancias: +  0.3820687235666612\n",
      "Penalización por duración del episodio: -  0.39789445146618424\n",
      "Step: 5320, Mean Reward (últimos 10 pasos): -0.015825727954506874\n",
      "Recompensa por acortar distancias: +  0.3812559547506714\n",
      "Penalización por duración del episodio: -  0.3980171323574395\n",
      "Recompensa por acortar distancias: +  0.3812559547506714\n",
      "Penalización por duración del episodio: -  0.39847403231338047\n",
      "steer input from model: 0.05 , throttle:  0.0\n",
      "reward: -0.017218077562709044\n",
      "Recompensa por acortar distancias: +  0.3812559547506714\n",
      "Penalización por duración del episodio: -  0.3985909097128617\n",
      "Recompensa por acortar distancias: +  0.3812559547506714\n",
      "Penalización por duración del episodio: -  0.3988517380977051\n",
      "Recompensa por acortar distancias: +  0.3778328973943369\n",
      "Penalización por duración del episodio: -  0.39923050209714633\n",
      "Recompensa por acortar distancias: +  0.37703994579229433\n",
      "Penalización por duración del episodio: -  0.39933965920511166\n",
      "Recompensa por acortar distancias: +  0.37703994579229433\n",
      "Penalización por duración del episodio: -  0.39959427978530865\n",
      "Recompensa por acortar distancias: +  0.37703994579229433\n",
      "Penalización por duración del episodio: -  0.3996972575939779\n",
      "Recompensa por acortar distancias: +  0.37703994579229433\n",
      "Penalización por duración del episodio: -  0.3998187120982227\n",
      "Recompensa por acortar distancias: +  0.3750873355106822\n",
      "Penalización por duración del episodio: -  0.4003431156688791\n",
      "Step: 5330, Mean Reward (últimos 10 pasos): -0.025255780667066574\n",
      "Recompensa por acortar distancias: +  0.3743588731840696\n",
      "Penalización por duración del episodio: -  0.4007180119541798\n",
      "Recompensa por acortar distancias: +  0.3743588731840696\n",
      "Penalización por duración del episodio: -  0.4008022592670857\n",
      "Recompensa por acortar distancias: +  0.3743588731840696\n",
      "Penalización por duración del episodio: -  0.4009286297765981\n",
      "Recompensa por acortar distancias: +  0.3743588731840696\n",
      "Penalización por duración del episodio: -  0.4010987288218043\n",
      "Recompensa por acortar distancias: +  0.3715194285309706\n",
      "Penalización por duración del episodio: -  0.4014651852510661\n",
      "Recompensa por acortar distancias: +  0.37096814444241627\n",
      "Penalización por duración del episodio: -  0.4018433909566632\n",
      "Recompensa por acortar distancias: +  0.37096814444241627\n",
      "Penalización por duración del episodio: -  0.4022177351589155\n",
      "Recompensa por acortar distancias: +  0.3687440247775765\n",
      "Penalización por duración del episodio: -  0.4025841482544758\n",
      "Recompensa por acortar distancias: +  0.3682593732859172\n",
      "Penalización por duración del episodio: -  0.40269106147237577\n",
      "Recompensa por acortar distancias: +  0.3682593732859172\n",
      "Penalización por duración del episodio: -  0.4028141745181942\n",
      "Step: 5340, Mean Reward (últimos 10 pasos): -0.034554801881313324\n",
      "Recompensa por acortar distancias: +  0.3682593732859172\n",
      "Penalización por duración del episodio: -  0.4029482381193793\n",
      "Recompensa por acortar distancias: +  0.3682593732859172\n",
      "Penalización por duración del episodio: -  0.40333500107147124\n",
      "steer input from model: 0.25 , throttle:  0.0\n",
      "reward: -0.035075627785554064\n",
      "Recompensa por acortar distancias: +  0.3682593732859172\n",
      "Penalización por duración del episodio: -  0.40344388410876375\n",
      "Recompensa por acortar distancias: +  0.3682593732859172\n",
      "Penalización por duración del episodio: -  0.40372329613861296\n",
      "Recompensa por acortar distancias: +  0.36556611386242793\n",
      "Penalización por duración del episodio: -  0.4041110401161579\n",
      "Recompensa por acortar distancias: +  0.36556611386242793\n",
      "Penalización por duración del episodio: -  0.40447222783997355\n",
      "Recompensa por acortar distancias: +  0.3642987613847651\n",
      "Penalización por duración del episodio: -  0.4045834151740177\n",
      "Recompensa por acortar distancias: +  0.36383621948065964\n",
      "Penalización por duración del episodio: -  0.40469192415717603\n",
      "Recompensa por acortar distancias: +  0.36383621948065964\n",
      "Penalización por duración del episodio: -  0.40481181064952104\n",
      "Recompensa por acortar distancias: +  0.3634635759627099\n",
      "Penalización por duración del episodio: -  0.40523060342536105\n",
      "Step: 5350, Mean Reward (últimos 10 pasos): -0.04176702722907066\n",
      "Recompensa por acortar distancias: +  0.3634635759627099\n",
      "Penalización por duración del episodio: -  0.40561071125743264\n",
      "Recompensa por acortar distancias: +  0.3634635759627099\n",
      "Penalización por duración del episodio: -  0.4059895235655796\n",
      "Recompensa por acortar distancias: +  0.3616913786710811\n",
      "Penalización por duración del episodio: -  0.4063468225292995\n",
      "Recompensa por acortar distancias: +  0.36138875285075006\n",
      "Penalización por duración del episodio: -  0.4067171475726621\n",
      "Recompensa por acortar distancias: +  0.36138875285075006\n",
      "Penalización por duración del episodio: -  0.4069006582699217\n",
      "Recompensa por acortar distancias: +  0.3604197096171996\n",
      "Penalización por duración del episodio: -  0.40698514429516874\n",
      "Recompensa por acortar distancias: +  0.3604197096171996\n",
      "Penalización por duración del episodio: -  0.4071248462919934\n",
      "Recompensa por acortar distancias: +  0.3599733934345251\n",
      "Penalización por duración del episodio: -  0.4072392454288722\n",
      "Recompensa por acortar distancias: +  0.3599733934345251\n",
      "Penalización por duración del episodio: -  0.40734778369983154\n",
      "Recompensa por acortar distancias: +  0.35972290747372176\n",
      "Penalización por duración del episodio: -  0.4074587428954213\n",
      "Step: 5360, Mean Reward (últimos 10 pasos): -0.04773583635687828\n",
      "Recompensa por acortar distancias: +  0.35972290747372176\n",
      "Penalización por duración del episodio: -  0.40756828960738917\n",
      "Recompensa por acortar distancias: +  0.35972290747372176\n",
      "Penalización por duración del episodio: -  0.4076762852937561\n",
      "steer input from model: 0.1 , throttle:  1.0\n",
      "reward: -0.04795337782003434\n",
      "Recompensa por acortar distancias: +  0.35972290747372176\n",
      "Penalización por duración del episodio: -  0.4078422656608051\n",
      "Recompensa por acortar distancias: +  0.35972290747372176\n",
      "Penalización por duración del episodio: -  0.4082370687381942\n",
      "Recompensa por acortar distancias: +  0.35972290747372176\n",
      "Penalización por duración del episodio: -  0.40861122623326324\n",
      "Recompensa por acortar distancias: +  0.35972290747372176\n",
      "Penalización por duración del episodio: -  0.4087404997238246\n",
      "Recompensa por acortar distancias: +  0.3582213151157466\n",
      "Penalización por duración del episodio: -  0.40890035606396485\n",
      "Recompensa por acortar distancias: +  0.3582213151157466\n",
      "Penalización por duración del episodio: -  0.4090194973508743\n",
      "Recompensa por acortar distancias: +  0.35777675718681495\n",
      "Penalización por duración del episodio: -  0.40936176089010406\n",
      "Recompensa por acortar distancias: +  0.35777675718681495\n",
      "Penalización por duración del episodio: -  0.4095299881877286\n",
      "Step: 5370, Mean Reward (últimos 10 pasos): -0.05175323039293289\n",
      "Recompensa por acortar distancias: +  0.35777675718681495\n",
      "Penalización por duración del episodio: -  0.40974446387043534\n",
      "Recompensa por acortar distancias: +  0.35715528625319265\n",
      "Penalización por duración del episodio: -  0.41012644561955924\n",
      "Recompensa por acortar distancias: +  0.3569168257966565\n",
      "Penalización por duración del episodio: -  0.4105058933713943\n",
      "Recompensa por acortar distancias: +  0.3569168257966565\n",
      "Penalización por duración del episodio: -  0.4108873463502047\n",
      "Recompensa por acortar distancias: +  0.3569168257966565\n",
      "Penalización por duración del episodio: -  0.41099206762542245\n",
      "Recompensa por acortar distancias: +  0.3561485312568496\n",
      "Penalización por duración del episodio: -  0.41110591102160493\n",
      "Recompensa por acortar distancias: +  0.3561485312568496\n",
      "Penalización por duración del episodio: -  0.411274217436567\n",
      "Recompensa por acortar distancias: +  0.35599728738378755\n",
      "Penalización por duración del episodio: -  0.4113667292919431\n",
      "Recompensa por acortar distancias: +  0.35599728738378755\n",
      "Penalización por duración del episodio: -  0.4114719666184989\n",
      "Recompensa por acortar distancias: +  0.35599728738378755\n",
      "Penalización por duración del episodio: -  0.4115695037015943\n",
      "Step: 5380, Mean Reward (últimos 10 pasos): -0.05557221546769142\n",
      "Recompensa por acortar distancias: +  0.35599728738378755\n",
      "Penalización por duración del episodio: -  0.4120257908503035\n",
      "Recompensa por acortar distancias: +  0.35554496833362625\n",
      "Penalización por duración del episodio: -  0.41238339108932115\n",
      "steer input from model: -0.9 , throttle:  1.0\n",
      "reward: -0.056838422755694895\n",
      "Recompensa por acortar distancias: +  0.35542859418116685\n",
      "Penalización por duración del episodio: -  0.4127538206452157\n",
      "Recompensa por acortar distancias: +  0.35542859418116685\n",
      "Penalización por duración del episodio: -  0.4129226927782148\n",
      "Recompensa por acortar distancias: +  0.35542859418116685\n",
      "Penalización por duración del episodio: -  0.41313820498662834\n",
      "Recompensa por acortar distancias: +  0.35542859418116685\n",
      "Penalización por duración del episodio: -  0.41326886373093674\n",
      "Recompensa por acortar distancias: +  0.35488963643753413\n",
      "Penalización por duración del episodio: -  0.4135091418890833\n",
      "Recompensa por acortar distancias: +  0.35477606568639475\n",
      "Penalización por duración del episodio: -  0.4138845378293818\n",
      "Recompensa por acortar distancias: +  0.35477606568639475\n",
      "Penalización por duración del episodio: -  0.41401894484355706\n",
      "Recompensa por acortar distancias: +  0.35477606568639475\n",
      "Penalización por duración del episodio: -  0.41426476036091303\n",
      "Step: 5390, Mean Reward (últimos 10 pasos): -0.059488695114851\n",
      "Recompensa por acortar distancias: +  0.3544742996530006\n",
      "Penalización por duración del episodio: -  0.41440491989582817\n",
      "Recompensa por acortar distancias: +  0.3544090758264789\n",
      "Penalización por duración del episodio: -  0.41464726090654525\n",
      "Recompensa por acortar distancias: +  0.3543283445634388\n",
      "Penalización por duración del episodio: -  0.41479940333992865\n",
      "Recompensa por acortar distancias: +  0.3543283445634388\n",
      "Penalización por duración del episodio: -  0.4149494957058763\n",
      "Recompensa por acortar distancias: +  0.3543283445634388\n",
      "Penalización por duración del episodio: -  0.4153802632068658\n",
      "Recompensa por acortar distancias: +  0.3543283445634388\n",
      "Penalización por duración del episodio: -  0.41549389144653404\n",
      "Recompensa por acortar distancias: +  0.3543283445634388\n",
      "Penalización por duración del episodio: -  0.41560313356759104\n",
      "Recompensa por acortar distancias: +  0.3543283445634388\n",
      "Penalización por duración del episodio: -  0.41573659091046294\n",
      "Recompensa por acortar distancias: +  0.35398940209271124\n",
      "Penalización por duración del episodio: -  0.4158577706439793\n",
      "Recompensa por acortar distancias: +  0.35398940209271124\n",
      "Penalización por duración del episodio: -  0.4159920450818297\n",
      "Step: 5400, Mean Reward (últimos 10 pasos): -0.06200264394283295\n",
      "Recompensa por acortar distancias: +  0.35391336971513593\n",
      "Penalización por duración del episodio: -  0.4161318466907322\n",
      "Recompensa por acortar distancias: +  0.35391336971513593\n",
      "Penalización por duración del episodio: -  0.4165006551303881\n",
      "steer input from model: 0.05 , throttle:  0.0\n",
      "reward: -0.06258728541525216\n",
      "Recompensa por acortar distancias: +  0.35391336971513593\n",
      "Penalización por duración del episodio: -  0.41660087568034604\n",
      "Recompensa por acortar distancias: +  0.35391336971513593\n",
      "Penalización por duración del episodio: -  0.41671021873906716\n",
      "Recompensa por acortar distancias: +  0.35378443250705804\n",
      "Penalización por duración del episodio: -  0.4168314855950516\n",
      "Recompensa por acortar distancias: +  0.35378443250705804\n",
      "Penalización por duración del episodio: -  0.41699059369725583\n",
      "Recompensa por acortar distancias: +  0.35378443250705804\n",
      "Penalización por duración del episodio: -  0.4172591611433457\n",
      "Recompensa por acortar distancias: +  0.3537443487223262\n",
      "Penalización por duración del episodio: -  0.41764744205870324\n",
      "Recompensa por acortar distancias: +  0.3537443487223262\n",
      "Penalización por duración del episodio: -  0.41802485098400527\n",
      "Recompensa por acortar distancias: +  0.3537443487223262\n",
      "Penalización por duración del episodio: -  0.41839762172762857\n",
      "Step: 5410, Mean Reward (últimos 10 pasos): -0.06465326994657516\n",
      "Recompensa por acortar distancias: +  0.35372442750810246\n",
      "Penalización por duración del episodio: -  0.41850934349993435\n",
      "Recompensa por acortar distancias: +  0.35372442750810246\n",
      "Penalización por duración del episodio: -  0.41877506438397194\n",
      "Recompensa por acortar distancias: +  0.35372442750810246\n",
      "Penalización por duración del episodio: -  0.4189327969850364\n",
      "Recompensa por acortar distancias: +  0.35372442750810246\n",
      "Penalización por duración del episodio: -  0.4191545466970963\n",
      "Recompensa por acortar distancias: +  0.3537653823693758\n",
      "Penalización por duración del episodio: -  0.4192872348729476\n",
      "Recompensa por acortar distancias: +  0.35379167113601573\n",
      "Penalización por duración del episodio: -  0.41953406661214043\n",
      "Recompensa por acortar distancias: +  0.35382161295397685\n",
      "Penalización por duración del episodio: -  0.41965806082705365\n",
      "Recompensa por acortar distancias: +  0.35382161295397685\n",
      "Penalización por duración del episodio: -  0.4198962708091547\n",
      "Recompensa por acortar distancias: +  0.35382161295397685\n",
      "Penalización por duración del episodio: -  0.4202666066071829\n",
      "Recompensa por acortar distancias: +  0.35382161295397685\n",
      "Penalización por duración del episodio: -  0.42064707822863495\n",
      "Step: 5420, Mean Reward (últimos 10 pasos): -0.06682546436786652\n",
      "Recompensa por acortar distancias: +  0.35409280946708194\n",
      "Penalización por duración del episodio: -  0.42102238449977436\n",
      "Recompensa por acortar distancias: +  0.35417329291045957\n",
      "Penalización por duración del episodio: -  0.4213979855260408\n",
      "steer input from model: -0.25 , throttle:  0.3\n",
      "reward: -0.06722469261558123\n",
      "Recompensa por acortar distancias: +  0.35449816258234196\n",
      "Penalización por duración del episodio: -  0.4217821377520113\n",
      "Recompensa por acortar distancias: +  0.35470285484818587\n",
      "Penalización por duración del episodio: -  0.4221679666211709\n",
      "Recompensa por acortar distancias: +  0.35470285484818587\n",
      "Penalización por duración del episodio: -  0.4225522150780063\n",
      "Recompensa por acortar distancias: +  0.35470285484818587\n",
      "Penalización por duración del episodio: -  0.4229361965157954\n",
      "Recompensa por acortar distancias: +  0.3554132839271416\n",
      "Penalización por duración del episodio: -  0.42330885756009606\n",
      "Recompensa por acortar distancias: +  0.3554132839271416\n",
      "Penalización por duración del episodio: -  0.42368805622548134\n",
      "Recompensa por acortar distancias: +  0.3557972164437458\n",
      "Penalización por duración del episodio: -  0.4238018846086833\n",
      "Recompensa por acortar distancias: +  0.3559619446174752\n",
      "Penalización por duración del episodio: -  0.4239310283681992\n",
      "Step: 5430, Mean Reward (últimos 10 pasos): -0.06796908378601074\n",
      "Recompensa por acortar distancias: +  0.35609556776111084\n",
      "Penalización por duración del episodio: -  0.4240796546545111\n",
      "Recompensa por acortar distancias: +  0.35609556776111084\n",
      "Penalización por duración del episodio: -  0.42446441735478463\n",
      "Recompensa por acortar distancias: +  0.3563966449328122\n",
      "Penalización por duración del episodio: -  0.4248531632746402\n",
      "Recompensa por acortar distancias: +  0.3563966449328122\n",
      "Penalización por duración del episodio: -  0.425239041943769\n",
      "Recompensa por acortar distancias: +  0.35728867085522936\n",
      "Penalización por duración del episodio: -  0.42562773367669804\n",
      "Recompensa por acortar distancias: +  0.3574694281755709\n",
      "Penalización por duración del episodio: -  0.42601877938309624\n",
      "Recompensa por acortar distancias: +  0.35809727375866746\n",
      "Penalización por duración del episodio: -  0.4264036139646755\n",
      "Recompensa por acortar distancias: +  0.358469114818025\n",
      "Penalización por duración del episodio: -  0.42652657786790543\n",
      "Recompensa por acortar distancias: +  0.35862741573851226\n",
      "Penalización por duración del episodio: -  0.4267918039941816\n",
      "Recompensa por acortar distancias: +  0.35883091239955883\n",
      "Penalización por duración del episodio: -  0.4271877385072757\n",
      "Step: 5440, Mean Reward (últimos 10 pasos): -0.06835682690143585\n",
      "Recompensa por acortar distancias: +  0.35883091239955883\n",
      "Penalización por duración del episodio: -  0.4275692945184383\n",
      "Recompensa por acortar distancias: +  0.35987118629414006\n",
      "Penalización por duración del episodio: -  0.4279421641787232\n",
      "steer input from model: 0.05 , throttle:  0.0\n",
      "reward: -0.06807097788458316\n",
      "Recompensa por acortar distancias: +  0.36011461375210524\n",
      "Penalización por duración del episodio: -  0.4283310475373119\n",
      "Recompensa por acortar distancias: +  0.3609178817184141\n",
      "Penalización por duración del episodio: -  0.4284609246688983\n",
      "Recompensa por acortar distancias: +  0.36119685165367615\n",
      "Penalización por duración del episodio: -  0.4287290529070647\n",
      "Recompensa por acortar distancias: +  0.3615441878339597\n",
      "Penalización por duración del episodio: -  0.42882798616755907\n",
      "Recompensa por acortar distancias: +  0.3615441878339597\n",
      "Penalización por duración del episodio: -  0.4289703988492382\n",
      "Recompensa por acortar distancias: +  0.36185320131168314\n",
      "Penalización por duración del episodio: -  0.42911144489882386\n",
      "Recompensa por acortar distancias: +  0.36185320131168314\n",
      "Penalización por duración del episodio: -  0.42924360060205263\n",
      "Recompensa por acortar distancias: +  0.36241441714860045\n",
      "Penalización por duración del episodio: -  0.42948792186883356\n",
      "Step: 5450, Mean Reward (últimos 10 pasos): -0.06707350164651871\n",
      "Recompensa por acortar distancias: +  0.36241441714860045\n",
      "Penalización por duración del episodio: -  0.42986703974864615\n",
      "Recompensa por acortar distancias: +  0.36241441714860045\n",
      "Penalización por duración del episodio: -  0.42997428319860775\n",
      "Recompensa por acortar distancias: +  0.36241441714860045\n",
      "Penalización por duración del episodio: -  0.4300602439810992\n",
      "Recompensa por acortar distancias: +  0.36241441714860045\n",
      "Penalización por duración del episodio: -  0.43022204400949515\n",
      "Recompensa por acortar distancias: +  0.3638774541353456\n",
      "Penalización por duración del episodio: -  0.43034672657651146\n",
      "Recompensa por acortar distancias: +  0.36427531775408517\n",
      "Penalización por duración del episodio: -  0.4306414457230733\n",
      "Recompensa por acortar distancias: +  0.36427531775408517\n",
      "Penalización por duración del episodio: -  0.43101655009048756\n",
      "Recompensa por acortar distancias: +  0.3652810722787305\n",
      "Penalización por duración del episodio: -  0.43116387740074835\n",
      "Recompensa por acortar distancias: +  0.3652810722787305\n",
      "Penalización por duración del episodio: -  0.43140698005398187\n",
      "Recompensa por acortar distancias: +  0.36599027621107816\n",
      "Penalización por duración del episodio: -  0.43180911840617353\n",
      "Step: 5460, Mean Reward (últimos 10 pasos): -0.06581883877515793\n",
      "Recompensa por acortar distancias: +  0.36622769411186873\n",
      "Penalización por duración del episodio: -  0.43218188175805666\n",
      "Recompensa por acortar distancias: +  0.36622769411186873\n",
      "Penalización por duración del episodio: -  0.43256907696645086\n",
      "steer input from model: -0.25 , throttle:  0.0\n",
      "reward: -0.06634138285458213\n",
      "Recompensa por acortar distancias: +  0.36834614418377926\n",
      "Penalización por duración del episodio: -  0.4326940929038172\n",
      "Recompensa por acortar distancias: +  0.36834614418377926\n",
      "Penalización por duración del episodio: -  0.43280893931777104\n",
      "Recompensa por acortar distancias: +  0.36834614418377926\n",
      "Penalización por duración del episodio: -  0.4329109393818285\n",
      "Recompensa por acortar distancias: +  0.36834614418377926\n",
      "Penalización por duración del episodio: -  0.43331782553066717\n",
      "Recompensa por acortar distancias: +  0.369740034506689\n",
      "Penalización por duración del episodio: -  0.43369215614490936\n",
      "Recompensa por acortar distancias: +  0.37047100312990655\n",
      "Penalización por duración del episodio: -  0.43409050526410586\n",
      "Recompensa por acortar distancias: +  0.37125496689216314\n",
      "Penalización por duración del episodio: -  0.4342375015251228\n",
      "Recompensa por acortar distancias: +  0.37125496689216314\n",
      "Penalización por duración del episodio: -  0.43433335960538405\n",
      "Step: 5470, Mean Reward (últimos 10 pasos): -0.0630783960223198\n",
      "Recompensa por acortar distancias: +  0.37125496689216314\n",
      "Penalización por duración del episodio: -  0.43483327170610764\n",
      "Recompensa por acortar distancias: +  0.3733620144387242\n",
      "Penalización por duración del episodio: -  0.43520857999568685\n",
      "Recompensa por acortar distancias: +  0.37388243652283093\n",
      "Penalización por duración del episodio: -  0.4355928252177854\n",
      "Recompensa por acortar distancias: +  0.37388243652283093\n",
      "Penalización por duración del episodio: -  0.4357531632432876\n",
      "Recompensa por acortar distancias: +  0.3753528302807437\n",
      "Penalización por duración del episodio: -  0.435982289442472\n",
      "Recompensa por acortar distancias: +  0.37618107541597434\n",
      "Penalización por duración del episodio: -  0.4361015239728124\n",
      "Recompensa por acortar distancias: +  0.37661064037990477\n",
      "Penalización por duración del episodio: -  0.43636662548931654\n",
      "Recompensa por acortar distancias: +  0.3770642696813974\n",
      "Penalización por duración del episodio: -  0.43675709662984846\n",
      "Recompensa por acortar distancias: +  0.377499048371732\n",
      "Penalización por duración del episodio: -  0.4371407767794846\n",
      "Recompensa por acortar distancias: +  0.377499048371732\n",
      "Penalización por duración del episodio: -  0.43727811070739636\n",
      "Step: 5480, Mean Reward (últimos 10 pasos): -0.05977906286716461\n",
      "Recompensa por acortar distancias: +  0.3798096383501925\n",
      "Penalización por duración del episodio: -  0.4373958289661531\n",
      "Recompensa por acortar distancias: +  0.3798096383501925\n",
      "Penalización por duración del episodio: -  0.43750066370078183\n",
      "steer input from model: -0.05 , throttle:  0.0\n",
      "reward: -0.05769102535058934\n",
      "Recompensa por acortar distancias: +  0.3804031254755634\n",
      "Penalización por duración del episodio: -  0.43793416062243895\n",
      "Recompensa por acortar distancias: +  0.3804031254755634\n",
      "Penalización por duración del episodio: -  0.4383229831038875\n",
      "Recompensa por acortar distancias: +  0.3826846414373961\n",
      "Penalización por duración del episodio: -  0.4386985779133002\n",
      "Recompensa por acortar distancias: +  0.3838944521835108\n",
      "Penalización por duración del episodio: -  0.43880664005195447\n",
      "Recompensa por acortar distancias: +  0.3838944521835108\n",
      "Penalización por duración del episodio: -  0.4388911458000693\n",
      "Recompensa por acortar distancias: +  0.3843294972611607\n",
      "Penalización por duración del episodio: -  0.43907133635423373\n",
      "Recompensa por acortar distancias: +  0.3843294972611607\n",
      "Penalización por duración del episodio: -  0.43944757579332844\n",
      "Recompensa por acortar distancias: +  0.3843294972611607\n",
      "Penalización por duración del episodio: -  0.43983572124302045\n",
      "Step: 5490, Mean Reward (últimos 10 pasos): -0.05550622567534447\n",
      "Recompensa por acortar distancias: +  0.3873137725980578\n",
      "Penalización por duración del episodio: -  0.4402291222828674\n",
      "Recompensa por acortar distancias: +  0.3879730288743495\n",
      "Penalización por duración del episodio: -  0.4406055804116556\n",
      "Recompensa por acortar distancias: +  0.3899086382432714\n",
      "Penalización por duración del episodio: -  0.4409888952878624\n",
      "Recompensa por acortar distancias: +  0.3907784279935649\n",
      "Penalización por duración del episodio: -  0.4410990296551017\n",
      "Recompensa por acortar distancias: +  0.391388140289965\n",
      "Penalización por duración del episodio: -  0.4413844138109694\n",
      "Recompensa por acortar distancias: +  0.39217920695255165\n",
      "Penalización por duración del episodio: -  0.4417622384960045\n",
      "Recompensa por acortar distancias: +  0.392842270777055\n",
      "Penalización por duración del episodio: -  0.4421491515484223\n",
      "Recompensa por acortar distancias: +  0.392842270777055\n",
      "Penalización por duración del episodio: -  0.4425440457866291\n",
      "Recompensa por acortar distancias: +  0.395945941893382\n",
      "Penalización por duración del episodio: -  0.44264273219009614\n",
      "Recompensa por acortar distancias: +  0.3968077366679659\n",
      "Penalización por duración del episodio: -  0.4429391362150475\n",
      "Step: 5500, Mean Reward (últimos 10 pasos): -0.046131398528814316\n",
      "Recompensa por acortar distancias: +  0.3968077366679659\n",
      "Penalización por duración del episodio: -  0.4433316746314229\n",
      "Recompensa por acortar distancias: +  0.3998359644427767\n",
      "Penalización por duración del episodio: -  0.44346742634269615\n",
      "steer input from model: 0.25 , throttle:  0.0\n",
      "reward: -0.043631461899919455\n",
      "Recompensa por acortar distancias: +  0.3998359644427767\n",
      "Penalización por duración del episodio: -  0.44359627794862116\n",
      "Recompensa por acortar distancias: +  0.4006518360663187\n",
      "Penalización por duración del episodio: -  0.44372539019652857\n",
      "Recompensa por acortar distancias: +  0.40128626797973516\n",
      "Penalización por duración del episodio: -  0.44411906462129297\n",
      "Recompensa por acortar distancias: +  0.4020072241342764\n",
      "Penalización por duración del episodio: -  0.4445075638543031\n",
      "Recompensa por acortar distancias: +  0.4020072241342764\n",
      "Penalización por duración del episodio: -  0.4448871045458887\n",
      "Recompensa por acortar distancias: +  0.4058913934480776\n",
      "Penalización por duración del episodio: -  0.4450335273776316\n",
      "Recompensa por acortar distancias: +  0.40688591707851235\n",
      "Penalización por duración del episodio: -  0.44514058748643676\n",
      "Recompensa por acortar distancias: +  0.40688591707851235\n",
      "Penalización por duración del episodio: -  0.44528235677733535\n",
      "Step: 5510, Mean Reward (últimos 10 pasos): -0.0383964404463768\n",
      "Recompensa por acortar distancias: +  0.40688591707851235\n",
      "Penalización por duración del episodio: -  0.4453871141878631\n",
      "Recompensa por acortar distancias: +  0.40688591707851235\n",
      "Penalización por duración del episodio: -  0.4456659922890388\n",
      "Recompensa por acortar distancias: +  0.40688591707851235\n",
      "Penalización por duración del episodio: -  0.4457910362104685\n",
      "Recompensa por acortar distancias: +  0.41000635202262514\n",
      "Penalización por duración del episodio: -  0.44604941566927525\n",
      "Recompensa por acortar distancias: +  0.41102256499320083\n",
      "Penalización por duración del episodio: -  0.4461558520811983\n",
      "Recompensa por acortar distancias: +  0.411854888472348\n",
      "Penalización por duración del episodio: -  0.44643859498852323\n",
      "Recompensa por acortar distancias: +  0.412507238913015\n",
      "Penalización por duración del episodio: -  0.4468315113491005\n",
      "Recompensa por acortar distancias: +  0.412507238913015\n",
      "Penalización por duración del episodio: -  0.4472065055400145\n",
      "Recompensa por acortar distancias: +  0.41705023761088517\n",
      "Penalización por duración del episodio: -  0.4475980893109656\n",
      "Recompensa por acortar distancias: +  0.41785558327942146\n",
      "Penalización por duración del episodio: -  0.4479728344004354\n",
      "Step: 5520, Mean Reward (últimos 10 pasos): -0.030117250978946686\n",
      "Recompensa por acortar distancias: +  0.4209041256969479\n",
      "Penalización por duración del episodio: -  0.4480746592692552\n",
      "Recompensa por acortar distancias: +  0.4209041256969479\n",
      "Penalización por duración del episodio: -  0.44835500377350695\n",
      "steer input from model: 0.9 , throttle:  0.0\n",
      "reward: -0.02745087807655905\n",
      "Recompensa por acortar distancias: +  0.42319154917171725\n",
      "Penalización por duración del episodio: -  0.44873026884557154\n",
      "Recompensa por acortar distancias: +  0.42499931365681326\n",
      "Penalización por duración del episodio: -  0.4491269929085016\n",
      "Recompensa por acortar distancias: +  0.4258144223370448\n",
      "Penalización por duración del episodio: -  0.449510702065063\n",
      "Recompensa por acortar distancias: +  0.4258144223370448\n",
      "Penalización por duración del episodio: -  0.4496122082901568\n",
      "Recompensa por acortar distancias: +  0.4258144223370448\n",
      "Penalización por duración del episodio: -  0.4498889011454436\n",
      "Recompensa por acortar distancias: +  0.43151356828668913\n",
      "Penalización por duración del episodio: -  0.45029885528937286\n",
      "Recompensa por acortar distancias: +  0.43276037613054297\n",
      "Penalización por duración del episodio: -  0.4506878167673473\n",
      "Recompensa por acortar distancias: +  0.4362047879728279\n",
      "Penalización por duración del episodio: -  0.45081535507205456\n",
      "Step: 5530, Mean Reward (últimos 10 pasos): -0.01461056713014841\n",
      "Recompensa por acortar distancias: +  0.4379315637590701\n",
      "Penalización por duración del episodio: -  0.45107703333701776\n",
      "Recompensa por acortar distancias: +  0.4389570155363834\n",
      "Penalización por duración del episodio: -  0.4512227334396851\n",
      "Recompensa por acortar distancias: +  0.43979789198192715\n",
      "Penalización por duración del episodio: -  0.4513219654300365\n",
      "Recompensa por acortar distancias: +  0.44098363204721924\n",
      "Penalización por duración del episodio: -  0.4514756385977681\n",
      "Recompensa por acortar distancias: +  0.44098363204721924\n",
      "Penalización por duración del episodio: -  0.4515899666233654\n",
      "Recompensa por acortar distancias: +  0.44098363204721924\n",
      "Penalización por duración del episodio: -  0.4517098148987122\n",
      "Recompensa por acortar distancias: +  0.44098363204721924\n",
      "Penalización por duración del episodio: -  0.4517851148631647\n",
      "Recompensa por acortar distancias: +  0.44098363204721924\n",
      "Penalización por duración del episodio: -  0.4522845820027698\n",
      "Recompensa por acortar distancias: +  0.44688105193796157\n",
      "Penalización por duración del episodio: -  0.45266737800914014\n",
      "Recompensa por acortar distancias: +  0.44808201181841517\n",
      "Penalización por duración del episodio: -  0.45304454070017347\n",
      "Step: 5540, Mean Reward (últimos 10 pasos): -0.004962529055774212\n",
      "Recompensa por acortar distancias: +  0.4533718643880244\n",
      "Penalización por duración del episodio: -  0.45315573558170774\n",
      "Recompensa por acortar distancias: +  0.4533718643880244\n",
      "Penalización por duración del episodio: -  0.4532794314215431\n",
      "steer input from model: 0.25 , throttle:  0.0\n",
      "reward: 9.243296648131505e-05\n",
      "Recompensa por acortar distancias: +  0.45472275121000805\n",
      "Penalización por duración del episodio: -  0.45339238513198965\n",
      "Recompensa por acortar distancias: +  0.45472275121000805\n",
      "Penalización por duración del episodio: -  0.453842918174043\n",
      "Recompensa por acortar distancias: +  0.4583760258671288\n",
      "Penalización por duración del episodio: -  0.4542377485295151\n",
      "Recompensa por acortar distancias: +  0.4583760258671288\n",
      "Penalización por duración del episodio: -  0.4546247624824516\n",
      "Recompensa por acortar distancias: +  0.4649313159330855\n",
      "Penalización por duración del episodio: -  0.4547645228091355\n",
      "Recompensa por acortar distancias: +  0.4649313159330855\n",
      "Penalización por duración del episodio: -  0.45500546382207957\n",
      "Recompensa por acortar distancias: +  0.46692848595165337\n",
      "Penalización por duración del episodio: -  0.4553845029922848\n",
      "Recompensa por acortar distancias: +  0.46692848595165337\n",
      "Penalización por duración del episodio: -  0.45577444572170933\n",
      "Step: 5550, Mean Reward (últimos 10 pasos): 0.011154040694236755\n",
      "Recompensa por acortar distancias: +  0.4744911305427438\n",
      "Penalización por duración del episodio: -  0.4559084563579458\n",
      "Recompensa por acortar distancias: +  0.4761125371553677\n",
      "Penalización por duración del episodio: -  0.45616075785555704\n",
      "Recompensa por acortar distancias: +  0.4775068658793588\n",
      "Penalización por duración del episodio: -  0.4565587998586749\n",
      "Recompensa por acortar distancias: +  0.47873190849293146\n",
      "Penalización por duración del episodio: -  0.4569469934934603\n",
      "Recompensa por acortar distancias: +  0.47873190849293146\n",
      "Penalización por duración del episodio: -  0.4573300679150079\n",
      "Recompensa por acortar distancias: +  0.48657639217524534\n",
      "Penalización por duración del episodio: -  0.4577355977978374\n",
      "Recompensa por acortar distancias: +  0.488298842304566\n",
      "Penalización por duración del episodio: -  0.4581204150836571\n",
      "Recompensa por acortar distancias: +  0.4951240893177587\n",
      "Penalización por duración del episodio: -  0.4584996707416445\n",
      "Recompensa por acortar distancias: +  0.49768637877935473\n",
      "Penalización por duración del episodio: -  0.45888230753646875\n",
      "Recompensa por acortar distancias: +  0.5002563893570294\n",
      "Penalización por duración del episodio: -  0.459272660404634\n",
      "Step: 5560, Mean Reward (últimos 10 pasos): 0.04098372906446457\n",
      "Recompensa por acortar distancias: +  0.5002563893570294\n",
      "Penalización por duración del episodio: -  0.459651060051512\n",
      "Recompensa por acortar distancias: +  0.5091663043656122\n",
      "Penalización por duración del episodio: -  0.46004107856627063\n",
      "steer input from model: -0.9 , throttle:  0.0\n",
      "reward: 0.04912522579934153\n",
      "Recompensa por acortar distancias: +  0.5109669140202138\n",
      "Penalización por duración del episodio: -  0.46043511452961006\n",
      "Recompensa por acortar distancias: +  0.5161730235694793\n",
      "Penalización por duración del episodio: -  0.4605563517569913\n",
      "Recompensa por acortar distancias: +  0.5161730235694793\n",
      "Penalización por duración del episodio: -  0.4606795365927435\n",
      "Recompensa por acortar distancias: +  0.5187554354073806\n",
      "Penalización por duración del episodio: -  0.46082141005677574\n",
      "Recompensa por acortar distancias: +  0.5202620525639948\n",
      "Penalización por duración del episodio: -  0.4610122591263462\n",
      "Recompensa por acortar distancias: +  0.5219502893277705\n",
      "Penalización por duración del episodio: -  0.46121057275411365\n",
      "Recompensa por acortar distancias: +  0.524314944193786\n",
      "Penalización por duración del episodio: -  0.46131100207847725\n",
      "Recompensa por acortar distancias: +  0.5257135616957423\n",
      "Penalización por duración del episodio: -  0.46146395976076693\n",
      "Step: 5570, Mean Reward (últimos 10 pasos): 0.06424960494041443\n",
      "Recompensa por acortar distancias: +  0.5257135616957423\n",
      "Penalización por duración del episodio: -  0.4615663404737483\n",
      "Recompensa por acortar distancias: +  0.5257135616957423\n",
      "Penalización por duración del episodio: -  0.46201010659866726\n",
      "Recompensa por acortar distancias: +  0.5257135616957423\n",
      "Penalización por duración del episodio: -  0.4621164987951009\n",
      "Recompensa por acortar distancias: +  0.5257135616957423\n",
      "Penalización por duración del episodio: -  0.4623793857943457\n",
      "Recompensa por acortar distancias: +  0.5351199762245029\n",
      "Penalización por duración del episodio: -  0.4627771222512397\n",
      "Recompensa por acortar distancias: +  0.5367518747540676\n",
      "Penalización por duración del episodio: -  0.4631875626711989\n",
      "Recompensa por acortar distancias: +  0.5439019898991757\n",
      "Penalización por duración del episodio: -  0.4635876656121638\n",
      "Recompensa por acortar distancias: +  0.5481136117073574\n",
      "Penalización por duración del episodio: -  0.4639676194695006\n",
      "Recompensa por acortar distancias: +  0.5494218136570406\n",
      "Penalización por duración del episodio: -  0.4643490799128345\n",
      "Recompensa por acortar distancias: +  0.5494218136570406\n",
      "Penalización por duración del episodio: -  0.4644736451819732\n",
      "Step: 5580, Mean Reward (últimos 10 pasos): 0.08494816720485687\n",
      "Recompensa por acortar distancias: +  0.5494218136570406\n",
      "Penalización por duración del episodio: -  0.46472875538588043\n",
      "Recompensa por acortar distancias: +  0.5494218136570406\n",
      "Penalización por duración del episodio: -  0.46483538691720855\n",
      "steer input from model: -0.1 , throttle:  0.0\n",
      "reward: 0.08458642673983202\n",
      "Recompensa por acortar distancias: +  0.5596871884160297\n",
      "Penalización por duración del episodio: -  0.4651356912197676\n",
      "Recompensa por acortar distancias: +  0.5624629643586182\n",
      "Penalización por duración del episodio: -  0.4652726102937076\n",
      "Recompensa por acortar distancias: +  0.5624629643586182\n",
      "Penalización por duración del episodio: -  0.46539707162183813\n",
      "Recompensa por acortar distancias: +  0.5624629643586182\n",
      "Penalización por duración del episodio: -  0.4658997653870493\n",
      "Recompensa por acortar distancias: +  0.5695103507251515\n",
      "Penalización por duración del episodio: -  0.4660868532150645\n",
      "Recompensa por acortar distancias: +  0.5695103507251515\n",
      "Penalización por duración del episodio: -  0.4662475947564594\n",
      "Recompensa por acortar distancias: +  0.57365894916209\n",
      "Penalización por duración del episodio: -  0.46637957751316006\n",
      "Recompensa por acortar distancias: +  0.57365894916209\n",
      "Penalización por duración del episodio: -  0.4665236519968819\n",
      "Step: 5590, Mean Reward (últimos 10 pasos): 0.10713529586791992\n",
      "Recompensa por acortar distancias: +  0.5755952936172417\n",
      "Penalización por duración del episodio: -  0.4666878126910506\n",
      "Recompensa por acortar distancias: +  0.5755952936172417\n",
      "Penalización por duración del episodio: -  0.4667914752982541\n",
      "Recompensa por acortar distancias: +  0.5755952936172417\n",
      "Penalización por duración del episodio: -  0.46708213038962765\n",
      "Recompensa por acortar distancias: +  0.5755952936172417\n",
      "Penalización por duración del episodio: -  0.467482839934493\n",
      "Recompensa por acortar distancias: +  0.5755952936172417\n",
      "Penalización por duración del episodio: -  0.46787148227000885\n",
      "Recompensa por acortar distancias: +  0.5871499386227057\n",
      "Penalización por duración del episodio: -  0.4682551888542544\n",
      "Recompensa por acortar distancias: +  0.5871499386227057\n",
      "Penalización por duración del episodio: -  0.4686420617924616\n",
      "Recompensa por acortar distancias: +  0.595089978622899\n",
      "Penalización por duración del episodio: -  0.4687629294888935\n",
      "Recompensa por acortar distancias: +  0.596653557935557\n",
      "Penalización por duración del episodio: -  0.468864160044443\n",
      "Recompensa por acortar distancias: +  0.596653557935557\n",
      "Penalización por duración del episodio: -  0.4690048539899347\n",
      "Step: 5600, Mean Reward (últimos 10 pasos): 0.1276487112045288\n",
      "Recompensa por acortar distancias: +  0.596653557935557\n",
      "Penalización por duración del episodio: -  0.46942140123214376\n",
      "Recompensa por acortar distancias: +  0.596653557935557\n",
      "Penalización por duración del episodio: -  0.4698084279707784\n",
      "steer input from model: 0.1 , throttle:  0.0\n",
      "reward: 0.1268451299647786\n",
      "Recompensa por acortar distancias: +  0.596653557935557\n",
      "Penalización por duración del episodio: -  0.4699205111784176\n",
      "Recompensa por acortar distancias: +  0.606167803031512\n",
      "Penalización por duración del episodio: -  0.4700630411193878\n",
      "Recompensa por acortar distancias: +  0.606167803031512\n",
      "Penalización por duración del episodio: -  0.4701757963998531\n",
      "Recompensa por acortar distancias: +  0.6095252804362153\n",
      "Penalización por duración del episodio: -  0.47033419345779043\n",
      "Recompensa por acortar distancias: +  0.6095252804362153\n",
      "Penalización por duración del episodio: -  0.4704546538220932\n",
      "Recompensa por acortar distancias: +  0.6095252804362153\n",
      "Penalización por duración del episodio: -  0.47056857788973616\n",
      "Recompensa por acortar distancias: +  0.6095252804362153\n",
      "Penalización por duración del episodio: -  0.47066812437599054\n",
      "Recompensa por acortar distancias: +  0.6095252804362153\n",
      "Penalización por duración del episodio: -  0.4709818426021301\n",
      "Step: 5610, Mean Reward (últimos 10 pasos): 0.13854344189167023\n",
      "Recompensa por acortar distancias: +  0.6155500841517536\n",
      "Penalización por duración del episodio: -  0.4711211707278809\n",
      "Recompensa por acortar distancias: +  0.6155500841517536\n",
      "Penalización por duración del episodio: -  0.4712677867463288\n",
      "Recompensa por acortar distancias: +  0.6178196411359691\n",
      "Penalización por duración del episodio: -  0.4713851960096863\n",
      "Recompensa por acortar distancias: +  0.6199619892093998\n",
      "Penalización por duración del episodio: -  0.4715262303263523\n",
      "Recompensa por acortar distancias: +  0.6199619892093998\n",
      "Penalización por duración del episodio: -  0.4717521359014126\n",
      "Recompensa por acortar distancias: +  0.6199619892093998\n",
      "Penalización por duración del episodio: -  0.4721320359814245\n",
      "Recompensa por acortar distancias: +  0.6199619892093998\n",
      "Penalización por duración del episodio: -  0.47253063361370934\n",
      "Recompensa por acortar distancias: +  0.6293156726948802\n",
      "Penalización por duración del episodio: -  0.472630064180614\n",
      "Recompensa por acortar distancias: +  0.6308750943585099\n",
      "Penalización por duración del episodio: -  0.4729170177780459\n",
      "Recompensa por acortar distancias: +  0.6308750943585099\n",
      "Penalización por duración del episodio: -  0.47301002630318456\n",
      "Step: 5620, Mean Reward (últimos 10 pasos): 0.15786506235599518\n",
      "Recompensa por acortar distancias: +  0.6308750943585099\n",
      "Penalización por duración del episodio: -  0.47311193964802\n",
      "Recompensa por acortar distancias: +  0.6308750943585099\n",
      "Penalización por duración del episodio: -  0.47329530966716016\n",
      "steer input from model: -0.05 , throttle:  1.0\n",
      "reward: 0.1575797846913497\n",
      "Recompensa por acortar distancias: +  0.6308750943585099\n",
      "Penalización por duración del episodio: -  0.47343292660884995\n",
      "Recompensa por acortar distancias: +  0.6368297968114203\n",
      "Penalización por duración del episodio: -  0.4736864295393466\n",
      "Recompensa por acortar distancias: +  0.6391370541837426\n",
      "Penalización por duración del episodio: -  0.4737935586730403\n",
      "Recompensa por acortar distancias: +  0.6404853515740951\n",
      "Penalización por duración del episodio: -  0.4740736583750734\n",
      "Recompensa por acortar distancias: +  0.6404853515740951\n",
      "Penalización por duración del episodio: -  0.47447018058201396\n",
      "Recompensa por acortar distancias: +  0.6404853515740951\n",
      "Penalización por duración del episodio: -  0.4748539583311053\n",
      "Recompensa por acortar distancias: +  0.6494270924458849\n",
      "Penalización por duración del episodio: -  0.4749570405506375\n",
      "Recompensa por acortar distancias: +  0.6494270924458849\n",
      "Penalización por duración del episodio: -  0.4750907925832658\n",
      "Step: 5630, Mean Reward (últimos 10 pasos): 0.1743362993001938\n",
      "Recompensa por acortar distancias: +  0.6516972455944879\n",
      "Penalización por duración del episodio: -  0.4752364458092699\n",
      "Recompensa por acortar distancias: +  0.6516972455944879\n",
      "Penalización por duración del episodio: -  0.47533648562444336\n",
      "Recompensa por acortar distancias: +  0.6516972455944879\n",
      "Penalización por duración del episodio: -  0.4754804394034833\n",
      "Recompensa por acortar distancias: +  0.6516972455944879\n",
      "Penalización por duración del episodio: -  0.4756325615314905\n",
      "Recompensa por acortar distancias: +  0.6516972455944879\n",
      "Penalización por duración del episodio: -  0.4760390790838604\n",
      "Recompensa por acortar distancias: +  0.6593948240544462\n",
      "Penalización por duración del episodio: -  0.47618152416076304\n",
      "Recompensa por acortar distancias: +  0.6610521270379031\n",
      "Penalización por duración del episodio: -  0.47642161944864375\n",
      "Recompensa por acortar distancias: +  0.6610521270379031\n",
      "Penalización por duración del episodio: -  0.4768172544532816\n",
      "Recompensa por acortar distancias: +  0.6610521270379031\n",
      "Penalización por duración del episodio: -  0.4769273525440722\n",
      "Recompensa por acortar distancias: +  0.6610521270379031\n",
      "Penalización por duración del episodio: -  0.47721493495345546\n",
      "Step: 5640, Mean Reward (últimos 10 pasos): 0.1838371902704239\n",
      "Recompensa por acortar distancias: +  0.6696729401603541\n",
      "Penalización por duración del episodio: -  0.4776123290720504\n",
      "Recompensa por acortar distancias: +  0.6714330551557336\n",
      "Penalización por duración del episodio: -  0.4780036419803393\n",
      "steer input from model: 0.05 , throttle:  0.0\n",
      "reward: 0.1934294131753943\n",
      "Recompensa por acortar distancias: +  0.6714330551557336\n",
      "Penalización por duración del episodio: -  0.4781280770872787\n",
      "Recompensa por acortar distancias: +  0.6768354841165802\n",
      "Penalización por duración del episodio: -  0.4782402714921539\n",
      "Recompensa por acortar distancias: +  0.6768354841165802\n",
      "Penalización por duración del episodio: -  0.4783463522237137\n",
      "Recompensa por acortar distancias: +  0.6768354841165802\n",
      "Penalización por duración del episodio: -  0.47878860921755445\n",
      "Recompensa por acortar distancias: +  0.6830662792774862\n",
      "Penalización por duración del episodio: -  0.47919762019841505\n",
      "Recompensa por acortar distancias: +  0.6830662792774862\n",
      "Penalización por duración del episodio: -  0.4795808872965816\n",
      "Recompensa por acortar distancias: +  0.6830662792774862\n",
      "Penalización por duración del episodio: -  0.47973685846235975\n",
      "Recompensa por acortar distancias: +  0.6830662792774862\n",
      "Penalización por duración del episodio: -  0.4798391097605436\n",
      "Step: 5650, Mean Reward (últimos 10 pasos): 0.20322716236114502\n",
      "Recompensa por acortar distancias: +  0.692023949280544\n",
      "Penalización por duración del episodio: -  0.48035511671830733\n",
      "Recompensa por acortar distancias: +  0.6939340825788138\n",
      "Penalización por duración del episodio: -  0.48073440198278056\n",
      "Recompensa por acortar distancias: +  0.6939340825788138\n",
      "Penalización por duración del episodio: -  0.48083949050410235\n",
      "Recompensa por acortar distancias: +  0.699736967275374\n",
      "Penalización por duración del episodio: -  0.4811412432790702\n",
      "Recompensa por acortar distancias: +  0.7019499271774198\n",
      "Penalización por duración del episodio: -  0.48130207976783584\n",
      "Recompensa por acortar distancias: +  0.7036178144534562\n",
      "Penalización por duración del episodio: -  0.4814271054071194\n",
      "Recompensa por acortar distancias: +  0.7036178144534562\n",
      "Penalización por duración del episodio: -  0.48155917500655576\n",
      "Recompensa por acortar distancias: +  0.7036178144534562\n",
      "Penalización por duración del episodio: -  0.4819356898256572\n",
      "Recompensa por acortar distancias: +  0.7036178144534562\n",
      "Penalización por duración del episodio: -  0.4823264111855819\n",
      "Recompensa por acortar distancias: +  0.7036178144534562\n",
      "Penalización por duración del episodio: -  0.4824392039036408\n",
      "Step: 5660, Mean Reward (últimos 10 pasos): 0.22117860615253448\n",
      "Recompensa por acortar distancias: +  0.7122196646904799\n",
      "Penalización por duración del episodio: -  0.48255321881861307\n",
      "Recompensa por acortar distancias: +  0.7122196646904799\n",
      "Penalización por duración del episodio: -  0.48272286341673987\n",
      "steer input from model: -0.9 , throttle:  0.0\n",
      "reward: 0.22949680127374006\n",
      "Recompensa por acortar distancias: +  0.7146944663125833\n",
      "Penalización por duración del episodio: -  0.4830886581984177\n",
      "Recompensa por acortar distancias: +  0.7146944663125833\n",
      "Penalización por duración del episodio: -  0.48347509557264284\n",
      "Recompensa por acortar distancias: +  0.7211994434467718\n",
      "Penalización por duración del episodio: -  0.48356266683349025\n",
      "Recompensa por acortar distancias: +  0.7224607742433518\n",
      "Penalización por duración del episodio: -  0.48369125099407034\n",
      "Recompensa por acortar distancias: +  0.7224607742433518\n",
      "Penalización por duración del episodio: -  0.4842602717147381\n",
      "Recompensa por acortar distancias: +  0.7224607742433518\n",
      "Penalización por duración del episodio: -  0.4846408722938537\n",
      "Recompensa por acortar distancias: +  0.7297124401462153\n",
      "Penalización por duración del episodio: -  0.48480310757081874\n",
      "Recompensa por acortar distancias: +  0.731782728640871\n",
      "Penalización por duración del episodio: -  0.4850192277460548\n",
      "Step: 5670, Mean Reward (últimos 10 pasos): 0.24676349759101868\n",
      "Recompensa por acortar distancias: +  0.731782728640871\n",
      "Penalización por parar muy lejos: -  0.047592685328225165\n",
      "Penalización por duración del episodio: -  0.4854191826975602\n",
      "Recompensa por acortar distancias: +  0.731782728640871\n",
      "Penalización por duración del episodio: -  0.4855527989942838\n",
      "Recompensa por acortar distancias: +  0.7365877275803334\n",
      "Penalización por parar muy lejos: -  0.04872124140903442\n",
      "Penalización por duración del episodio: -  0.4857978767419866\n",
      "Recompensa por acortar distancias: +  0.7389894834075407\n",
      "Penalización por parar muy lejos: -  0.049299881155572975\n",
      "Penalización por duración del episodio: -  0.48592288088248686\n",
      "Recompensa por acortar distancias: +  0.7389894834075407\n",
      "Penalización por parar muy lejos: -  0.049299881155572975\n",
      "Penalización por duración del episodio: -  0.4860567430979199\n",
      "Recompensa por acortar distancias: +  0.7407290312240501\n",
      "Penalización por parar muy lejos: -  0.04972522416204836\n",
      "Penalización por duración del episodio: -  0.48615321613882884\n",
      "Recompensa por acortar distancias: +  0.7407290312240501\n",
      "Penalización por parar muy lejos: -  0.04972522416204836\n",
      "Penalización por duración del episodio: -  0.4865581901426219\n",
      "Recompensa por acortar distancias: +  0.7421324046441949\n",
      "Penalización por duración del episodio: -  0.4869552299888337\n",
      "Recompensa por acortar distancias: +  0.7421324046441949\n",
      "Penalización por duración del episodio: -  0.48733452358184326\n",
      "Recompensa por acortar distancias: +  0.7498083109210417\n",
      "Penalización por parar muy lejos: -  0.052034566942318734\n",
      "Penalización por duración del episodio: -  0.487717656069987\n",
      "Step: 5680, Mean Reward (últimos 10 pasos): 0.21005608141422272\n",
      "Recompensa por acortar distancias: +  0.7513970649866544\n",
      "Penalización por duración del episodio: -  0.4881025424608756\n",
      "Recompensa por acortar distancias: +  0.7513970649866544\n",
      "Penalización por duración del episodio: -  0.48821545970086055\n",
      "steer input from model: 0.05 , throttle:  1.0\n",
      "reward: 0.2631816052857938\n",
      "Recompensa por acortar distancias: +  0.7560039941979767\n",
      "Penalización por duración del episodio: -  0.4883417818892689\n",
      "Recompensa por acortar distancias: +  0.7560039941979767\n",
      "Penalización por parar muy lejos: -  0.053702106171753854\n",
      "Penalización por duración del episodio: -  0.4884745513606664\n",
      "Recompensa por acortar distancias: +  0.75752528669236\n",
      "Penalización por parar muy lejos: -  0.05412365497573797\n",
      "Penalización por duración del episodio: -  0.4888823657363574\n",
      "Recompensa por acortar distancias: +  0.7589098498244535\n",
      "Penalización por duración del episodio: -  0.4892630336533244\n",
      "Recompensa por acortar distancias: +  0.7589098498244535\n",
      "Penalización por parar muy lejos: -  0.05451160830143567\n",
      "Penalización por duración del episodio: -  0.4896555285595321\n",
      "Recompensa por acortar distancias: +  0.7589098498244535\n",
      "Penalización por duración del episodio: -  0.48976183011311747\n",
      "Recompensa por acortar distancias: +  0.7667496281322246\n",
      "Penalización por parar muy lejos: -  0.05678874560191448\n",
      "Penalización por duración del episodio: -  0.4898859470763144\n",
      "Recompensa por acortar distancias: +  0.7667496281322246\n",
      "Penalización por duración del episodio: -  0.4900708617341964\n",
      "Step: 5690, Mean Reward (últimos 10 pasos): 0.27667877078056335\n",
      "Recompensa por acortar distancias: +  0.7688412308034628\n",
      "Penalización por duración del episodio: -  0.4902175036852013\n",
      "Recompensa por acortar distancias: +  0.7688412308034628\n",
      "Penalización por parar muy lejos: -  0.05742042329642563\n",
      "Penalización por duración del episodio: -  0.49032003846444916\n",
      "Recompensa por acortar distancias: +  0.7688412308034628\n",
      "Penalización por duración del episodio: -  0.490829804759742\n",
      "Recompensa por acortar distancias: +  0.7739273711736216\n",
      "Penalización por parar muy lejos: -  0.05900152207400824\n",
      "Penalización por duración del episodio: -  0.49096723731899633\n",
      "Recompensa por acortar distancias: +  0.7739273711736216\n",
      "Penalización por duración del episodio: -  0.49113152062143184\n",
      "Recompensa por acortar distancias: +  0.7739273711736216\n",
      "Penalización por duración del episodio: -  0.49129072906346\n",
      "Recompensa por acortar distancias: +  0.7769321808651752\n",
      "Penalización por parar muy lejos: -  0.05996687522037176\n",
      "Penalización por duración del episodio: -  0.4916064101738268\n",
      "Recompensa por acortar distancias: +  0.7785262893845345\n",
      "Penalización por parar muy lejos: -  0.060488821685948636\n",
      "Penalización por duración del episodio: -  0.49170049372260627\n",
      "Recompensa por acortar distancias: +  0.7785262893845345\n",
      "Penalización por parar muy lejos: -  0.060488821685948636\n",
      "Penalización por duración del episodio: -  0.49198767590715997\n",
      "Recompensa por acortar distancias: +  0.7785262893845345\n",
      "Penalización por parar muy lejos: -  0.060488821685948636\n",
      "Penalización por duración del episodio: -  0.4923836281717129\n",
      "Step: 5700, Mean Reward (últimos 10 pasos): 0.22565384209156036\n",
      "Recompensa por acortar distancias: +  0.7785262893845345\n",
      "Penalización por parar muy lejos: -  0.060488821685948636\n",
      "Penalización por duración del episodio: -  0.49277987007477464\n",
      "Recompensa por acortar distancias: +  0.7872290835176528\n",
      "Penalización por parar muy lejos: -  0.0634650912161367\n",
      "Penalización por duración del episodio: -  0.49317844519717435\n",
      "steer input from model: 0.9 , throttle:  0.0\n",
      "reward: 0.23058554710434165\n",
      "Recompensa por acortar distancias: +  0.7872290835176528\n",
      "Penalización por parar muy lejos: -  0.0634650912161367\n",
      "Penalización por duración del episodio: -  0.49358171314341553\n",
      "Recompensa por acortar distancias: +  0.7929873242793243\n",
      "Penalización por duración del episodio: -  0.4939628256938768\n",
      "Recompensa por acortar distancias: +  0.7929873242793243\n",
      "Penalización por duración del episodio: -  0.49435478596067844\n",
      "Recompensa por acortar distancias: +  0.7929873242793243\n",
      "Penalización por duración del episodio: -  0.49475483466582765\n",
      "Recompensa por acortar distancias: +  0.8005365234277482\n",
      "Penalización por parar muy lejos: -  0.06847533968675808\n",
      "Penalización por duración del episodio: -  0.4951572800092059\n",
      "Recompensa por acortar distancias: +  0.8005365234277482\n",
      "Penalización por duración del episodio: -  0.49527203823963545\n",
      "Recompensa por acortar distancias: +  0.8005365234277482\n",
      "Penalización por duración del episodio: -  0.4955492599197412\n",
      "Recompensa por acortar distancias: +  0.8050546288037976\n",
      "Penalización por parar muy lejos: -  0.07031836256222856\n",
      "Penalización por duración del episodio: -  0.4956835686617286\n",
      "Step: 5710, Mean Reward (últimos 10 pasos): 0.2390526980161667\n",
      "Recompensa por acortar distancias: +  0.8064610339001399\n",
      "Penalización por duración del episodio: -  0.4959373891354129\n",
      "Recompensa por acortar distancias: +  0.8079822916526124\n",
      "Penalización por duración del episodio: -  0.49607003079771456\n",
      "Recompensa por acortar distancias: +  0.8079822916526124\n",
      "Penalización por duración del episodio: -  0.4962101291250188\n",
      "Recompensa por acortar distancias: +  0.8093144860927346\n",
      "Penalización por duración del episodio: -  0.4963381885528592\n",
      "Recompensa por acortar distancias: +  0.8093144860927346\n",
      "Penalización por parar muy lejos: -  0.07212890368126391\n",
      "Penalización por duración del episodio: -  0.49671415052536155\n",
      "Recompensa por acortar distancias: +  0.8093144860927346\n",
      "Penalización por duración del episodio: -  0.4968552408048282\n",
      "Recompensa por acortar distancias: +  0.8093144860927346\n",
      "Penalización por duración del episodio: -  0.49709781091333455\n",
      "Recompensa por acortar distancias: +  0.8093144860927346\n",
      "Penalización por parar muy lejos: -  0.07212890368126391\n",
      "Penalización por duración del episodio: -  0.4973322108231464\n",
      "Recompensa por acortar distancias: +  0.8169637782082019\n",
      "Penalización por parar muy lejos: -  0.07557200110821519\n",
      "Penalización por duración del episodio: -  0.4974974781626108\n",
      "Recompensa por acortar distancias: +  0.8169637782082019\n",
      "Penalización por duración del episodio: -  0.4978908723521465\n",
      "Step: 5720, Mean Reward (últimos 10 pasos): 0.3190729022026062\n",
      "Recompensa por acortar distancias: +  0.8186473986776112\n",
      "Penalización por duración del episodio: -  0.4982845969746846\n",
      "Recompensa por acortar distancias: +  0.8229391326598817\n",
      "Penalización por duración del episodio: -  0.498678144911936\n",
      "steer input from model: 0.0 , throttle:  1.0\n",
      "reward: 0.3242609877479457\n",
      "Recompensa por acortar distancias: +  0.8252758309094101\n",
      "Penalización por duración del episodio: -  0.49876681816285423\n",
      "Recompensa por acortar distancias: +  0.8252758309094101\n",
      "Penalización por duración del episodio: -  0.4990651022362099\n",
      "Recompensa por acortar distancias: +  0.8252758309094101\n",
      "Penalización por parar muy lejos: -  0.07962222979740975\n",
      "Penalización por duración del episodio: -  0.4994677903277965\n",
      "Recompensa por acortar distancias: +  0.8252758309094101\n",
      "Penalización por duración del episodio: -  0.4998805940173913\n",
      "Penalización por duración del episodio\n",
      "Recompensa por acortar distancias: +  0.9156937566765231\n",
      "Penalización por duración del episodio: -  0.2693058314214174\n",
      "Recompensa por acortar distancias: +  0.9156937566765231\n",
      "Penalización por duración del episodio: -  0.26960749564993813\n",
      "Recompensa por acortar distancias: +  0.915693992267962\n",
      "Penalización por parar muy lejos: -  0.16592729154691657\n",
      "Penalización por duración del episodio: -  0.26992075224804374\n",
      "Step: 5730, Mean Reward (últimos 10 pasos): 0.47984594106674194\n",
      "Recompensa por acortar distancias: +  0.9156940217168499\n",
      "Penalización por duración del episodio: -  0.27001724865622323\n",
      "Recompensa por acortar distancias: +  0.9156940217168499\n",
      "Penalización por parar muy lejos: -  0.16592734434058842\n",
      "Penalización por duración del episodio: -  0.2700766440335273\n",
      "Recompensa por acortar distancias: +  0.9156940217168499\n",
      "Penalización por parar muy lejos: -  0.16592734434058842\n",
      "Penalización por duración del episodio: -  0.2702191456486082\n",
      "Recompensa por acortar distancias: +  0.9156940217168499\n",
      "Penalización por duración del episodio: -  0.2705287374831402\n",
      "Recompensa por acortar distancias: +  0.9156940217168499\n",
      "Penalización por duración del episodio: -  0.27061460330164694\n",
      "Recompensa por acortar distancias: +  0.9156940217168499\n",
      "Penalización por duración del episodio: -  0.270843595117835\n",
      "Recompensa por acortar distancias: +  0.9156941027012433\n",
      "Penalización por duración del episodio: -  0.27115497944405426\n",
      "Recompensa por acortar distancias: +  0.915694146874519\n",
      "Penalización por duración del episodio: -  0.27145928931574864\n",
      "Recompensa por acortar distancias: +  0.915694146874519\n",
      "Penalización por parar muy lejos: -  0.16592756871384384\n",
      "Penalización por duración del episodio: -  0.2717650024280486\n",
      "Recompensa por acortar distancias: +  0.9156945297086951\n",
      "Penalización por parar muy lejos: -  0.16592825503354564\n",
      "Penalización por duración del episodio: -  0.27187955946386483\n",
      "Step: 5740, Mean Reward (últimos 10 pasos): 0.47788670659065247\n",
      "Recompensa por acortar distancias: +  0.9156946622278497\n",
      "Penalización por parar muy lejos: -  0.16592849260627995\n",
      "Penalización por duración del episodio: -  0.2719774960851251\n",
      "Recompensa por acortar distancias: +  0.9156947505738479\n",
      "Penalización por duración del episodio: -  0.27238426742356897\n",
      "Recompensa por acortar distancias: +  0.9156947505738479\n",
      "Penalización por parar muy lejos: -  0.1659286509882542\n",
      "Penalización por duración del episodio: -  0.2727000564625675\n",
      "Recompensa por acortar distancias: +  0.9156947505738479\n",
      "Penalización por parar muy lejos: -  0.1659286509882542\n",
      "Penalización por duración del episodio: -  0.27300321733678756\n",
      "Recompensa por acortar distancias: +  0.915695133405535\n",
      "Penalización por duración del episodio: -  0.27331527782745446\n",
      "Recompensa por acortar distancias: +  0.91569522911321\n",
      "Penalización por parar muy lejos: -  0.16592950889271932\n",
      "Penalización por duración del episodio: -  0.27362491657945204\n",
      "Recompensa por acortar distancias: +  0.9156954058040434\n",
      "Penalización por parar muy lejos: -  0.1659298256583431\n",
      "Penalización por duración del episodio: -  0.27393122213091975\n",
      "steer input from model: 0.1 , throttle:  0.0\n",
      "reward: 0.4758343580147805\n",
      "Recompensa por acortar distancias: +  0.9156954573388064\n",
      "Penalización por duración del episodio: -  0.2740482222437895\n",
      "Recompensa por acortar distancias: +  0.915695685563842\n",
      "Penalización por parar muy lejos: -  0.16593032720490475\n",
      "Penalización por duración del episodio: -  0.2741495257294556\n",
      "Recompensa por acortar distancias: +  0.915695685563842\n",
      "Penalización por parar muy lejos: -  0.16593032720490475\n",
      "Penalización por duración del episodio: -  0.27425462039484105\n",
      "Step: 5750, Mean Reward (últimos 10 pasos): 0.47551074624061584\n",
      "Recompensa por acortar distancias: +  0.915695685563842\n",
      "Penalización por duración del episodio: -  0.27436404055267866\n",
      "Recompensa por acortar distancias: +  0.915695685563842\n",
      "Penalización por duración del episodio: -  0.2744831830003957\n",
      "Recompensa por acortar distancias: +  0.915695685563842\n",
      "Penalización por duración del episodio: -  0.27485369022699\n",
      "Recompensa por acortar distancias: +  0.915695685563842\n",
      "Penalización por parar muy lejos: -  0.16593032720490475\n",
      "Penalización por duración del episodio: -  0.27496363433588045\n",
      "Recompensa por acortar distancias: +  0.915695685563842\n",
      "Penalización por duración del episodio: -  0.27504606041429236\n",
      "Recompensa por acortar distancias: +  0.915695685563842\n",
      "Penalización por duración del episodio: -  0.2751556718631652\n",
      "Recompensa por acortar distancias: +  0.915695685563842\n",
      "Penalización por duración del episodio: -  0.2752750229101403\n",
      "Recompensa por acortar distancias: +  0.9156961052019593\n",
      "Penalización por parar muy lejos: -  0.16593107952702424\n",
      "Penalización por duración del episodio: -  0.27538660825856626\n",
      "Recompensa por acortar distancias: +  0.9156961052019593\n",
      "Penalización por duración del episodio: -  0.2754733290072595\n",
      "Recompensa por acortar distancias: +  0.9156961493742826\n",
      "Penalización por parar muy lejos: -  0.16593115871898523\n",
      "Penalización por duración del episodio: -  0.27577783248021726\n",
      "Step: 5760, Mean Reward (últimos 10 pasos): 0.4739871621131897\n",
      "Recompensa por acortar distancias: +  0.9156961493742826\n",
      "Penalización por duración del episodio: -  0.27587744621331634\n",
      "Recompensa por acortar distancias: +  0.9156961493742826\n",
      "Penalización por duración del episodio: -  0.2759477468967357\n",
      "Recompensa por acortar distancias: +  0.9156961493742826\n",
      "Penalización por parar muy lejos: -  0.16593115871898523\n",
      "Penalización por duración del episodio: -  0.27607492502560327\n",
      "Recompensa por acortar distancias: +  0.9156961493742826\n",
      "Penalización por parar muy lejos: -  0.16593115871898523\n",
      "Penalización por duración del episodio: -  0.27641545991205424\n",
      "Recompensa por acortar distancias: +  0.9156965616482846\n",
      "Penalización por parar muy lejos: -  0.16593189784541454\n",
      "Penalización por duración del episodio: -  0.27672397122336995\n",
      "Recompensa por acortar distancias: +  0.9156965616482846\n",
      "Penalización por duración del episodio: -  0.27702849767248755\n",
      "Recompensa por acortar distancias: +  0.9156965616482846\n",
      "Penalización por parar muy lejos: -  0.16593189784541454\n",
      "Penalización por duración del episodio: -  0.2771214457546365\n",
      "steer input from model: -0.25 , throttle:  0.0\n",
      "reward: 0.4726432180482336\n",
      "Recompensa por acortar distancias: +  0.9156965616482846\n",
      "Penalización por duración del episodio: -  0.2772310616068002\n",
      "Recompensa por acortar distancias: +  0.9156965616482846\n",
      "Penalización por parar muy lejos: -  0.16593189784541454\n",
      "Penalización por duración del episodio: -  0.2773333358686795\n",
      "Recompensa por acortar distancias: +  0.9156965616482846\n",
      "Penalización por duración del episodio: -  0.27745335118663567\n",
      "Step: 5770, Mean Reward (últimos 10 pasos): 0.6382431983947754\n",
      "Recompensa por acortar distancias: +  0.9156965616482846\n",
      "Penalización por parar muy lejos: -  0.16593189784541454\n",
      "Penalización por duración del episodio: -  0.2775640805715182\n",
      "Recompensa por acortar distancias: +  0.9156964291318408\n",
      "Penalización por duración del episodio: -  0.2777342717475747\n",
      "Recompensa por acortar distancias: +  0.9156964291318408\n",
      "Penalización por duración del episodio: -  0.2778744053589658\n",
      "Recompensa por acortar distancias: +  0.9156964291318408\n",
      "Penalización por parar muy lejos: -  0.16593166026877465\n",
      "Penalización por duración del episodio: -  0.2779719017378643\n",
      "Recompensa por acortar distancias: +  0.9156966794405205\n",
      "Penalización por parar muy lejos: -  0.1659321090248788\n",
      "Penalización por duración del episodio: -  0.27807621557483725\n",
      "Recompensa por acortar distancias: +  0.9156966794405205\n",
      "Penalización por parar muy lejos: -  0.1659321090248788\n",
      "Penalización por duración del episodio: -  0.2782746155814081\n",
      "Recompensa por acortar distancias: +  0.9156966794405205\n",
      "Penalización por parar muy lejos: -  0.1659321090248788\n",
      "Penalización por duración del episodio: -  0.27835442521246206\n",
      "Recompensa por acortar distancias: +  0.9156966794405205\n",
      "Penalización por parar muy lejos: -  0.1659321090248788\n",
      "Penalización por duración del episodio: -  0.2785932053164425\n",
      "Recompensa por acortar distancias: +  0.9156968561285941\n",
      "Penalización por duración del episodio: -  0.27891533704581917\n",
      "Recompensa por acortar distancias: +  0.9156968561285941\n",
      "Penalización por duración del episodio: -  0.2792265742691017\n",
      "Step: 5780, Mean Reward (últimos 10 pasos): 0.6364702582359314\n",
      "Recompensa por acortar distancias: +  0.9156968561285941\n",
      "Penalización por duración del episodio: -  0.2793171672898196\n",
      "Recompensa por acortar distancias: +  0.9156968561285941\n",
      "Penalización por duración del episodio: -  0.27941814706935386\n",
      "Recompensa por acortar distancias: +  0.9156968561285941\n",
      "Penalización por duración del episodio: -  0.2795286706079908\n",
      "Recompensa por acortar distancias: +  0.9156968561285941\n",
      "Penalización por duración del episodio: -  0.2796181710144352\n",
      "Recompensa por acortar distancias: +  0.9156968561285941\n",
      "Penalización por parar muy lejos: -  0.16593242579447878\n",
      "Penalización por duración del episodio: -  0.2798811119568645\n",
      "Recompensa por acortar distancias: +  0.9156968561285941\n",
      "Penalización por parar muy lejos: -  0.16593242579447878\n",
      "Penalización por duración del episodio: -  0.28019122895502396\n",
      "Recompensa por acortar distancias: +  0.9156966941645394\n",
      "Penalización por duración del episodio: -  0.2802918102517964\n",
      "steer input from model: 0.25 , throttle:  0.7\n",
      "reward: 0.635404883912743\n",
      "Recompensa por acortar distancias: +  0.9156966941645394\n",
      "Penalización por duración del episodio: -  0.2803847839918133\n",
      "Recompensa por acortar distancias: +  0.9156966941645394\n",
      "Penalización por parar muy lejos: -  0.16593213542232693\n",
      "Penalización por duración del episodio: -  0.280485412506877\n",
      "Recompensa por acortar distancias: +  0.9156968561285941\n",
      "Penalización por duración del episodio: -  0.28083483883923344\n",
      "Step: 5790, Mean Reward (últimos 10 pasos): 0.6348620057106018\n",
      "Recompensa por acortar distancias: +  0.9156968561285941\n",
      "Penalización por duración del episodio: -  0.2809005718226169\n",
      "Recompensa por acortar distancias: +  0.9156968561285941\n",
      "Penalización por duración del episodio: -  0.28105239545016625\n",
      "Recompensa por acortar distancias: +  0.9156968561285941\n",
      "Penalización por duración del episodio: -  0.2811634336530465\n",
      "Recompensa por acortar distancias: +  0.9156969886444285\n",
      "Penalización por parar muy lejos: -  0.1659326633719967\n",
      "Penalización por duración del episodio: -  0.28126844487024916\n",
      "Recompensa por acortar distancias: +  0.9156969886444285\n",
      "Penalización por parar muy lejos: -  0.1659326633719967\n",
      "Penalización por duración del episodio: -  0.2813942921715869\n",
      "Recompensa por acortar distancias: +  0.9156971064361227\n",
      "Penalización por duración del episodio: -  0.2817555961272959\n",
      "Recompensa por acortar distancias: +  0.9156971064361227\n",
      "Penalización por parar muy lejos: -  0.16593287455224134\n",
      "Penalización por duración del episodio: -  0.28206885470169907\n",
      "Recompensa por acortar distancias: +  0.9156971064361227\n",
      "Penalización por parar muy lejos: -  0.16593287455224134\n",
      "Penalización por duración del episodio: -  0.2822009032194973\n",
      "Recompensa por acortar distancias: +  0.9156971064361227\n",
      "Penalización por duración del episodio: -  0.2822874992326822\n",
      "Recompensa por acortar distancias: +  0.9156971064361227\n",
      "Penalización por duración del episodio: -  0.28239896901373085\n",
      "Step: 5800, Mean Reward (últimos 10 pasos): 0.6332981586456299\n",
      "Recompensa por acortar distancias: +  0.9156971064361227\n",
      "Penalización por parar muy lejos: -  0.16593287455224134\n",
      "Penalización por duración del episodio: -  0.28269596223877413\n",
      "Recompensa por acortar distancias: +  0.9156971064361227\n",
      "Penalización por parar muy lejos: -  0.16593287455224134\n",
      "Penalización por duración del episodio: -  0.28279744725926637\n",
      "Recompensa por acortar distancias: +  0.9156969003005598\n",
      "Penalización por parar muy lejos: -  0.1659325049869545\n",
      "Penalización por duración del episodio: -  0.2828986254458492\n",
      "Recompensa por acortar distancias: +  0.9156969003005598\n",
      "Penalización por parar muy lejos: -  0.1659325049869545\n",
      "Penalización por duración del episodio: -  0.2830105316629786\n",
      "Recompensa por acortar distancias: +  0.9156969003005598\n",
      "Penalización por duración del episodio: -  0.2830915055028436\n",
      "Recompensa por acortar distancias: +  0.9156969003005598\n",
      "Penalización por duración del episodio: -  0.28321068388134246\n",
      "Recompensa por acortar distancias: +  0.9156969960064137\n",
      "Penalización por parar muy lejos: -  0.16593267657075564\n",
      "Penalización por duración del episodio: -  0.28331193214738964\n",
      "steer input from model: -0.1 , throttle:  0.0\n",
      "reward: 0.4664523872882685\n",
      "Recompensa por acortar distancias: +  0.9156969960064137\n",
      "Penalización por parar muy lejos: -  0.16593267657075564\n",
      "Penalización por duración del episodio: -  0.28344647318143656\n",
      "Recompensa por acortar distancias: +  0.9156969960064137\n",
      "Penalización por parar muy lejos: -  0.16593267657075564\n",
      "Penalización por duración del episodio: -  0.2835581229341111\n",
      "Recompensa por acortar distancias: +  0.9156969960064137\n",
      "Penalización por duración del episodio: -  0.28368011372461266\n",
      "Step: 5810, Mean Reward (últimos 10 pasos): 0.6320168972015381\n",
      "Recompensa por acortar distancias: +  0.9156969960064137\n",
      "Penalización por duración del episodio: -  0.28379492047989363\n",
      "Recompensa por acortar distancias: +  0.9156969960064137\n",
      "Penalización por duración del episodio: -  0.2839674934562347\n",
      "Recompensa por acortar distancias: +  0.9156969960064137\n",
      "Penalización por duración del episodio: -  0.284060390627251\n",
      "Recompensa por acortar distancias: +  0.9156969960064137\n",
      "Penalización por duración del episodio: -  0.28417452879374416\n",
      "Recompensa por acortar distancias: +  0.9156969960064137\n",
      "Penalización por parar muy lejos: -  0.16593267657075564\n",
      "Penalización por duración del episodio: -  0.28429687358634476\n",
      "Recompensa por acortar distancias: +  0.9156969960064137\n",
      "Penalización por parar muy lejos: -  0.16593267657075564\n",
      "Penalización por duración del episodio: -  0.28440869624354376\n",
      "Recompensa por acortar distancias: +  0.9156968561285941\n",
      "Penalización por parar muy lejos: -  0.16593242579447878\n",
      "Penalización por duración del episodio: -  0.2845254959476727\n",
      "Recompensa por acortar distancias: +  0.9156968561285941\n",
      "Penalización por parar muy lejos: -  0.16593242579447878\n",
      "Penalización por duración del episodio: -  0.28492524421846543\n",
      "Recompensa por acortar distancias: +  0.9156969518344935\n",
      "Penalización por duración del episodio: -  0.28503242974911336\n",
      "Recompensa por acortar distancias: +  0.9156969518344935\n",
      "Penalización por duración del episodio: -  0.2851368500028464\n",
      "Step: 5820, Mean Reward (últimos 10 pasos): 0.6305601000785828\n",
      "Recompensa por acortar distancias: +  0.9156969518344935\n",
      "Penalización por duración del episodio: -  0.28526967172150486\n",
      "Recompensa por acortar distancias: +  0.9156971358840228\n",
      "Penalización por parar muy lejos: -  0.16593292734733617\n",
      "Penalización por duración del episodio: -  0.2853713435742432\n",
      "Recompensa por acortar distancias: +  0.9156971653319136\n",
      "Penalización por duración del episodio: -  0.2855668968498938\n",
      "Recompensa por acortar distancias: +  0.9156971653319136\n",
      "Penalización por parar muy lejos: -  0.16593298014244443\n",
      "Penalización por duración del episodio: -  0.2856607896274404\n",
      "Recompensa por acortar distancias: +  0.9156971653319136\n",
      "Penalización por duración del episodio: -  0.28574224874609033\n",
      "Recompensa por acortar distancias: +  0.9156971653319136\n",
      "Penalización por duración del episodio: -  0.28589505500488593\n",
      "Recompensa por acortar distancias: +  0.9156971653319136\n",
      "Penalización por duración del episodio: -  0.28598542929212395\n",
      "steer input from model: 0.0 , throttle:  0.3\n",
      "reward: 0.6297117360397897\n",
      "Recompensa por acortar distancias: +  0.9156971653319136\n",
      "Penalización por duración del episodio: -  0.28606740649482404\n",
      "Recompensa por acortar distancias: +  0.9156971653319136\n",
      "Penalización por parar muy lejos: -  0.16593298014244443\n",
      "Penalización por duración del episodio: -  0.28621003470513673\n",
      "Recompensa por acortar distancias: +  0.9156971579699418\n",
      "Penalización por duración del episodio: -  0.2863019204003755\n",
      "Step: 5830, Mean Reward (últimos 10 pasos): 0.6293952465057373\n",
      "Recompensa por acortar distancias: +  0.9156971579699418\n",
      "Penalización por parar muy lejos: -  0.1659329669436661\n",
      "Penalización por duración del episodio: -  0.28644772769293897\n",
      "Recompensa por acortar distancias: +  0.9156971432459964\n",
      "Penalización por duración del episodio: -  0.2868217918070793\n",
      "Recompensa por acortar distancias: +  0.9156971432459964\n",
      "Penalización por parar muy lejos: -  0.16593294054611193\n",
      "Penalización por duración del episodio: -  0.287137172130908\n",
      "Recompensa por acortar distancias: +  0.9156971432459964\n",
      "Penalización por duración del episodio: -  0.28745937648450054\n",
      "Recompensa por acortar distancias: +  0.9156970475402941\n",
      "Penalización por parar muy lejos: -  0.16593276896209214\n",
      "Penalización por duración del episodio: -  0.2877838488554939\n",
      "Recompensa por acortar distancias: +  0.9156970475402941\n",
      "Penalización por duración del episodio: -  0.28809763967156804\n",
      "Recompensa por acortar distancias: +  0.9156972389515999\n",
      "Penalización por duración del episodio: -  0.2884134592026925\n",
      "Recompensa por acortar distancias: +  0.9156972389515999\n",
      "Penalización por parar muy lejos: -  0.16593311213027395\n",
      "Penalización por duración del episodio: -  0.28873195715571737\n",
      "Recompensa por acortar distancias: +  0.9156972389515999\n",
      "Penalización por duración del episodio: -  0.28882439344675903\n",
      "Recompensa por acortar distancias: +  0.9156971064361227\n",
      "Penalización por duración del episodio: -  0.2888990624004813\n",
      "Step: 5840, Mean Reward (últimos 10 pasos): 0.6267980337142944\n",
      "Recompensa por acortar distancias: +  0.9156971064361227\n",
      "Penalización por parar muy lejos: -  0.16593287455224134\n",
      "Penalización por duración del episodio: -  0.2890424965423021\n",
      "Recompensa por acortar distancias: +  0.9156971064361227\n",
      "Penalización por parar muy lejos: -  0.16593287455224134\n",
      "Penalización por duración del episodio: -  0.2891604498664255\n",
      "Recompensa por acortar distancias: +  0.9156971064361227\n",
      "Penalización por duración del episodio: -  0.28924096871622185\n",
      "Recompensa por acortar distancias: +  0.9156971064361227\n",
      "Penalización por parar muy lejos: -  0.16593287455224134\n",
      "Penalización por duración del episodio: -  0.28935785717820434\n",
      "Recompensa por acortar distancias: +  0.9156971064361227\n",
      "Penalización por duración del episodio: -  0.2896764976236408\n",
      "Recompensa por acortar distancias: +  0.915697018092366\n",
      "Penalización por duración del episodio: -  0.28975063963995484\n",
      "Recompensa por acortar distancias: +  0.9156969739204561\n",
      "Penalización por parar muy lejos: -  0.16593263697448127\n",
      "Penalización por duración del episodio: -  0.2899898624541488\n",
      "steer input from model: 0.05 , throttle:  0.0\n",
      "reward: 0.45977447449182607\n",
      "Recompensa por acortar distancias: +  0.9156970107303826\n",
      "Penalización por duración del episodio: -  0.29031277549954876\n",
      "Recompensa por acortar distancias: +  0.9156970917121691\n",
      "Penalización por parar muy lejos: -  0.16593284815469897\n",
      "Penalización por duración del episodio: -  0.2904056389895457\n",
      "Recompensa por acortar distancias: +  0.9156970917121691\n",
      "Penalización por duración del episodio: -  0.29062538700983515\n",
      "Step: 5850, Mean Reward (últimos 10 pasos): 0.6250717043876648\n",
      "Recompensa por acortar distancias: +  0.9156970917121691\n",
      "Penalización por parar muy lejos: -  0.16593284815469897\n",
      "Penalización por duración del episodio: -  0.29095020313403486\n",
      "Recompensa por acortar distancias: +  0.915697018092366\n",
      "Penalización por duración del episodio: -  0.29126534548867816\n",
      "Recompensa por acortar distancias: +  0.9156970475402941\n",
      "Penalización por duración del episodio: -  0.29158219581186623\n",
      "Recompensa por acortar distancias: +  0.9156970475402941\n",
      "Penalización por duración del episodio: -  0.2919057735330716\n",
      "Recompensa por acortar distancias: +  0.9156970475402941\n",
      "Penalización por parar muy lejos: -  0.16593276896209214\n",
      "Penalización por duración del episodio: -  0.2919842586996118\n",
      "Recompensa por acortar distancias: +  0.915696811956607\n",
      "Penalización por parar muy lejos: -  0.16593234660203335\n",
      "Penalización por duración del episodio: -  0.2920940256541745\n",
      "Recompensa por acortar distancias: +  0.915696811956607\n",
      "Penalización por duración del episodio: -  0.29220816106534253\n",
      "Recompensa por acortar distancias: +  0.9156969739204561\n",
      "Penalización por duración del episodio: -  0.2925678619101099\n",
      "Recompensa por acortar distancias: +  0.915697025454349\n",
      "Penalización por duración del episodio: -  0.29266101108109166\n",
      "Recompensa por acortar distancias: +  0.915697025454349\n",
      "Penalización por parar muy lejos: -  0.16593272936580003\n",
      "Penalización por duración del episodio: -  0.2929012656096791\n",
      "Step: 5860, Mean Reward (últimos 10 pasos): 0.45686301589012146\n",
      "Recompensa por acortar distancias: +  0.915697025454349\n",
      "Penalización por parar muy lejos: -  0.16593272936580003\n",
      "Penalización por duración del episodio: -  0.29300573758126625\n",
      "Recompensa por acortar distancias: +  0.915697025454349\n",
      "Penalización por duración del episodio: -  0.2932264078239029\n",
      "Recompensa por acortar distancias: +  0.915697025454349\n",
      "Penalización por duración del episodio: -  0.29332970718500534\n",
      "Recompensa por acortar distancias: +  0.9156969960064137\n",
      "Penalización por duración del episodio: -  0.2935572295589656\n",
      "Recompensa por acortar distancias: +  0.9156969297485253\n",
      "Penalización por duración del episodio: -  0.2936504541791979\n",
      "Recompensa por acortar distancias: +  0.9156969297485253\n",
      "Penalización por duración del episodio: -  0.293733358659164\n",
      "Recompensa por acortar distancias: +  0.9156969297485253\n",
      "Penalización por duración del episodio: -  0.2938266406836122\n",
      "steer input from model: 0.1 , throttle:  0.3\n",
      "reward: 0.6218702890649132\n",
      "Recompensa por acortar distancias: +  0.9156969297485253\n",
      "Penalización por duración del episodio: -  0.2939194501593749\n",
      "Recompensa por acortar distancias: +  0.9156969297485253\n",
      "Penalización por parar muy lejos: -  0.16593255778195506\n",
      "Penalización por duración del episodio: -  0.29419669405951887\n",
      "Recompensa por acortar distancias: +  0.9156969297485253\n",
      "Penalización por duración del episodio: -  0.2942751183322097\n",
      "Step: 5870, Mean Reward (últimos 10 pasos): 0.6214218139648438\n",
      "Recompensa por acortar distancias: +  0.9156970475402941\n",
      "Penalización por duración del episodio: -  0.2945210405627147\n",
      "Recompensa por acortar distancias: +  0.9156970475402941\n",
      "Penalización por parar muy lejos: -  0.16593276896209214\n",
      "Penalización por duración del episodio: -  0.29485037384333407\n",
      "Recompensa por acortar distancias: +  0.9156970475402941\n",
      "Penalización por duración del episodio: -  0.29493980190757735\n",
      "Recompensa por acortar distancias: +  0.9156970475402941\n",
      "Penalización por parar muy lejos: -  0.16593276896209214\n",
      "Penalización por duración del episodio: -  0.2950480448919498\n",
      "Recompensa por acortar distancias: +  0.9156970475402941\n",
      "Penalización por duración del episodio: -  0.2951348344621266\n",
      "Recompensa por acortar distancias: +  0.9156970475402941\n",
      "Penalización por parar muy lejos: -  0.16593276896209214\n",
      "Penalización por duración del episodio: -  0.2952202945291343\n",
      "Recompensa por acortar distancias: +  0.9156971653319136\n",
      "Penalización por parar muy lejos: -  0.16593298014244443\n",
      "Penalización por duración del episodio: -  0.29534218766801734\n",
      "Recompensa por acortar distancias: +  0.9156971653319136\n",
      "Penalización por duración del episodio: -  0.2955055183801951\n",
      "Recompensa por acortar distancias: +  0.9156972904853456\n",
      "Penalización por parar muy lejos: -  0.16593320452180466\n",
      "Penalización por duración del episodio: -  0.29562969908324876\n",
      "Recompensa por acortar distancias: +  0.9156972904853456\n",
      "Penalización por parar muy lejos: -  0.16593320452180466\n",
      "Penalización por duración del episodio: -  0.29573326240872627\n",
      "Step: 5880, Mean Reward (últimos 10 pasos): 0.4540308117866516\n",
      "Recompensa por acortar distancias: +  0.9156972904853456\n",
      "Penalización por duración del episodio: -  0.29613739913974096\n",
      "Recompensa por acortar distancias: +  0.9156970475402941\n",
      "Penalización por parar muy lejos: -  0.16593276896209214\n",
      "Penalización por duración del episodio: -  0.2962551872030282\n",
      "Recompensa por acortar distancias: +  0.915697194779795\n",
      "Penalización por parar muy lejos: -  0.16593303293756617\n",
      "Penalización por duración del episodio: -  0.2963674637374176\n",
      "Recompensa por acortar distancias: +  0.915697194779795\n",
      "Penalización por duración del episodio: -  0.2964832757924377\n",
      "Recompensa por acortar distancias: +  0.9156971358840228\n",
      "Penalización por duración del episodio: -  0.29655708476466036\n",
      "Recompensa por acortar distancias: +  0.9156971358840228\n",
      "Penalización por parar muy lejos: -  0.16593292734733617\n",
      "Penalización por duración del episodio: -  0.29678389959073853\n",
      "Recompensa por acortar distancias: +  0.9156971358840228\n",
      "Penalización por parar muy lejos: -  0.16593292734733617\n",
      "Penalización por duración del episodio: -  0.29710786629765307\n",
      "steer input from model: -0.25 , throttle:  0.0\n",
      "reward: 0.4526563422390336\n",
      "Recompensa por acortar distancias: +  0.9156971358840228\n",
      "Penalización por duración del episodio: -  0.2974305175173103\n",
      "Recompensa por acortar distancias: +  0.9156970917121691\n",
      "Penalización por parar muy lejos: -  0.16593284815469897\n",
      "Penalización por duración del episodio: -  0.29753049360722067\n",
      "Recompensa por acortar distancias: +  0.9156972242276673\n",
      "Penalización por parar muy lejos: -  0.16593308573270132\n",
      "Penalización por duración del episodio: -  0.2976323630756653\n",
      "Step: 5890, Mean Reward (últimos 10 pasos): 0.4521317780017853\n",
      "Recompensa por acortar distancias: +  0.9156972242276673\n",
      "Penalización por parar muy lejos: -  0.16593308573270132\n",
      "Penalización por duración del episodio: -  0.29808198270380265\n",
      "Recompensa por acortar distancias: +  0.9156972242276673\n",
      "Penalización por parar muy lejos: -  0.16593308573270132\n",
      "Penalización por duración del episodio: -  0.29820104480352455\n",
      "Recompensa por acortar distancias: +  0.9156969812824427\n",
      "Penalización por duración del episodio: -  0.2983921850289528\n",
      "Recompensa por acortar distancias: +  0.9156971358840228\n",
      "Penalización por parar muy lejos: -  0.16593292734733617\n",
      "Penalización por duración del episodio: -  0.29872319997984975\n",
      "Recompensa por acortar distancias: +  0.9156971653319136\n",
      "Penalización por parar muy lejos: -  0.16593298014244443\n",
      "Penalización por duración del episodio: -  0.29880675593307515\n",
      "Recompensa por acortar distancias: +  0.9156971653319136\n",
      "Penalización por parar muy lejos: -  0.16593298014244443\n",
      "Penalización por duración del episodio: -  0.29906615547113813\n",
      "Recompensa por acortar distancias: +  0.9156971653319136\n",
      "Penalización por duración del episodio: -  0.29915799929693\n",
      "Recompensa por acortar distancias: +  0.9156971653319136\n",
      "Penalización por duración del episodio: -  0.2993826661475455\n",
      "Recompensa por acortar distancias: +  0.9156971653319136\n",
      "Penalización por duración del episodio: -  0.2994996201243203\n",
      "Recompensa por acortar distancias: +  0.9156971653319136\n",
      "Penalización por parar muy lejos: -  0.16593298014244443\n",
      "Penalización por duración del episodio: -  0.2996204626816652\n",
      "Step: 5900, Mean Reward (últimos 10 pasos): 0.4501437246799469\n",
      "Recompensa por acortar distancias: +  0.9156970328163313\n",
      "Penalización por parar muy lejos: -  0.1659327425645632\n",
      "Penalización por duración del episodio: -  0.2997211611008754\n",
      "Recompensa por acortar distancias: +  0.9156970328163313\n",
      "Penalización por parar muy lejos: -  0.1659327425645632\n",
      "Penalización por duración del episodio: -  0.29983868623958676\n",
      "Recompensa por acortar distancias: +  0.9156970769882131\n",
      "Penalización por duración del episodio: -  0.29999230487093376\n",
      "Recompensa por acortar distancias: +  0.9156970769882131\n",
      "Penalización por duración del episodio: -  0.30039083541244976\n",
      "Recompensa por acortar distancias: +  0.9156970769882131\n",
      "Penalización por parar muy lejos: -  0.16593282175715998\n",
      "Penalización por duración del episodio: -  0.3007262156637467\n",
      "Recompensa por acortar distancias: +  0.9156969150245438\n",
      "Penalización por duración del episodio: -  0.30083861981992627\n",
      "Recompensa por acortar distancias: +  0.9156969150245438\n",
      "Penalización por duración del episodio: -  0.3009125527500013\n",
      "steer input from model: 0.1 , throttle:  0.7\n",
      "reward: 0.6147843622745425\n",
      "Recompensa por acortar distancias: +  0.9156969150245438\n",
      "Penalización por parar muy lejos: -  0.1659325313844531\n",
      "Penalización por duración del episodio: -  0.3010220217721121\n",
      "Recompensa por acortar distancias: +  0.9156969150245438\n",
      "Penalización por duración del episodio: -  0.30139531166649963\n",
      "Recompensa por acortar distancias: +  0.9156969150245438\n",
      "Penalización por parar muy lejos: -  0.1659325313844531\n",
      "Penalización por duración del episodio: -  0.3014897221207053\n",
      "Step: 5910, Mean Reward (últimos 10 pasos): 0.4482746720314026\n",
      "Recompensa por acortar distancias: +  0.915697025454349\n",
      "Penalización por parar muy lejos: -  0.16593272936580003\n",
      "Penalización por duración del episodio: -  0.3017200175247201\n",
      "Recompensa por acortar distancias: +  0.9156971653319136\n",
      "Penalización por parar muy lejos: -  0.16593298014244443\n",
      "Penalización por duración del episodio: -  0.3020499431461052\n",
      "Recompensa por acortar distancias: +  0.9156971653319136\n",
      "Penalización por parar muy lejos: -  0.16593298014244443\n",
      "Penalización por duración del episodio: -  0.3023812099451354\n",
      "Recompensa por acortar distancias: +  0.9156971506079694\n",
      "Penalización por parar muy lejos: -  0.16593295374488862\n",
      "Penalización por duración del episodio: -  0.3024844325310369\n",
      "Recompensa por acortar distancias: +  0.9156971506079694\n",
      "Penalización por parar muy lejos: -  0.16593295374488862\n",
      "Penalización por duración del episodio: -  0.3025980698543725\n",
      "Recompensa por acortar distancias: +  0.9156971211600738\n",
      "Penalización por parar muy lejos: -  0.16593290094978708\n",
      "Penalización por duración del episodio: -  0.3027020036540585\n",
      "Recompensa por acortar distancias: +  0.9156971211600738\n",
      "Penalización por duración del episodio: -  0.3030378142909161\n",
      "Recompensa por acortar distancias: +  0.9156971211600738\n",
      "Penalización por duración del episodio: -  0.3031481593808811\n",
      "Recompensa por acortar distancias: +  0.9156971211600738\n",
      "Penalización por duración del episodio: -  0.30336184342858\n",
      "Recompensa por acortar distancias: +  0.9156971211600738\n",
      "Penalización por parar muy lejos: -  0.16593290094978708\n",
      "Penalización por duración del episodio: -  0.30350156130206596\n",
      "Step: 5920, Mean Reward (últimos 10 pasos): 0.4462626576423645\n",
      "Recompensa por acortar distancias: +  0.9156971211600738\n",
      "Penalización por duración del episodio: -  0.3036873183950904\n",
      "Recompensa por acortar distancias: +  0.9156971211600738\n",
      "Penalización por parar muy lejos: -  0.16593290094978708\n",
      "Penalización por duración del episodio: -  0.3038139891397527\n",
      "Recompensa por acortar distancias: +  0.9156966794405205\n",
      "Penalización por parar muy lejos: -  0.1659321090248788\n",
      "Penalización por duración del episodio: -  0.3040201284359132\n",
      "Recompensa por acortar distancias: +  0.9156968266806051\n",
      "Penalización por duración del episodio: -  0.3040965516229723\n",
      "Recompensa por acortar distancias: +  0.9156968266806051\n",
      "Penalización por duración del episodio: -  0.304355238646556\n",
      "Recompensa por acortar distancias: +  0.9156968266806051\n",
      "Penalización por duración del episodio: -  0.3044475973581565\n",
      "Recompensa por acortar distancias: +  0.9156968266806051\n",
      "Penalización por parar muy lejos: -  0.16593237299951183\n",
      "Penalización por duración del episodio: -  0.30468325788410405\n",
      "steer input from model: -0.25 , throttle:  0.0\n",
      "reward: 0.4450811957969893\n",
      "Recompensa por acortar distancias: +  0.9156966941645394\n",
      "Penalización por parar muy lejos: -  0.16593213542232693\n",
      "Penalización por duración del episodio: -  0.3050126532191794\n",
      "Recompensa por acortar distancias: +  0.9156967383365824\n",
      "Penalización por parar muy lejos: -  0.1659322146146916\n",
      "Penalización por duración del episodio: -  0.30532847808944796\n",
      "Recompensa por acortar distancias: +  0.9156967383365824\n",
      "Penalización por parar muy lejos: -  0.1659322146146916\n",
      "Penalización por duración del episodio: -  0.3056549095739439\n",
      "Step: 5930, Mean Reward (últimos 10 pasos): 0.44410961866378784\n",
      "Recompensa por acortar distancias: +  0.915696811956607\n",
      "Penalización por duración del episodio: -  0.30600052790386884\n",
      "Recompensa por acortar distancias: +  0.915696811956607\n",
      "Penalización por duración del episodio: -  0.3063279132665762\n",
      "Recompensa por acortar distancias: +  0.9156968855765736\n",
      "Penalización por parar muy lejos: -  0.1659324785894592\n",
      "Penalización por duración del episodio: -  0.3066740173135615\n",
      "Recompensa por acortar distancias: +  0.9156969665584692\n",
      "Penalización por parar muy lejos: -  0.1659326237757248\n",
      "Penalización por duración del episodio: -  0.3067676921608343\n",
      "Recompensa por acortar distancias: +  0.9156969665584692\n",
      "Penalización por parar muy lejos: -  0.1659326237757248\n",
      "Penalización por duración del episodio: -  0.3070113203793751\n",
      "Recompensa por acortar distancias: +  0.9156969591964816\n",
      "Penalización por parar muy lejos: -  0.16593261057696915\n",
      "Penalización por duración del episodio: -  0.30734107961117046\n",
      "Recompensa por acortar distancias: +  0.9156969591964816\n",
      "Penalización por duración del episodio: -  0.3076652056445264\n",
      "Recompensa por acortar distancias: +  0.9156969591964816\n",
      "Penalización por duración del episodio: -  0.30776798351192747\n",
      "Recompensa por acortar distancias: +  0.9156969591964816\n",
      "Penalización por duración del episodio: -  0.30788917678759825\n",
      "Recompensa por acortar distancias: +  0.9156969591964816\n",
      "Penalización por duración del episodio: -  0.3083486378035364\n",
      "Step: 5940, Mean Reward (últimos 10 pasos): 0.6073483228683472\n",
      "Recompensa por acortar distancias: +  0.915696870852585\n",
      "Penalización por duración del episodio: -  0.30869994700150116\n",
      "Recompensa por acortar distancias: +  0.9156969297485253\n",
      "Penalización por parar muy lejos: -  0.16593255778195506\n",
      "Penalización por duración del episodio: -  0.30884074338452117\n",
      "Recompensa por acortar distancias: +  0.9156969297485253\n",
      "Penalización por duración del episodio: -  0.30894716950399165\n",
      "Recompensa por acortar distancias: +  0.9156970107303826\n",
      "Penalización por duración del episodio: -  0.30905170161914275\n",
      "Recompensa por acortar distancias: +  0.9156970107303826\n",
      "Penalización por duración del episodio: -  0.30916788887720303\n",
      "Recompensa por acortar distancias: +  0.9156969960064137\n",
      "Penalización por parar muy lejos: -  0.16593267657075564\n",
      "Penalización por duración del episodio: -  0.3092644151005908\n",
      "Recompensa por acortar distancias: +  0.9156969960064137\n",
      "Penalización por parar muy lejos: -  0.16593267657075564\n",
      "Penalización por duración del episodio: -  0.309370926961018\n",
      "steer input from model: -0.05 , throttle:  0.0\n",
      "reward: 0.44039339247464016\n",
      "Recompensa por acortar distancias: +  0.9156969960064137\n",
      "Penalización por duración del episodio: -  0.3094959135811763\n",
      "Recompensa por acortar distancias: +  0.9156969960064137\n",
      "Penalización por duración del episodio: -  0.309604813676542\n",
      "Recompensa por acortar distancias: +  0.9156969960064137\n",
      "Penalización por duración del episodio: -  0.3096918123685277\n",
      "Step: 5950, Mean Reward (últimos 10 pasos): 0.6060051918029785\n",
      "Recompensa por acortar distancias: +  0.9156969960064137\n",
      "Penalización por parar muy lejos: -  0.16593267657075564\n",
      "Penalización por duración del episodio: -  0.3097923541781642\n",
      "Recompensa por acortar distancias: +  0.9156969960064137\n",
      "Penalización por duración del episodio: -  0.30988294080548395\n",
      "Recompensa por acortar distancias: +  0.9156969960064137\n",
      "Penalización por duración del episodio: -  0.3099743783494185\n",
      "Recompensa por acortar distancias: +  0.9156969960064137\n",
      "Penalización por duración del episodio: -  0.3101271864408637\n",
      "Recompensa por acortar distancias: +  0.915696811956607\n",
      "Penalización por duración del episodio: -  0.31023389769939375\n",
      "Recompensa por acortar distancias: +  0.915696811956607\n",
      "Penalización por duración del episodio: -  0.310394609758312\n",
      "Recompensa por acortar distancias: +  0.915696811956607\n",
      "Penalización por parar muy lejos: -  0.16593234660203335\n",
      "Penalización por duración del episodio: -  0.3105336419867474\n",
      "Recompensa por acortar distancias: +  0.9156969591964816\n",
      "Penalización por parar muy lejos: -  0.16593261057696915\n",
      "Penalización por duración del episodio: -  0.3107197557607038\n",
      "Recompensa por acortar distancias: +  0.9156969591964816\n",
      "Penalización por duración del episodio: -  0.3110539277474908\n",
      "Recompensa por acortar distancias: +  0.9156970769882131\n",
      "Penalización por duración del episodio: -  0.31139303589587775\n",
      "Step: 5960, Mean Reward (últimos 10 pasos): 0.6043040156364441\n",
      "Recompensa por acortar distancias: +  0.9156970033683983\n",
      "Penalización por parar muy lejos: -  0.16593268976951547\n",
      "Penalización por duración del episodio: -  0.3117337531952608\n",
      "Recompensa por acortar distancias: +  0.9156970033683983\n",
      "Penalización por duración del episodio: -  0.3120780167132644\n",
      "Recompensa por acortar distancias: +  0.9156970033683983\n",
      "Penalización por duración del episodio: -  0.31219454094369176\n",
      "Recompensa por acortar distancias: +  0.9156970033683983\n",
      "Penalización por parar muy lejos: -  0.16593268976951547\n",
      "Penalización por duración del episodio: -  0.3123053436630918\n",
      "Recompensa por acortar distancias: +  0.9156970033683983\n",
      "Penalización por duración del episodio: -  0.312741041396904\n",
      "Recompensa por acortar distancias: +  0.9156971211600738\n",
      "Penalización por parar muy lejos: -  0.16593290094978708\n",
      "Penalización por duración del episodio: -  0.3128418477436119\n",
      "Recompensa por acortar distancias: +  0.9156970769882131\n",
      "Penalización por parar muy lejos: -  0.16593282175715998\n",
      "Penalización por duración del episodio: -  0.31307789706081346\n",
      "steer input from model: 0.1 , throttle:  0.0\n",
      "reward: 0.4366863581702397\n",
      "Recompensa por acortar distancias: +  0.9156971653319136\n",
      "Penalización por parar muy lejos: -  0.16593298014244443\n",
      "Penalización por duración del episodio: -  0.31341810531679787\n",
      "Recompensa por acortar distancias: +  0.9156972389515999\n",
      "Penalización por parar muy lejos: -  0.16593311213027395\n",
      "Penalización por duración del episodio: -  0.3134933997694765\n",
      "Recompensa por acortar distancias: +  0.9156972389515999\n",
      "Penalización por duración del episodio: -  0.31374831938495684\n",
      "Step: 5970, Mean Reward (últimos 10 pasos): 0.6019489169120789\n",
      "Recompensa por acortar distancias: +  0.9156972389515999\n",
      "Penalización por duración del episodio: -  0.3140889127783959\n",
      "Recompensa por acortar distancias: +  0.9156972389515999\n",
      "Penalización por parar muy lejos: -  0.16593311213027395\n",
      "Penalización por duración del episodio: -  0.31443345316290394\n",
      "Recompensa por acortar distancias: +  0.915697025454349\n",
      "Penalización por parar muy lejos: -  0.16593272936580003\n",
      "Penalización por duración del episodio: -  0.3145267883220897\n",
      "Recompensa por acortar distancias: +  0.915697025454349\n",
      "Penalización por parar muy lejos: -  0.16593272936580003\n",
      "Penalización por duración del episodio: -  0.31478220408166957\n",
      "Recompensa por acortar distancias: +  0.915697025454349\n",
      "Penalización por duración del episodio: -  0.31511084425619146\n",
      "Recompensa por acortar distancias: +  0.9156968855765736\n",
      "Penalización por parar muy lejos: -  0.1659324785894592\n",
      "Penalización por duración del episodio: -  0.31521848679485837\n",
      "Recompensa por acortar distancias: +  0.9156968855765736\n",
      "Penalización por duración del episodio: -  0.3154513564623376\n",
      "Recompensa por acortar distancias: +  0.9156969150245438\n",
      "Penalización por duración del episodio: -  0.3155525786668048\n",
      "Recompensa por acortar distancias: +  0.9156969591964816\n",
      "Penalización por duración del episodio: -  0.3156462527290602\n",
      "Recompensa por acortar distancias: +  0.9156969591964816\n",
      "Penalización por parar muy lejos: -  0.16593261057696915\n",
      "Penalización por duración del episodio: -  0.3157842059096125\n",
      "Step: 5980, Mean Reward (últimos 10 pasos): 0.43398013710975647\n",
      "Recompensa por acortar distancias: +  0.9156969591964816\n",
      "Penalización por parar muy lejos: -  0.16593261057696915\n",
      "Penalización por duración del episodio: -  0.31591334976865665\n",
      "Recompensa por acortar distancias: +  0.9156969591964816\n",
      "Penalización por duración del episodio: -  0.31600082021118164\n",
      "Recompensa por acortar distancias: +  0.9156969591964816\n",
      "Penalización por duración del episodio: -  0.3160767535715005\n",
      "Recompensa por acortar distancias: +  0.9156969591964816\n",
      "Penalización por parar muy lejos: -  0.16593261057696915\n",
      "Penalización por duración del episodio: -  0.31616333080875386\n",
      "Recompensa por acortar distancias: +  0.9156969591964816\n",
      "Penalización por duración del episodio: -  0.3164450668958093\n",
      "Recompensa por acortar distancias: +  0.9156969591964816\n",
      "Penalización por parar muy lejos: -  0.16593261057696915\n",
      "Penalización por duración del episodio: -  0.3165423650285055\n",
      "Recompensa por acortar distancias: +  0.9156968414046006\n",
      "Penalización por duración del episodio: -  0.3166636788044179\n",
      "steer input from model: 0.05 , throttle:  0.3\n",
      "reward: 0.5990331626001827\n",
      "Recompensa por acortar distancias: +  0.9156968414046006\n",
      "Penalización por duración del episodio: -  0.31677874281776014\n",
      "Recompensa por acortar distancias: +  0.9156969665584692\n",
      "Penalización por duración del episodio: -  0.3171258506185293\n",
      "Recompensa por acortar distancias: +  0.9156969665584692\n",
      "Penalización por parar muy lejos: -  0.1659326237757248\n",
      "Penalización por duración del episodio: -  0.31746611544255027\n",
      "Step: 5990, Mean Reward (últimos 10 pasos): 0.4322982132434845\n",
      "Recompensa por acortar distancias: +  0.9156968855765736\n",
      "Penalización por duración del episodio: -  0.3176586608767734\n",
      "Recompensa por acortar distancias: +  0.9156968414046006\n",
      "Penalización por duración del episodio: -  0.31777597547360914\n",
      "Recompensa por acortar distancias: +  0.9156968414046006\n",
      "Penalización por parar muy lejos: -  0.1659323993969936\n",
      "Penalización por duración del episodio: -  0.31813984997380784\n",
      "Recompensa por acortar distancias: +  0.9156969739204561\n",
      "Penalización por duración del episodio: -  0.3182085631540176\n",
      "Recompensa por acortar distancias: +  0.9156969739204561\n",
      "Penalización por duración del episodio: -  0.318483350091657\n",
      "Recompensa por acortar distancias: +  0.9156969739204561\n",
      "Penalización por duración del episodio: -  0.31861779399269885\n",
      "Recompensa por acortar distancias: +  0.9156969739204561\n",
      "Penalización por duración del episodio: -  0.31881323840484316\n",
      "Recompensa por acortar distancias: +  0.9156969739204561\n",
      "Penalización por parar muy lejos: -  0.16593263697448127\n",
      "Penalización por duración del episodio: -  0.31889738822950114\n",
      "Recompensa por acortar distancias: +  0.915696811956607\n",
      "Penalización por duración del episodio: -  0.3191588556413189\n",
      "Recompensa por acortar distancias: +  0.9156969591964816\n",
      "Penalización por parar muy lejos: -  0.16593261057696915\n",
      "Penalización por duración del episodio: -  0.31925462428859497\n",
      "Step: 6000, Mean Reward (últimos 10 pasos): 0.4305097162723541\n",
      "Recompensa por acortar distancias: +  0.9156969591964816\n",
      "Penalización por duración del episodio: -  0.31950578113410255\n",
      "Recompensa por acortar distancias: +  0.9156969591964816\n",
      "Penalización por duración del episodio: -  0.319583775559365\n",
      "Recompensa por acortar distancias: +  0.9156969591964816\n",
      "Penalización por parar muy lejos: -  0.16593261057696915\n",
      "Penalización por duración del episodio: -  0.3196939958588271\n",
      "Recompensa por acortar distancias: +  0.9156968561285941\n",
      "Penalización por parar muy lejos: -  0.16593242579447878\n",
      "Penalización por duración del episodio: -  0.3198365323033288\n",
      "Recompensa por acortar distancias: +  0.9156968414046006\n",
      "Penalización por duración del episodio: -  0.3199384209794353\n",
      "Recompensa por acortar distancias: +  0.9156968414046006\n",
      "Penalización por duración del episodio: -  0.32019525997026965\n",
      "Recompensa por acortar distancias: +  0.9156968414046006\n",
      "Penalización por duración del episodio: -  0.3205256305923002\n",
      "steer input from model: 0.1 , throttle:  0.3\n",
      "reward: 0.5951712108123004\n",
      "Recompensa por acortar distancias: +  0.9156968414046006\n",
      "Penalización por parar muy lejos: -  0.1659323993969936\n",
      "Penalización por duración del episodio: -  0.3206339297005824\n",
      "Recompensa por acortar distancias: +  0.9156968414046006\n",
      "Penalización por duración del episodio: -  0.3207171235960802\n",
      "Recompensa por acortar distancias: +  0.9156555535095101\n",
      "Penalización por duración del episodio: -  0.32084562440165676\n",
      "Step: 6010, Mean Reward (últimos 10 pasos): 0.5948099493980408\n",
      "Recompensa por acortar distancias: +  0.9156555535095101\n",
      "Penalización por parar muy lejos: -  0.16585840727133536\n",
      "Penalización por duración del episodio: -  0.3209498963946086\n",
      "Recompensa por acortar distancias: +  0.9155885422174443\n",
      "Penalización por parar muy lejos: -  0.16573844237585952\n",
      "Penalización por duración del episodio: -  0.32120233463973363\n",
      "Recompensa por acortar distancias: +  0.9155885422174443\n",
      "Penalización por duración del episodio: -  0.3213251978127384\n",
      "Recompensa por acortar distancias: +  0.9155885422174443\n",
      "Penalización por duración del episodio: -  0.3215325871384759\n",
      "Recompensa por acortar distancias: +  0.9152142129872493\n",
      "Penalización por duración del episodio: -  0.32164136193765297\n",
      "Recompensa por acortar distancias: +  0.9152142129872493\n",
      "Penalización por parar muy lejos: -  0.16507117015298833\n",
      "Penalización por duración del episodio: -  0.32176176394683165\n",
      "Recompensa por acortar distancias: +  0.9150521034612553\n",
      "Penalización por duración del episodio: -  0.3218706939826589\n",
      "Recompensa por acortar distancias: +  0.9148994105717484\n",
      "Penalización por duración del episodio: -  0.32221562626245975\n",
      "Recompensa por acortar distancias: +  0.9147178235226664\n",
      "Penalización por duración del episodio: -  0.3225620912844805\n",
      "Recompensa por acortar distancias: +  0.9147178235226664\n",
      "Penalización por duración del episodio: -  0.32264325003496397\n",
      "Step: 6020, Mean Reward (últimos 10 pasos): 0.5920745730400085\n",
      "Recompensa por acortar distancias: +  0.9147178235226664\n",
      "Penalización por duración del episodio: -  0.32273134519492835\n",
      "Recompensa por acortar distancias: +  0.9147178235226664\n",
      "Penalización por parar muy lejos: -  0.16419372823181425\n",
      "Penalización por duración del episodio: -  0.32290399213662396\n",
      "Recompensa por acortar distancias: +  0.913678057847499\n",
      "Penalización por parar muy lejos: -  0.16238268280636728\n",
      "Penalización por duración del episodio: -  0.32324907622631155\n",
      "Recompensa por acortar distancias: +  0.9134612099913159\n",
      "Penalización por parar muy lejos: -  0.16200949286447539\n",
      "Penalización por duración del episodio: -  0.32359000583357356\n",
      "Recompensa por acortar distancias: +  0.9126813731511189\n",
      "Penalización por duración del episodio: -  0.3239290134778866\n",
      "Recompensa por acortar distancias: +  0.9120363648232431\n",
      "Penalización por parar muy lejos: -  0.1595951251168463\n",
      "Penalización por duración del episodio: -  0.32425655096483635\n",
      "Recompensa por acortar distancias: +  0.9115466090007308\n",
      "Penalización por parar muy lejos: -  0.15878007908710154\n",
      "Penalización por duración del episodio: -  0.32460112785599127\n",
      "steer input from model: 0.05 , throttle:  0.0\n",
      "reward: 0.428165402057638\n",
      "Recompensa por acortar distancias: +  0.9115466090007308\n",
      "Penalización por parar muy lejos: -  0.15878007908710154\n",
      "Penalización por duración del episodio: -  0.3249595762894215\n",
      "Recompensa por acortar distancias: +  0.9115466090007308\n",
      "Penalización por duración del episodio: -  0.32529705245663243\n",
      "Recompensa por acortar distancias: +  0.9096732292757596\n",
      "Penalización por parar muy lejos: -  0.1557300231000547\n",
      "Penalización por duración del episodio: -  0.3254239707580235\n",
      "Step: 6030, Mean Reward (últimos 10 pasos): 0.42851924896240234\n",
      "Recompensa por acortar distancias: +  0.9096732292757596\n",
      "Penalización por parar muy lejos: -  0.1557300231000547\n",
      "Penalización por duración del episodio: -  0.32563195087991237\n",
      "Recompensa por acortar distancias: +  0.9096732292757596\n",
      "Penalización por duración del episodio: -  0.325718307080068\n",
      "Recompensa por acortar distancias: +  0.9096732292757596\n",
      "Penalización por parar muy lejos: -  0.1557300231000547\n",
      "Penalización por duración del episodio: -  0.3259852310577616\n",
      "Recompensa por acortar distancias: +  0.9086002529992057\n",
      "Penalización por duración del episodio: -  0.326319992146599\n",
      "Recompensa por acortar distancias: +  0.9077905903133605\n",
      "Penalización por parar muy lejos: -  0.15276873467692736\n",
      "Penalización por duración del episodio: -  0.3266550090629694\n",
      "Recompensa por acortar distancias: +  0.9077905903133605\n",
      "Penalización por parar muy lejos: -  0.15276873467692736\n",
      "Penalización por duración del episodio: -  0.3270144437544689\n",
      "Recompensa por acortar distancias: +  0.9077905903133605\n",
      "Penalización por duración del episodio: -  0.32710622076468254\n",
      "Recompensa por acortar distancias: +  0.9077905903133605\n",
      "Penalización por duración del episodio: -  0.32720631424424945\n",
      "Recompensa por acortar distancias: +  0.9061701263586983\n",
      "Penalización por parar muy lejos: -  0.1502992117096419\n",
      "Penalización por duración del episodio: -  0.32735750242526107\n",
      "Recompensa por acortar distancias: +  0.9056895923860339\n",
      "Penalización por duración del episodio: -  0.32769217869466183\n",
      "Step: 6040, Mean Reward (últimos 10 pasos): 0.5779973864555359\n",
      "Recompensa por acortar distancias: +  0.9056895923860339\n",
      "Penalización por duración del episodio: -  0.32778006073267724\n",
      "Recompensa por acortar distancias: +  0.9056895923860339\n",
      "Penalización por parar muy lejos: -  0.14958051668503797\n",
      "Penalización por duración del episodio: -  0.32784598806630766\n",
      "Recompensa por acortar distancias: +  0.9056895923860339\n",
      "Penalización por duración del episodio: -  0.327945120379164\n",
      "Recompensa por acortar distancias: +  0.9046556105445897\n",
      "Penalización por parar muy lejos: -  0.14805461984409032\n",
      "Penalización por duración del episodio: -  0.3280550418827891\n",
      "Recompensa por acortar distancias: +  0.9046556105445897\n",
      "Penalización por duración del episodio: -  0.32815474795554417\n",
      "Recompensa por acortar distancias: +  0.9042500904313316\n",
      "Penalización por duración del episodio: -  0.3283710903473638\n",
      "Recompensa por acortar distancias: +  0.9038596045257288\n",
      "Penalización por duración del episodio: -  0.328461132252071\n",
      "steer input from model: -0.25 , throttle:  0.7\n",
      "reward: 0.5753984722736578\n",
      "Recompensa por acortar distancias: +  0.9035905028053899\n",
      "Penalización por duración del episodio: -  0.32857141040376553\n",
      "Recompensa por acortar distancias: +  0.9032409687433774\n",
      "Penalización por parar muy lejos: -  0.14601125552942196\n",
      "Penalización por duración del episodio: -  0.3287159818766098\n",
      "Recompensa por acortar distancias: +  0.9032409687433774\n",
      "Penalización por parar muy lejos: -  0.14601125552942196\n",
      "Penalización por duración del episodio: -  0.32906517974035665\n",
      "Step: 6050, Mean Reward (últimos 10 pasos): 0.428164541721344\n",
      "Recompensa por acortar distancias: +  0.9032409687433774\n",
      "Penalización por duración del episodio: -  0.3294126494543732\n",
      "Recompensa por acortar distancias: +  0.9016460404893873\n",
      "Penalización por duración del episodio: -  0.32954628380644324\n",
      "Recompensa por acortar distancias: +  0.9016460404893873\n",
      "Penalización por parar muy lejos: -  0.14376673227889003\n",
      "Penalización por duración del episodio: -  0.32965358098924724\n",
      "Recompensa por acortar distancias: +  0.9011529777390642\n",
      "Penalización por parar muy lejos: -  0.14308518093545694\n",
      "Penalización por duración del episodio: -  0.32976652903913883\n",
      "Recompensa por acortar distancias: +  0.9011529777390642\n",
      "Penalización por duración del episodio: -  0.3301225418890047\n",
      "Recompensa por acortar distancias: +  0.9000341547067778\n",
      "Penalización por parar muy lejos: -  0.14155966761364225\n",
      "Penalización por duración del episodio: -  0.3304666692241218\n",
      "Recompensa por acortar distancias: +  0.8993529271489987\n",
      "Penalización por duración del episodio: -  0.3305740497319217\n",
      "Recompensa por acortar distancias: +  0.8990287885872215\n",
      "Penalización por duración del episodio: -  0.330806027394042\n",
      "Recompensa por acortar distancias: +  0.8987167500071385\n",
      "Penalización por duración del episodio: -  0.33092952203754916\n",
      "Recompensa por acortar distancias: +  0.8987167500071385\n",
      "Penalización por duración del episodio: -  0.33117397241898805\n",
      "Step: 6060, Mean Reward (últimos 10 pasos): 0.5675427913665771\n",
      "Recompensa por acortar distancias: +  0.8987167500071385\n",
      "Penalización por parar muy lejos: -  0.13979987445441028\n",
      "Penalización por duración del episodio: -  0.3315139191981141\n",
      "Recompensa por acortar distancias: +  0.8987167500071385\n",
      "Penalización por parar muy lejos: -  0.13979987445441028\n",
      "Penalización por duración del episodio: -  0.33161694791879026\n",
      "Recompensa por acortar distancias: +  0.8973402338130084\n",
      "Penalización por parar muy lejos: -  0.1380019506492087\n",
      "Penalización por duración del episodio: -  0.3318506479397557\n",
      "Recompensa por acortar distancias: +  0.8971912050039071\n",
      "Penalización por duración del episodio: -  0.3322096414914058\n",
      "Recompensa por acortar distancias: +  0.8971912050039071\n",
      "Penalización por duración del episodio: -  0.33228849803790067\n",
      "Recompensa por acortar distancias: +  0.8971912050039071\n",
      "Penalización por parar muy lejos: -  0.1378097427828632\n",
      "Penalización por duración del episodio: -  0.3325570129404252\n",
      "Recompensa por acortar distancias: +  0.8970630336827367\n",
      "Penalización por duración del episodio: -  0.3326455647092772\n",
      "steer input from model: 0.1 , throttle:  0.3\n",
      "reward: 0.5644174689734595\n",
      "Recompensa por acortar distancias: +  0.8970611359055105\n",
      "Penalización por parar muy lejos: -  0.1376423729888941\n",
      "Penalización por duración del episodio: -  0.3327515968185789\n",
      "Recompensa por acortar distancias: +  0.8970591368212933\n",
      "Penalización por duración del episodio: -  0.3329018344406659\n",
      "Recompensa por acortar distancias: +  0.8970591368212933\n",
      "Penalización por parar muy lejos: -  0.1376398034091668\n",
      "Penalización por duración del episodio: -  0.333242247342482\n",
      "Step: 6070, Mean Reward (últimos 10 pasos): 0.42617708444595337\n",
      "Recompensa por acortar distancias: +  0.8970569483570966\n",
      "Penalización por duración del episodio: -  0.3335807566092055\n",
      "Recompensa por acortar distancias: +  0.8970569483570966\n",
      "Penalización por duración del episodio: -  0.33365999863401047\n",
      "Recompensa por acortar distancias: +  0.8970569483570966\n",
      "Penalización por duración del episodio: -  0.33375883906248016\n",
      "Recompensa por acortar distancias: +  0.8968925726537447\n",
      "Penalización por duración del episodio: -  0.33393773787917913\n",
      "Recompensa por acortar distancias: +  0.8968371923956372\n",
      "Penalización por parar muy lejos: -  0.137355045270807\n",
      "Penalización por duración del episodio: -  0.3340350653358867\n",
      "Recompensa por acortar distancias: +  0.8968371923956372\n",
      "Penalización por duración del episodio: -  0.3342867598631649\n",
      "Recompensa por acortar distancias: +  0.8968371923956372\n",
      "Penalización por parar muy lejos: -  0.137355045270807\n",
      "Penalización por duración del episodio: -  0.3346196611480333\n",
      "Recompensa por acortar distancias: +  0.8967986762267168\n",
      "Penalización por parar muy lejos: -  0.13730573405255733\n",
      "Penalización por duración del episodio: -  0.33470855573895897\n",
      "Recompensa por acortar distancias: +  0.8967989057111515\n",
      "Penalización por duración del episodio: -  0.33495750175383837\n",
      "Recompensa por acortar distancias: +  0.8967997000768618\n",
      "Penalización por parar muy lejos: -  0.13730704445714298\n",
      "Penalización por duración del episodio: -  0.33531747873315443\n",
      "Step: 6080, Mean Reward (últimos 10 pasos): 0.4241751730442047\n",
      "Recompensa por acortar distancias: +  0.8968007239180181\n",
      "Penalización por parar muy lejos: -  0.13730835487224424\n",
      "Penalización por duración del episodio: -  0.33566812518302314\n",
      "Recompensa por acortar distancias: +  0.8968007239180181\n",
      "Penalización por parar muy lejos: -  0.13730835487224424\n",
      "Penalización por duración del episodio: -  0.33577932068080185\n",
      "Recompensa por acortar distancias: +  0.8968007239180181\n",
      "Penalización por parar muy lejos: -  0.13730835487224424\n",
      "Penalización por duración del episodio: -  0.3358573273765305\n",
      "Recompensa por acortar distancias: +  0.8968007239180181\n",
      "Penalización por duración del episodio: -  0.33602884170812486\n",
      "Recompensa por acortar distancias: +  0.8968007239180181\n",
      "Penalización por duración del episodio: -  0.3361198474428189\n",
      "Recompensa por acortar distancias: +  0.8968007239180181\n",
      "Penalización por duración del episodio: -  0.33638131918090536\n",
      "Recompensa por acortar distancias: +  0.8967701460290048\n",
      "Penalización por parar muy lejos: -  0.13726922769753286\n",
      "Penalización por duración del episodio: -  0.33673938371147905\n",
      "steer input from model: -0.9 , throttle:  0.0\n",
      "reward: 0.422761534619993\n",
      "Recompensa por acortar distancias: +  0.8967701460290048\n",
      "Penalización por parar muy lejos: -  0.13726922769753286\n",
      "Penalización por duración del episodio: -  0.33683261453912466\n",
      "Recompensa por acortar distancias: +  0.8967742600338651\n",
      "Penalización por parar muy lejos: -  0.1372744907958573\n",
      "Penalización por duración del episodio: -  0.3370796867592702\n",
      "Recompensa por acortar distancias: +  0.896774983942456\n",
      "Penalización por duración del episodio: -  0.3374345559715423\n",
      "Step: 6090, Mean Reward (últimos 10 pasos): 0.5593404173851013\n",
      "Recompensa por acortar distancias: +  0.8967685215751152\n",
      "Penalización por duración del episodio: -  0.33777692634316425\n",
      "Recompensa por acortar distancias: +  0.8967685215751152\n",
      "Penalización por duración del episodio: -  0.3381316216083194\n",
      "Recompensa por acortar distancias: +  0.8967685215751152\n",
      "Penalización por parar muy lejos: -  0.1372671496110157\n",
      "Penalización por duración del episodio: -  0.3382265088712118\n",
      "Recompensa por acortar distancias: +  0.8967332812504091\n",
      "Penalización por parar muy lejos: -  0.13722208197219388\n",
      "Penalización por duración del episodio: -  0.3384646167439849\n",
      "Recompensa por acortar distancias: +  0.8967187087253982\n",
      "Penalización por duración del episodio: -  0.338818516341075\n",
      "Recompensa por acortar distancias: +  0.8967187087253982\n",
      "Penalización por duración del episodio: -  0.3391690052424038\n",
      "Recompensa por acortar distancias: +  0.8966652296378985\n",
      "Penalización por duración del episodio: -  0.3392552427755632\n",
      "Recompensa por acortar distancias: +  0.8966652296378985\n",
      "Penalización por parar muy lejos: -  0.13713512679446987\n",
      "Penalización por duración del episodio: -  0.3393826279130628\n",
      "Recompensa por acortar distancias: +  0.8966356282615041\n",
      "Penalización por duración del episodio: -  0.33952761004080984\n",
      "Recompensa por acortar distancias: +  0.896624663376157\n",
      "Penalización por duración del episodio: -  0.3398780167642375\n",
      "Step: 6100, Mean Reward (últimos 10 pasos): 0.5567466616630554\n",
      "Recompensa por acortar distancias: +  0.8965767125116735\n",
      "Penalización por parar muy lejos: -  0.1370221661942983\n",
      "Penalización por duración del episodio: -  0.3402374883222741\n",
      "Recompensa por acortar distancias: +  0.8965767125116735\n",
      "Penalización por duración del episodio: -  0.34032727792667233\n",
      "Recompensa por acortar distancias: +  0.8965767125116735\n",
      "Penalización por parar muy lejos: -  0.1370221661942983\n",
      "Penalización por duración del episodio: -  0.3404203819887266\n",
      "Recompensa por acortar distancias: +  0.8965767125116735\n",
      "Penalización por parar muy lejos: -  0.1370221661942983\n",
      "Penalización por duración del episodio: -  0.3406141879991559\n",
      "Recompensa por acortar distancias: +  0.896443366179898\n",
      "Penalización por duración del episodio: -  0.3407261655492727\n",
      "Recompensa por acortar distancias: +  0.896443366179898\n",
      "Penalización por parar muy lejos: -  0.1368523059918093\n",
      "Penalización por duración del episodio: -  0.3408047746659855\n",
      "Recompensa por acortar distancias: +  0.8964031834097437\n",
      "Penalización por parar muy lejos: -  0.13680119273469507\n",
      "Penalización por duración del episodio: -  0.3412706155731765\n",
      "steer input from model: -0.1 , throttle:  0.0\n",
      "reward: 0.4183313751018721\n",
      "Recompensa por acortar distancias: +  0.8964031834097437\n",
      "Penalización por duración del episodio: -  0.3416259125436102\n",
      "Recompensa por acortar distancias: +  0.8963624774399176\n",
      "Penalización por parar muy lejos: -  0.1367494482052403\n",
      "Penalización por duración del episodio: -  0.34172532332139727\n",
      "Recompensa por acortar distancias: +  0.8963599214959354\n",
      "Penalización por parar muy lejos: -  0.13674620029505644\n",
      "Penalización por duración del episodio: -  0.3419630656751827\n",
      "Step: 6110, Mean Reward (últimos 10 pasos): 0.41765066981315613\n",
      "Recompensa por acortar distancias: +  0.8963600366696539\n",
      "Penalización por duración del episodio: -  0.3423072651323038\n",
      "Recompensa por acortar distancias: +  0.8963600366696539\n",
      "Penalización por duración del episodio: -  0.34266321419945933\n",
      "Recompensa por acortar distancias: +  0.8963600366696539\n",
      "Penalización por parar muy lejos: -  0.13674634664663154\n",
      "Penalización por duración del episodio: -  0.3427690537852463\n",
      "Recompensa por acortar distancias: +  0.8963076209354395\n",
      "Penalización por parar muy lejos: -  0.13667977029395068\n",
      "Penalización por duración del episodio: -  0.34301646584516177\n",
      "Recompensa por acortar distancias: +  0.8962790948042794\n",
      "Penalización por duración del episodio: -  0.3431161939768456\n",
      "Recompensa por acortar distancias: +  0.8962790948042794\n",
      "Penalización por duración del episodio: -  0.343216247671496\n",
      "Recompensa por acortar distancias: +  0.8962790948042794\n",
      "Penalización por duración del episodio: -  0.34333288707848914\n",
      "Recompensa por acortar distancias: +  0.8962790948042794\n",
      "Penalización por parar muy lejos: -  0.1366435615166573\n",
      "Penalización por duración del episodio: -  0.34344052965386207\n",
      "Recompensa por acortar distancias: +  0.8962790948042794\n",
      "Penalización por duración del episodio: -  0.34371502542519955\n",
      "Recompensa por acortar distancias: +  0.8962790948042794\n",
      "Penalización por duración del episodio: -  0.3440704241957271\n",
      "Step: 6120, Mean Reward (últimos 10 pasos): 0.552208662033081\n",
      "Recompensa por acortar distancias: +  0.8962111688441354\n",
      "Penalización por parar muy lejos: -  0.13655740968049923\n",
      "Penalización por duración del episodio: -  0.34418140576030437\n",
      "Recompensa por acortar distancias: +  0.8961890475082157\n",
      "Penalización por parar muy lejos: -  0.13652937338288254\n",
      "Penalización por duración del episodio: -  0.3442988901802341\n",
      "Recompensa por acortar distancias: +  0.8961890475082157\n",
      "Penalización por parar muy lejos: -  0.13652937338288254\n",
      "Penalización por duración del episodio: -  0.3444066660077681\n",
      "Recompensa por acortar distancias: +  0.8961890475082157\n",
      "Penalización por duración del episodio: -  0.34453325387661266\n",
      "Recompensa por acortar distancias: +  0.8961890475082157\n",
      "Penalización por parar muy lejos: -  0.13652937338288254\n",
      "Penalización por duración del episodio: -  0.3447926736669504\n",
      "Recompensa por acortar distancias: +  0.8961890475082157\n",
      "Penalización por duración del episodio: -  0.34488291849059666\n",
      "Recompensa por acortar distancias: +  0.8961890475082157\n",
      "Penalización por parar muy lejos: -  0.13652937338288254\n",
      "Penalización por duración del episodio: -  0.3451479971625392\n",
      "steer input from model: -0.1 , throttle:  0.0\n",
      "reward: 0.414511676962794\n",
      "Recompensa por acortar distancias: +  0.8961890475082157\n",
      "Penalización por parar muy lejos: -  0.13652937338288254\n",
      "Penalización por duración del episodio: -  0.3453091819028034\n",
      "Recompensa por acortar distancias: +  0.8961480940738309\n",
      "Penalización por duración del episodio: -  0.3454971373340583\n",
      "Recompensa por acortar distancias: +  0.896148200580154\n",
      "Penalización por parar muy lejos: -  0.13647763111838032\n",
      "Penalización por duración del episodio: -  0.34584246886461845\n",
      "Step: 6130, Mean Reward (últimos 10 pasos): 0.4138281047344208\n",
      "Recompensa por acortar distancias: +  0.896148200580154\n",
      "Penalización por duración del episodio: -  0.34620406065990944\n",
      "Recompensa por acortar distancias: +  0.8961280913619216\n",
      "Penalización por duración del episodio: -  0.3463359906198409\n",
      "Recompensa por acortar distancias: +  0.8961320726479436\n",
      "Penalización por duración del episodio: -  0.3464168495401268\n",
      "Recompensa por acortar distancias: +  0.8961141979693162\n",
      "Penalización por duración del episodio: -  0.34654034654017335\n",
      "Recompensa por acortar distancias: +  0.8961141979693162\n",
      "Penalización por duración del episodio: -  0.34689994214790565\n",
      "Recompensa por acortar distancias: +  0.8961141979693162\n",
      "Penalización por duración del episodio: -  0.34700835520358336\n",
      "Recompensa por acortar distancias: +  0.8961141979693162\n",
      "Penalización por duración del episodio: -  0.3470975705952567\n",
      "Recompensa por acortar distancias: +  0.8961141979693162\n",
      "Penalización por duración del episodio: -  0.34723330253554957\n",
      "Recompensa por acortar distancias: +  0.8961141979693162\n",
      "Penalización por duración del episodio: -  0.3473359433744354\n",
      "Recompensa por acortar distancias: +  0.8961141979693162\n",
      "Penalización por duración del episodio: -  0.34759285624945635\n",
      "Step: 6140, Mean Reward (últimos 10 pasos): 0.5485213398933411\n",
      "Recompensa por acortar distancias: +  0.8960645145446147\n",
      "Penalización por duración del episodio: -  0.3479510151276885\n",
      "Recompensa por acortar distancias: +  0.8960278312422874\n",
      "Penalización por duración del episodio: -  0.3483144764872168\n",
      "Recompensa por acortar distancias: +  0.8958909819150169\n",
      "Penalización por duración del episodio: -  0.3486699927426844\n",
      "Recompensa por acortar distancias: +  0.895774097672501\n",
      "Penalización por duración del episodio: -  0.3490174870165614\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 818          |\n",
      "|    ep_rew_mean          | 251          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 56           |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 108          |\n",
      "|    total_timesteps      | 6144         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0008093716 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.5          |\n",
      "|    entropy_loss         | -3.98        |\n",
      "|    explained_variance   | 0.205        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 15.4         |\n",
      "|    n_updates            | 70           |\n",
      "|    policy_gradient_loss | -0.00201     |\n",
      "|    value_loss           | 35.5         |\n",
      "------------------------------------------\n",
      "Recompensa por acortar distancias: +  0.7590590854899344\n",
      "Penalización por duración del episodio: -  0.3894070399540482\n",
      "Recompensa por acortar distancias: +  0.7590590854899344\n",
      "Penalización por parar muy lejos: -  0.054553671060660884\n",
      "Penalización por duración del episodio: -  0.38957777687474454\n",
      "Recompensa por acortar distancias: +  0.7503319230865473\n",
      "Penalización por parar muy lejos: -  0.0521725156717277\n",
      "Penalización por duración del episodio: -  0.3897084103747782\n",
      "steer input from model: -0.05 , throttle:  0.0\n",
      "reward: 0.3084509970400414\n",
      "Recompensa por acortar distancias: +  0.7503319230865473\n",
      "Penalización por parar muy lejos: -  0.0521725156717277\n",
      "Penalización por duración del episodio: -  0.38982702562633176\n",
      "Recompensa por acortar distancias: +  0.7479152570623286\n",
      "Penalización por duración del episodio: -  0.39017037838516594\n",
      "Recompensa por acortar distancias: +  0.7479152570623286\n",
      "Penalización por parar muy lejos: -  0.05154028244007539\n",
      "Penalización por duración del episodio: -  0.3902575058405057\n",
      "Step: 6150, Mean Reward (últimos 10 pasos): 0.3061174750328064\n",
      "Recompensa por acortar distancias: +  0.7479152570623286\n",
      "Penalización por parar muy lejos: -  0.05154028244007539\n",
      "Penalización por duración del episodio: -  0.3905408517633454\n",
      "Recompensa por acortar distancias: +  0.7424744560773687\n",
      "Penalización por duración del episodio: -  0.390648354962123\n",
      "Recompensa por acortar distancias: +  0.7424744560773687\n",
      "Penalización por parar muy lejos: -  0.050157389443508955\n",
      "Penalización por duración del episodio: -  0.3909131033533531\n",
      "Recompensa por acortar distancias: +  0.7402394937691941\n",
      "Penalización por duración del episodio: -  0.3912970665320429\n",
      "Recompensa por acortar distancias: +  0.7402394937691941\n",
      "Penalización por parar muy lejos: -  0.049604988213132105\n",
      "Penalización por duración del episodio: -  0.3916625714570972\n",
      "Recompensa por acortar distancias: +  0.7402394937691941\n",
      "Penalización por duración del episodio: -  0.39177070193284363\n",
      "Recompensa por acortar distancias: +  0.7402394937691941\n",
      "Penalización por parar muy lejos: -  0.049604988213132105\n",
      "Penalización por duración del episodio: -  0.3918784737171817\n",
      "Recompensa por acortar distancias: +  0.7306049061355142\n",
      "Penalización por duración del episodio: -  0.3919690842580262\n",
      "Recompensa por acortar distancias: +  0.7306049061355142\n",
      "Penalización por duración del episodio: -  0.39240785533611683\n",
      "Recompensa por acortar distancias: +  0.7286547040923392\n",
      "Penalización por duración del episodio: -  0.3927864771806998\n",
      "Step: 6160, Mean Reward (últimos 10 pasos): 0.335868239402771\n",
      "Recompensa por acortar distancias: +  0.7286547040923392\n",
      "Penalización por duración del episodio: -  0.39315303790225775\n",
      "Recompensa por acortar distancias: +  0.7195102762747217\n",
      "Penalización por duración del episodio: -  0.39325985751916853\n",
      "Recompensa por acortar distancias: +  0.7195102762747217\n",
      "Penalización por duración del episodio: -  0.3933550469621269\n",
      "Recompensa por acortar distancias: +  0.7165523307466342\n",
      "Penalización por duración del episodio: -  0.393486733731555\n",
      "Recompensa por acortar distancias: +  0.7165523307466342\n",
      "Penalización por duración del episodio: -  0.39360581420173435\n",
      "Recompensa por acortar distancias: +  0.7165523307466342\n",
      "Penalización por duración del episodio: -  0.39390361335402446\n",
      "Recompensa por acortar distancias: +  0.7165523307466342\n",
      "Penalización por duración del episodio: -  0.39428079452302567\n",
      "steer input from model: 0.05 , throttle:  0.0\n",
      "reward: 0.3222715362236085\n",
      "Recompensa por acortar distancias: +  0.7165523307466342\n",
      "Penalización por duración del episodio: -  0.3944297421589869\n",
      "Recompensa por acortar distancias: +  0.7165523307466342\n",
      "Penalización por duración del episodio: -  0.3945585475378054\n",
      "Recompensa por acortar distancias: +  0.7056418495629297\n",
      "Penalización por duración del episodio: -  0.39468716820312083\n",
      "Step: 6170, Mean Reward (últimos 10 pasos): 0.3109546899795532\n",
      "Recompensa por acortar distancias: +  0.7056418495629297\n",
      "Penalización por duración del episodio: -  0.3947973178626434\n",
      "Recompensa por acortar distancias: +  0.7030799723582744\n",
      "Penalización por duración del episodio: -  0.3950421951682323\n",
      "Recompensa por acortar distancias: +  0.7030799723582744\n",
      "Penalización por duración del episodio: -  0.3954058595047626\n",
      "Recompensa por acortar distancias: +  0.6975583487664085\n",
      "Penalización por duración del episodio: -  0.3957737389522746\n",
      "Recompensa por acortar distancias: +  0.6952498232639\n",
      "Penalización por duración del episodio: -  0.39615457459252845\n",
      "Recompensa por acortar distancias: +  0.6952498232639\n",
      "Penalización por duración del episodio: -  0.39652529533631925\n",
      "Recompensa por acortar distancias: +  0.6866606008674346\n",
      "Penalización por duración del episodio: -  0.39689671138485627\n",
      "Recompensa por acortar distancias: +  0.6847853884338435\n",
      "Penalización por duración del episodio: -  0.39699222797741124\n",
      "Recompensa por acortar distancias: +  0.6847853884338435\n",
      "Penalización por duración del episodio: -  0.3972619608911903\n",
      "Recompensa por acortar distancias: +  0.6795083792849953\n",
      "Penalización por duración del episodio: -  0.3976284213501326\n",
      "Step: 6180, Mean Reward (últimos 10 pasos): 0.2818799614906311\n",
      "Recompensa por acortar distancias: +  0.6774041846118187\n",
      "Penalización por duración del episodio: -  0.3980019486382608\n",
      "Recompensa por acortar distancias: +  0.6742723774924102\n",
      "Penalización por duración del episodio: -  0.39837870330506797\n",
      "Recompensa por acortar distancias: +  0.6742723774924102\n",
      "Penalización por duración del episodio: -  0.39848917068782963\n",
      "Recompensa por acortar distancias: +  0.6742723774924102\n",
      "Penalización por duración del episodio: -  0.39875191438032304\n",
      "Recompensa por acortar distancias: +  0.6742723774924102\n",
      "Penalización por duración del episodio: -  0.39912426538350554\n",
      "Recompensa por acortar distancias: +  0.6628093404006098\n",
      "Penalización por duración del episodio: -  0.39950411141678366\n",
      "Recompensa por acortar distancias: +  0.6628093404006098\n",
      "Penalización por duración del episodio: -  0.3999003046341725\n",
      "steer input from model: 0.0 , throttle:  1.0\n",
      "reward: 0.2629090357664373\n",
      "Recompensa por acortar distancias: +  0.6539163368301364\n",
      "Penalización por duración del episodio: -  0.40028414032261034\n",
      "Recompensa por acortar distancias: +  0.6510636006864754\n",
      "Penalización por duración del episodio: -  0.40067215191042327\n",
      "Recompensa por acortar distancias: +  0.6510636006864754\n",
      "Penalización por duración del episodio: -  0.4010559870605767\n",
      "Step: 6190, Mean Reward (últimos 10 pasos): 0.25000759959220886\n",
      "Recompensa por acortar distancias: +  0.6510636006864754\n",
      "Penalización por duración del episodio: -  0.40143936500592453\n",
      "Recompensa por acortar distancias: +  0.6395375966485646\n",
      "Penalización por duración del episodio: -  0.40182978048953477\n",
      "Recompensa por acortar distancias: +  0.6395375966485646\n",
      "Penalización por duración del episodio: -  0.40195944423995605\n",
      "Recompensa por acortar distancias: +  0.6331468817009324\n",
      "Penalización por duración del episodio: -  0.40221259884640015\n",
      "Recompensa por acortar distancias: +  0.6309683313416417\n",
      "Penalización por duración del episodio: -  0.402585604744387\n",
      "Recompensa por acortar distancias: +  0.6262448127050831\n",
      "Penalización por duración del episodio: -  0.40296948406378713\n",
      "Recompensa por acortar distancias: +  0.6262448127050831\n",
      "Penalización por duración del episodio: -  0.4030567889847978\n",
      "Recompensa por acortar distancias: +  0.6262448127050831\n",
      "Penalización por duración del episodio: -  0.40333434697575277\n",
      "Recompensa por acortar distancias: +  0.6262448127050831\n",
      "Penalización por duración del episodio: -  0.40346076596290686\n",
      "Recompensa por acortar distancias: +  0.6165842199089286\n",
      "Penalización por duración del episodio: -  0.40371449182349467\n",
      "Step: 6200, Mean Reward (últimos 10 pasos): 0.21286973357200623\n",
      "Recompensa por acortar distancias: +  0.6143353491544402\n",
      "Penalización por duración del episodio: -  0.404098392215094\n",
      "Recompensa por acortar distancias: +  0.6143353491544402\n",
      "Penalización por duración del episodio: -  0.40447554723724044\n",
      "Recompensa por acortar distancias: +  0.6064051287326392\n",
      "Penalización por duración del episodio: -  0.40484865026892486\n",
      "Recompensa por acortar distancias: +  0.6020422989587397\n",
      "Penalización por duración del episodio: -  0.4052239204552426\n",
      "Recompensa por acortar distancias: +  0.6006889634792422\n",
      "Penalización por duración del episodio: -  0.40530861806259255\n",
      "Recompensa por acortar distancias: +  0.6006889634792422\n",
      "Penalización por duración del episodio: -  0.40561222299529615\n",
      "Recompensa por acortar distancias: +  0.6006889634792422\n",
      "Penalización por duración del episodio: -  0.4056985559670855\n",
      "steer input from model: -0.9 , throttle:  0.0\n",
      "reward: 0.19499040751215668\n",
      "Recompensa por acortar distancias: +  0.6006889634792422\n",
      "Penalización por duración del episodio: -  0.40598165793052127\n",
      "Recompensa por acortar distancias: +  0.5909251179630962\n",
      "Penalización por duración del episodio: -  0.4063503193545458\n",
      "Recompensa por acortar distancias: +  0.5889523624724333\n",
      "Penalización por duración del episodio: -  0.40643776032570245\n",
      "Step: 6210, Mean Reward (últimos 10 pasos): 0.18251460790634155\n",
      "Recompensa por acortar distancias: +  0.5889523624724333\n",
      "Penalización por duración del episodio: -  0.40656179714318397\n",
      "Recompensa por acortar distancias: +  0.5889523624724333\n",
      "Penalización por duración del episodio: -  0.40664659470544096\n",
      "Recompensa por acortar distancias: +  0.5833787096793626\n",
      "Penalización por duración del episodio: -  0.4071089861337554\n",
      "Recompensa por acortar distancias: +  0.5798087851402511\n",
      "Penalización por duración del episodio: -  0.4074923024718939\n",
      "Recompensa por acortar distancias: +  0.5759214691922835\n",
      "Penalización por duración del episodio: -  0.40787044549067486\n",
      "Recompensa por acortar distancias: +  0.5759214691922835\n",
      "Penalización por duración del episodio: -  0.4082589385222043\n",
      "Recompensa por acortar distancias: +  0.5759214691922835\n",
      "Penalización por duración del episodio: -  0.40838167408661197\n",
      "Recompensa por acortar distancias: +  0.5662588666492213\n",
      "Penalización por duración del episodio: -  0.40864690669002823\n",
      "Recompensa por acortar distancias: +  0.5638423534453594\n",
      "Penalización por duración del episodio: -  0.40875022585082704\n",
      "Recompensa por acortar distancias: +  0.5638423534453594\n",
      "Penalización por duración del episodio: -  0.40901599338179057\n",
      "Step: 6220, Mean Reward (últimos 10 pasos): 0.154826357960701\n",
      "Recompensa por acortar distancias: +  0.5638423534453594\n",
      "Penalización por duración del episodio: -  0.4091253123482261\n",
      "Recompensa por acortar distancias: +  0.5638423534453594\n",
      "Penalización por duración del episodio: -  0.4093988335265629\n",
      "Recompensa por acortar distancias: +  0.5562603916908236\n",
      "Penalización por duración del episodio: -  0.40951818085820196\n",
      "Recompensa por acortar distancias: +  0.5562603916908236\n",
      "Penalización por duración del episodio: -  0.40978535295336244\n",
      "Recompensa por acortar distancias: +  0.5516886798656173\n",
      "Penalización por duración del episodio: -  0.41017032842438744\n",
      "Recompensa por acortar distancias: +  0.5516886798656173\n",
      "Penalización por duración del episodio: -  0.4105299697525881\n",
      "Recompensa por acortar distancias: +  0.5516886798656173\n",
      "Penalización por duración del episodio: -  0.41062654498379025\n",
      "steer input from model: 0.05 , throttle:  0.0\n",
      "reward: 0.14106213488182706\n",
      "Recompensa por acortar distancias: +  0.5516886798656173\n",
      "Penalización por duración del episodio: -  0.41074794597776404\n",
      "Recompensa por acortar distancias: +  0.5516886798656173\n",
      "Penalización por duración del episodio: -  0.41085013458330066\n",
      "Recompensa por acortar distancias: +  0.542170916024016\n",
      "Penalización por duración del episodio: -  0.41128359245548\n",
      "Step: 6230, Mean Reward (últimos 10 pasos): 0.13088732957839966\n",
      "Recompensa por acortar distancias: +  0.5386158971906747\n",
      "Penalización por duración del episodio: -  0.4114116972239575\n",
      "Recompensa por acortar distancias: +  0.5386158971906747\n",
      "Penalización por duración del episodio: -  0.4115700291377224\n",
      "Recompensa por acortar distancias: +  0.5386158971906747\n",
      "Penalización por duración del episodio: -  0.41203903514748375\n",
      "Recompensa por acortar distancias: +  0.5315224971199549\n",
      "Penalización por duración del episodio: -  0.4121388364366251\n",
      "Recompensa por acortar distancias: +  0.5295061799290308\n",
      "Penalización por duración del episodio: -  0.41242058673788706\n",
      "Recompensa por acortar distancias: +  0.5279039364290208\n",
      "Penalización por duración del episodio: -  0.4127880499816453\n",
      "Recompensa por acortar distancias: +  0.5279039364290208\n",
      "Penalización por duración del episodio: -  0.4131643218839101\n",
      "Recompensa por acortar distancias: +  0.5279039364290208\n",
      "Penalización por duración del episodio: -  0.4132736967548659\n",
      "Recompensa por acortar distancias: +  0.5279039364290208\n",
      "Penalización por duración del episodio: -  0.4134553692841274\n",
      "Recompensa por acortar distancias: +  0.5176454667045722\n",
      "Penalización por duración del episodio: -  0.4136120903792545\n",
      "Step: 6240, Mean Reward (últimos 10 pasos): 0.10403337329626083\n",
      "Recompensa por acortar distancias: +  0.5176454667045722\n",
      "Penalización por duración del episodio: -  0.41393662640089546\n",
      "Recompensa por acortar distancias: +  0.5145864272833454\n",
      "Penalización por duración del episodio: -  0.4143261138866869\n",
      "Recompensa por acortar distancias: +  0.5145864272833454\n",
      "Penalización por duración del episodio: -  0.4144601405192145\n",
      "Recompensa por acortar distancias: +  0.5094777435792215\n",
      "Penalización por duración del episodio: -  0.41458113697355814\n",
      "Recompensa por acortar distancias: +  0.5094777435792215\n",
      "Penalización por duración del episodio: -  0.41473296561740564\n",
      "Recompensa por acortar distancias: +  0.506268637725318\n",
      "Penalización por duración del episodio: -  0.414844233191779\n",
      "Recompensa por acortar distancias: +  0.506268637725318\n",
      "Penalización por duración del episodio: -  0.4150864406184165\n",
      "steer input from model: 0.25 , throttle:  0.0\n",
      "reward: 0.09118219710690156\n",
      "Recompensa por acortar distancias: +  0.5047119593393804\n",
      "Penalización por duración del episodio: -  0.415456261409798\n",
      "Recompensa por acortar distancias: +  0.5047119593393804\n",
      "Penalización por duración del episodio: -  0.41555740558696436\n",
      "Recompensa por acortar distancias: +  0.5047119593393804\n",
      "Penalización por duración del episodio: -  0.41567363058129947\n",
      "Step: 6250, Mean Reward (últimos 10 pasos): 0.08903832733631134\n",
      "Recompensa por acortar distancias: +  0.5047119593393804\n",
      "Penalización por duración del episodio: -  0.41582112723738257\n",
      "Recompensa por acortar distancias: +  0.5047119593393804\n",
      "Penalización por duración del episodio: -  0.4162071372007373\n",
      "Recompensa por acortar distancias: +  0.4951111742228093\n",
      "Penalización por duración del episodio: -  0.4165970917889394\n",
      "Recompensa por acortar distancias: +  0.4951111742228093\n",
      "Penalización por duración del episodio: -  0.4167006047512118\n",
      "Recompensa por acortar distancias: +  0.4951111742228093\n",
      "Penalización por duración del episodio: -  0.41681667803904954\n",
      "Recompensa por acortar distancias: +  0.49044552536339164\n",
      "Penalización por duración del episodio: -  0.4169016945774156\n",
      "Recompensa por acortar distancias: +  0.48872250285210234\n",
      "Penalización por duración del episodio: -  0.4173639152415558\n",
      "Recompensa por acortar distancias: +  0.48735028486361415\n",
      "Penalización por duración del episodio: -  0.4174892136969311\n",
      "Recompensa por acortar distancias: +  0.48735028486361415\n",
      "Penalización por duración del episodio: -  0.41773970337574706\n",
      "Recompensa por acortar distancias: +  0.48735028486361415\n",
      "Penalización por duración del episodio: -  0.4181155928524396\n",
      "Step: 6260, Mean Reward (últimos 10 pasos): 0.0692346915602684\n",
      "Recompensa por acortar distancias: +  0.48735028486361415\n",
      "Penalización por duración del episodio: -  0.41822811721810277\n",
      "Recompensa por acortar distancias: +  0.48735028486361415\n",
      "Penalización por duración del episodio: -  0.4185192825940453\n",
      "Recompensa por acortar distancias: +  0.47722096036865674\n",
      "Penalización por duración del episodio: -  0.41864441175501405\n",
      "Recompensa por acortar distancias: +  0.47722096036865674\n",
      "Penalización por duración del episodio: -  0.41890643645508857\n",
      "Recompensa por acortar distancias: +  0.47722096036865674\n",
      "Penalización por duración del episodio: -  0.41929357410514484\n",
      "Recompensa por acortar distancias: +  0.4723346907103262\n",
      "Penalización por duración del episodio: -  0.41939084866679627\n",
      "Recompensa por acortar distancias: +  0.47051330235620703\n",
      "Penalización por duración del episodio: -  0.4195246723811837\n",
      "steer input from model: 0.25 , throttle:  0.7\n",
      "reward: 0.05098862997502335\n",
      "Recompensa por acortar distancias: +  0.47051330235620703\n",
      "Penalización por duración del episodio: -  0.4196705043563651\n",
      "Recompensa por acortar distancias: +  0.4689134403629951\n",
      "Penalización por duración del episodio: -  0.42003942032624286\n",
      "Recompensa por acortar distancias: +  0.4689134403629951\n",
      "Penalización por duración del episodio: -  0.4204090472723916\n",
      "Step: 6270, Mean Reward (últimos 10 pasos): 0.04850439354777336\n",
      "Recompensa por acortar distancias: +  0.4689134403629951\n",
      "Penalización por duración del episodio: -  0.42056203471096193\n",
      "Recompensa por acortar distancias: +  0.4689134403629951\n",
      "Penalización por duración del episodio: -  0.42069000558360753\n",
      "Recompensa por acortar distancias: +  0.46150279282917483\n",
      "Penalización por duración del episodio: -  0.4208076784701262\n",
      "Recompensa por acortar distancias: +  0.46150279282917483\n",
      "Penalización por duración del episodio: -  0.42091279618998895\n",
      "Recompensa por acortar distancias: +  0.46007553525605754\n",
      "Penalización por duración del episodio: -  0.4211691963275632\n",
      "Recompensa por acortar distancias: +  0.46007553525605754\n",
      "Penalización por duración del episodio: -  0.421292456958893\n",
      "Recompensa por acortar distancias: +  0.46007553525605754\n",
      "Penalización por duración del episodio: -  0.4215478270323967\n",
      "Recompensa por acortar distancias: +  0.46007553525605754\n",
      "Penalización por duración del episodio: -  0.42192941105689696\n",
      "Recompensa por acortar distancias: +  0.45319370751020716\n",
      "Penalización por duración del episodio: -  0.42203534338209375\n",
      "Recompensa por acortar distancias: +  0.45319370751020716\n",
      "Penalización por duración del episodio: -  0.4221693450219926\n",
      "Step: 6280, Mean Reward (últimos 10 pasos): 0.03102436289191246\n",
      "Recompensa por acortar distancias: +  0.45319370751020716\n",
      "Penalización por duración del episodio: -  0.4223204471988483\n",
      "Recompensa por acortar distancias: +  0.45319370751020716\n",
      "Penalización por duración del episodio: -  0.4226904671940643\n",
      "Recompensa por acortar distancias: +  0.45319370751020716\n",
      "Penalización por duración del episodio: -  0.42278789206255324\n",
      "Recompensa por acortar distancias: +  0.45319370751020716\n",
      "Penalización por duración del episodio: -  0.42306708580404334\n",
      "Recompensa por acortar distancias: +  0.44627732299039463\n",
      "Penalización por duración del episodio: -  0.42315264422806237\n",
      "Recompensa por acortar distancias: +  0.44627732299039463\n",
      "Penalización por duración del episodio: -  0.4233002436313992\n",
      "Recompensa por acortar distancias: +  0.4448416375124883\n",
      "Penalización por duración del episodio: -  0.4234435377382824\n",
      "steer input from model: -0.9 , throttle:  0.3\n",
      "reward: 0.02139809977420587\n",
      "Recompensa por acortar distancias: +  0.4448416375124883\n",
      "Penalización por duración del episodio: -  0.42381361605216644\n",
      "Recompensa por acortar distancias: +  0.4448416375124883\n",
      "Penalización por duración del episodio: -  0.4239089961648767\n",
      "Recompensa por acortar distancias: +  0.4448416375124883\n",
      "Penalización por duración del episodio: -  0.42420274100879485\n",
      "Step: 6290, Mean Reward (últimos 10 pasos): 0.02063889615237713\n",
      "Recompensa por acortar distancias: +  0.43925570069399583\n",
      "Penalización por duración del episodio: -  0.4243711475950293\n",
      "Recompensa por acortar distancias: +  0.43925570069399583\n",
      "Penalización por duración del episodio: -  0.4245703672382371\n",
      "Recompensa por acortar distancias: +  0.43773555881745857\n",
      "Penalización por duración del episodio: -  0.42473903347880887\n",
      "Recompensa por acortar distancias: +  0.43773555881745857\n",
      "Penalización por duración del episodio: -  0.42496159720657684\n",
      "Recompensa por acortar distancias: +  0.43773555881745857\n",
      "Penalización por duración del episodio: -  0.42533190113237906\n",
      "Recompensa por acortar distancias: +  0.43773555881745857\n",
      "Penalización por duración del episodio: -  0.4254435081228196\n",
      "Recompensa por acortar distancias: +  0.43773555881745857\n",
      "Penalización por duración del episodio: -  0.4255682423398436\n",
      "Recompensa por acortar distancias: +  0.43773555881745857\n",
      "Penalización por duración del episodio: -  0.42572914843418047\n",
      "Recompensa por acortar distancias: +  0.4308734503380275\n",
      "Penalización por duración del episodio: -  0.42609780655208795\n",
      "Recompensa por acortar distancias: +  0.4295306034888016\n",
      "Penalización por duración del episodio: -  0.4264758190209704\n",
      "Step: 6300, Mean Reward (últimos 10 pasos): 0.0030547843780368567\n",
      "Recompensa por acortar distancias: +  0.42681949198149416\n",
      "Penalización por duración del episodio: -  0.4265932653552816\n",
      "Recompensa por acortar distancias: +  0.42681949198149416\n",
      "Penalización por duración del episodio: -  0.42686319175615933\n",
      "Recompensa por acortar distancias: +  0.4248944223146665\n",
      "Penalización por duración del episodio: -  0.42723512344205056\n",
      "Recompensa por acortar distancias: +  0.4248944223146665\n",
      "Penalización por duración del episodio: -  0.427621848814268\n",
      "Recompensa por acortar distancias: +  0.4248944223146665\n",
      "Penalización por duración del episodio: -  0.4277194981684737\n",
      "Recompensa por acortar distancias: +  0.4248944223146665\n",
      "Penalización por duración del episodio: -  0.4280043491949667\n",
      "Recompensa por acortar distancias: +  0.4192653989762541\n",
      "Penalización por duración del episodio: -  0.4283789431789109\n",
      "steer input from model: 0.05 , throttle:  0.0\n",
      "reward: -0.00911354420265681\n",
      "Recompensa por acortar distancias: +  0.4192653989762541\n",
      "Penalización por duración del episodio: -  0.4287653974594187\n",
      "Recompensa por acortar distancias: +  0.41647770724087846\n",
      "Penalización por duración del episodio: -  0.4291511092399009\n",
      "Recompensa por acortar distancias: +  0.4144199716997883\n",
      "Penalización por duración del episodio: -  0.42928621779921344\n",
      "Step: 6310, Mean Reward (últimos 10 pasos): -0.014866245910525322\n",
      "Recompensa por acortar distancias: +  0.4144199716997883\n",
      "Penalización por duración del episodio: -  0.4294329035010978\n",
      "Recompensa por acortar distancias: +  0.4134077938134448\n",
      "Penalización por duración del episodio: -  0.429566666944459\n",
      "Recompensa por acortar distancias: +  0.4134077938134448\n",
      "Penalización por duración del episodio: -  0.42971332958027836\n",
      "Recompensa por acortar distancias: +  0.4134077938134448\n",
      "Penalización por duración del episodio: -  0.42982962032767297\n",
      "Recompensa por acortar distancias: +  0.4134077938134448\n",
      "Penalización por duración del episodio: -  0.43031104447198576\n",
      "Recompensa por acortar distancias: +  0.4134077938134448\n",
      "Penalización por duración del episodio: -  0.4306845471152477\n",
      "Recompensa por acortar distancias: +  0.40874268636759786\n",
      "Penalización por duración del episodio: -  0.4310575439350436\n",
      "Recompensa por acortar distancias: +  0.40874268636759786\n",
      "Penalización por duración del episodio: -  0.43144695355246687\n",
      "Recompensa por acortar distancias: +  0.4063556422539643\n",
      "Penalización por duración del episodio: -  0.43183999870917333\n",
      "Recompensa por acortar distancias: +  0.40545833381818014\n",
      "Penalización por duración del episodio: -  0.4319192638931134\n",
      "Step: 6320, Mean Reward (últimos 10 pasos): -0.026460930705070496\n",
      "Recompensa por acortar distancias: +  0.40545833381818014\n",
      "Penalización por duración del episodio: -  0.43220679467294976\n",
      "Recompensa por acortar distancias: +  0.40545833381818014\n",
      "Penalización por duración del episodio: -  0.43258862294255485\n",
      "Recompensa por acortar distancias: +  0.40545833381818014\n",
      "Penalización por duración del episodio: -  0.43272411041218584\n",
      "Recompensa por acortar distancias: +  0.40545833381818014\n",
      "Penalización por duración del episodio: -  0.4329651520939277\n",
      "Recompensa por acortar distancias: +  0.40269589583833204\n",
      "Penalización por duración del episodio: -  0.4333671148162339\n",
      "Recompensa por acortar distancias: +  0.40269589583833204\n",
      "Penalización por duración del episodio: -  0.4337388554486777\n",
      "Recompensa por acortar distancias: +  0.4022134673173773\n",
      "Penalización por duración del episodio: -  0.434124668839783\n",
      "steer input from model: -0.1 , throttle:  0.0\n",
      "reward: -0.03191120152240573\n",
      "Recompensa por acortar distancias: +  0.4021997782224671\n",
      "Penalización por duración del episodio: -  0.43424354046835\n",
      "Recompensa por acortar distancias: +  0.4021997782224671\n",
      "Penalización por duración del episodio: -  0.43451943142932475\n",
      "Recompensa por acortar distancias: +  0.4021997782224671\n",
      "Penalización por duración del episodio: -  0.43468209830058074\n",
      "Step: 6330, Mean Reward (últimos 10 pasos): -0.032482318580150604\n",
      "Recompensa por acortar distancias: +  0.4021997782224671\n",
      "Penalización por duración del episodio: -  0.43480152674542216\n",
      "Recompensa por acortar distancias: +  0.4021997782224671\n",
      "Penalización por duración del episodio: -  0.43527789781358955\n",
      "Recompensa por acortar distancias: +  0.4021974336649693\n",
      "Penalización por duración del episodio: -  0.4356690856581078\n",
      "Recompensa por acortar distancias: +  0.4021974336649693\n",
      "Penalización por duración del episodio: -  0.43577882748554464\n",
      "Recompensa por acortar distancias: +  0.4021974336649693\n",
      "Penalización por duración del episodio: -  0.4360637013716192\n",
      "Recompensa por acortar distancias: +  0.4021974336649693\n",
      "Penalización por duración del episodio: -  0.43618309339582584\n",
      "Recompensa por acortar distancias: +  0.4022047797689937\n",
      "Penalización por duración del episodio: -  0.4364360145457625\n",
      "Recompensa por acortar distancias: +  0.4022066055535123\n",
      "Penalización por duración del episodio: -  0.4365371676411775\n",
      "Recompensa por acortar distancias: +  0.40220902751675197\n",
      "Penalización por duración del episodio: -  0.43680873369988304\n",
      "Recompensa por acortar distancias: +  0.40221120012215594\n",
      "Penalización por duración del episodio: -  0.43719309277247365\n",
      "Step: 6340, Mean Reward (últimos 10 pasos): -0.03498189151287079\n",
      "Recompensa por acortar distancias: +  0.40221120012215594\n",
      "Penalización por duración del episodio: -  0.437566977428284\n",
      "Recompensa por acortar distancias: +  0.40221120012215594\n",
      "Penalización por duración del episodio: -  0.43769846146158575\n",
      "Recompensa por acortar distancias: +  0.40221120012215594\n",
      "Penalización por duración del episodio: -  0.43795654367162906\n",
      "Recompensa por acortar distancias: +  0.40214863750249785\n",
      "Penalización por duración del episodio: -  0.4383515338632777\n",
      "Recompensa por acortar distancias: +  0.4021187617367093\n",
      "Penalización por duración del episodio: -  0.4387389405500935\n",
      "Recompensa por acortar distancias: +  0.4020922656588216\n",
      "Penalización por duración del episodio: -  0.43913362702620923\n",
      "Recompensa por acortar distancias: +  0.4020680313477487\n",
      "Penalización por duración del episodio: -  0.43926516129926785\n",
      "steer input from model: 0.05 , throttle:  0.0\n",
      "reward: -0.03719712995151914\n",
      "Recompensa por acortar distancias: +  0.40206953594750294\n",
      "Penalización por duración del episodio: -  0.4395077812787192\n",
      "Recompensa por acortar distancias: +  0.40206953594750294\n",
      "Penalización por duración del episodio: -  0.43989980936547446\n",
      "Recompensa por acortar distancias: +  0.40206953594750294\n",
      "Penalización por duración del episodio: -  0.4402751145507365\n",
      "Step: 6350, Mean Reward (últimos 10 pasos): -0.0382055789232254\n",
      "Recompensa por acortar distancias: +  0.4020330936272208\n",
      "Penalización por duración del episodio: -  0.4404233919508359\n",
      "Recompensa por acortar distancias: +  0.4020330936272208\n",
      "Penalización por duración del episodio: -  0.44066563177892343\n",
      "Recompensa por acortar distancias: +  0.40200076186133693\n",
      "Penalización por duración del episodio: -  0.44105713935491314\n",
      "Recompensa por acortar distancias: +  0.40200076186133693\n",
      "Penalización por duración del episodio: -  0.4414516243343763\n",
      "Recompensa por acortar distancias: +  0.40195140612125907\n",
      "Penalización por duración del episodio: -  0.441549184228278\n",
      "Recompensa por acortar distancias: +  0.40195140612125907\n",
      "Penalización por duración del episodio: -  0.44166924288169324\n",
      "Recompensa por acortar distancias: +  0.4019521225289857\n",
      "Penalización por duración del episodio: -  0.44184899379340775\n",
      "Recompensa por acortar distancias: +  0.4019521225289857\n",
      "Penalización por duración del episodio: -  0.44198732159137827\n",
      "Recompensa por acortar distancias: +  0.4019521225289857\n",
      "Penalización por duración del episodio: -  0.4420994898483003\n",
      "Recompensa por acortar distancias: +  0.4019521225289857\n",
      "Penalización por duración del episodio: -  0.44222247303274304\n",
      "Step: 6360, Mean Reward (últimos 10 pasos): -0.040270350873470306\n",
      "Recompensa por acortar distancias: +  0.4019521225289857\n",
      "Penalización por duración del episodio: -  0.4426102224660288\n",
      "Recompensa por acortar distancias: +  0.4019521225289857\n",
      "Penalización por duración del episodio: -  0.4430041778362553\n",
      "Recompensa por acortar distancias: +  0.4019270485076857\n",
      "Penalización por duración del episodio: -  0.4433807469197207\n",
      "Recompensa por acortar distancias: +  0.4019270485076857\n",
      "Penalización por duración del episodio: -  0.44377284703796904\n",
      "Recompensa por acortar distancias: +  0.4018606950932165\n",
      "Penalización por duración del episodio: -  0.443901457644289\n",
      "Recompensa por acortar distancias: +  0.4018606950932165\n",
      "Penalización por duración del episodio: -  0.44407138253657935\n",
      "Recompensa por acortar distancias: +  0.401816728910024\n",
      "Penalización por duración del episodio: -  0.4445584991558008\n",
      "steer input from model: 0.0 , throttle:  0.0\n",
      "reward: -0.0427417702457768\n",
      "Recompensa por acortar distancias: +  0.4018036029722833\n",
      "Penalización por duración del episodio: -  0.4449493243965648\n",
      "Recompensa por acortar distancias: +  0.4018036029722833\n",
      "Penalización por duración del episodio: -  0.44513266718395283\n",
      "Recompensa por acortar distancias: +  0.4018036029722833\n",
      "Penalización por duración del episodio: -  0.4453110485645699\n",
      "Step: 6370, Mean Reward (últimos 10 pasos): -0.043507445603609085\n",
      "Recompensa por acortar distancias: +  0.4018036029722833\n",
      "Penalización por duración del episodio: -  0.4454342118463242\n",
      "Recompensa por acortar distancias: +  0.40161244900873505\n",
      "Penalización por duración del episodio: -  0.44568766199263427\n",
      "Recompensa por acortar distancias: +  0.4015510685682861\n",
      "Penalización por duración del episodio: -  0.44607278565844927\n",
      "Recompensa por acortar distancias: +  0.4015510685682861\n",
      "Penalización por duración del episodio: -  0.4464549514227733\n",
      "Recompensa por acortar distancias: +  0.40152879865350194\n",
      "Penalización por duración del episodio: -  0.44657863008434484\n",
      "Recompensa por acortar distancias: +  0.40152879865350194\n",
      "Penalización por duración del episodio: -  0.4468359016875739\n",
      "Recompensa por acortar distancias: +  0.40152879865350194\n",
      "Penalización por duración del episodio: -  0.44694197949831405\n",
      "Recompensa por acortar distancias: +  0.40152879865350194\n",
      "Penalización por duración del episodio: -  0.4472309245655564\n",
      "Recompensa por acortar distancias: +  0.40152879865350194\n",
      "Penalización por duración del episodio: -  0.4476047388754673\n",
      "Recompensa por acortar distancias: +  0.4015243527402794\n",
      "Penalización por duración del episodio: -  0.44797500999912804\n",
      "Step: 6380, Mean Reward (últimos 10 pasos): -0.0464506559073925\n",
      "Recompensa por acortar distancias: +  0.4014989551987017\n",
      "Penalización por duración del episodio: -  0.44836792385784735\n",
      "Recompensa por acortar distancias: +  0.4014989551987017\n",
      "Penalización por duración del episodio: -  0.4484790595087862\n",
      "Recompensa por acortar distancias: +  0.40148326318544664\n",
      "Penalización por duración del episodio: -  0.4487662456578958\n",
      "Recompensa por acortar distancias: +  0.4014762221834191\n",
      "Penalización por duración del episodio: -  0.4491614360134821\n",
      "Recompensa por acortar distancias: +  0.4014769497708421\n",
      "Penalización por duración del episodio: -  0.44954546327058137\n",
      "Recompensa por acortar distancias: +  0.4014769497708421\n",
      "Penalización por duración del episodio: -  0.4496577738851466\n",
      "Recompensa por acortar distancias: +  0.4014769497708421\n",
      "Penalización por duración del episodio: -  0.4497864040443118\n",
      "steer input from model: -0.9 , throttle:  0.0\n",
      "reward: -0.04830945427346972\n",
      "Recompensa por acortar distancias: +  0.4014769497708421\n",
      "Penalización por duración del episodio: -  0.4499308488290474\n",
      "Recompensa por acortar distancias: +  0.4014769497708421\n",
      "Penalización por duración del episodio: -  0.45005547464367984\n",
      "Recompensa por acortar distancias: +  0.4014769497708421\n",
      "Penalización por duración del episodio: -  0.4502047093203462\n",
      "Step: 6390, Mean Reward (últimos 10 pasos): -0.04872775822877884\n",
      "Recompensa por acortar distancias: +  0.4014769497708421\n",
      "Penalización por duración del episodio: -  0.4506943862455731\n",
      "Recompensa por acortar distancias: +  0.4014779294364831\n",
      "Penalización por duración del episodio: -  0.45109186862475825\n",
      "Recompensa por acortar distancias: +  0.4014779294364831\n",
      "Penalización por duración del episodio: -  0.45121923842836\n",
      "Recompensa por acortar distancias: +  0.4014770357063931\n",
      "Penalización por duración del episodio: -  0.45148776611242136\n",
      "Recompensa por acortar distancias: +  0.4014775284036694\n",
      "Penalización por duración del episodio: -  0.4518838372161899\n",
      "Recompensa por acortar distancias: +  0.4014775284036694\n",
      "Penalización por duración del episodio: -  0.4522820541579922\n",
      "Recompensa por acortar distancias: +  0.4014775284036694\n",
      "Penalización por duración del episodio: -  0.45236412768355927\n",
      "Recompensa por acortar distancias: +  0.4014775284036694\n",
      "Penalización por duración del episodio: -  0.4526775795038956\n",
      "Recompensa por acortar distancias: +  0.4014838590084764\n",
      "Penalización por duración del episodio: -  0.45279138173195443\n",
      "Recompensa por acortar distancias: +  0.4014838590084764\n",
      "Penalización por duración del episodio: -  0.45289314926448226\n",
      "Step: 6400, Mean Reward (últimos 10 pasos): -0.0514092892408371\n",
      "Recompensa por acortar distancias: +  0.4014838590084764\n",
      "Penalización por duración del episodio: -  0.45307132133581723\n",
      "Recompensa por acortar distancias: +  0.4014838590084764\n",
      "Penalización por duración del episodio: -  0.4534482463181545\n",
      "Recompensa por acortar distancias: +  0.4014554975822364\n",
      "Penalización por duración del episodio: -  0.4535606399281868\n",
      "Recompensa por acortar distancias: +  0.40144454963518744\n",
      "Penalización por duración del episodio: -  0.4536772043288406\n",
      "Recompensa por acortar distancias: +  0.40144454963518744\n",
      "Penalización por duración del episodio: -  0.45378859703741403\n",
      "Recompensa por acortar distancias: +  0.4014508743398574\n",
      "Penalización por duración del episodio: -  0.4539089359084296\n",
      "Recompensa por acortar distancias: +  0.4014508743398574\n",
      "Penalización por duración del episodio: -  0.454012353751165\n",
      "steer input from model: -0.9 , throttle:  0.3\n",
      "reward: -0.05256147941130762\n",
      "Recompensa por acortar distancias: +  0.40144601623044956\n",
      "Penalización por duración del episodio: -  0.4542145734199673\n",
      "Recompensa por acortar distancias: +  0.40144601623044956\n",
      "Penalización por duración del episodio: -  0.4543382058480614\n",
      "Recompensa por acortar distancias: +  0.40144601623044956\n",
      "Penalización por duración del episodio: -  0.4544488396872345\n",
      "Step: 6410, Mean Reward (últimos 10 pasos): -0.053002823144197464\n",
      "Recompensa por acortar distancias: +  0.40144601623044956\n",
      "Penalización por duración del episodio: -  0.45455055207424117\n",
      "Recompensa por acortar distancias: +  0.40144601623044956\n",
      "Penalización por duración del episodio: -  0.4546513046904276\n",
      "Recompensa por acortar distancias: +  0.40144601623044956\n",
      "Penalización por duración del episodio: -  0.45477788914594164\n",
      "Recompensa por acortar distancias: +  0.40144601623044956\n",
      "Penalización por duración del episodio: -  0.4549892408028123\n",
      "Recompensa por acortar distancias: +  0.40144601623044956\n",
      "Penalización por duración del episodio: -  0.45537924042170963\n",
      "Recompensa por acortar distancias: +  0.4014109100908018\n",
      "Penalización por duración del episodio: -  0.4557640019135003\n",
      "Recompensa por acortar distancias: +  0.4014121675468472\n",
      "Penalización por duración del episodio: -  0.4558987986257522\n",
      "Recompensa por acortar distancias: +  0.4014121675468472\n",
      "Penalización por duración del episodio: -  0.45598558929449584\n",
      "Recompensa por acortar distancias: +  0.4014121675468472\n",
      "Penalización por duración del episodio: -  0.4560951947944937\n",
      "Recompensa por acortar distancias: +  0.401411202255872\n",
      "Penalización por duración del episodio: -  0.4562083474756832\n",
      "Step: 6420, Mean Reward (últimos 10 pasos): -0.05479714646935463\n",
      "Recompensa por acortar distancias: +  0.401411202255872\n",
      "Penalización por duración del episodio: -  0.4565280868953007\n",
      "Recompensa por acortar distancias: +  0.40141283207995115\n",
      "Penalización por duración del episodio: -  0.45692096201367843\n",
      "Recompensa por acortar distancias: +  0.40141283207995115\n",
      "Penalización por duración del episodio: -  0.45730889676909353\n",
      "Recompensa por acortar distancias: +  0.40141283207995115\n",
      "Penalización por duración del episodio: -  0.45769261657729887\n",
      "Recompensa por acortar distancias: +  0.4014121732755793\n",
      "Penalización por duración del episodio: -  0.4577792661312776\n",
      "Recompensa por acortar distancias: +  0.4014121732755793\n",
      "Penalización por duración del episodio: -  0.45788780951512154\n",
      "Recompensa por acortar distancias: +  0.4014121732755793\n",
      "Penalización por duración del episodio: -  0.45808977440008375\n",
      "steer input from model: 0.9 , throttle:  0.0\n",
      "reward: -0.05667760112450443\n",
      "Recompensa por acortar distancias: +  0.4014121732755793\n",
      "Penalización por duración del episodio: -  0.458489075030499\n",
      "Recompensa por acortar distancias: +  0.4014106293832512\n",
      "Penalización por duración del episodio: -  0.4586037238014895\n",
      "Recompensa por acortar distancias: +  0.4014106293832512\n",
      "Penalización por duración del episodio: -  0.45870348861045307\n",
      "Step: 6430, Mean Reward (últimos 10 pasos): -0.05729286000132561\n",
      "Recompensa por acortar distancias: +  0.4014108184311863\n",
      "Penalización por duración del episodio: -  0.4588767189144791\n",
      "Recompensa por acortar distancias: +  0.40141141421881\n",
      "Penalización por duración del episodio: -  0.4589967936794395\n",
      "Recompensa por acortar distancias: +  0.40141141421881\n",
      "Penalización por duración del episodio: -  0.4592708959716993\n",
      "Recompensa por acortar distancias: +  0.40141141421881\n",
      "Penalización por duración del episodio: -  0.45965909573976454\n",
      "Recompensa por acortar distancias: +  0.40141141421881\n",
      "Penalización por duración del episodio: -  0.46005507321908473\n",
      "Recompensa por acortar distancias: +  0.4013790186895148\n",
      "Penalización por duración del episodio: -  0.4601426019319199\n",
      "Recompensa por acortar distancias: +  0.4013790186895148\n",
      "Penalización por duración del episodio: -  0.46030612297619694\n",
      "Recompensa por acortar distancias: +  0.4013657141438741\n",
      "Penalización por duración del episodio: -  0.4604423289259581\n",
      "Recompensa por acortar distancias: +  0.4013657141438741\n",
      "Penalización por duración del episodio: -  0.4605755435384112\n",
      "Recompensa por acortar distancias: +  0.4013657141438741\n",
      "Penalización por duración del episodio: -  0.4608243601444786\n",
      "Step: 6440, Mean Reward (últimos 10 pasos): -0.059458646923303604\n",
      "Recompensa por acortar distancias: +  0.4013657141438741\n",
      "Penalización por duración del episodio: -  0.46120874205584805\n",
      "Recompensa por acortar distancias: +  0.40131350272540334\n",
      "Penalización por duración del episodio: -  0.46133266906127995\n",
      "Recompensa por acortar distancias: +  0.40126789797387746\n",
      "Penalización por duración del episodio: -  0.4614781740078885\n",
      "Recompensa por acortar distancias: +  0.40126789797387746\n",
      "Penalización por duración del episodio: -  0.46200931250737426\n",
      "Recompensa por acortar distancias: +  0.40125817177811574\n",
      "Penalización por duración del episodio: -  0.4621028980850439\n",
      "Recompensa por acortar distancias: +  0.40125817177811574\n",
      "Penalización por duración del episodio: -  0.462397527536647\n",
      "Recompensa por acortar distancias: +  0.40125817177811574\n",
      "Penalización por duración del episodio: -  0.462539766747455\n",
      "steer input from model: 0.05 , throttle:  0.0\n",
      "reward: -0.06128159496933927\n",
      "Recompensa por acortar distancias: +  0.40125817177811574\n",
      "Penalización por duración del episodio: -  0.4626530041642874\n",
      "Recompensa por acortar distancias: +  0.4012559808171865\n",
      "Penalización por duración del episodio: -  0.46279168005243854\n",
      "Recompensa por acortar distancias: +  0.4012559808171865\n",
      "Penalización por duración del episodio: -  0.46317677937437723\n",
      "Step: 6450, Mean Reward (últimos 10 pasos): -0.06192079931497574\n",
      "Recompensa por acortar distancias: +  0.4012558662572464\n",
      "Penalización por duración del episodio: -  0.4635732941013879\n",
      "Recompensa por acortar distancias: +  0.40125954936472047\n",
      "Penalización por duración del episodio: -  0.4639703233270376\n",
      "Recompensa por acortar distancias: +  0.4012421592382917\n",
      "Penalización por duración del episodio: -  0.4643632174471136\n",
      "Recompensa por acortar distancias: +  0.4012421592382917\n",
      "Penalización por duración del episodio: -  0.46475963721623814\n",
      "Recompensa por acortar distancias: +  0.4012421592382917\n",
      "Penalización por duración del episodio: -  0.4648821233705191\n",
      "Recompensa por acortar distancias: +  0.4012421592382917\n",
      "Penalización por duración del episodio: -  0.4649822885460663\n",
      "Recompensa por acortar distancias: +  0.40124010864029686\n",
      "Penalización por duración del episodio: -  0.4655183695070971\n",
      "Recompensa por acortar distancias: +  0.4012289478344516\n",
      "Penalización por duración del episodio: -  0.4659082610814003\n",
      "Recompensa por acortar distancias: +  0.40119824683896943\n",
      "Penalización por duración del episodio: -  0.4660459985021868\n",
      "Recompensa por acortar distancias: +  0.40119824683896943\n",
      "Penalización por duración del episodio: -  0.46629181593061303\n",
      "Step: 6460, Mean Reward (últimos 10 pasos): -0.06509356945753098\n",
      "Recompensa por acortar distancias: +  0.4011793197178829\n",
      "Penalización por duración del episodio: -  0.46640426101886046\n",
      "Recompensa por acortar distancias: +  0.4011788844176117\n",
      "Penalización por duración del episodio: -  0.46655318436661297\n",
      "Recompensa por acortar distancias: +  0.4011788844176117\n",
      "Penalización por duración del episodio: -  0.4666727047394663\n",
      "Recompensa por acortar distancias: +  0.4011788844176117\n",
      "Penalización por duración del episodio: -  0.46708407101406074\n",
      "Recompensa por acortar distancias: +  0.4011788844176117\n",
      "Penalización por duración del episodio: -  0.4671908306293281\n",
      "Recompensa por acortar distancias: +  0.4011788844176117\n",
      "Penalización por duración del episodio: -  0.4672675208909276\n",
      "Recompensa por acortar distancias: +  0.4011788844176117\n",
      "Penalización por duración del episodio: -  0.467470708292674\n",
      "steer input from model: -0.25 , throttle:  0.0\n",
      "reward: -0.06629182387506233\n",
      "Recompensa por acortar distancias: +  0.4011788844176117\n",
      "Penalización por duración del episodio: -  0.467854660096528\n",
      "Recompensa por acortar distancias: +  0.40117790499257133\n",
      "Penalización por duración del episodio: -  0.4682462367155921\n",
      "Recompensa por acortar distancias: +  0.40117790499257133\n",
      "Penalización por duración del episodio: -  0.46862281401932815\n",
      "Step: 6470, Mean Reward (últimos 10 pasos): -0.06744490563869476\n",
      "Recompensa por acortar distancias: +  0.4011779393583488\n",
      "Penalización por duración del episodio: -  0.4687524740922176\n",
      "Recompensa por acortar distancias: +  0.4011779393583488\n",
      "Penalización por duración del episodio: -  0.46900865996745816\n",
      "Recompensa por acortar distancias: +  0.40117820282934213\n",
      "Penalización por duración del episodio: -  0.46939213802997676\n",
      "Recompensa por acortar distancias: +  0.40117820282934213\n",
      "Penalización por duración del episodio: -  0.4697757235039804\n",
      "Recompensa por acortar distancias: +  0.40117820282934213\n",
      "Penalización por duración del episodio: -  0.4701713003843098\n",
      "Recompensa por acortar distancias: +  0.4011774410546697\n",
      "Penalización por duración del episodio: -  0.4702753276625241\n",
      "Recompensa por acortar distancias: +  0.40117711171614334\n",
      "Penalización por duración del episodio: -  0.47041974663030206\n",
      "Recompensa por acortar distancias: +  0.40117711171614334\n",
      "Penalización por duración del episodio: -  0.4705503842832983\n",
      "Recompensa por acortar distancias: +  0.40117711171614334\n",
      "Penalización por duración del episodio: -  0.47067218136509115\n",
      "Recompensa por acortar distancias: +  0.40117711171614334\n",
      "Penalización por duración del episodio: -  0.4709427075020774\n",
      "Step: 6480, Mean Reward (últimos 10 pasos): -0.0697655975818634\n",
      "Recompensa por acortar distancias: +  0.40117711171614334\n",
      "Penalización por duración del episodio: -  0.47109133723488283\n",
      "Recompensa por acortar distancias: +  0.4011774410546697\n",
      "Penalización por duración del episodio: -  0.4713275751889668\n",
      "Recompensa por acortar distancias: +  0.4011766506423564\n",
      "Penalización por duración del episodio: -  0.4714788084474139\n",
      "Recompensa por acortar distancias: +  0.4011769828445703\n",
      "Penalización por duración del episodio: -  0.4717362425778852\n",
      "Recompensa por acortar distancias: +  0.4011769828445703\n",
      "Penalización por duración del episodio: -  0.4718683519978666\n",
      "Recompensa por acortar distancias: +  0.4011769828445703\n",
      "Penalización por duración del episodio: -  0.47213283220257196\n",
      "Recompensa por acortar distancias: +  0.4011769828445703\n",
      "Penalización por duración del episodio: -  0.4725326599978709\n",
      "steer input from model: 0.25 , throttle:  0.0\n",
      "reward: -0.0713556771533006\n",
      "Recompensa por acortar distancias: +  0.4011767365567134\n",
      "Penalización por duración del episodio: -  0.47265880270529387\n",
      "Recompensa por acortar distancias: +  0.4011767365567134\n",
      "Penalización por duración del episodio: -  0.4727831125770516\n",
      "Recompensa por acortar distancias: +  0.4011764272650566\n",
      "Penalización por duración del episodio: -  0.47292009624103853\n",
      "Step: 6490, Mean Reward (últimos 10 pasos): -0.0717436671257019\n",
      "Recompensa por acortar distancias: +  0.4011764272650566\n",
      "Penalización por duración del episodio: -  0.47331170770729575\n",
      "Recompensa por acortar distancias: +  0.4011764272650566\n",
      "Penalización por duración del episodio: -  0.4734090748555379\n",
      "Recompensa por acortar distancias: +  0.40117620961541944\n",
      "Penalización por duración del episodio: -  0.473712440363413\n",
      "Recompensa por acortar distancias: +  0.40117572563149745\n",
      "Penalización por duración del episodio: -  0.473861595218184\n",
      "Recompensa por acortar distancias: +  0.40117644444792433\n",
      "Penalización por duración del episodio: -  0.47411230332544746\n",
      "Recompensa por acortar distancias: +  0.40117644444792433\n",
      "Penalización por duración del episodio: -  0.4745094826394547\n",
      "Recompensa por acortar distancias: +  0.40117644444792433\n",
      "Penalización por duración del episodio: -  0.47462158233000595\n",
      "Recompensa por acortar distancias: +  0.40117644444792433\n",
      "Penalización por duración del episodio: -  0.47472106878655346\n",
      "Recompensa por acortar distancias: +  0.40117644444792433\n",
      "Penalización por duración del episodio: -  0.47489744904015846\n",
      "Recompensa por acortar distancias: +  0.40117644444792433\n",
      "Penalización por duración del episodio: -  0.47505291285447115\n",
      "Step: 6500, Mean Reward (últimos 10 pasos): -0.07387647032737732\n",
      "Recompensa por acortar distancias: +  0.40117444550927195\n",
      "Penalización por duración del episodio: -  0.4751561775577841\n",
      "Recompensa por acortar distancias: +  0.40117444550927195\n",
      "Penalización por duración del episodio: -  0.4756817377335096\n",
      "Recompensa por acortar distancias: +  0.4011742593618571\n",
      "Penalización por duración del episodio: -  0.4757582323419028\n",
      "Recompensa por acortar distancias: +  0.4011742593618571\n",
      "Penalización por duración del episodio: -  0.47608246694413686\n",
      "Recompensa por acortar distancias: +  0.4011738842033074\n",
      "Penalización por duración del episodio: -  0.4762243958159549\n",
      "Recompensa por acortar distancias: +  0.40117395579844156\n",
      "Penalización por duración del episodio: -  0.4764787962327547\n",
      "Recompensa por acortar distancias: +  0.40117395579844156\n",
      "Penalización por duración del episodio: -  0.47658015064420023\n",
      "steer input from model: -0.25 , throttle:  1.0\n",
      "reward: -0.07540619484575867\n",
      "Recompensa por acortar distancias: +  0.40117395579844156\n",
      "Penalización por duración del episodio: -  0.47687849181530306\n",
      "Recompensa por acortar distancias: +  0.40117395579844156\n",
      "Penalización por duración del episodio: -  0.4772801561128814\n",
      "Recompensa por acortar distancias: +  0.40117395579844156\n",
      "Penalización por duración del episodio: -  0.4776583231778043\n",
      "Step: 6510, Mean Reward (últimos 10 pasos): -0.07648436725139618\n",
      "Recompensa por acortar distancias: +  0.4011813558942482\n",
      "Penalización por duración del episodio: -  0.47804132262069754\n",
      "Recompensa por acortar distancias: +  0.4011813558942482\n",
      "Penalización por duración del episodio: -  0.4784407324606742\n",
      "Recompensa por acortar distancias: +  0.401151351992237\n",
      "Penalización por duración del episodio: -  0.4788316081273333\n",
      "Recompensa por acortar distancias: +  0.4011282703688748\n",
      "Penalización por duración del episodio: -  0.4789604817880349\n",
      "Recompensa por acortar distancias: +  0.40114118571451385\n",
      "Penalización por duración del episodio: -  0.4790701456025899\n",
      "Recompensa por acortar distancias: +  0.40114118571451385\n",
      "Penalización por duración del episodio: -  0.47923578456373134\n",
      "Recompensa por acortar distancias: +  0.40114118571451385\n",
      "Penalización por duración del episodio: -  0.479621821087133\n",
      "Recompensa por acortar distancias: +  0.40114118571451385\n",
      "Penalización por duración del episodio: -  0.47999940782118267\n",
      "Recompensa por acortar distancias: +  0.4010994046382314\n",
      "Penalización por duración del episodio: -  0.48014580234264576\n",
      "Recompensa por acortar distancias: +  0.4010994046382314\n",
      "Penalización por duración del episodio: -  0.48039156831109847\n",
      "Step: 6520, Mean Reward (últimos 10 pasos): -0.0792921632528305\n",
      "Recompensa por acortar distancias: +  0.4011017270441593\n",
      "Penalización por duración del episodio: -  0.48050519149529675\n",
      "Recompensa por acortar distancias: +  0.4011017270441593\n",
      "Penalización por duración del episodio: -  0.4807878239013661\n",
      "Recompensa por acortar distancias: +  0.4011017270441593\n",
      "Penalización por duración del episodio: -  0.48118155024451364\n",
      "Recompensa por acortar distancias: +  0.40106983515770944\n",
      "Penalización por duración del episodio: -  0.48156481189071565\n",
      "Recompensa por acortar distancias: +  0.401033371132461\n",
      "Penalización por duración del episodio: -  0.48194467243228256\n",
      "Recompensa por acortar distancias: +  0.401033371132461\n",
      "Penalización por duración del episodio: -  0.48234037697805504\n",
      "Recompensa por acortar distancias: +  0.401033371132461\n",
      "Penalización por duración del episodio: -  0.482721791814234\n",
      "steer input from model: 0.25 , throttle:  1.0\n",
      "reward: -0.08168842068177301\n",
      "Recompensa por acortar distancias: +  0.4009624392288481\n",
      "Penalización por duración del episodio: -  0.48284127051691766\n",
      "Recompensa por acortar distancias: +  0.4009624392288481\n",
      "Penalización por duración del episodio: -  0.4831146816303183\n",
      "Recompensa por acortar distancias: +  0.4009624392288481\n",
      "Penalización por duración del episodio: -  0.48351625536812\n",
      "Step: 6530, Mean Reward (últimos 10 pasos): -0.08255381882190704\n",
      "Recompensa por acortar distancias: +  0.4008548466708316\n",
      "Penalización por duración del episodio: -  0.4839152066878131\n",
      "Recompensa por acortar distancias: +  0.40081991220991453\n",
      "Penalización por duración del episodio: -  0.48430995670141913\n",
      "Recompensa por acortar distancias: +  0.40081991220991453\n",
      "Penalización por duración del episodio: -  0.48469466254234433\n",
      "Recompensa por acortar distancias: +  0.40081991220991453\n",
      "Penalización por duración del episodio: -  0.4850894507433237\n",
      "Recompensa por acortar distancias: +  0.40070893713832045\n",
      "Penalización por duración del episodio: -  0.4852231631013131\n",
      "Recompensa por acortar distancias: +  0.4006523656422515\n",
      "Penalización por duración del episodio: -  0.48536790093893856\n",
      "Recompensa por acortar distancias: +  0.4006523656422515\n",
      "Penalización por duración del episodio: -  0.4854517528184816\n",
      "Recompensa por acortar distancias: +  0.4006523656422515\n",
      "Penalización por duración del episodio: -  0.4858760629351926\n",
      "Recompensa por acortar distancias: +  0.4005790802648877\n",
      "Penalización por duración del episodio: -  0.4859855533539347\n",
      "Recompensa por acortar distancias: +  0.4005790802648877\n",
      "Penalización por duración del episodio: -  0.4862643299648167\n",
      "Step: 6540, Mean Reward (últimos 10 pasos): -0.08568525314331055\n",
      "Recompensa por acortar distancias: +  0.4005787224649923\n",
      "Penalización por duración del episodio: -  0.4864158748286104\n",
      "Recompensa por acortar distancias: +  0.4005787224649923\n",
      "Penalización por duración del episodio: -  0.486658587660562\n",
      "Recompensa por acortar distancias: +  0.4005787224649923\n",
      "Penalización por duración del episodio: -  0.4870636193460796\n",
      "Recompensa por acortar distancias: +  0.4005787224649923\n",
      "Penalización por duración del episodio: -  0.48717563149767\n",
      "Recompensa por acortar distancias: +  0.4005787224649923\n",
      "Penalización por duración del episodio: -  0.48746134721466555\n",
      "Recompensa por acortar distancias: +  0.4004594235812561\n",
      "Penalización por duración del episodio: -  0.4878616643643169\n",
      "Recompensa por acortar distancias: +  0.4004214009725377\n",
      "Penalización por duración del episodio: -  0.4882496776453334\n",
      "steer input from model: 0.25 , throttle:  0.0\n",
      "reward: -0.08782827667279569\n",
      "Recompensa por acortar distancias: +  0.4003783196721602\n",
      "Penalización por duración del episodio: -  0.4886390157122778\n",
      "Recompensa por acortar distancias: +  0.4003786058645169\n",
      "Penalización por duración del episodio: -  0.48903947252549673\n",
      "Recompensa por acortar distancias: +  0.40038025147188727\n",
      "Penalización por duración del episodio: -  0.4894407179222817\n",
      "Step: 6550, Mean Reward (últimos 10 pasos): -0.0890604630112648\n",
      "Recompensa por acortar distancias: +  0.40038025147188727\n",
      "Penalización por duración del episodio: -  0.48983882514187693\n",
      "Recompensa por acortar distancias: +  0.4003079012474751\n",
      "Penalización por duración del episodio: -  0.49021984525128687\n",
      "Recompensa por acortar distancias: +  0.4003079012474751\n",
      "Penalización por duración del episodio: -  0.49059898196638463\n",
      "Recompensa por acortar distancias: +  0.4002987150460398\n",
      "Penalización por duración del episodio: -  0.4909712771956045\n",
      "Recompensa por acortar distancias: +  0.40027648243929553\n",
      "Penalización por duración del episodio: -  0.4911093368108815\n",
      "Recompensa por acortar distancias: +  0.4002604857475664\n",
      "Penalización por duración del episodio: -  0.4912211797991811\n",
      "Recompensa por acortar distancias: +  0.4002604857475664\n",
      "Penalización por duración del episodio: -  0.4917347212362146\n",
      "Recompensa por acortar distancias: +  0.4002577500197894\n",
      "Penalización por duración del episodio: -  0.492134379586416\n",
      "Recompensa por acortar distancias: +  0.4002577500197894\n",
      "Penalización por duración del episodio: -  0.49224106968976583\n",
      "Recompensa por acortar distancias: +  0.4002577500197894\n",
      "Penalización por duración del episodio: -  0.49253483459606834\n",
      "Step: 6560, Mean Reward (últimos 10 pasos): -0.09227708727121353\n",
      "Recompensa por acortar distancias: +  0.4002577500197894\n",
      "Penalización por duración del episodio: -  0.4926391317142526\n",
      "Recompensa por acortar distancias: +  0.40019359955901224\n",
      "Penalización por duración del episodio: -  0.4929342980271556\n",
      "Recompensa por acortar distancias: +  0.40019301867788437\n",
      "Penalización por duración del episodio: -  0.4933270661506974\n",
      "Recompensa por acortar distancias: +  0.4001477766261729\n",
      "Penalización por duración del episodio: -  0.49371590922562897\n",
      "Recompensa por acortar distancias: +  0.40013566162541647\n",
      "Penalización por duración del episodio: -  0.49411692948305225\n",
      "Recompensa por acortar distancias: +  0.40012145226433304\n",
      "Penalización por duración del episodio: -  0.4945265572283919\n",
      "Recompensa por acortar distancias: +  0.40012145226433304\n",
      "Penalización por duración del episodio: -  0.49492234162730614\n",
      "steer input from model: -0.05 , throttle:  0.3\n",
      "reward: -0.0948008893629731\n",
      "Recompensa por acortar distancias: +  0.399985476093367\n",
      "Penalización por duración del episodio: -  0.49500955226262894\n",
      "Recompensa por acortar distancias: +  0.399985476093367\n",
      "Penalización por duración del episodio: -  0.4953091924788068\n",
      "Recompensa por acortar distancias: +  0.399985476093367\n",
      "Penalización por duración del episodio: -  0.4957050009025237\n",
      "Step: 6570, Mean Reward (últimos 10 pasos): -0.09571952372789383\n",
      "Recompensa por acortar distancias: +  0.39981623769014035\n",
      "Penalización por duración del episodio: -  0.49610744234379794\n",
      "Recompensa por acortar distancias: +  0.39971683364779304\n",
      "Penalización por duración del episodio: -  0.49623491132172687\n",
      "Recompensa por acortar distancias: +  0.39971683364779304\n",
      "Penalización por duración del episodio: -  0.4963539114184189\n",
      "Recompensa por acortar distancias: +  0.3996354852890512\n",
      "Penalización por duración del episodio: -  0.496481762778594\n",
      "Recompensa por acortar distancias: +  0.399574165197152\n",
      "Penalización por duración del episodio: -  0.49664280691422\n",
      "Recompensa por acortar distancias: +  0.399574165197152\n",
      "Penalización por duración del episodio: -  0.49674805219818263\n",
      "Recompensa por acortar distancias: +  0.399574165197152\n",
      "Penalización por duración del episodio: -  0.4968609924259331\n",
      "Recompensa por acortar distancias: +  0.399574165197152\n",
      "Penalización por duración del episodio: -  0.49698565677986356\n",
      "Recompensa por acortar distancias: +  0.399574165197152\n",
      "Penalización por duración del episodio: -  0.4972972417867042\n",
      "Recompensa por acortar distancias: +  0.399574165197152\n",
      "Penalización por duración del episodio: -  0.49769641002721293\n",
      "Step: 6580, Mean Reward (últimos 10 pasos): -0.0981222465634346\n",
      "Recompensa por acortar distancias: +  0.39916905987825085\n",
      "Penalización por duración del episodio: -  0.49808136570414596\n",
      "Recompensa por acortar distancias: +  0.39906127919736367\n",
      "Penalización por duración del episodio: -  0.49819421361225014\n",
      "Recompensa por acortar distancias: +  0.39906127919736367\n",
      "Penalización por duración del episodio: -  0.4983170334477496\n",
      "Recompensa por acortar distancias: +  0.39906127919736367\n",
      "Penalización por duración del episodio: -  0.49842826049665323\n",
      "Recompensa por acortar distancias: +  0.39906127919736367\n",
      "Penalización por duración del episodio: -  0.49855250524545064\n",
      "Recompensa por acortar distancias: +  0.3987532576545796\n",
      "Penalización por duración del episodio: -  0.4988855559207445\n",
      "Recompensa por acortar distancias: +  0.39864147958745005\n",
      "Penalización por duración del episodio: -  0.4992826883945613\n",
      "steer input from model: 0.25 , throttle:  0.0\n",
      "reward: -0.10064120880711125\n",
      "Recompensa por acortar distancias: +  0.3986366928458162\n",
      "Penalización por duración del episodio: -  0.4994001153009568\n",
      "Recompensa por acortar distancias: +  0.3986366928458162\n",
      "Penalización por duración del episodio: -  0.4996629953894724\n",
      "Recompensa por acortar distancias: +  0.3986366928458162\n",
      "Penalización por duración del episodio: -  0.499800252925055\n",
      "Step: 6590, Mean Reward (últimos 10 pasos): -0.10116355866193771\n",
      "Penalización por duración del episodio\n",
      "Recompensa por acortar distancias: +  0.9156967898706059\n",
      "Penalización por duración del episodio: -  0.26913970119852865\n",
      "Recompensa por acortar distancias: +  0.9156967898706059\n",
      "Penalización por parar muy lejos: -  0.16593230700582204\n",
      "Penalización por duración del episodio: -  0.2694515494235009\n",
      "Recompensa por acortar distancias: +  0.9156967898706059\n",
      "Penalización por duración del episodio: -  0.269752236420681\n",
      "Recompensa por acortar distancias: +  0.9156963407874398\n",
      "Penalización por duración del episodio: -  0.27006090378596836\n",
      "Recompensa por acortar distancias: +  0.9156964070457484\n",
      "Penalización por parar muy lejos: -  0.16593162067269449\n",
      "Penalización por duración del episodio: -  0.2703784853329886\n",
      "Recompensa por acortar distancias: +  0.9156964070457484\n",
      "Penalización por parar muy lejos: -  0.16593162067269449\n",
      "Penalización por duración del episodio: -  0.27068018587537784\n",
      "Recompensa por acortar distancias: +  0.9156963187013263\n",
      "Penalización por duración del episodio: -  0.27098371356186696\n",
      "Recompensa por acortar distancias: +  0.9156963039772478\n",
      "Penalización por duración del episodio: -  0.2712909947150498\n",
      "Recompensa por acortar distancias: +  0.9156963923216838\n",
      "Penalización por parar muy lejos: -  0.16593159427531193\n",
      "Penalización por duración del episodio: -  0.271598395444881\n",
      "Step: 6600, Mean Reward (últimos 10 pasos): 0.478166401386261\n",
      "Recompensa por acortar distancias: +  0.9156965837343402\n",
      "Penalización por duración del episodio: -  0.27190920056634954\n",
      "Recompensa por acortar distancias: +  0.915696701526548\n",
      "Penalización por duración del episodio: -  0.27222693580527507\n",
      "Recompensa por acortar distancias: +  0.915696701526548\n",
      "Penalización por duración del episodio: -  0.272538068177761\n",
      "Recompensa por acortar distancias: +  0.9156967456985874\n",
      "Penalización por duración del episodio: -  0.27285751169660266\n",
      "Recompensa por acortar distancias: +  0.9156967236125705\n",
      "Penalización por parar muy lejos: -  0.16593218821723335\n",
      "Penalización por duración del episodio: -  0.2731549500441987\n",
      "Recompensa por acortar distancias: +  0.9156965763723223\n",
      "Penalización por duración del episodio: -  0.2732465262660176\n",
      "Recompensa por acortar distancias: +  0.9156966426304628\n",
      "Penalización por duración del episodio: -  0.2734781417978393\n",
      "Recompensa por acortar distancias: +  0.9156967751466021\n",
      "Penalización por duración del episodio: -  0.27357465635999273\n",
      "Recompensa por acortar distancias: +  0.9156967751466021\n",
      "Penalización por duración del episodio: -  0.27377492591475866\n",
      "Recompensa por acortar distancias: +  0.9156968634905899\n",
      "Penalización por parar muy lejos: -  0.16593243899322263\n",
      "Penalización por duración del episodio: -  0.2738460360324186\n",
      "Step: 6610, Mean Reward (últimos 10 pasos): 0.47591838240623474\n",
      "Recompensa por acortar distancias: +  0.9156969076625522\n",
      "Penalización por duración del episodio: -  0.2740944902119367\n",
      "steer input from model: 0.9 , throttle:  1.0\n",
      "reward: 0.6416024174506154\n",
      "Recompensa por acortar distancias: +  0.9156969591964816\n",
      "Penalización por parar muy lejos: -  0.16593261057696915\n",
      "Penalización por duración del episodio: -  0.27440544741601697\n",
      "Recompensa por acortar distancias: +  0.9156969591964816\n",
      "Penalización por parar muy lejos: -  0.16593261057696915\n",
      "Penalización por duración del episodio: -  0.274715317524281\n",
      "Recompensa por acortar distancias: +  0.9156969591964816\n",
      "Penalización por parar muy lejos: -  0.16593261057696915\n",
      "Penalización por duración del episodio: -  0.2750235985010643\n",
      "Recompensa por acortar distancias: +  0.9156969812824427\n",
      "Penalización por duración del episodio: -  0.2753338066315545\n",
      "Recompensa por acortar distancias: +  0.9156969076625522\n",
      "Penalización por duración del episodio: -  0.27564399360377995\n",
      "Recompensa por acortar distancias: +  0.9156971211600738\n",
      "Penalización por duración del episodio: -  0.27571536679122466\n",
      "Recompensa por acortar distancias: +  0.9156971726938848\n",
      "Penalización por parar muy lejos: -  0.1659329933412236\n",
      "Penalización por duración del episodio: -  0.27580398506037973\n",
      "Recompensa por acortar distancias: +  0.9156972242276673\n",
      "Penalización por duración del episodio: -  0.27594079683336964\n",
      "Recompensa por acortar distancias: +  0.9156972610374945\n",
      "Penalización por parar muy lejos: -  0.16593315172663922\n",
      "Penalización por duración del episodio: -  0.27625850009187014\n",
      "Step: 6620, Mean Reward (últimos 10 pasos): 0.4735056161880493\n",
      "Recompensa por acortar distancias: +  0.9156972610374945\n",
      "Penalización por duración del episodio: -  0.27656040618043604\n",
      "Recompensa por acortar distancias: +  0.9156972168657003\n",
      "Penalización por duración del episodio: -  0.27686434419398154\n",
      "Recompensa por acortar distancias: +  0.9156971874178257\n",
      "Penalización por parar muy lejos: -  0.16593301973878447\n",
      "Penalización por duración del episodio: -  0.2771817005945864\n",
      "Recompensa por acortar distancias: +  0.9156971874178257\n",
      "Penalización por duración del episodio: -  0.27725347242520865\n",
      "Recompensa por acortar distancias: +  0.9156972168657003\n",
      "Penalización por parar muy lejos: -  0.16593307253391626\n",
      "Penalización por duración del episodio: -  0.27749043800621953\n",
      "Recompensa por acortar distancias: +  0.9156973714668881\n",
      "Penalización por duración del episodio: -  0.2775904428018971\n",
      "Recompensa por acortar distancias: +  0.9156974377244613\n",
      "Penalización por duración del episodio: -  0.2778094370009842\n",
      "Recompensa por acortar distancias: +  0.9156975555155857\n",
      "Penalización por parar muy lejos: -  0.16593367967889924\n",
      "Penalización por duración del episodio: -  0.2781183604607063\n",
      "Recompensa por acortar distancias: +  0.9156975996872189\n",
      "Penalización por duración del episodio: -  0.2784394077992504\n",
      "Recompensa por acortar distancias: +  0.9156975996872189\n",
      "Penalización por parar muy lejos: -  0.16593375887185433\n",
      "Penalización por duración del episodio: -  0.27875736555235897\n",
      "Step: 6630, Mean Reward (últimos 10 pasos): 0.47100648283958435\n",
      "Recompensa por acortar distancias: +  0.9156975996872189\n",
      "Penalización por duración del episodio: -  0.27906603400564256\n",
      "steer input from model: -0.9 , throttle:  1.0\n",
      "reward: 0.6366315656815763\n",
      "Recompensa por acortar distancias: +  0.9156975996872189\n",
      "Penalización por parar muy lejos: -  0.16593375887185433\n",
      "Penalización por duración del episodio: -  0.2793847566625948\n",
      "Recompensa por acortar distancias: +  0.9156976144110918\n",
      "Penalización por duración del episodio: -  0.2796943259493358\n",
      "Recompensa por acortar distancias: +  0.9156977542877692\n",
      "Penalización por duración del episodio: -  0.28000658996734273\n",
      "Recompensa por acortar distancias: +  0.915697805821229\n",
      "Penalización por duración del episodio: -  0.28032081773147244\n",
      "Recompensa por acortar distancias: +  0.915697805821229\n",
      "Penalización por parar muy lejos: -  0.16593412843937824\n",
      "Penalización por duración del episodio: -  0.28064154191386426\n",
      "Recompensa por acortar distancias: +  0.9156975039819871\n",
      "Penalización por duración del episodio: -  0.2807155465964312\n",
      "Recompensa por acortar distancias: +  0.9156975039819871\n",
      "Penalización por duración del episodio: -  0.280950275070653\n",
      "Recompensa por acortar distancias: +  0.91569745244836\n",
      "Penalización por parar muy lejos: -  0.1659334948954552\n",
      "Penalización por duración del episodio: -  0.2810428905569983\n",
      "Recompensa por acortar distancias: +  0.91569745244836\n",
      "Penalización por duración del episodio: -  0.28126389019425396\n",
      "Step: 6640, Mean Reward (últimos 10 pasos): 0.6344335675239563\n",
      "Recompensa por acortar distancias: +  0.9156975260678185\n",
      "Penalización por parar muy lejos: -  0.1659336268836127\n",
      "Penalización por duración del episodio: -  0.2813373440367546\n",
      "Recompensa por acortar distancias: +  0.9156975260678185\n",
      "Penalización por duración del episodio: -  0.28158396896953464\n",
      "Recompensa por acortar distancias: +  0.9156975187058752\n",
      "Penalización por parar muy lejos: -  0.16593361368479315\n",
      "Penalización por duración del episodio: -  0.2816902576260336\n",
      "Recompensa por acortar distancias: +  0.9156975555155857\n",
      "Penalización por parar muy lejos: -  0.16593367967889924\n",
      "Penalización por duración del episodio: -  0.28178580074726184\n",
      "Recompensa por acortar distancias: +  0.9156975996872189\n",
      "Penalización por parar muy lejos: -  0.16593375887185433\n",
      "Penalización por duración del episodio: -  0.2818698195015725\n",
      "Recompensa por acortar distancias: +  0.9156976291349626\n",
      "Penalización por parar muy lejos: -  0.16593381166717452\n",
      "Penalización por duración del episodio: -  0.28196482037423143\n",
      "Recompensa por acortar distancias: +  0.915697658582697\n",
      "Penalización por duración del episodio: -  0.2822024486593322\n",
      "Recompensa por acortar distancias: +  0.915697658582697\n",
      "Penalización por parar muy lejos: -  0.16593386446250816\n",
      "Penalización por duración del episodio: -  0.2825042458369698\n",
      "Recompensa por acortar distancias: +  0.915697658582697\n",
      "Penalización por parar muy lejos: -  0.16593386446250816\n",
      "Penalización por duración del episodio: -  0.2825794864437396\n",
      "Recompensa por acortar distancias: +  0.915697658582697\n",
      "Penalización por duración del episodio: -  0.2828220228234464\n",
      "Step: 6650, Mean Reward (últimos 10 pasos): 0.6328756213188171\n",
      "Recompensa por acortar distancias: +  0.9156975849633434\n",
      "Penalización por duración del episodio: -  0.28289295200066805\n",
      "steer input from model: 0.25 , throttle:  1.0\n",
      "reward: 0.6328046329626753\n",
      "Recompensa por acortar distancias: +  0.9156975849633434\n",
      "Penalización por parar muy lejos: -  0.16593373247419926\n",
      "Penalización por duración del episodio: -  0.28313318327059545\n",
      "Recompensa por acortar distancias: +  0.9156975849633434\n",
      "Penalización por parar muy lejos: -  0.16593373247419926\n",
      "Penalización por duración del episodio: -  0.2834409480466541\n",
      "Recompensa por acortar distancias: +  0.9156976880304221\n",
      "Penalización por parar muy lejos: -  0.16593391725785528\n",
      "Penalización por duración del episodio: -  0.2837654965769543\n",
      "Recompensa por acortar distancias: +  0.9156977690116177\n",
      "Penalización por duración del episodio: -  0.28407624136189036\n",
      "Recompensa por acortar distancias: +  0.915697805821229\n",
      "Penalización por duración del episodio: -  0.28414791816784973\n",
      "Recompensa por acortar distancias: +  0.915697805821229\n",
      "Penalización por duración del episodio: -  0.28422906417507665\n",
      "Recompensa por acortar distancias: +  0.915697805821229\n",
      "Penalización por parar muy lejos: -  0.16593412843937824\n",
      "Penalización por duración del episodio: -  0.28439064601702035\n",
      "Recompensa por acortar distancias: +  0.915697805821229\n",
      "Penalización por duración del episodio: -  0.2847143932667673\n",
      "Recompensa por acortar distancias: +  0.9156975996872189\n",
      "Penalización por parar muy lejos: -  0.16593375887185433\n",
      "Penalización por duración del episodio: -  0.2850257442153749\n",
      "Step: 6660, Mean Reward (últimos 10 pasos): 0.4647381007671356\n",
      "Recompensa por acortar distancias: +  0.9156975555155857\n",
      "Penalización por parar muy lejos: -  0.16593367967889924\n",
      "Penalización por duración del episodio: -  0.28532726024891175\n",
      "Recompensa por acortar distancias: +  0.9156973641049325\n",
      "Penalización por duración del episodio: -  0.2856365764484881\n",
      "Recompensa por acortar distancias: +  0.9156974230005601\n",
      "Penalización por parar muy lejos: -  0.1659334421002157\n",
      "Penalización por duración del episodio: -  0.2859609562013178\n",
      "Recompensa por acortar distancias: +  0.9156975113439315\n",
      "Penalización por duración del episodio: -  0.2862842219092039\n",
      "Recompensa por acortar distancias: +  0.9156975113439315\n",
      "Penalización por duración del episodio: -  0.2866040600386441\n",
      "Recompensa por acortar distancias: +  0.9156975113439315\n",
      "Penalización por parar muy lejos: -  0.16593360048597444\n",
      "Penalización por duración del episodio: -  0.28667554394835265\n",
      "Recompensa por acortar distancias: +  0.9156973346571048\n",
      "Penalización por duración del episodio: -  0.28692075578232795\n",
      "Recompensa por acortar distancias: +  0.9156973199331874\n",
      "Penalización por duración del episodio: -  0.2872483261031149\n",
      "Recompensa por acortar distancias: +  0.9156971285220487\n",
      "Penalización por parar muy lejos: -  0.1659329141485612\n",
      "Penalización por duración del episodio: -  0.28757513777273175\n",
      "Recompensa por acortar distancias: +  0.9156972904853456\n",
      "Penalización por parar muy lejos: -  0.16593320452180466\n",
      "Penalización por duración del episodio: -  0.2878919309771293\n",
      "Step: 6670, Mean Reward (últimos 10 pasos): 0.4618721604347229\n",
      "Recompensa por acortar distancias: +  0.9156974230005601\n",
      "Penalización por duración del episodio: -  0.2882129230773614\n",
      "steer input from model: 0.25 , throttle:  1.0\n",
      "reward: 0.6274844999231988\n",
      "Recompensa por acortar distancias: +  0.9156974892580966\n",
      "Penalización por parar muy lejos: -  0.16593356088952343\n",
      "Penalización por duración del episodio: -  0.28852637064407277\n",
      "Recompensa por acortar distancias: +  0.9156974892580966\n",
      "Penalización por parar muy lejos: -  0.16593356088952343\n",
      "Penalización por duración del episodio: -  0.28885452705833076\n",
      "Recompensa por acortar distancias: +  0.915697378828843\n",
      "Penalización por parar muy lejos: -  0.16593336290738175\n",
      "Penalización por duración del episodio: -  0.28916412534140945\n",
      "Recompensa por acortar distancias: +  0.915697378828843\n",
      "Penalización por parar muy lejos: -  0.16593336290738175\n",
      "Penalización por duración del episodio: -  0.2894861211003094\n",
      "Recompensa por acortar distancias: +  0.91569745244836\n",
      "Penalización por duración del episodio: -  0.2898178785765623\n",
      "Recompensa por acortar distancias: +  0.9156975996872189\n",
      "Penalización por parar muy lejos: -  0.16593375887185433\n",
      "Penalización por duración del episodio: -  0.2901302536036841\n",
      "Recompensa por acortar distancias: +  0.9156976438588309\n",
      "Penalización por duración del episodio: -  0.29044659135460565\n",
      "Recompensa por acortar distancias: +  0.9156976438588309\n",
      "Penalización por parar muy lejos: -  0.16593383806483963\n",
      "Penalización por duración del episodio: -  0.29050980275491733\n",
      "Recompensa por acortar distancias: +  0.9156976438588309\n",
      "Penalización por duración del episodio: -  0.2907629606583834\n",
      "Step: 6680, Mean Reward (últimos 10 pasos): 0.6249346733093262\n",
      "Recompensa por acortar distancias: +  0.9156974377244613\n",
      "Penalización por parar muy lejos: -  0.16593346849783375\n",
      "Penalización por duración del episodio: -  0.29106681070792845\n",
      "Recompensa por acortar distancias: +  0.9156974377244613\n",
      "Penalización por parar muy lejos: -  0.16593346849783375\n",
      "Penalización por duración del episodio: -  0.2913800140277021\n",
      "Recompensa por acortar distancias: +  0.9156973052092677\n",
      "Penalización por duración del episodio: -  0.29169279503477225\n",
      "Recompensa por acortar distancias: +  0.9156974377244613\n",
      "Penalización por duración del episodio: -  0.29202087128020604\n",
      "Recompensa por acortar distancias: +  0.9156975555155857\n",
      "Penalización por parar muy lejos: -  0.16593367967889924\n",
      "Penalización por duración del episodio: -  0.2923509645624504\n",
      "Recompensa por acortar distancias: +  0.9156975996872189\n",
      "Penalización por duración del episodio: -  0.29267901616802383\n",
      "Recompensa por acortar distancias: +  0.9156975996872189\n",
      "Penalización por parar muy lejos: -  0.16593375887185433\n",
      "Penalización por duración del episodio: -  0.292999978832122\n",
      "Recompensa por acortar distancias: +  0.9156974671722563\n",
      "Penalización por duración del episodio: -  0.29334259639046956\n",
      "Recompensa por acortar distancias: +  0.9156975113439315\n",
      "Penalización por duración del episodio: -  0.293659761272822\n",
      "Recompensa por acortar distancias: +  0.9156975113439315\n",
      "Penalización por duración del episodio: -  0.29398610305263334\n",
      "Step: 6690, Mean Reward (últimos 10 pasos): 0.6217114329338074\n",
      "Recompensa por acortar distancias: +  0.9156975407917033\n",
      "Penalización por parar muy lejos: -  0.16593365328125428\n",
      "Penalización por duración del episodio: -  0.2941084070767791\n",
      "steer input from model: -0.1 , throttle:  0.0\n",
      "reward: 0.4556554804336699\n",
      "Recompensa por acortar distancias: +  0.9156975407917033\n",
      "Penalización por duración del episodio: -  0.2943109876353721\n",
      "Recompensa por acortar distancias: +  0.9156975113439315\n",
      "Penalización por parar muy lejos: -  0.16593360048597444\n",
      "Penalización por duración del episodio: -  0.29463352962407746\n",
      "Recompensa por acortar distancias: +  0.9156975113439315\n",
      "Penalización por parar muy lejos: -  0.16593360048597444\n",
      "Penalización por duración del episodio: -  0.29497005109109997\n",
      "Recompensa por acortar distancias: +  0.9156972904853456\n",
      "Penalización por duración del episodio: -  0.2953037893412572\n",
      "Recompensa por acortar distancias: +  0.9156973052092677\n",
      "Penalización por duración del episodio: -  0.2956328367557277\n",
      "Recompensa por acortar distancias: +  0.9156971579699418\n",
      "Penalización por duración del episodio: -  0.2959623203859632\n",
      "Recompensa por acortar distancias: +  0.9156973199331874\n",
      "Penalización por parar muy lejos: -  0.16593325731698358\n",
      "Penalización por duración del episodio: -  0.29628777145755597\n",
      "Recompensa por acortar distancias: +  0.9156974377244613\n",
      "Penalización por duración del episodio: -  0.29661046997966\n",
      "Recompensa por acortar distancias: +  0.9156974671722563\n",
      "Penalización por duración del episodio: -  0.296946979838064\n",
      "Step: 6700, Mean Reward (últimos 10 pasos): 0.6187505125999451\n",
      "Recompensa por acortar distancias: +  0.9156974671722563\n",
      "Penalización por duración del episodio: -  0.297034157345981\n",
      "Recompensa por acortar distancias: +  0.9156973199331874\n",
      "Penalización por duración del episodio: -  0.2972640566115848\n",
      "Recompensa por acortar distancias: +  0.9156972904853456\n",
      "Penalización por parar muy lejos: -  0.16593320452180466\n",
      "Penalización por duración del episodio: -  0.2975975454876335\n",
      "Recompensa por acortar distancias: +  0.9156972904853456\n",
      "Penalización por duración del episodio: -  0.2976826897522677\n",
      "Recompensa por acortar distancias: +  0.9156972904853456\n",
      "Penalización por parar muy lejos: -  0.16593320452180466\n",
      "Penalización por duración del episodio: -  0.2979293797705422\n",
      "Recompensa por acortar distancias: +  0.9156973199331874\n",
      "Penalización por duración del episodio: -  0.2980535246017409\n",
      "Recompensa por acortar distancias: +  0.9156973641049325\n",
      "Penalización por parar muy lejos: -  0.16593333650977715\n",
      "Penalización por duración del episodio: -  0.29826345294570444\n",
      "Recompensa por acortar distancias: +  0.9156974892580966\n",
      "Penalización por parar muy lejos: -  0.16593356088952343\n",
      "Penalización por duración del episodio: -  0.2985985902743818\n",
      "Recompensa por acortar distancias: +  0.9156974892580966\n",
      "Penalización por duración del episodio: -  0.29893625218992054\n",
      "Recompensa por acortar distancias: +  0.9156974892580966\n",
      "Penalización por duración del episodio: -  0.29926582832588344\n",
      "Step: 6710, Mean Reward (últimos 10 pasos): 0.6164316534996033\n",
      "Recompensa por acortar distancias: +  0.9156972757614211\n",
      "Penalización por parar muy lejos: -  0.16593317812422026\n",
      "Penalización por duración del episodio: -  0.29960420764382395\n",
      "steer input from model: -0.05 , throttle:  0.0\n",
      "reward: 0.4501598899933769\n",
      "Recompensa por acortar distancias: +  0.9156972757614211\n",
      "Penalización por duración del episodio: -  0.29992027817882894\n",
      "Recompensa por acortar distancias: +  0.9156973714668881\n",
      "Penalización por duración del episodio: -  0.3002521977268502\n",
      "Recompensa por acortar distancias: +  0.9156975113439315\n",
      "Penalización por parar muy lejos: -  0.16593360048597444\n",
      "Penalización por duración del episodio: -  0.300579479966107\n",
      "Recompensa por acortar distancias: +  0.9156976291349626\n",
      "Penalización por parar muy lejos: -  0.16593381166717452\n",
      "Penalización por duración del episodio: -  0.3009164949265559\n",
      "Recompensa por acortar distancias: +  0.9156976291349626\n",
      "Penalización por parar muy lejos: -  0.16593381166717452\n",
      "Penalización por duración del episodio: -  0.301240139528158\n",
      "Recompensa por acortar distancias: +  0.9156974892580966\n",
      "Penalización por parar muy lejos: -  0.16593356088952343\n",
      "Penalización por duración del episodio: -  0.30155777534407663\n",
      "Recompensa por acortar distancias: +  0.9156975113439315\n",
      "Penalización por duración del episodio: -  0.3018933284523012\n",
      "Recompensa por acortar distancias: +  0.9156972757614211\n",
      "Penalización por parar muy lejos: -  0.16593317812422026\n",
      "Penalización por duración del episodio: -  0.3022205107650338\n",
      "Recompensa por acortar distancias: +  0.9156974230005601\n",
      "Penalización por parar muy lejos: -  0.1659334421002157\n",
      "Penalización por duración del episodio: -  0.3025509628727028\n",
      "Step: 6720, Mean Reward (últimos 10 pasos): 0.4472130239009857\n",
      "Recompensa por acortar distancias: +  0.9156974377244613\n",
      "Penalización por parar muy lejos: -  0.16593346849783375\n",
      "Penalización por duración del episodio: -  0.3026365665305049\n",
      "Recompensa por acortar distancias: +  0.9156974377244613\n",
      "Penalización por duración del episodio: -  0.3028710278787443\n",
      "Recompensa por acortar distancias: +  0.9156974377244613\n",
      "Penalización por parar muy lejos: -  0.16593346849783375\n",
      "Penalización por duración del episodio: -  0.3031968501801623\n",
      "Recompensa por acortar distancias: +  0.9156974377244613\n",
      "Penalización por parar muy lejos: -  0.16593346849783375\n",
      "Penalización por duración del episodio: -  0.303536186469833\n",
      "Recompensa por acortar distancias: +  0.9156971579699418\n",
      "Penalización por duración del episodio: -  0.3038767859463603\n",
      "Recompensa por acortar distancias: +  0.9156971579699418\n",
      "Penalización por parar muy lejos: -  0.1659329669436661\n",
      "Penalización por duración del episodio: -  0.3042089660266688\n",
      "Recompensa por acortar distancias: +  0.9156972463135653\n",
      "Penalización por duración del episodio: -  0.30453656336091056\n",
      "Recompensa por acortar distancias: +  0.9156973493810199\n",
      "Penalización por parar muy lejos: -  0.16593331011217594\n",
      "Penalización por duración del episodio: -  0.30487450970571434\n",
      "Recompensa por acortar distancias: +  0.9156974009147041\n",
      "Penalización por parar muy lejos: -  0.16593340250379493\n",
      "Penalización por duración del episodio: -  0.30521326813616134\n",
      "Recompensa por acortar distancias: +  0.9156974009147041\n",
      "Penalización por parar muy lejos: -  0.16593340250379493\n",
      "Penalización por duración del episodio: -  0.3052978996947055\n",
      "Step: 6730, Mean Reward (últimos 10 pasos): 0.44446608424186707\n",
      "Recompensa por acortar distancias: +  0.9156974009147041\n",
      "Penalización por duración del episodio: -  0.30555399805601274\n",
      "steer input from model: -0.05 , throttle:  0.3\n",
      "reward: 0.6101434028586914\n",
      "Recompensa por acortar distancias: +  0.9156972757614211\n",
      "Penalización por duración del episodio: -  0.3058962671778635\n",
      "Recompensa por acortar distancias: +  0.9156972757614211\n",
      "Penalización por duración del episodio: -  0.3062380161479726\n",
      "Recompensa por acortar distancias: +  0.9156971726938848\n",
      "Penalización por duración del episodio: -  0.3063342105683842\n",
      "Recompensa por acortar distancias: +  0.9156972242276673\n",
      "Penalización por parar muy lejos: -  0.16593308573270132\n",
      "Penalización por duración del episodio: -  0.3065701708039512\n",
      "Recompensa por acortar distancias: +  0.9156972904853456\n",
      "Penalización por parar muy lejos: -  0.16593320452180466\n",
      "Penalización por duración del episodio: -  0.30691347071924013\n",
      "Recompensa por acortar distancias: +  0.9156974009147041\n",
      "Penalización por duración del episodio: -  0.30725215866560884\n",
      "Recompensa por acortar distancias: +  0.9156974009147041\n",
      "Penalización por parar muy lejos: -  0.16593340250379493\n",
      "Penalización por duración del episodio: -  0.3075908259918324\n",
      "Recompensa por acortar distancias: +  0.9156973199331874\n",
      "Penalización por parar muy lejos: -  0.16593325731698358\n",
      "Penalización por duración del episodio: -  0.3079139500700611\n",
      "Recompensa por acortar distancias: +  0.9156972904853456\n",
      "Penalización por parar muy lejos: -  0.16593320452180466\n",
      "Penalización por duración del episodio: -  0.30825613868852947\n",
      "Step: 6740, Mean Reward (últimos 10 pasos): 0.4415079355239868\n",
      "Recompensa por acortar distancias: +  0.9156971137980985\n",
      "Penalización por duración del episodio: -  0.3085798994564431\n",
      "Recompensa por acortar distancias: +  0.9156973346571048\n",
      "Penalización por parar muy lejos: -  0.16593328371457805\n",
      "Penalización por duración del episodio: -  0.30891196673152554\n",
      "Recompensa por acortar distancias: +  0.9156974818961505\n",
      "Penalización por parar muy lejos: -  0.16593354769070812\n",
      "Penalización por duración del episodio: -  0.30924118087786584\n",
      "Recompensa por acortar distancias: +  0.9156975113439315\n",
      "Penalización por parar muy lejos: -  0.16593360048597444\n",
      "Penalización por duración del episodio: -  0.3095568198174347\n",
      "Recompensa por acortar distancias: +  0.9156975113439315\n",
      "Penalización por duración del episodio: -  0.30988766733186385\n",
      "Recompensa por acortar distancias: +  0.9156973714668881\n",
      "Penalización por parar muy lejos: -  0.16593334970857904\n",
      "Penalización por duración del episodio: -  0.31021859733531465\n",
      "Recompensa por acortar distancias: +  0.9156973714668881\n",
      "Penalización por duración del episodio: -  0.3105486343998523\n",
      "Recompensa por acortar distancias: +  0.9156974377244613\n",
      "Penalización por duración del episodio: -  0.31088532052998114\n",
      "Recompensa por acortar distancias: +  0.9156975407917033\n",
      "Penalización por parar muy lejos: -  0.16593365328125428\n",
      "Penalización por duración del episodio: -  0.31095148541156176\n",
      "Recompensa por acortar distancias: +  0.9156975407917033\n",
      "Penalización por duración del episodio: -  0.3112223806775558\n",
      "Step: 6750, Mean Reward (últimos 10 pasos): 0.6044751405715942\n",
      "Recompensa por acortar distancias: +  0.9156975407917033\n",
      "Penalización por parar muy lejos: -  0.16593365328125428\n",
      "Penalización por duración del episodio: -  0.31155421527891264\n",
      "steer input from model: -0.05 , throttle:  0.0\n",
      "reward: 0.43820967223153634\n",
      "Recompensa por acortar distancias: +  0.9156975407917033\n",
      "Penalización por parar muy lejos: -  0.16593365328125428\n",
      "Penalización por duración del episodio: -  0.3119104719394355\n",
      "Recompensa por acortar distancias: +  0.9156972242276673\n",
      "Penalización por parar muy lejos: -  0.16593308573270132\n",
      "Penalización por duración del episodio: -  0.3122408849063021\n",
      "Recompensa por acortar distancias: +  0.9156972242276673\n",
      "Penalización por duración del episodio: -  0.31257886593178497\n",
      "Recompensa por acortar distancias: +  0.9156972463135653\n",
      "Penalización por duración del episodio: -  0.31290723527111175\n",
      "Recompensa por acortar distancias: +  0.9156973641049325\n",
      "Penalización por parar muy lejos: -  0.16593333650977715\n",
      "Penalización por duración del episodio: -  0.313242659939223\n",
      "Recompensa por acortar distancias: +  0.9156974377244613\n",
      "Penalización por duración del episodio: -  0.31356903761666316\n",
      "Recompensa por acortar distancias: +  0.91569745244836\n",
      "Penalización por duración del episodio: -  0.3139115690790766\n",
      "Recompensa por acortar distancias: +  0.91569745244836\n",
      "Penalización por parar muy lejos: -  0.1659334948954552\n",
      "Penalización por duración del episodio: -  0.3142542571715518\n",
      "Recompensa por acortar distancias: +  0.9156972757614211\n",
      "Penalización por duración del episodio: -  0.3145810775350571\n",
      "Step: 6760, Mean Reward (últimos 10 pasos): 0.6011161804199219\n",
      "Recompensa por acortar distancias: +  0.9156973052092677\n",
      "Penalización por parar muy lejos: -  0.16593323091939247\n",
      "Penalización por duración del episodio: -  0.3149086115015701\n",
      "Recompensa por acortar distancias: +  0.9156973493810199\n",
      "Penalización por duración del episodio: -  0.3152495564568416\n",
      "Recompensa por acortar distancias: +  0.9156974377244613\n",
      "Penalización por parar muy lejos: -  0.16593346849783375\n",
      "Penalización por duración del episodio: -  0.31557618373632756\n",
      "Recompensa por acortar distancias: +  0.9156974230005601\n",
      "Penalización por parar muy lejos: -  0.1659334421002157\n",
      "Penalización por duración del episodio: -  0.31591798189711373\n",
      "Recompensa por acortar distancias: +  0.9156974230005601\n",
      "Penalización por duración del episodio: -  0.316264851213202\n",
      "Recompensa por acortar distancias: +  0.9156972904853456\n",
      "Penalización por duración del episodio: -  0.3166043987133422\n",
      "Recompensa por acortar distancias: +  0.9156972904853456\n",
      "Penalización por parar muy lejos: -  0.16593320452180466\n",
      "Penalización por duración del episodio: -  0.3169400486892103\n",
      "Recompensa por acortar distancias: +  0.9156972315896338\n",
      "Penalización por parar muy lejos: -  0.16593309893148722\n",
      "Penalización por duración del episodio: -  0.3172845346211719\n",
      "Recompensa por acortar distancias: +  0.9156972904853456\n",
      "Penalización por parar muy lejos: -  0.16593320452180466\n",
      "Penalización por duración del episodio: -  0.31736039056526655\n",
      "Recompensa por acortar distancias: +  0.9156973346571048\n",
      "Penalización por duración del episodio: -  0.31762320075384004\n",
      "Step: 6770, Mean Reward (últimos 10 pasos): 0.5980741381645203\n",
      "Recompensa por acortar distancias: +  0.9156974009147041\n",
      "Penalización por duración del episodio: -  0.3179760150847813\n",
      "steer input from model: -0.9 , throttle:  0.7\n",
      "reward: 0.5977213858299228\n",
      "Recompensa por acortar distancias: +  0.9156974009147041\n",
      "Penalización por parar muy lejos: -  0.16593340250379493\n",
      "Penalización por duración del episodio: -  0.31806251896968746\n",
      "Recompensa por acortar distancias: +  0.9156974009147041\n",
      "Penalización por duración del episodio: -  0.31830954993974103\n",
      "Recompensa por acortar distancias: +  0.9156974009147041\n",
      "Penalización por parar muy lejos: -  0.16593340250379493\n",
      "Penalización por duración del episodio: -  0.3183956986173774\n",
      "Recompensa por acortar distancias: +  0.9156974009147041\n",
      "Penalización por duración del episodio: -  0.3186542864632761\n",
      "Recompensa por acortar distancias: +  0.9156972021417641\n",
      "Penalización por parar muy lejos: -  0.16593304613634868\n",
      "Penalización por duración del episodio: -  0.31899784391842284\n",
      "Recompensa por acortar distancias: +  0.9156972021417641\n",
      "Penalización por parar muy lejos: -  0.16593304613634868\n",
      "Penalización por duración del episodio: -  0.319073845519894\n",
      "Recompensa por acortar distancias: +  0.9156972757614211\n",
      "Penalización por parar muy lejos: -  0.16593317812422026\n",
      "Penalización por duración del episodio: -  0.3193314305341836\n",
      "Recompensa por acortar distancias: +  0.9156972757614211\n",
      "Penalización por parar muy lejos: -  0.16593317812422026\n",
      "Penalización por duración del episodio: -  0.31942218875266903\n",
      "Recompensa por acortar distancias: +  0.9156973199331874\n",
      "Penalización por duración del episodio: -  0.3196722488527906\n",
      "Step: 6780, Mean Reward (últimos 10 pasos): 0.5960250496864319\n",
      "Recompensa por acortar distancias: +  0.9156974082766567\n",
      "Penalización por duración del episodio: -  0.32001879563677693\n",
      "Recompensa por acortar distancias: +  0.9156974082766567\n",
      "Penalización por duración del episodio: -  0.3203483536307645\n",
      "Recompensa por acortar distancias: +  0.9156974082766567\n",
      "Penalización por duración del episodio: -  0.320696446111881\n",
      "Recompensa por acortar distancias: +  0.9156969665584692\n",
      "Penalización por parar muy lejos: -  0.1659326237757248\n",
      "Penalización por duración del episodio: -  0.32079669250585946\n",
      "Recompensa por acortar distancias: +  0.9156969665584692\n",
      "Penalización por duración del episodio: -  0.3209121737340976\n",
      "Recompensa por acortar distancias: +  0.915696892938567\n",
      "Penalización por duración del episodio: -  0.3210014181028429\n",
      "Recompensa por acortar distancias: +  0.915696892938567\n",
      "Penalización por duración del episodio: -  0.32136104298209595\n",
      "Recompensa por acortar distancias: +  0.9156970107303826\n",
      "Penalización por parar muy lejos: -  0.16593270296827617\n",
      "Penalización por duración del episodio: -  0.32170102151996927\n",
      "Recompensa por acortar distancias: +  0.9156970917121691\n",
      "Penalización por parar muy lejos: -  0.16593284815469897\n",
      "Penalización por duración del episodio: -  0.32178806065361043\n",
      "Recompensa por acortar distancias: +  0.9156971579699418\n",
      "Penalización por parar muy lejos: -  0.1659329669436661\n",
      "Penalización por duración del episodio: -  0.32188666514756215\n",
      "Step: 6790, Mean Reward (últimos 10 pasos): 0.4278775155544281\n",
      "Recompensa por acortar distancias: +  0.9156971726938848\n",
      "Penalización por parar muy lejos: -  0.1659329933412236\n",
      "Penalización por duración del episodio: -  0.3220333289358908\n",
      "steer input from model: -0.9 , throttle:  0.0\n",
      "reward: 0.42773085041677045\n",
      "Recompensa por acortar distancias: +  0.9156972242276673\n",
      "Penalización por parar muy lejos: -  0.16593308573270132\n",
      "Penalización por duración del episodio: -  0.32236468630733967\n",
      "Recompensa por acortar distancias: +  0.9156972242276673\n",
      "Penalización por duración del episodio: -  0.32270642027217766\n",
      "Recompensa por acortar distancias: +  0.9156972242276673\n",
      "Penalización por duración del episodio: -  0.3227833557007808\n",
      "Recompensa por acortar distancias: +  0.9156972242276673\n",
      "Penalización por duración del episodio: -  0.3230441726702639\n",
      "Recompensa por acortar distancias: +  0.9156970475402941\n",
      "Penalización por parar muy lejos: -  0.16593276896209214\n",
      "Penalización por duración del episodio: -  0.32337545325524525\n",
      "Recompensa por acortar distancias: +  0.9156970475402941\n",
      "Penalización por duración del episodio: -  0.3236987009329086\n",
      "Recompensa por acortar distancias: +  0.9156971579699418\n",
      "Penalización por duración del episodio: -  0.32405288129164334\n",
      "Recompensa por acortar distancias: +  0.9156972757614211\n",
      "Penalización por parar muy lejos: -  0.16593317812422026\n",
      "Penalización por duración del episodio: -  0.32414146965120594\n",
      "Recompensa por acortar distancias: +  0.9156973199331874\n",
      "Penalización por duración del episodio: -  0.3243920524744945\n",
      "Step: 6800, Mean Reward (últimos 10 pasos): 0.5913052558898926\n",
      "Recompensa por acortar distancias: +  0.9156973199331874\n",
      "Penalización por parar muy lejos: -  0.16593325731698358\n",
      "Penalización por duración del episodio: -  0.32473743609675504\n",
      "Recompensa por acortar distancias: +  0.9156973199331874\n",
      "Penalización por duración del episodio: -  0.32484440201393616\n",
      "Recompensa por acortar distancias: +  0.9156973199331874\n",
      "Penalización por duración del episodio: -  0.32493423759607964\n",
      "Recompensa por acortar distancias: +  0.9156973199331874\n",
      "Penalización por duración del episodio: -  0.3250750385163248\n",
      "Recompensa por acortar distancias: +  0.9156971137980985\n",
      "Penalización por parar muy lejos: -  0.1659328877510138\n",
      "Penalización por duración del episodio: -  0.3251812563847455\n",
      "Recompensa por acortar distancias: +  0.9156971064361227\n",
      "Penalización por parar muy lejos: -  0.16593287455224134\n",
      "Penalización por duración del episodio: -  0.3254176221407239\n",
      "Recompensa por acortar distancias: +  0.9156971064361227\n",
      "Penalización por parar muy lejos: -  0.16593287455224134\n",
      "Penalización por duración del episodio: -  0.3257675615420583\n",
      "Recompensa por acortar distancias: +  0.9156971726938848\n",
      "Penalización por duración del episodio: -  0.32610888761701773\n",
      "Recompensa por acortar distancias: +  0.9156973346571048\n",
      "Penalización por parar muy lejos: -  0.16593328371457805\n",
      "Penalización por duración del episodio: -  0.32647142562007947\n",
      "Recompensa por acortar distancias: +  0.9156974230005601\n",
      "Penalización por parar muy lejos: -  0.1659334421002157\n",
      "Penalización por duración del episodio: -  0.3268131107233504\n",
      "Step: 6810, Mean Reward (últimos 10 pasos): 0.4229508638381958\n",
      "Recompensa por acortar distancias: +  0.9156974230005601\n",
      "Penalización por parar muy lejos: -  0.1659334421002157\n",
      "Penalización por duración del episodio: -  0.3271462153332237\n",
      "steer input from model: 0.9 , throttle:  0.0\n",
      "reward: 0.4226177655671208\n",
      "Recompensa por acortar distancias: +  0.9156973199331874\n",
      "Penalización por parar muy lejos: -  0.16593325731698358\n",
      "Penalización por duración del episodio: -  0.32749978916199773\n",
      "Recompensa por acortar distancias: +  0.9156973493810199\n",
      "Penalización por parar muy lejos: -  0.16593331011217594\n",
      "Penalización por duración del episodio: -  0.32783211801764267\n",
      "Recompensa por acortar distancias: +  0.9156972021417641\n",
      "Penalización por duración del episodio: -  0.3279107189342533\n",
      "Recompensa por acortar distancias: +  0.9156972757614211\n",
      "Penalización por parar muy lejos: -  0.16593317812422026\n",
      "Penalización por duración del episodio: -  0.32817960593176376\n",
      "Recompensa por acortar distancias: +  0.9156974009147041\n",
      "Penalización por duración del episodio: -  0.3285256096464515\n",
      "Recompensa por acortar distancias: +  0.9156975555155857\n",
      "Penalización por parar muy lejos: -  0.16593367967889924\n",
      "Penalización por duración del episodio: -  0.32886779501425334\n",
      "Recompensa por acortar distancias: +  0.9156975996872189\n",
      "Penalización por duración del episodio: -  0.32919940044730156\n",
      "Recompensa por acortar distancias: +  0.9156975996872189\n",
      "Penalización por parar muy lejos: -  0.16593375887185433\n",
      "Penalización por duración del episodio: -  0.3293096311447196\n",
      "Recompensa por acortar distancias: +  0.9156975996872189\n",
      "Penalización por duración del episodio: -  0.3294644913166348\n",
      "Step: 6820, Mean Reward (últimos 10 pasos): 0.5862330794334412\n",
      "Recompensa por acortar distancias: +  0.9156975996872189\n",
      "Penalización por parar muy lejos: -  0.16593375887185433\n",
      "Penalización por duración del episodio: -  0.3298791014599321\n",
      "Recompensa por acortar distancias: +  0.9156976733065607\n",
      "Penalización por duración del episodio: -  0.33022064807172663\n",
      "Recompensa por acortar distancias: +  0.9156976880304221\n",
      "Penalización por duración del episodio: -  0.33056628866390664\n",
      "Recompensa por acortar distancias: +  0.9156977690116177\n",
      "Penalización por duración del episodio: -  0.3309169371438237\n",
      "Recompensa por acortar distancias: +  0.915697805821229\n",
      "Penalización por duración del episodio: -  0.33099605601268944\n",
      "Recompensa por acortar distancias: +  0.915697805821229\n",
      "Penalización por duración del episodio: -  0.3310905867373042\n",
      "Recompensa por acortar distancias: +  0.915697805821229\n",
      "Penalización por duración del episodio: -  0.331261789406853\n",
      "Recompensa por acortar distancias: +  0.915697805821229\n",
      "Penalización por duración del episodio: -  0.3316223751019241\n",
      "Recompensa por acortar distancias: +  0.9156976144110918\n",
      "Penalización por duración del episodio: -  0.3319661437616636\n",
      "Recompensa por acortar distancias: +  0.9156976144110918\n",
      "Penalización por parar muy lejos: -  0.16593378526951275\n",
      "Penalización por duración del episodio: -  0.33230257979780387\n",
      "Step: 6830, Mean Reward (últimos 10 pasos): 0.41746124625205994\n",
      "Recompensa por acortar distancias: +  0.9156976733065607\n",
      "Penalización por parar muy lejos: -  0.16593389086018007\n",
      "Penalización por duración del episodio: -  0.332655155175431\n",
      "steer input from model: -0.05 , throttle:  0.0\n",
      "reward: 0.41710862727094966\n",
      "Recompensa por acortar distancias: +  0.9156978205450692\n",
      "Penalización por parar muy lejos: -  0.1659341548370838\n",
      "Penalización por duración del episodio: -  0.33299714160393934\n",
      "Recompensa por acortar distancias: +  0.9156978647165764\n",
      "Penalización por duración del episodio: -  0.3333524596526577\n",
      "Recompensa por acortar distancias: +  0.9156978647165764\n",
      "Penalización por duración del episodio: -  0.3334274725080581\n",
      "Recompensa por acortar distancias: +  0.9156978647165764\n",
      "Penalización por duración del episodio: -  0.33368918008810794\n",
      "Recompensa por acortar distancias: +  0.9156978647165764\n",
      "Penalización por duración del episodio: -  0.3340379081550094\n",
      "Recompensa por acortar distancias: +  0.9156974671722563\n",
      "Penalización por parar muy lejos: -  0.16593352129307995\n",
      "Penalización por duración del episodio: -  0.3344012888516755\n",
      "Recompensa por acortar distancias: +  0.9156975260678185\n",
      "Penalización por duración del episodio: -  0.3345071171052603\n",
      "Recompensa por acortar distancias: +  0.9156975260678185\n",
      "Penalización por duración del episodio: -  0.3346167680904138\n",
      "Recompensa por acortar distancias: +  0.9156974671722563\n",
      "Penalización por parar muy lejos: -  0.16593352129307995\n",
      "Penalización por duración del episodio: -  0.3347432779832573\n",
      "Step: 6840, Mean Reward (últimos 10 pasos): 0.4150206744670868\n",
      "Recompensa por acortar distancias: +  0.9156975113439315\n",
      "Penalización por duración del episodio: -  0.33507878483237824\n",
      "Recompensa por acortar distancias: +  0.9156976438588309\n",
      "Penalización por duración del episodio: -  0.335431056191792\n",
      "Recompensa por acortar distancias: +  0.9156976733065607\n",
      "Penalización por duración del episodio: -  0.3357684358722242\n",
      "Recompensa por acortar distancias: +  0.9156976733065607\n",
      "Penalización por duración del episodio: -  0.33611302172362767\n",
      "Recompensa por acortar distancias: +  0.9156975849633434\n",
      "Penalización por duración del episodio: -  0.3364594268244882\n",
      "Recompensa por acortar distancias: +  0.9156975849633434\n",
      "Penalización por duración del episodio: -  0.3365607698426598\n",
      "Recompensa por acortar distancias: +  0.9156976291349626\n",
      "Penalización por duración del episodio: -  0.33666216516893693\n",
      "Recompensa por acortar distancias: +  0.9156975996872189\n",
      "Penalización por duración del episodio: -  0.3368195986313242\n",
      "Recompensa por acortar distancias: +  0.9156976438588309\n",
      "Penalización por duración del episodio: -  0.33715818321406177\n",
      "Recompensa por acortar distancias: +  0.9156976880304221\n",
      "Penalización por duración del episodio: -  0.33750308679237917\n",
      "Step: 6850, Mean Reward (últimos 10 pasos): 0.5781946182250977\n",
      "Recompensa por acortar distancias: +  0.9156977174781378\n",
      "Penalización por duración del episodio: -  0.33785099550257003\n",
      "steer input from model: 0.05 , throttle:  0.3\n",
      "reward: 0.5778467219755677\n",
      "Recompensa por acortar distancias: +  0.9156977174781378\n",
      "Penalización por duración del episodio: -  0.3382132424413659\n",
      "Recompensa por acortar distancias: +  0.915660988920271\n",
      "Penalización por parar muy lejos: -  0.16586814469193487\n",
      "Penalización por duración del episodio: -  0.3383204537855097\n",
      "Recompensa por acortar distancias: +  0.915660988920271\n",
      "Penalización por parar muy lejos: -  0.16586814469193487\n",
      "Penalización por duración del episodio: -  0.3385660206407056\n",
      "Recompensa por acortar distancias: +  0.9155773456279325\n",
      "Penalización por parar muy lejos: -  0.16571841323523226\n",
      "Penalización por duración del episodio: -  0.33892270697537913\n",
      "Recompensa por acortar distancias: +  0.9152651349694261\n",
      "Penalización por parar muy lejos: -  0.16516165878422412\n",
      "Penalización por duración del episodio: -  0.3390248028708154\n",
      "Recompensa por acortar distancias: +  0.9151172417450227\n",
      "Penalización por duración del episodio: -  0.3392656805013444\n",
      "Recompensa por acortar distancias: +  0.9148439653538295\n",
      "Penalización por parar muy lejos: -  0.16441590737491402\n",
      "Penalización por duración del episodio: -  0.3393706864058044\n",
      "Recompensa por acortar distancias: +  0.9146422447455242\n",
      "Penalización por duración del episodio: -  0.3396146298034207\n",
      "Recompensa por acortar distancias: +  0.9142721851265525\n",
      "Penalización por parar muy lejos: -  0.1634131052586359\n",
      "Penalización por duración del episodio: -  0.3399625817341308\n",
      "Step: 6860, Mean Reward (últimos 10 pasos): 0.41089650988578796\n",
      "Recompensa por acortar distancias: +  0.9142721851265525\n",
      "Penalización por parar muy lejos: -  0.1634131052586359\n",
      "Penalización por duración del episodio: -  0.34032044268038764\n",
      "Recompensa por acortar distancias: +  0.9142721851265525\n",
      "Penalización por parar muy lejos: -  0.1634131052586359\n",
      "Penalización por duración del episodio: -  0.34066396252828973\n",
      "Recompensa por acortar distancias: +  0.9126076228664286\n",
      "Penalización por parar muy lejos: -  0.16055531764962955\n",
      "Penalización por duración del episodio: -  0.3410131630541434\n",
      "Recompensa por acortar distancias: +  0.9115919583750863\n",
      "Penalización por duración del episodio: -  0.3413724852975737\n",
      "Recompensa por acortar distancias: +  0.910610199892875\n",
      "Penalización por parar muy lejos: -  0.15724228731495038\n",
      "Penalización por duración del episodio: -  0.3417337650563898\n",
      "Recompensa por acortar distancias: +  0.9097863740567954\n",
      "Penalización por parar muy lejos: -  0.15591125616302892\n",
      "Penalización por duración del episodio: -  0.3420945578203626\n",
      "Recompensa por acortar distancias: +  0.9091600097695409\n",
      "Penalización por duración del episodio: -  0.34245055119311485\n",
      "Recompensa por acortar distancias: +  0.9091600097695409\n",
      "Penalización por parar muy lejos: -  0.15491266079542954\n",
      "Penalización por duración del episodio: -  0.34257542116277967\n",
      "Recompensa por acortar distancias: +  0.9091600097695409\n",
      "Penalización por duración del episodio: -  0.342690436577787\n",
      "Recompensa por acortar distancias: +  0.9091600097695409\n",
      "Penalización por duración del episodio: -  0.34281481664643776\n",
      "Step: 6870, Mean Reward (últimos 10 pasos): 0.56634521484375\n",
      "Recompensa por acortar distancias: +  0.9068581671345213\n",
      "Penalización por parar muy lejos: -  0.15133901358631013\n",
      "Penalización por duración del episodio: -  0.34314212233528574\n",
      "steer input from model: -0.9 , throttle:  0.0\n",
      "reward: 0.41237703121292535\n",
      "Recompensa por acortar distancias: +  0.9062655586508547\n",
      "Penalización por duración del episodio: -  0.3432455656447921\n",
      "Recompensa por acortar distancias: +  0.9062655586508547\n",
      "Penalización por parar muy lejos: -  0.15044267335632874\n",
      "Penalización por duración del episodio: -  0.343492437575302\n",
      "Recompensa por acortar distancias: +  0.9048672434240917\n",
      "Penalización por parar muy lejos: -  0.1483646796047071\n",
      "Penalización por duración del episodio: -  0.34384746319982634\n",
      "Recompensa por acortar distancias: +  0.9036511542376272\n",
      "Penalización por duración del episodio: -  0.3439754059883669\n",
      "Recompensa por acortar distancias: +  0.9032272779682808\n",
      "Penalización por parar muy lejos: -  0.1459917247369381\n",
      "Penalización por duración del episodio: -  0.34407226980313943\n",
      "Recompensa por acortar distancias: +  0.9032272779682808\n",
      "Penalización por parar muy lejos: -  0.1459917247369381\n",
      "Penalización por duración del episodio: -  0.3445366567046328\n",
      "Recompensa por acortar distancias: +  0.9028176365945253\n",
      "Penalización por parar muy lejos: -  0.14540947993167072\n",
      "Penalización por duración del episodio: -  0.34462826984083317\n",
      "Recompensa por acortar distancias: +  0.9028176365945253\n",
      "Penalización por duración del episodio: -  0.34487884608256797\n",
      "Recompensa por acortar distancias: +  0.9028176365945253\n",
      "Penalización por duración del episodio: -  0.3452230717991701\n",
      "Step: 6880, Mean Reward (últimos 10 pasos): 0.5575945377349854\n",
      "Recompensa por acortar distancias: +  0.9000061016750766\n",
      "Penalización por duración del episodio: -  0.3455668290128903\n",
      "Recompensa por acortar distancias: +  0.8986652047088094\n",
      "Penalización por duración del episodio: -  0.34590911319858997\n",
      "Recompensa por acortar distancias: +  0.8975186096865233\n",
      "Penalización por duración del episodio: -  0.3459831977278369\n",
      "Recompensa por acortar distancias: +  0.897162564106743\n",
      "Penalización por duración del episodio: -  0.3462745426962774\n",
      "Recompensa por acortar distancias: +  0.8960876272754233\n",
      "Penalización por parar muy lejos: -  0.13640096423760417\n",
      "Penalización por duración del episodio: -  0.34661768035356816\n",
      "Recompensa por acortar distancias: +  0.8956885815308535\n",
      "Penalización por parar muy lejos: -  0.13589778477059192\n",
      "Penalización por duración del episodio: -  0.34696847027457706\n",
      "Recompensa por acortar distancias: +  0.8956885815308535\n",
      "Penalización por duración del episodio: -  0.3473408455429909\n",
      "Recompensa por acortar distancias: +  0.8927760787108611\n",
      "Penalización por duración del episodio: -  0.3476891227803468\n",
      "Recompensa por acortar distancias: +  0.8927760787108611\n",
      "Penalización por duración del episodio: -  0.34776111453267067\n",
      "Recompensa por acortar distancias: +  0.891179348872595\n",
      "Penalización por duración del episodio: -  0.34803597791317975\n",
      "Step: 6890, Mean Reward (últimos 10 pasos): 0.5431433916091919\n",
      "Recompensa por acortar distancias: +  0.8902196034344305\n",
      "Penalización por duración del episodio: -  0.348396812237766\n",
      "steer input from model: -0.9 , throttle:  0.7\n",
      "reward: 0.5418227911966645\n",
      "Recompensa por acortar distancias: +  0.8889863481582687\n",
      "Penalización por duración del episodio: -  0.34849258162618074\n",
      "Recompensa por acortar distancias: +  0.888545990083498\n",
      "Penalización por parar muy lejos: -  0.12741332829762153\n",
      "Penalización por duración del episodio: -  0.34873895998468696\n",
      "Recompensa por acortar distancias: +  0.8880586872476057\n",
      "Penalización por duración del episodio: -  0.3491028470878469\n",
      "Recompensa por acortar distancias: +  0.8880586872476057\n",
      "Penalización por parar muy lejos: -  0.12686829472930877\n",
      "Penalización por duración del episodio: -  0.3494653979056073\n",
      "Recompensa por acortar distancias: +  0.8852320127216972\n",
      "Penalización por duración del episodio: -  0.3498205906577556\n",
      "Recompensa por acortar distancias: +  0.8846626696740852\n",
      "Penalización por parar muy lejos: -  0.12318003156342917\n",
      "Penalización por duración del episodio: -  0.3501693529814965\n",
      "Recompensa por acortar distancias: +  0.8824151715137375\n",
      "Penalización por duración del episodio: -  0.3502675343484933\n",
      "Recompensa por acortar distancias: +  0.8819802700767765\n",
      "Penalización por duración del episodio: -  0.3505298475539347\n",
      "Recompensa por acortar distancias: +  0.8810792395827782\n",
      "Penalización por parar muy lejos: -  0.11948566231765698\n",
      "Penalización por duración del episodio: -  0.3508797119178832\n",
      "Step: 6900, Mean Reward (últimos 10 pasos): 0.4107138514518738\n",
      "Recompensa por acortar distancias: +  0.8793844531203044\n",
      "Penalización por parar muy lejos: -  0.11780462521317264\n",
      "Penalización por duración del episodio: -  0.35124432922903615\n",
      "Recompensa por acortar distancias: +  0.8793844531203044\n",
      "Penalización por duración del episodio: -  0.35160614700154946\n",
      "Recompensa por acortar distancias: +  0.8793844531203044\n",
      "Penalización por duración del episodio: -  0.3519531156478567\n",
      "Recompensa por acortar distancias: +  0.8758078687504267\n",
      "Penalización por duración del episodio: -  0.3523137600359048\n",
      "Recompensa por acortar distancias: +  0.8739915516357\n",
      "Penalización por duración del episodio: -  0.35238383069558976\n",
      "Recompensa por acortar distancias: +  0.8733763056128556\n",
      "Penalización por duración del episodio: -  0.3526757431027687\n",
      "Recompensa por acortar distancias: +  0.8724559659001706\n",
      "Penalización por duración del episodio: -  0.3527614912738867\n",
      "Recompensa por acortar distancias: +  0.8719210548339404\n",
      "Penalización por parar muy lejos: -  0.11086380613209143\n",
      "Penalización por duración del episodio: -  0.3530308434330149\n",
      "Recompensa por acortar distancias: +  0.8709497896715567\n",
      "Penalización por duración del episodio: -  0.3531007338907587\n",
      "Recompensa por acortar distancias: +  0.8702931763452659\n",
      "Penalización por parar muy lejos: -  0.10944267661783919\n",
      "Penalización por duración del episodio: -  0.35338759341323583\n",
      "Step: 6910, Mean Reward (últimos 10 pasos): 0.4074628949165344\n",
      "Recompensa por acortar distancias: +  0.8697661215166123\n",
      "Penalización por parar muy lejos: -  0.10898921982908104\n",
      "Penalización por duración del episodio: -  0.3537361240062581\n",
      "steer input from model: 0.05 , throttle:  0.0\n",
      "reward: 0.4070407776812731\n",
      "Recompensa por acortar distancias: +  0.8697661215166123\n",
      "Penalización por duración del episodio: -  0.35409987645391033\n",
      "Recompensa por acortar distancias: +  0.8666166555721612\n",
      "Penalización por duración del episodio: -  0.3544599626034282\n",
      "Recompensa por acortar distancias: +  0.8658722966337281\n",
      "Penalización por duración del episodio: -  0.3548116775912644\n",
      "Recompensa por acortar distancias: +  0.8632501746502022\n",
      "Penalización por parar muy lejos: -  0.1036372257729724\n",
      "Penalización por duración del episodio: -  0.35516374613370383\n",
      "Recompensa por acortar distancias: +  0.8616597555141883\n",
      "Penalización por parar muy lejos: -  0.10239835559906678\n",
      "Penalización por duración del episodio: -  0.35551530506816803\n",
      "Recompensa por acortar distancias: +  0.8599308003690774\n",
      "Penalización por parar muy lejos: -  0.1010797363146443\n",
      "Penalización por duración del episodio: -  0.3558655334232283\n",
      "Recompensa por acortar distancias: +  0.8599308003690774\n",
      "Penalización por duración del episodio: -  0.3562340303367114\n",
      "Recompensa por acortar distancias: +  0.8564918307861418\n",
      "Penalización por parar muy lejos: -  0.09854052693704986\n",
      "Penalización por duración del episodio: -  0.35658962935653893\n",
      "Recompensa por acortar distancias: +  0.8556939301414105\n",
      "Penalización por parar muy lejos: -  0.09796670329016863\n",
      "Penalización por duración del episodio: -  0.35694553975734333\n",
      "Step: 6920, Mean Reward (últimos 10 pasos): 0.40078169107437134\n",
      "Recompensa por acortar distancias: +  0.8535081233244312\n",
      "Penalización por parar muy lejos: -  0.09642314379253741\n",
      "Penalización por duración del episodio: -  0.3570562187861047\n",
      "Recompensa por acortar distancias: +  0.8528001973053411\n",
      "Penalización por duración del episodio: -  0.3573087420476197\n",
      "Recompensa por acortar distancias: +  0.8516923255604467\n",
      "Penalización por duración del episodio: -  0.35766970921046354\n",
      "Recompensa por acortar distancias: +  0.8493925013946628\n",
      "Penalización por parar muy lejos: -  0.0936249974467508\n",
      "Penalización por duración del episodio: -  0.35802631696328263\n",
      "Recompensa por acortar distancias: +  0.8485826891963241\n",
      "Penalización por parar muy lejos: -  0.09309036390967529\n",
      "Penalización por duración del episodio: -  0.35838327925243885\n",
      "Recompensa por acortar distancias: +  0.8485826891963241\n",
      "Penalización por parar muy lejos: -  0.09309036390967529\n",
      "Penalización por duración del episodio: -  0.35873201795705817\n",
      "Recompensa por acortar distancias: +  0.8448665196710391\n",
      "Penalización por duración del episodio: -  0.35908114752441367\n",
      "Recompensa por acortar distancias: +  0.8440452760521084\n",
      "Penalización por parar muy lejos: -  0.09018652369178119\n",
      "Penalización por duración del episodio: -  0.3594373155953148\n",
      "Recompensa por acortar distancias: +  0.8406255321640979\n",
      "Penalización por parar muy lejos: -  0.08809578401331851\n",
      "Penalización por duración del episodio: -  0.3598114267098723\n",
      "Recompensa por acortar distancias: +  0.8387378939560509\n",
      "Penalización por duración del episodio: -  0.3601669835468097\n",
      "Step: 6930, Mean Reward (últimos 10 pasos): 0.4785709083080292\n",
      "Recompensa por acortar distancias: +  0.8371146023941158\n",
      "Penalización por duración del episodio: -  0.36023846171050955\n",
      "steer input from model: -0.9 , throttle:  0.3\n",
      "reward: 0.4768761406836063\n",
      "Recompensa por acortar distancias: +  0.8371146023941158\n",
      "Penalización por parar muy lejos: -  0.08603124122006993\n",
      "Penalización por duración del episodio: -  0.36052367777221916\n",
      "Recompensa por acortar distancias: +  0.8371146023941158\n",
      "Penalización por parar muy lejos: -  0.08603124122006993\n",
      "Penalización por duración del episodio: -  0.360892354493085\n",
      "Recompensa por acortar distancias: +  0.8371146023941158\n",
      "Penalización por duración del episodio: -  0.3612430183326565\n",
      "Recompensa por acortar distancias: +  0.8323333912408879\n",
      "Penalización por duración del episodio: -  0.3616209475070853\n",
      "Recompensa por acortar distancias: +  0.8299491836518734\n",
      "Penalización por parar muy lejos: -  0.08205612111155841\n",
      "Penalización por duración del episodio: -  0.36198569504563516\n",
      "Recompensa por acortar distancias: +  0.8280354499591835\n",
      "Penalización por duración del episodio: -  0.3623508991319786\n",
      "Recompensa por acortar distancias: +  0.8262379738100533\n",
      "Penalización por duración del episodio: -  0.3627210293353074\n",
      "Recompensa por acortar distancias: +  0.8254008042819616\n",
      "Penalización por duración del episodio: -  0.3630878212185156\n",
      "Recompensa por acortar distancias: +  0.8254008042819616\n",
      "Penalización por duración del episodio: -  0.36343804829973286\n",
      "Step: 6940, Mean Reward (últimos 10 pasos): 0.4619627594947815\n",
      "Recompensa por acortar distancias: +  0.8207471582155453\n",
      "Penalización por duración del episodio: -  0.3637881553780091\n",
      "Recompensa por acortar distancias: +  0.818399923437938\n",
      "Penalización por duración del episodio: -  0.36413580669628454\n",
      "Recompensa por acortar distancias: +  0.8169863089907198\n",
      "Penalización por parar muy lejos: -  0.07558252845577286\n",
      "Penalización por duración del episodio: -  0.3642216140601802\n",
      "Recompensa por acortar distancias: +  0.8163488857071484\n",
      "Penalización por duración del episodio: -  0.36449994701103966\n",
      "Recompensa por acortar distancias: +  0.8150887165986174\n",
      "Penalización por duración del episodio: -  0.3648471978427274\n",
      "Recompensa por acortar distancias: +  0.8130521212529443\n",
      "Penalización por parar muy lejos: -  0.07377927958620818\n",
      "Penalización por duración del episodio: -  0.36520915367649126\n",
      "Recompensa por acortar distancias: +  0.8130521212529443\n",
      "Penalización por parar muy lejos: -  0.07377927958620818\n",
      "Penalización por duración del episodio: -  0.3655910637027169\n",
      "Recompensa por acortar distancias: +  0.8130521212529443\n",
      "Penalización por duración del episodio: -  0.36596078956522465\n",
      "Recompensa por acortar distancias: +  0.8075308921229138\n",
      "Penalización por duración del episodio: -  0.3663315644776651\n",
      "Recompensa por acortar distancias: +  0.8049009528782025\n",
      "Penalización por duración del episodio: -  0.3666895029209011\n",
      "Step: 6950, Mean Reward (últimos 10 pasos): 0.43821144104003906\n",
      "Recompensa por acortar distancias: +  0.8028096400615661\n",
      "Penalización por duración del episodio: -  0.36678475137643995\n",
      "steer input from model: 0.1 , throttle:  0.3\n",
      "reward: 0.4360248886851261\n",
      "Recompensa por acortar distancias: +  0.8020897496865584\n",
      "Penalización por parar muy lejos: -  0.06910025676136732\n",
      "Penalización por duración del episodio: -  0.3670579521010247\n",
      "Recompensa por acortar distancias: +  0.8008700900206602\n",
      "Penalización por duración del episodio: -  0.36744443353501755\n",
      "Recompensa por acortar distancias: +  0.8008700900206602\n",
      "Penalización por parar muy lejos: -  0.0686087935743122\n",
      "Penalización por duración del episodio: -  0.3678178797534263\n",
      "Recompensa por acortar distancias: +  0.8008700900206602\n",
      "Penalización por parar muy lejos: -  0.0686087935743122\n",
      "Penalización por duración del episodio: -  0.3681718566410787\n",
      "Recompensa por acortar distancias: +  0.7946539083742852\n",
      "Penalización por duración del episodio: -  0.36854720383600886\n",
      "Recompensa por acortar distancias: +  0.7937672037810721\n",
      "Penalización por parar muy lejos: -  0.06585259662284328\n",
      "Penalización por duración del episodio: -  0.36891901341177963\n",
      "Recompensa por acortar distancias: +  0.7901682446423862\n",
      "Penalización por duración del episodio: -  0.3693027847515845\n",
      "Recompensa por acortar distancias: +  0.7875317372710039\n",
      "Penalización por parar muy lejos: -  0.06357262870104415\n",
      "Penalización por duración del episodio: -  0.3696737214567609\n",
      "Recompensa por acortar distancias: +  0.7875317372710039\n",
      "Penalización por parar muy lejos: -  0.06357262870104415\n",
      "Penalización por duración del episodio: -  0.37003412452543666\n",
      "Step: 6960, Mean Reward (últimos 10 pasos): 0.3539249897003174\n",
      "Recompensa por acortar distancias: +  0.7875317372710039\n",
      "Penalización por duración del episodio: -  0.3704089728706001\n",
      "Recompensa por acortar distancias: +  0.7820078928493015\n",
      "Penalización por duración del episodio: -  0.37076978235531965\n",
      "Recompensa por acortar distancias: +  0.7792602627663827\n",
      "Penalización por duración del episodio: -  0.3711379310688583\n",
      "Recompensa por acortar distancias: +  0.7768659875176559\n",
      "Penalización por parar muy lejos: -  0.05994535087362524\n",
      "Penalización por duración del episodio: -  0.3714998889192764\n",
      "Recompensa por acortar distancias: +  0.7747507296229511\n",
      "Penalización por parar muy lejos: -  0.059263676066404494\n",
      "Penalización por duración del episodio: -  0.3716004082773926\n",
      "Recompensa por acortar distancias: +  0.7738247283776912\n",
      "Penalización por parar muy lejos: -  0.058968964629530385\n",
      "Penalización por duración del episodio: -  0.3718728840564792\n",
      "Recompensa por acortar distancias: +  0.7730006168024529\n",
      "Penalización por duración del episodio: -  0.3719761459049268\n",
      "Recompensa por acortar distancias: +  0.7730006168024529\n",
      "Penalización por parar muy lejos: -  0.05870854941746349\n",
      "Penalización por duración del episodio: -  0.3722293681593496\n",
      "Recompensa por acortar distancias: +  0.7730006168024529\n",
      "Penalización por duración del episodio: -  0.37259210533803616\n",
      "Recompensa por acortar distancias: +  0.7681329072113232\n",
      "Penalización por duración del episodio: -  0.3729529062853158\n",
      "Step: 6970, Mean Reward (últimos 10 pasos): 0.39517998695373535\n",
      "Recompensa por acortar distancias: +  0.7671371879818604\n",
      "Penalización por duración del episodio: -  0.37331375390636745\n",
      "steer input from model: 0.9 , throttle:  1.0\n",
      "reward: 0.3938234340754929\n",
      "Recompensa por acortar distancias: +  0.7642820195224874\n",
      "Penalización por duración del episodio: -  0.3736702618786103\n",
      "Recompensa por acortar distancias: +  0.7620146918908709\n",
      "Penalización por duración del episodio: -  0.37403147887427163\n",
      "Recompensa por acortar distancias: +  0.7598209648356276\n",
      "Penalización por duración del episodio: -  0.37439367955556824\n",
      "Recompensa por acortar distancias: +  0.7589628645356055\n",
      "Penalización por parar muy lejos: -  0.05452654520538005\n",
      "Penalización por duración del episodio: -  0.37475466348321473\n",
      "Recompensa por acortar distancias: +  0.7589628645356055\n",
      "Penalización por parar muy lejos: -  0.05452654520538005\n",
      "Penalización por duración del episodio: -  0.37486177903571516\n",
      "Recompensa por acortar distancias: +  0.7543376695037858\n",
      "Penalización por duración del episodio: -  0.37512178897336346\n",
      "Recompensa por acortar distancias: +  0.7533627942721228\n",
      "Penalización por duración del episodio: -  0.37548035881326186\n",
      "Recompensa por acortar distancias: +  0.7503956083714508\n",
      "Penalización por duración del episodio: -  0.37584707434736114\n",
      "Recompensa por acortar distancias: +  0.7478601881394294\n",
      "Penalización por parar muy lejos: -  0.051526007148544384\n",
      "Penalización por duración del episodio: -  0.37596773913347176\n",
      "Step: 6980, Mean Reward (últimos 10 pasos): 0.32036644220352173\n",
      "Recompensa por acortar distancias: +  0.746864321242553\n",
      "Penalización por parar muy lejos: -  0.051268850848137204\n",
      "Penalización por duración del episodio: -  0.37620795669579676\n",
      "Recompensa por acortar distancias: +  0.7453911104774876\n",
      "Penalización por parar muy lejos: -  0.05089187034959235\n",
      "Penalización por duración del episodio: -  0.3763170226700311\n",
      "Recompensa por acortar distancias: +  0.7453911104774876\n",
      "Penalización por parar muy lejos: -  0.05089187034959235\n",
      "Penalización por duración del episodio: -  0.3765826114429712\n",
      "Recompensa por acortar distancias: +  0.7442819394477423\n",
      "Penalización por duración del episodio: -  0.3769647380177769\n",
      "Recompensa por acortar distancias: +  0.7442819394477423\n",
      "Penalización por parar muy lejos: -  0.05061071545754413\n",
      "Penalización por duración del episodio: -  0.37732719870294407\n",
      "Recompensa por acortar distancias: +  0.7376699504117001\n",
      "Penalización por parar muy lejos: -  0.04898075005106413\n",
      "Penalización por duración del episodio: -  0.3776960785051054\n",
      "Recompensa por acortar distancias: +  0.7376699504117001\n",
      "Penalización por parar muy lejos: -  0.04898075005106413\n",
      "Penalización por duración del episodio: -  0.37806809357047566\n",
      "Recompensa por acortar distancias: +  0.7333705120426515\n",
      "Penalización por parar muy lejos: -  0.04796140447366066\n",
      "Penalización por duración del episodio: -  0.37844091959662307\n",
      "Recompensa por acortar distancias: +  0.7304310291419202\n",
      "Penalización por duración del episodio: -  0.3788173901893517\n",
      "Recompensa por acortar distancias: +  0.7287787383717981\n",
      "Penalización por duración del episodio: -  0.37918532990681714\n",
      "Step: 6990, Mean Reward (últimos 10 pasos): 0.3495934009552002\n",
      "Recompensa por acortar distancias: +  0.7287787383717981\n",
      "Penalización por duración del episodio: -  0.37955944433049005\n",
      "steer input from model: -0.25 , throttle:  0.7\n",
      "reward: 0.349219294041308\n",
      "Recompensa por acortar distancias: +  0.7287787383717981\n",
      "Penalización por duración del episodio: -  0.3799264844593064\n",
      "Recompensa por acortar distancias: +  0.7211998365465323\n",
      "Penalización por duración del episodio: -  0.380286925026162\n",
      "Recompensa por acortar distancias: +  0.7211998365465323\n",
      "Penalización por duración del episodio: -  0.38064514812313777\n",
      "Recompensa por acortar distancias: +  0.7160534047899862\n",
      "Penalización por duración del episodio: -  0.3810074484550778\n",
      "Recompensa por acortar distancias: +  0.7140435809435117\n",
      "Penalización por duración del episodio: -  0.38138348810253847\n",
      "Recompensa por acortar distancias: +  0.7130893464042816\n",
      "Penalización por duración del episodio: -  0.3817552076809831\n",
      "Recompensa por acortar distancias: +  0.7130893464042816\n",
      "Penalización por duración del episodio: -  0.381831232854315\n",
      "Recompensa por acortar distancias: +  0.7130893464042816\n",
      "Penalización por duración del episodio: -  0.3819689820224944\n",
      "Recompensa por acortar distancias: +  0.707619390541016\n",
      "Penalización por duración del episodio: -  0.38212341241505193\n",
      "Step: 7000, Mean Reward (últimos 10 pasos): 0.32549598813056946\n",
      "Recompensa por acortar distancias: +  0.7064199764359839\n",
      "Penalización por duración del episodio: -  0.3824896859043318\n",
      "Recompensa por acortar distancias: +  0.7064199764359839\n",
      "Penalización por duración del episodio: -  0.382862272671587\n",
      "Recompensa por acortar distancias: +  0.7013493411617849\n",
      "Penalización por duración del episodio: -  0.3832257043966994\n",
      "Recompensa por acortar distancias: +  0.6994778727594253\n",
      "Penalización por duración del episodio: -  0.3835872203140013\n",
      "Recompensa por acortar distancias: +  0.6966407766275364\n",
      "Penalización por duración del episodio: -  0.3839570702784743\n",
      "Recompensa por acortar distancias: +  0.6966407766275364\n",
      "Penalización por duración del episodio: -  0.384329124924314\n",
      "Recompensa por acortar distancias: +  0.6966407766275364\n",
      "Penalización por duración del episodio: -  0.38469699767551235\n",
      "Recompensa por acortar distancias: +  0.6903685733919482\n",
      "Penalización por duración del episodio: -  0.3850627102418409\n",
      "Recompensa por acortar distancias: +  0.6872451276056621\n",
      "Penalización por duración del episodio: -  0.38543588317726185\n",
      "Recompensa por acortar distancias: +  0.6848995443238001\n",
      "Penalización por duración del episodio: -  0.38580568813283206\n",
      "Step: 7010, Mean Reward (últimos 10 pasos): 0.2990938425064087\n",
      "Recompensa por acortar distancias: +  0.6825925477384499\n",
      "Penalización por duración del episodio: -  0.38616459879053844\n",
      "steer input from model: -0.9 , throttle:  0.0\n",
      "reward: 0.29642794894791147\n",
      "Recompensa por acortar distancias: +  0.681651441268063\n",
      "Penalización por duración del episodio: -  0.3865246904121273\n",
      "Recompensa por acortar distancias: +  0.681651441268063\n",
      "Penalización por duración del episodio: -  0.3868999553266085\n",
      "Recompensa por acortar distancias: +  0.6754881947676172\n",
      "Penalización por duración del episodio: -  0.3872894418709567\n",
      "Recompensa por acortar distancias: +  0.6723925191219287\n",
      "Penalización por duración del episodio: -  0.3876524384780538\n",
      "Recompensa por acortar distancias: +  0.6704972316313458\n",
      "Penalización por duración del episodio: -  0.387755594163708\n",
      "Recompensa por acortar distancias: +  0.6697315325938645\n",
      "Penalización por duración del episodio: -  0.3880225404764172\n",
      "Recompensa por acortar distancias: +  0.6680616350260459\n",
      "Penalización por duración del episodio: -  0.388126808016827\n",
      "Recompensa por acortar distancias: +  0.6673081383103195\n",
      "Penalización por duración del episodio: -  0.3883898550132136\n",
      "Recompensa por acortar distancias: +  0.6662894988869649\n",
      "Penalización por duración del episodio: -  0.38877225886541056\n",
      "Step: 7020, Mean Reward (últimos 10 pasos): 0.2775172293186188\n",
      "Recompensa por acortar distancias: +  0.6662894988869649\n",
      "Penalización por duración del episodio: -  0.38915225494525024\n",
      "Recompensa por acortar distancias: +  0.6612020037300934\n",
      "Penalización por duración del episodio: -  0.3895469394966168\n",
      "Recompensa por acortar distancias: +  0.6600693988045668\n",
      "Penalización por duración del episodio: -  0.38992431154329676\n",
      "Recompensa por acortar distancias: +  0.6551917440907856\n",
      "Penalización por duración del episodio: -  0.39029538730718516\n",
      "Recompensa por acortar distancias: +  0.6528659416286428\n",
      "Penalización por duración del episodio: -  0.3906743995408092\n",
      "Recompensa por acortar distancias: +  0.650414090770962\n",
      "Penalización por duración del episodio: -  0.39103503534547956\n",
      "Recompensa por acortar distancias: +  0.650414090770962\n",
      "Penalización por duración del episodio: -  0.39140032226981386\n",
      "Recompensa por acortar distancias: +  0.650414090770962\n",
      "Penalización por duración del episodio: -  0.39150805207032535\n",
      "Recompensa por acortar distancias: +  0.644920802414077\n",
      "Penalización por duración del episodio: -  0.39177948508908156\n",
      "Recompensa por acortar distancias: +  0.6437137406228836\n",
      "Penalización por duración del episodio: -  0.3921477986680556\n",
      "Step: 7030, Mean Reward (últimos 10 pasos): 0.25156593322753906\n",
      "Recompensa por acortar distancias: +  0.6404993781955015\n",
      "Penalización por duración del episodio: -  0.39225191858003666\n",
      "steer input from model: -0.05 , throttle:  0.3\n",
      "reward: 0.24824745961546485\n",
      "Recompensa por acortar distancias: +  0.6394079740132366\n",
      "Penalización por duración del episodio: -  0.3925092083761618\n",
      "Recompensa por acortar distancias: +  0.637692299187319\n",
      "Penalización por duración del episodio: -  0.3928821892392312\n",
      "Recompensa por acortar distancias: +  0.6350362506801682\n",
      "Penalización por duración del episodio: -  0.3932566262722218\n",
      "Recompensa por acortar distancias: +  0.6339177776484128\n",
      "Penalización por duración del episodio: -  0.39332801169934895\n",
      "Recompensa por acortar distancias: +  0.6339177776484128\n",
      "Penalización por duración del episodio: -  0.39364334421288166\n",
      "Recompensa por acortar distancias: +  0.6339177776484128\n",
      "Penalización por duración del episodio: -  0.39401612882766524\n",
      "Recompensa por acortar distancias: +  0.6273401636580922\n",
      "Penalización por duración del episodio: -  0.39437991423711577\n",
      "Recompensa por acortar distancias: +  0.623976098639154\n",
      "Penalización por duración del episodio: -  0.3947460439937857\n",
      "Recompensa por acortar distancias: +  0.6211730329105936\n",
      "Penalización por duración del episodio: -  0.39511445150603003\n",
      "Step: 7040, Mean Reward (últimos 10 pasos): 0.22605858743190765\n",
      "Recompensa por acortar distancias: +  0.6186305743292141\n",
      "Penalización por duración del episodio: -  0.39518873541080934\n",
      "Recompensa por acortar distancias: +  0.6186305743292141\n",
      "Penalización por duración del episodio: -  0.3954920355513856\n",
      "Recompensa por acortar distancias: +  0.6165205490363822\n",
      "Penalización por duración del episodio: -  0.3958764383830652\n",
      "Recompensa por acortar distancias: +  0.6165205490363822\n",
      "Penalización por duración del episodio: -  0.396235097399448\n",
      "Recompensa por acortar distancias: +  0.6105272843038753\n",
      "Penalización por duración del episodio: -  0.39631446218464983\n",
      "Recompensa por acortar distancias: +  0.6105272843038753\n",
      "Penalización por duración del episodio: -  0.3966130159490258\n",
      "Recompensa por acortar distancias: +  0.609164199855978\n",
      "Penalización por duración del episodio: -  0.39698235977250496\n",
      "Recompensa por acortar distancias: +  0.6047596003455697\n",
      "Penalización por duración del episodio: -  0.39707265497379945\n",
      "Recompensa por acortar distancias: +  0.6037806106361642\n",
      "Penalización por duración del episodio: -  0.3973575531447837\n",
      "Recompensa por acortar distancias: +  0.6021215017624917\n",
      "Penalización por duración del episodio: -  0.397494795159436\n",
      "Step: 7050, Mean Reward (últimos 10 pasos): 0.20462670922279358\n",
      "Recompensa por acortar distancias: +  0.6011252068757987\n",
      "Penalización por duración del episodio: -  0.39772443766114945\n",
      "steer input from model: -0.05 , throttle:  0.0\n",
      "reward: 0.20340076921464928\n",
      "Recompensa por acortar distancias: +  0.5999005224134686\n",
      "Penalización por duración del episodio: -  0.39782510533639104\n",
      "Recompensa por acortar distancias: +  0.5988889575148051\n",
      "Penalización por duración del episodio: -  0.3980912829095301\n",
      "Recompensa por acortar distancias: +  0.5988889575148051\n",
      "Penalización por duración del episodio: -  0.3984657745805347\n",
      "Recompensa por acortar distancias: +  0.5988889575148051\n",
      "Penalización por duración del episodio: -  0.39882983823866475\n",
      "Recompensa por acortar distancias: +  0.5917974256869112\n",
      "Penalización por duración del episodio: -  0.39889025676412965\n",
      "Recompensa por acortar distancias: +  0.5917974256869112\n",
      "Penalización por duración del episodio: -  0.398985952881939\n",
      "Recompensa por acortar distancias: +  0.5917974256869112\n",
      "Penalización por duración del episodio: -  0.399192412693975\n",
      "Recompensa por acortar distancias: +  0.5881754859810137\n",
      "Penalización por duración del episodio: -  0.3995812551718727\n",
      "Recompensa por acortar distancias: +  0.5851738355032549\n",
      "Penalización por duración del episodio: -  0.39994643854292133\n",
      "Step: 7060, Mean Reward (últimos 10 pasos): 0.1852273941040039\n",
      "Recompensa por acortar distancias: +  0.5823937750255239\n",
      "Penalización por duración del episodio: -  0.40031981479627904\n",
      "Recompensa por acortar distancias: +  0.5803899239027689\n",
      "Penalización por duración del episodio: -  0.40069607220061826\n",
      "Recompensa por acortar distancias: +  0.5803899239027689\n",
      "Penalización por duración del episodio: -  0.401083694867173\n",
      "Recompensa por acortar distancias: +  0.5736636490277767\n",
      "Penalización por duración del episodio: -  0.4014582302876486\n",
      "Recompensa por acortar distancias: +  0.5720208017487677\n",
      "Penalización por duración del episodio: -  0.40184253707448764\n",
      "Recompensa por acortar distancias: +  0.5680424652767454\n",
      "Penalización por duración del episodio: -  0.4019349489182483\n",
      "Recompensa por acortar distancias: +  0.5668273005946615\n",
      "Penalización por duración del episodio: -  0.40222497533230683\n",
      "Recompensa por acortar distancias: +  0.5639401916581215\n",
      "Penalización por duración del episodio: -  0.40260007225519695\n",
      "Recompensa por acortar distancias: +  0.5619255098044413\n",
      "Penalización por duración del episodio: -  0.4029754667212869\n",
      "Recompensa por acortar distancias: +  0.5619255098044413\n",
      "Penalización por duración del episodio: -  0.4033681423710299\n",
      "Step: 7070, Mean Reward (últimos 10 pasos): 0.15855737030506134\n",
      "Recompensa por acortar distancias: +  0.5554350072748303\n",
      "Penalización por duración del episodio: -  0.40373886741616727\n",
      "steer input from model: 0.1 , throttle:  0.7\n",
      "reward: 0.15169613985866304\n",
      "Recompensa por acortar distancias: +  0.5542307463939039\n",
      "Penalización por duración del episodio: -  0.40411655746561076\n",
      "Recompensa por acortar distancias: +  0.549205157032441\n",
      "Penalización por duración del episodio: -  0.4044814050184419\n",
      "Recompensa por acortar distancias: +  0.5463550248241904\n",
      "Penalización por duración del episodio: -  0.4048717954962449\n",
      "Recompensa por acortar distancias: +  0.5425941158708807\n",
      "Penalización por duración del episodio: -  0.4052404986528417\n",
      "Recompensa por acortar distancias: +  0.5425941158708807\n",
      "Penalización por duración del episodio: -  0.4055997095384411\n",
      "Recompensa por acortar distancias: +  0.5425941158708807\n",
      "Penalización por duración del episodio: -  0.405707190159883\n",
      "Recompensa por acortar distancias: +  0.5363339421869258\n",
      "Penalización por duración del episodio: -  0.40598779864148143\n",
      "Recompensa por acortar distancias: +  0.5346653197407897\n",
      "Penalización por duración del episodio: -  0.40637237602863374\n",
      "Recompensa por acortar distancias: +  0.5309855152768084\n",
      "Penalización por duración del episodio: -  0.4067409249402349\n",
      "Step: 7080, Mean Reward (últimos 10 pasos): 0.12424459308385849\n",
      "Recompensa por acortar distancias: +  0.5279669795479871\n",
      "Penalización por duración del episodio: -  0.40710732301516983\n",
      "Recompensa por acortar distancias: +  0.5257627776215981\n",
      "Penalización por duración del episodio: -  0.4072277233375816\n",
      "Recompensa por acortar distancias: +  0.5246542981264621\n",
      "Penalización por duración del episodio: -  0.4073193734023543\n",
      "Recompensa por acortar distancias: +  0.5246542981264621\n",
      "Penalización por duración del episodio: -  0.4074327074756493\n",
      "Recompensa por acortar distancias: +  0.5231969842041686\n",
      "Penalización por duración del episodio: -  0.40786729005663264\n",
      "Recompensa por acortar distancias: +  0.5231969842041686\n",
      "Penalización por duración del episodio: -  0.4082487552328316\n",
      "Recompensa por acortar distancias: +  0.5170510487298975\n",
      "Penalización por duración del episodio: -  0.40861693573301056\n",
      "Recompensa por acortar distancias: +  0.5157964512009774\n",
      "Penalización por duración del episodio: -  0.4089827061365209\n",
      "Recompensa por acortar distancias: +  0.5111823088880387\n",
      "Penalización por duración del episodio: -  0.40937437965195034\n",
      "Recompensa por acortar distancias: +  0.5087907016981773\n",
      "Penalización por duración del episodio: -  0.4097633253978749\n",
      "Step: 7090, Mean Reward (últimos 10 pasos): 0.0990273728966713\n",
      "Recompensa por acortar distancias: +  0.5061563837494658\n",
      "Penalización por duración del episodio: -  0.4101512881410987\n",
      "steer input from model: -0.9 , throttle:  0.0\n",
      "reward: 0.09600509560836712\n",
      "Recompensa por acortar distancias: +  0.5052703216727452\n",
      "Penalización por duración del episodio: -  0.4105234154879718\n",
      "Recompensa por acortar distancias: +  0.5052703216727452\n",
      "Penalización por duración del episodio: -  0.4106258121908251\n",
      "Recompensa por acortar distancias: +  0.49954087151080484\n",
      "Penalización por duración del episodio: -  0.410893152124155\n",
      "Recompensa por acortar distancias: +  0.4983067219617461\n",
      "Penalización por duración del episodio: -  0.41127617440871783\n",
      "Recompensa por acortar distancias: +  0.4949470928958336\n",
      "Penalización por duración del episodio: -  0.411634099211979\n",
      "Recompensa por acortar distancias: +  0.49234950054789417\n",
      "Penalización por duración del episodio: -  0.41200990710325125\n",
      "Recompensa por acortar distancias: +  0.489813741975616\n",
      "Penalización por duración del episodio: -  0.4123879899379331\n",
      "Recompensa por acortar distancias: +  0.48797352460818566\n",
      "Penalización por duración del episodio: -  0.41275566992092316\n",
      "Recompensa por acortar distancias: +  0.48797352460818566\n",
      "Penalización por duración del episodio: -  0.4131328117174576\n",
      "Step: 7100, Mean Reward (últimos 10 pasos): 0.07484070956707001\n",
      "Recompensa por acortar distancias: +  0.4821296369484692\n",
      "Penalización por duración del episodio: -  0.41325967756285864\n",
      "Recompensa por acortar distancias: +  0.4821296369484692\n",
      "Penalización por duración del episodio: -  0.4133329142165293\n",
      "Recompensa por acortar distancias: +  0.48074872158490695\n",
      "Penalización por duración del episodio: -  0.41351755488647146\n",
      "Recompensa por acortar distancias: +  0.48074872158490695\n",
      "Penalización por duración del episodio: -  0.4138857466140654\n",
      "Recompensa por acortar distancias: +  0.47709365481022514\n",
      "Penalización por duración del episodio: -  0.41425430073237934\n",
      "Recompensa por acortar distancias: +  0.47455019398278886\n",
      "Penalización por duración del episodio: -  0.41464564061063786\n",
      "Recompensa por acortar distancias: +  0.47234768041465086\n",
      "Penalización por duración del episodio: -  0.4150368566972346\n",
      "Recompensa por acortar distancias: +  0.47234768041465086\n",
      "Penalización por duración del episodio: -  0.4154063346647868\n",
      "Recompensa por acortar distancias: +  0.46681572240155206\n",
      "Penalización por duración del episodio: -  0.4157886140155219\n",
      "Recompensa por acortar distancias: +  0.46564991659481036\n",
      "Penalización por duración del episodio: -  0.4161774190820003\n",
      "Step: 7110, Mean Reward (últimos 10 pasos): 0.049472495913505554\n",
      "Recompensa por acortar distancias: +  0.4623134516832784\n",
      "Penalización por duración del episodio: -  0.416550752954303\n",
      "steer input from model: -0.9 , throttle:  0.0\n",
      "reward: 0.045762698728975426\n",
      "Recompensa por acortar distancias: +  0.45961680350244405\n",
      "Penalización por duración del episodio: -  0.416937321969768\n",
      "Recompensa por acortar distancias: +  0.4571412075764954\n",
      "Penalización por duración del episodio: -  0.4173176970615911\n",
      "Recompensa por acortar distancias: +  0.4562093234084027\n",
      "Penalización por duración del episodio: -  0.4176878890356319\n",
      "Recompensa por acortar distancias: +  0.4562093234084027\n",
      "Penalización por duración del episodio: -  0.4180754010146928\n",
      "Recompensa por acortar distancias: +  0.4503575707035249\n",
      "Penalización por duración del episodio: -  0.4184562722942847\n",
      "Recompensa por acortar distancias: +  0.4503575707035249\n",
      "Penalización por duración del episodio: -  0.4188373336707636\n",
      "Recompensa por acortar distancias: +  0.4458348730074977\n",
      "Penalización por duración del episodio: -  0.4189289955150125\n",
      "Recompensa por acortar distancias: +  0.4450837444762012\n",
      "Penalización por duración del episodio: -  0.4190326949403783\n",
      "Recompensa por acortar distancias: +  0.44438819543511715\n",
      "Penalización por duración del episodio: -  0.4192246567030435\n",
      "Step: 7120, Mean Reward (últimos 10 pasos): 0.02516353875398636\n",
      "Recompensa por acortar distancias: +  0.4429348829282487\n",
      "Penalización por duración del episodio: -  0.4193246436943062\n",
      "Recompensa por acortar distancias: +  0.4429348829282487\n",
      "Penalización por duración del episodio: -  0.4196095825545424\n",
      "Recompensa por acortar distancias: +  0.44133301240739564\n",
      "Penalización por duración del episodio: -  0.41999554131491784\n",
      "Recompensa por acortar distancias: +  0.44133301240739564\n",
      "Penalización por duración del episodio: -  0.4203648497444067\n",
      "Recompensa por acortar distancias: +  0.4367359999614642\n",
      "Penalización por duración del episodio: -  0.4204654985733976\n",
      "Recompensa por acortar distancias: +  0.4358206483926386\n",
      "Penalización por duración del episodio: -  0.4205682688676312\n",
      "Recompensa por acortar distancias: +  0.4358206483926386\n",
      "Penalización por duración del episodio: -  0.4207350957049115\n",
      "Recompensa por acortar distancias: +  0.4358206483926386\n",
      "Penalización por duración del episodio: -  0.42111226585697875\n",
      "Recompensa por acortar distancias: +  0.4329836779676362\n",
      "Penalización por duración del episodio: -  0.4214823019314369\n",
      "Recompensa por acortar distancias: +  0.43080994639423403\n",
      "Penalización por duración del episodio: -  0.42187958184904295\n",
      "Step: 7130, Mean Reward (últimos 10 pasos): 0.00893036462366581\n",
      "Recompensa por acortar distancias: +  0.4280208851655279\n",
      "Penalización por duración del episodio: -  0.4222564833515878\n",
      "steer input from model: 0.25 , throttle:  1.0\n",
      "reward: 0.005764401813940112\n",
      "Recompensa por acortar distancias: +  0.4267651896623673\n",
      "Penalización por duración del episodio: -  0.42262575527063284\n",
      "Recompensa por acortar distancias: +  0.4267651896623673\n",
      "Penalización por duración del episodio: -  0.4230085151046247\n",
      "Recompensa por acortar distancias: +  0.42224613607594674\n",
      "Penalización por duración del episodio: -  0.4233856574507192\n",
      "Recompensa por acortar distancias: +  0.4214515721869724\n",
      "Penalización por duración del episodio: -  0.4237755517607447\n",
      "Recompensa por acortar distancias: +  0.41776114292378935\n",
      "Penalización por duración del episodio: -  0.42415681181644593\n",
      "Recompensa por acortar distancias: +  0.41521260199832316\n",
      "Penalización por duración del episodio: -  0.42455510047496425\n",
      "Recompensa por acortar distancias: +  0.4145776361422433\n",
      "Penalización por duración del episodio: -  0.42493709232375015\n",
      "Recompensa por acortar distancias: +  0.4145776361422433\n",
      "Penalización por duración del episodio: -  0.42502582668535327\n",
      "Recompensa por acortar distancias: +  0.4145776361422433\n",
      "Penalización por duración del episodio: -  0.4253223614798671\n",
      "Step: 7140, Mean Reward (últimos 10 pasos): -0.010744725354015827\n",
      "Recompensa por acortar distancias: +  0.4091773007964195\n",
      "Penalización por duración del episodio: -  0.42539900078414233\n",
      "Recompensa por acortar distancias: +  0.4091773007964195\n",
      "Penalización por duración del episodio: -  0.42571502495138125\n",
      "Recompensa por acortar distancias: +  0.4091773007964195\n",
      "Penalización por duración del episodio: -  0.42610816111089533\n",
      "Recompensa por acortar distancias: +  0.40494553674717754\n",
      "Penalización por duración del episodio: -  0.42648958160679273\n",
      "Recompensa por acortar distancias: +  0.40294338556005266\n",
      "Penalización por duración del episodio: -  0.42688148977193485\n",
      "Recompensa por acortar distancias: +  0.40093479145610583\n",
      "Penalización por duración del episodio: -  0.4269546663361262\n",
      "Recompensa por acortar distancias: +  0.40093479145610583\n",
      "Penalización por duración del episodio: -  0.42726984912765836\n",
      "Recompensa por acortar distancias: +  0.40093479145610583\n",
      "Penalización por duración del episodio: -  0.42766309510195377\n",
      "Recompensa por acortar distancias: +  0.39671875736439444\n",
      "Penalización por duración del episodio: -  0.42803684343429954\n",
      "Recompensa por acortar distancias: +  0.3958654222147484\n",
      "Penalización por duración del episodio: -  0.4284142352557734\n",
      "Step: 7150, Mean Reward (últimos 10 pasos): -0.03254881128668785\n",
      "Recompensa por acortar distancias: +  0.39282785225859895\n",
      "Penalización por duración del episodio: -  0.42879502724690516\n",
      "steer input from model: -0.1 , throttle:  0.0\n",
      "reward: -0.035967174988306205\n",
      "Recompensa por acortar distancias: +  0.3909519216432836\n",
      "Penalización por duración del episodio: -  0.42917433237178165\n",
      "Recompensa por acortar distancias: +  0.3892626524689813\n",
      "Penalización por duración del episodio: -  0.4295574421532917\n",
      "Recompensa por acortar distancias: +  0.38867525287572463\n",
      "Penalización por duración del episodio: -  0.4299353480347142\n",
      "Recompensa por acortar distancias: +  0.38867525287572463\n",
      "Penalización por duración del episodio: -  0.43031843800176695\n",
      "Recompensa por acortar distancias: +  0.38453703407465323\n",
      "Penalización por duración del episodio: -  0.4306980979937753\n",
      "Recompensa por acortar distancias: +  0.38453703407465323\n",
      "Penalización por duración del episodio: -  0.43108566891348843\n",
      "Recompensa por acortar distancias: +  0.38142080513531107\n",
      "Penalización por duración del episodio: -  0.431187086247409\n",
      "Recompensa por acortar distancias: +  0.380952165819645\n",
      "Penalización por duración del episodio: -  0.43145790767513265\n",
      "Recompensa por acortar distancias: +  0.37985028536655685\n",
      "Penalización por duración del episodio: -  0.431575781316909\n",
      "Step: 7160, Mean Reward (últimos 10 pasos): -0.05172549560666084\n",
      "Recompensa por acortar distancias: +  0.3793440408685412\n",
      "Penalización por duración del episodio: -  0.43184653283628344\n",
      "Recompensa por acortar distancias: +  0.37858942952710095\n",
      "Penalización por duración del episodio: -  0.4322250261356262\n",
      "Recompensa por acortar distancias: +  0.37858942952710095\n",
      "Penalización por duración del episodio: -  0.4326146358020857\n",
      "Recompensa por acortar distancias: +  0.37568719613360496\n",
      "Penalización por duración del episodio: -  0.43298254241106043\n",
      "Recompensa por acortar distancias: +  0.3750468033161934\n",
      "Penalización por duración del episodio: -  0.43334576318448453\n",
      "Recompensa por acortar distancias: +  0.37352111578224934\n",
      "Penalización por duración del episodio: -  0.43373618521224744\n",
      "Recompensa por acortar distancias: +  0.3722818284425519\n",
      "Penalización por duración del episodio: -  0.4338709725392352\n",
      "Recompensa por acortar distancias: +  0.37183438036656696\n",
      "Penalización por duración del episodio: -  0.43412046937456406\n",
      "Recompensa por acortar distancias: +  0.3711235356662792\n",
      "Penalización por duración del episodio: -  0.43451654332039724\n",
      "Recompensa por acortar distancias: +  0.3711235356662792\n",
      "Penalización por duración del episodio: -  0.43489733159368904\n",
      "Step: 7170, Mean Reward (últimos 10 pasos): -0.06377379596233368\n",
      "Recompensa por acortar distancias: +  0.36889613327469156\n",
      "Penalización por duración del episodio: -  0.4352926900056947\n",
      "steer input from model: -0.9 , throttle:  0.0\n",
      "reward: -0.06639655673100314\n",
      "Recompensa por acortar distancias: +  0.3684482300176621\n",
      "Penalización por duración del episodio: -  0.43567614913503644\n",
      "Recompensa por acortar distancias: +  0.3668565628136278\n",
      "Penalización por duración del episodio: -  0.4360522744136357\n",
      "Recompensa por acortar distancias: +  0.36598406899503794\n",
      "Penalización por duración del episodio: -  0.4364411691266835\n",
      "Recompensa por acortar distancias: +  0.3651554466578798\n",
      "Penalización por duración del episodio: -  0.43682797771533344\n",
      "Recompensa por acortar distancias: +  0.36461228654928796\n",
      "Penalización por duración del episodio: -  0.43692615975854426\n",
      "Recompensa por acortar distancias: +  0.36461228654928796\n",
      "Penalización por duración del episodio: -  0.4372105923675324\n",
      "Recompensa por acortar distancias: +  0.36461228654928796\n",
      "Penalización por duración del episodio: -  0.4375842280470309\n",
      "Recompensa por acortar distancias: +  0.36276553306674597\n",
      "Penalización por duración del episodio: -  0.4376921065114793\n",
      "Recompensa por acortar distancias: +  0.36276553306674597\n",
      "Penalización por duración del episodio: -  0.4379558863786979\n",
      "Step: 7180, Mean Reward (últimos 10 pasos): -0.07519035041332245\n",
      "Recompensa por acortar distancias: +  0.3623289912136756\n",
      "Penalización por duración del episodio: -  0.4383282482934034\n",
      "Recompensa por acortar distancias: +  0.3613791677442837\n",
      "Penalización por duración del episodio: -  0.43871876206580296\n",
      "Recompensa por acortar distancias: +  0.3606893525107259\n",
      "Penalización por duración del episodio: -  0.43910314499176645\n",
      "Recompensa por acortar distancias: +  0.3600294018303515\n",
      "Penalización por duración del episodio: -  0.43949281636975984\n",
      "Recompensa por acortar distancias: +  0.3600294018303515\n",
      "Penalización por duración del episodio: -  0.4398885365247688\n",
      "Recompensa por acortar distancias: +  0.3587349248325966\n",
      "Penalización por duración del episodio: -  0.4399931548619947\n",
      "Recompensa por acortar distancias: +  0.3584922310044646\n",
      "Penalización por duración del episodio: -  0.44028509103647784\n",
      "Recompensa por acortar distancias: +  0.3584922310044646\n",
      "Penalización por duración del episodio: -  0.4406718021420824\n",
      "Recompensa por acortar distancias: +  0.35760212543694947\n",
      "Penalización por duración del episodio: -  0.44105743323651614\n",
      "Recompensa por acortar distancias: +  0.357145444096322\n",
      "Penalización por duración del episodio: -  0.4414453752465588\n",
      "Step: 7190, Mean Reward (últimos 10 pasos): -0.08429992944002151\n",
      "Recompensa por acortar distancias: +  0.3566692727987043\n",
      "Penalización por duración del episodio: -  0.44183972130238663\n",
      "steer input from model: 0.25 , throttle:  0.0\n",
      "reward: -0.08517044850368233\n",
      "Recompensa por acortar distancias: +  0.3565194125074866\n",
      "Penalización por duración del episodio: -  0.4422304651562465\n",
      "Recompensa por acortar distancias: +  0.3565194125074866\n",
      "Penalización por duración del episodio: -  0.4423395115238946\n",
      "Recompensa por acortar distancias: +  0.3555972231746288\n",
      "Penalización por duración del episodio: -  0.44260829319081924\n",
      "Recompensa por acortar distancias: +  0.35538306848237455\n",
      "Penalización por duración del episodio: -  0.44300856656887666\n",
      "Recompensa por acortar distancias: +  0.3548697134340296\n",
      "Penalización por duración del episodio: -  0.44337293293699653\n",
      "Recompensa por acortar distancias: +  0.35448774769398206\n",
      "Penalización por duración del episodio: -  0.44374485773498756\n",
      "Recompensa por acortar distancias: +  0.3541546859353946\n",
      "Penalización por duración del episodio: -  0.4441380588701568\n",
      "Recompensa por acortar distancias: +  0.35389586466870604\n",
      "Penalización por duración del episodio: -  0.4445384533970174\n",
      "Recompensa por acortar distancias: +  0.35389586466870604\n",
      "Penalización por duración del episodio: -  0.4449211200485214\n",
      "Step: 7200, Mean Reward (últimos 10 pasos): -0.09102525562047958\n",
      "Recompensa por acortar distancias: +  0.35322668762898896\n",
      "Penalización por duración del episodio: -  0.4453024386344615\n",
      "Recompensa por acortar distancias: +  0.35310098985146715\n",
      "Penalización por duración del episodio: -  0.4456927039538242\n",
      "Recompensa por acortar distancias: +  0.3526173910005814\n",
      "Penalización por duración del episodio: -  0.44607910095734576\n",
      "Recompensa por acortar distancias: +  0.35229635081018834\n",
      "Penalización por duración del episodio: -  0.4464549278543409\n",
      "Recompensa por acortar distancias: +  0.3520614952085786\n",
      "Penalización por duración del episodio: -  0.44685018065782195\n",
      "Recompensa por acortar distancias: +  0.3520614952085786\n",
      "Penalización por duración del episodio: -  0.4472409975614366\n",
      "Recompensa por acortar distancias: +  0.3520614952085786\n",
      "Penalización por duración del episodio: -  0.44764267358447213\n",
      "Recompensa por acortar distancias: +  0.35153048927503744\n",
      "Penalización por duración del episodio: -  0.4480205329422694\n",
      "Recompensa por acortar distancias: +  0.3512924932766288\n",
      "Penalización por duración del episodio: -  0.4484155005609957\n",
      "Recompensa por acortar distancias: +  0.3511546158069258\n",
      "Penalización por duración del episodio: -  0.4488115713067491\n",
      "Step: 7210, Mean Reward (últimos 10 pasos): -0.09765695780515671\n",
      "Recompensa por acortar distancias: +  0.3509679810555733\n",
      "Penalización por duración del episodio: -  0.4492100606683833\n",
      "steer input from model: 0.9 , throttle:  0.0\n",
      "reward: -0.09824207961281001\n",
      "Recompensa por acortar distancias: +  0.3509095737016345\n",
      "Penalización por duración del episodio: -  0.44958653782162084\n",
      "Recompensa por acortar distancias: +  0.3509095737016345\n",
      "Penalización por duración del episodio: -  0.44967394005094724\n",
      "Recompensa por acortar distancias: +  0.3509095737016345\n",
      "Penalización por duración del episodio: -  0.44996569267769204\n",
      "Recompensa por completar el objetivo\n",
      "Recompensa por acortar distancias: +  0.915695435252483\n",
      "Penalización por duración del episodio: -  0.26916246129634086\n",
      "Recompensa por acortar distancias: +  0.9156955309598469\n",
      "Penalización por duración del episodio: -  0.26945577802487386\n",
      "Recompensa por acortar distancias: +  0.915695494149334\n",
      "Penalización por duración del episodio: -  0.26978010173058997\n",
      "Recompensa por acortar distancias: +  0.9156954794251246\n",
      "Penalización por duración del episodio: -  0.2700981990992933\n",
      "Recompensa por acortar distancias: +  0.9156954794251246\n",
      "Penalización por parar muy lejos: -  0.16592995764416263\n",
      "Penalización por duración del episodio: -  0.27039818823410583\n",
      "Step: 7220, Mean Reward (últimos 10 pasos): 0.47936734557151794\n",
      "Recompensa por acortar distancias: +  0.9156951260434019\n",
      "Penalización por parar muy lejos: -  0.16592932411299582\n",
      "Penalización por duración del episodio: -  0.27071619347517567\n",
      "Recompensa por acortar distancias: +  0.9156951554919303\n",
      "Penalización por duración del episodio: -  0.27102835250138063\n",
      "Recompensa por acortar distancias: +  0.9156952806480712\n",
      "Penalización por duración del episodio: -  0.271343726168075\n",
      "Recompensa por acortar distancias: +  0.9156955383219477\n",
      "Penalización por parar muy lejos: -  0.16593006323287882\n",
      "Penalización por duración del episodio: -  0.2716531220472749\n",
      "Recompensa por acortar distancias: +  0.9156956929259306\n",
      "Penalización por parar muy lejos: -  0.16593034040351487\n",
      "Penalización por duración del episodio: -  0.2719539209268422\n",
      "Recompensa por acortar distancias: +  0.9156956929259306\n",
      "Penalización por duración del episodio: -  0.2722718636701077\n",
      "Recompensa por acortar distancias: +  0.9156958328055027\n",
      "Penalización por duración del episodio: -  0.27259040296511955\n",
      "Recompensa por acortar distancias: +  0.9156958328055027\n",
      "Penalización por parar muy lejos: -  0.16593059117726708\n",
      "Penalización por duración del episodio: -  0.27289280171654134\n",
      "Recompensa por acortar distancias: +  0.9156960978399036\n",
      "Penalización por parar muy lejos: -  0.165931066328367\n",
      "Penalización por duración del episodio: -  0.27319562770793926\n",
      "Recompensa por acortar distancias: +  0.9156963113392873\n",
      "Penalización por parar muy lejos: -  0.16593144908976795\n",
      "Penalización por duración del episodio: -  0.2735070152961399\n",
      "Step: 7230, Mean Reward (últimos 10 pasos): 0.476257860660553\n",
      "Recompensa por acortar distancias: +  0.9156964733040096\n",
      "Penalización por parar muy lejos: -  0.16593173946095768\n",
      "Penalización por duración del episodio: -  0.27382722391684855\n",
      "Recompensa por acortar distancias: +  0.9156964733040096\n",
      "Penalización por duración del episodio: -  0.27412951460604085\n",
      "Recompensa por acortar distancias: +  0.9156964733040096\n",
      "Penalización por parar muy lejos: -  0.16593173946095768\n",
      "Penalización por duración del episodio: -  0.27421977111329715\n",
      "Recompensa por acortar distancias: +  0.9156964217698105\n",
      "Penalización por duración del episodio: -  0.27445804348394165\n",
      "Recompensa por acortar distancias: +  0.9156965027521107\n",
      "Penalización por duración del episodio: -  0.27477200309879285\n",
      "steer input from model: 0.25 , throttle:  1.0\n",
      "reward: 0.6409244996533179\n",
      "Recompensa por acortar distancias: +  0.9156966499924755\n",
      "Penalización por duración del episodio: -  0.2750759258257442\n",
      "Recompensa por acortar distancias: +  0.9156968266806051\n",
      "Penalización por duración del episodio: -  0.27539720835062015\n",
      "Recompensa por acortar distancias: +  0.9156969591964816\n",
      "Penalización por parar muy lejos: -  0.16593261057696915\n",
      "Penalización por duración del episodio: -  0.2757200565321997\n",
      "Recompensa por acortar distancias: +  0.9156969665584692\n",
      "Penalización por parar muy lejos: -  0.1659326237757248\n",
      "Penalización por duración del episodio: -  0.27603305238502596\n",
      "Recompensa por acortar distancias: +  0.9156969665584692\n",
      "Penalización por parar muy lejos: -  0.1659326237757248\n",
      "Penalización por duración del episodio: -  0.27633772880578117\n",
      "Step: 7240, Mean Reward (últimos 10 pasos): 0.47342661023139954\n",
      "Recompensa por acortar distancias: +  0.9156968045946072\n",
      "Penalización por duración del episodio: -  0.2766572221447842\n",
      "Recompensa por acortar distancias: +  0.9156968045946072\n",
      "Penalización por parar muy lejos: -  0.1659323334032954\n",
      "Penalización por duración del episodio: -  0.2769596550427071\n",
      "Recompensa por acortar distancias: +  0.9156969371105153\n",
      "Penalización por duración del episodio: -  0.27728057137167017\n",
      "Recompensa por acortar distancias: +  0.9156969444725047\n",
      "Penalización por duración del episodio: -  0.27758988341320845\n",
      "Recompensa por acortar distancias: +  0.9156969665584692\n",
      "Penalización por duración del episodio: -  0.2779134501881223\n",
      "Recompensa por acortar distancias: +  0.9156969665584692\n",
      "Penalización por parar muy lejos: -  0.1659326237757248\n",
      "Penalización por duración del episodio: -  0.27823664557697514\n",
      "Recompensa por acortar distancias: +  0.9156966794405205\n",
      "Penalización por parar muy lejos: -  0.1659321090248788\n",
      "Penalización por duración del episodio: -  0.2785413571465145\n",
      "Recompensa por acortar distancias: +  0.9156966794405205\n",
      "Penalización por duración del episodio: -  0.2788648425252009\n",
      "Recompensa por acortar distancias: +  0.9156965469242446\n",
      "Penalización por parar muy lejos: -  0.16593187144799665\n",
      "Penalización por duración del episodio: -  0.2791760308238719\n",
      "Recompensa por acortar distancias: +  0.9156966794405205\n",
      "Penalización por duración del episodio: -  0.27948255386806337\n",
      "Step: 7250, Mean Reward (últimos 10 pasos): 0.6362141370773315\n",
      "Recompensa por acortar distancias: +  0.9156968340426032\n",
      "Penalización por parar muy lejos: -  0.16593238619825226\n",
      "Penalización por duración del episodio: -  0.27980227866395235\n",
      "Recompensa por acortar distancias: +  0.9156968782145795\n",
      "Penalización por parar muy lejos: -  0.16593246539071285\n",
      "Penalización por duración del episodio: -  0.28011171248188566\n",
      "Recompensa por acortar distancias: +  0.9156968782145795\n",
      "Penalización por parar muy lejos: -  0.16593246539071285\n",
      "Penalización por duración del episodio: -  0.2804233662354665\n",
      "Recompensa por acortar distancias: +  0.9156968266806051\n",
      "Penalización por duración del episodio: -  0.28073524114372805\n",
      "Recompensa por acortar distancias: +  0.9156968266806051\n",
      "Penalización por parar muy lejos: -  0.16593237299951183\n",
      "Penalización por duración del episodio: -  0.2808220063507129\n",
      "steer input from model: 0.0 , throttle:  0.0\n",
      "reward: 0.46894244733038043\n",
      "Recompensa por acortar distancias: +  0.9156968855765736\n",
      "Penalización por parar muy lejos: -  0.1659324785894592\n",
      "Penalización por duración del episodio: -  0.2810525496112229\n",
      "Recompensa por acortar distancias: +  0.9156969591964816\n",
      "Penalización por duración del episodio: -  0.2811273960679891\n",
      "Recompensa por acortar distancias: +  0.9156969591964816\n",
      "Penalización por duración del episodio: -  0.28136538576591313\n",
      "Recompensa por acortar distancias: +  0.9156970769882131\n",
      "Penalización por duración del episodio: -  0.28168580492748774\n",
      "Recompensa por acortar distancias: +  0.9156971211600738\n",
      "Penalización por parar muy lejos: -  0.16593290094978708\n",
      "Penalización por duración del episodio: -  0.2819954344603496\n",
      "Step: 7260, Mean Reward (últimos 10 pasos): 0.4677687883377075\n",
      "Recompensa por acortar distancias: +  0.9156971211600738\n",
      "Penalización por duración del episodio: -  0.28205869162097974\n",
      "Recompensa por acortar distancias: +  0.9156971211600738\n",
      "Penalización por duración del episodio: -  0.2823147482639983\n",
      "Recompensa por acortar distancias: +  0.9156969812824427\n",
      "Penalización por duración del episodio: -  0.28262180012069094\n",
      "Recompensa por acortar distancias: +  0.9156969812824427\n",
      "Penalización por duración del episodio: -  0.2829430238632943\n",
      "Recompensa por acortar distancias: +  0.9156971726938848\n",
      "Penalización por duración del episodio: -  0.28325743049229557\n",
      "Recompensa por acortar distancias: +  0.9156972978473069\n",
      "Penalización por parar muy lejos: -  0.16593321772059813\n",
      "Penalización por duración del episodio: -  0.28357769125539545\n",
      "Recompensa por acortar distancias: +  0.9156973935527511\n",
      "Penalización por parar muy lejos: -  0.16593338930498974\n",
      "Penalización por duración del episodio: -  0.2836666259906585\n",
      "Recompensa por acortar distancias: +  0.9156973935527511\n",
      "Penalización por parar muy lejos: -  0.16593338930498974\n",
      "Penalización por duración del episodio: -  0.2838862374063112\n",
      "Recompensa por acortar distancias: +  0.9156973935527511\n",
      "Penalización por parar muy lejos: -  0.16593338930498974\n",
      "Penalización por duración del episodio: -  0.28420289668696946\n",
      "Recompensa por acortar distancias: +  0.9156973935527511\n",
      "Penalización por duración del episodio: -  0.28452930111061464\n",
      "Step: 7270, Mean Reward (últimos 10 pasos): 0.6311680674552917\n",
      "Recompensa por acortar distancias: +  0.9156971506079694\n",
      "Penalización por parar muy lejos: -  0.16593295374488862\n",
      "Penalización por duración del episodio: -  0.2848530413789406\n",
      "Recompensa por acortar distancias: +  0.9156972315896338\n",
      "Penalización por parar muy lejos: -  0.16593309893148722\n",
      "Penalización por duración del episodio: -  0.2851644203197213\n",
      "Recompensa por acortar distancias: +  0.9156972536755301\n",
      "Penalización por duración del episodio: -  0.2854828123604667\n",
      "Recompensa por acortar distancias: +  0.9156973420190626\n",
      "Penalización por parar muy lejos: -  0.1659332969133766\n",
      "Penalización por duración del episodio: -  0.2857937724334448\n",
      "Recompensa por acortar distancias: +  0.9156973935527511\n",
      "Penalización por parar muy lejos: -  0.16593338930498974\n",
      "Penalización por duración del episodio: -  0.2861040493120104\n",
      "steer input from model: -0.05 , throttle:  0.0\n",
      "reward: 0.46365995493575096\n",
      "Recompensa por acortar distancias: +  0.9156973935527511\n",
      "Penalización por duración del episodio: -  0.28643619791935676\n",
      "Recompensa por acortar distancias: +  0.9156971358840228\n",
      "Penalización por duración del episodio: -  0.286750632302987\n",
      "Recompensa por acortar distancias: +  0.9156971506079694\n",
      "Penalización por parar muy lejos: -  0.16593295374488862\n",
      "Penalización por duración del episodio: -  0.28706492167501674\n",
      "Recompensa por acortar distancias: +  0.9156973125712279\n",
      "Penalización por parar muy lejos: -  0.16593324411818758\n",
      "Penalización por duración del episodio: -  0.2873845728148179\n",
      "Recompensa por acortar distancias: +  0.9156974598103085\n",
      "Penalización por parar muy lejos: -  0.16593350809426713\n",
      "Penalización por duración del episodio: -  0.2877060486114385\n",
      "Step: 7280, Mean Reward (últimos 10 pasos): 0.462057888507843\n",
      "Recompensa por acortar distancias: +  0.9156975334297612\n",
      "Penalización por parar muy lejos: -  0.16593364008243308\n",
      "Penalización por duración del episodio: -  0.28782288563106856\n",
      "Recompensa por acortar distancias: +  0.9156975334297612\n",
      "Penalización por parar muy lejos: -  0.16593364008243308\n",
      "Penalización por duración del episodio: -  0.28802509362210144\n",
      "Recompensa por acortar distancias: +  0.9156975334297612\n",
      "Penalización por duración del episodio: -  0.2883551321659967\n",
      "Recompensa por acortar distancias: +  0.9156972315896338\n",
      "Penalización por parar muy lejos: -  0.16593309893148722\n",
      "Penalización por duración del episodio: -  0.28867485982964264\n",
      "Recompensa por acortar distancias: +  0.9156972536755301\n",
      "Penalización por parar muy lejos: -  0.16593313852784994\n",
      "Penalización por duración del episodio: -  0.28899516056326785\n",
      "Recompensa por acortar distancias: +  0.9156973420190626\n",
      "Penalización por parar muy lejos: -  0.1659332969133766\n",
      "Penalización por duración del episodio: -  0.28906990961696716\n",
      "Recompensa por acortar distancias: +  0.9156973567429766\n",
      "Penalización por duración del episodio: -  0.2893173633939831\n",
      "Recompensa por acortar distancias: +  0.9156974156386088\n",
      "Penalización por parar muy lejos: -  0.16593342890140797\n",
      "Penalización por duración del episodio: -  0.28942034969926994\n",
      "Recompensa por acortar distancias: +  0.9156974156386088\n",
      "Penalización por parar muy lejos: -  0.16593342890140797\n",
      "Penalización por duración del episodio: -  0.2896424623907957\n",
      "Recompensa por acortar distancias: +  0.9156974598103085\n",
      "Penalización por duración del episodio: -  0.2897352431594047\n",
      "Step: 7290, Mean Reward (últimos 10 pasos): 0.6259621977806091\n",
      "Recompensa por acortar distancias: +  0.9156974818961505\n",
      "Penalización por parar muy lejos: -  0.16593354769070812\n",
      "Penalización por duración del episodio: -  0.28982458187686055\n",
      "Recompensa por acortar distancias: +  0.9156974818961505\n",
      "Penalización por parar muy lejos: -  0.16593354769070812\n",
      "Penalización por duración del episodio: -  0.2899583333656595\n",
      "Recompensa por acortar distancias: +  0.9156974818961505\n",
      "Penalización por parar muy lejos: -  0.16593354769070812\n",
      "Penalización por duración del episodio: -  0.29028119618514514\n",
      "Recompensa por acortar distancias: +  0.9156974818961505\n",
      "Penalización por parar muy lejos: -  0.16593354769070812\n",
      "Penalización por duración del episodio: -  0.2906059965664138\n",
      "Recompensa por acortar distancias: +  0.9156973420190626\n",
      "Penalización por duración del episodio: -  0.2906735248133185\n",
      "steer input from model: -0.05 , throttle:  0.3\n",
      "reward: 0.6250238172057441\n",
      "Recompensa por acortar distancias: +  0.9156973420190626\n",
      "Penalización por parar muy lejos: -  0.1659332969133766\n",
      "Penalización por duración del episodio: -  0.290926934108074\n",
      "Recompensa por acortar distancias: +  0.9156973420190626\n",
      "Penalización por duración del episodio: -  0.29126585734272803\n",
      "Recompensa por acortar distancias: +  0.9156974156386088\n",
      "Penalización por parar muy lejos: -  0.16593342890140797\n",
      "Penalización por duración del episodio: -  0.29158783969036584\n",
      "Recompensa por acortar distancias: +  0.9156975260678185\n",
      "Penalización por parar muy lejos: -  0.1659336268836127\n",
      "Penalización por duración del episodio: -  0.2919160387372415\n",
      "Recompensa por acortar distancias: +  0.9156975776014049\n",
      "Penalización por parar muy lejos: -  0.165933719275373\n",
      "Penalización por duración del episodio: -  0.2922501012755801\n",
      "Step: 7300, Mean Reward (últimos 10 pasos): 0.4575137495994568\n",
      "Recompensa por acortar distancias: +  0.9156975776014049\n",
      "Penalización por parar muy lejos: -  0.165933719275373\n",
      "Penalización por duración del episodio: -  0.29234388654936555\n",
      "Recompensa por acortar distancias: +  0.9156975776014049\n",
      "Penalización por duración del episodio: -  0.2925794089956253\n",
      "Recompensa por acortar distancias: +  0.9156975776014049\n",
      "Penalización por duración del episodio: -  0.29289711779935423\n",
      "Recompensa por acortar distancias: +  0.9156973935527511\n",
      "Penalización por duración del episodio: -  0.29321454932841007\n",
      "Recompensa por acortar distancias: +  0.9156971653319136\n",
      "Penalización por duración del episodio: -  0.2935320139689375\n",
      "Recompensa por acortar distancias: +  0.9156972831233836\n",
      "Penalización por parar muy lejos: -  0.16593319132301204\n",
      "Penalización por duración del episodio: -  0.29385095581435894\n",
      "Recompensa por acortar distancias: +  0.9156973199331874\n",
      "Penalización por parar muy lejos: -  0.16593325731698358\n",
      "Penalización por duración del episodio: -  0.29417254540309756\n",
      "Recompensa por acortar distancias: +  0.9156973199331874\n",
      "Penalización por parar muy lejos: -  0.16593325731698358\n",
      "Penalización por duración del episodio: -  0.29450190926017444\n",
      "Recompensa por acortar distancias: +  0.9156973199331874\n",
      "Penalización por parar muy lejos: -  0.16593325731698358\n",
      "Penalización por duración del episodio: -  0.2946392079998631\n",
      "Recompensa por acortar distancias: +  0.915696892938567\n",
      "Penalización por parar muy lejos: -  0.1659324917882064\n",
      "Penalización por duración del episodio: -  0.2948114228632622\n",
      "Step: 7310, Mean Reward (últimos 10 pasos): 0.45495298504829407\n",
      "Recompensa por acortar distancias: +  0.9156968487665976\n",
      "Penalización por parar muy lejos: -  0.16593241259573577\n",
      "Penalización por duración del episodio: -  0.29493930611563307\n",
      "Recompensa por acortar distancias: +  0.9156968487665976\n",
      "Penalización por duración del episodio: -  0.2951363174528627\n",
      "Recompensa por acortar distancias: +  0.9156968487665976\n",
      "Penalización por duración del episodio: -  0.2954592165002232\n",
      "Recompensa por acortar distancias: +  0.9156966499924755\n",
      "Penalización por duración del episodio: -  0.2955423484805391\n",
      "Recompensa por acortar distancias: +  0.9156966499924755\n",
      "Penalización por parar muy lejos: -  0.16593205622999252\n",
      "Penalización por duración del episodio: -  0.2957947261530362\n",
      "steer input from model: -0.25 , throttle:  0.0\n",
      "reward: 0.45396986760944674\n",
      "Recompensa por acortar distancias: +  0.9156967456985874\n",
      "Penalización por duración del episodio: -  0.2961281557713695\n",
      "Recompensa por acortar distancias: +  0.9156967972326069\n",
      "Penalización por parar muy lejos: -  0.16593232020455828\n",
      "Penalización por duración del episodio: -  0.2964431605170141\n",
      "Recompensa por acortar distancias: +  0.9156967972326069\n",
      "Penalización por parar muy lejos: -  0.16593232020455828\n",
      "Penalización por duración del episodio: -  0.29652049972894867\n",
      "Recompensa por acortar distancias: +  0.9156967972326069\n",
      "Penalización por parar muy lejos: -  0.16593232020455828\n",
      "Penalización por duración del episodio: -  0.2966196723158713\n",
      "Recompensa por acortar distancias: +  0.9156967972326069\n",
      "Penalización por duración del episodio: -  0.29671573963880593\n",
      "Step: 7320, Mean Reward (últimos 10 pasos): 0.6189810633659363\n",
      "Recompensa por acortar distancias: +  0.9156966499924755\n",
      "Penalización por parar muy lejos: -  0.16593205622999252\n",
      "Penalización por duración del episodio: -  0.29711097818781196\n",
      "Recompensa por acortar distancias: +  0.9156966499924755\n",
      "Penalización por parar muy lejos: -  0.16593205622999252\n",
      "Penalización por duración del episodio: -  0.29717149698914797\n",
      "Recompensa por acortar distancias: +  0.9156966499924755\n",
      "Penalización por duración del episodio: -  0.2972652320155762\n",
      "Recompensa por acortar distancias: +  0.9156966499924755\n",
      "Penalización por parar muy lejos: -  0.16593205622999252\n",
      "Penalización por duración del episodio: -  0.2973389142794237\n",
      "Recompensa por acortar distancias: +  0.9156966499924755\n",
      "Penalización por duración del episodio: -  0.2974540436634409\n",
      "Recompensa por acortar distancias: +  0.9156967309745766\n",
      "Penalización por duración del episodio: -  0.2975484928555408\n",
      "Recompensa por acortar distancias: +  0.9156967309745766\n",
      "Penalización por duración del episodio: -  0.29763465575615783\n",
      "Recompensa por acortar distancias: +  0.9156967309745766\n",
      "Penalización por duración del episodio: -  0.2980769793519157\n",
      "Recompensa por acortar distancias: +  0.9156969371105153\n",
      "Penalización por duración del episodio: -  0.2981547038707189\n",
      "Recompensa por acortar distancias: +  0.9156969371105153\n",
      "Penalización por duración del episodio: -  0.2982574747717537\n",
      "Step: 7330, Mean Reward (últimos 10 pasos): 0.6174394488334656\n",
      "Recompensa por acortar distancias: +  0.9156969371105153\n",
      "Penalización por parar muy lejos: -  0.16593257098070735\n",
      "Penalización por duración del episodio: -  0.2984013043880846\n",
      "Recompensa por acortar distancias: +  0.9156969371105153\n",
      "Penalización por parar muy lejos: -  0.16593257098070735\n",
      "Penalización por duración del episodio: -  0.2984921073990838\n",
      "Recompensa por acortar distancias: +  0.9156969371105153\n",
      "Penalización por parar muy lejos: -  0.16593257098070735\n",
      "Penalización por duración del episodio: -  0.29856682836424797\n",
      "Recompensa por acortar distancias: +  0.9156969371105153\n",
      "Penalización por duración del episodio: -  0.2987203930363937\n",
      "Recompensa por acortar distancias: +  0.9156969371105153\n",
      "Penalización por duración del episodio: -  0.29886029913144996\n",
      "steer input from model: 0.0 , throttle:  0.3\n",
      "reward: 0.6168366379790653\n",
      "Recompensa por acortar distancias: +  0.9156969371105153\n",
      "Penalización por duración del episodio: -  0.2990512420595499\n",
      "Recompensa por acortar distancias: +  0.9156969591964816\n",
      "Penalización por duración del episodio: -  0.299147097151623\n",
      "Recompensa por acortar distancias: +  0.9156971064361227\n",
      "Penalización por duración del episodio: -  0.2992463145658296\n",
      "Recompensa por acortar distancias: +  0.9156971064361227\n",
      "Penalización por parar muy lejos: -  0.16593287455224134\n",
      "Penalización por duración del episodio: -  0.299334524760666\n",
      "Recompensa por acortar distancias: +  0.9156971064361227\n",
      "Penalización por duración del episodio: -  0.29945044265195964\n",
      "Step: 7340, Mean Reward (últimos 10 pasos): 0.6162466406822205\n",
      "Recompensa por acortar distancias: +  0.9156971064361227\n",
      "Penalización por duración del episodio: -  0.2995377168360884\n",
      "Recompensa por acortar distancias: +  0.9156971064361227\n",
      "Penalización por parar muy lejos: -  0.16593287455224134\n",
      "Penalización por duración del episodio: -  0.29972381830016087\n",
      "Recompensa por acortar distancias: +  0.9156970107303826\n",
      "Penalización por duración del episodio: -  0.3000442871777035\n",
      "Recompensa por acortar distancias: +  0.9156970549022747\n",
      "Penalización por duración del episodio: -  0.30011792840638\n",
      "Recompensa por acortar distancias: +  0.9156971211600738\n",
      "Penalización por parar muy lejos: -  0.16593290094978708\n",
      "Penalización por duración del episodio: -  0.30037822911063705\n",
      "Recompensa por acortar distancias: +  0.9156971211600738\n",
      "Penalización por duración del episodio: -  0.3004620747067046\n",
      "Recompensa por acortar distancias: +  0.9156971211600738\n",
      "Penalización por parar muy lejos: -  0.16593290094978708\n",
      "Penalización por duración del episodio: -  0.30071140539200375\n",
      "Recompensa por acortar distancias: +  0.9156971211600738\n",
      "Penalización por parar muy lejos: -  0.16593290094978708\n",
      "Penalización por duración del episodio: -  0.30080376831103545\n",
      "Recompensa por acortar distancias: +  0.9156971211600738\n",
      "Penalización por parar muy lejos: -  0.16593290094978708\n",
      "Penalización por duración del episodio: -  0.3008779671797421\n",
      "Recompensa por acortar distancias: +  0.9156971211600738\n",
      "Penalización por parar muy lejos: -  0.16593290094978708\n",
      "Penalización por duración del episodio: -  0.30104463167517753\n",
      "Step: 7350, Mean Reward (últimos 10 pasos): 0.4487195909023285\n",
      "Recompensa por acortar distancias: +  0.915696892938567\n",
      "Penalización por duración del episodio: -  0.30113135791987133\n",
      "Recompensa por acortar distancias: +  0.9156969371105153\n",
      "Penalización por duración del episodio: -  0.3013611714027449\n",
      "Recompensa por acortar distancias: +  0.9156969371105153\n",
      "Penalización por duración del episodio: -  0.3016867152631304\n",
      "Recompensa por acortar distancias: +  0.9156969371105153\n",
      "Penalización por duración del episodio: -  0.3017846238369796\n",
      "Recompensa por acortar distancias: +  0.9156971211600738\n",
      "Penalización por parar muy lejos: -  0.16593290094978708\n",
      "Penalización por duración del episodio: -  0.3018686875957105\n",
      "steer input from model: -0.1 , throttle:  0.0\n",
      "reward: 0.44789553261457626\n",
      "Recompensa por acortar distancias: +  0.9156971211600738\n",
      "Penalización por duración del episodio: -  0.301992983817866\n",
      "Recompensa por acortar distancias: +  0.9156970549022747\n",
      "Penalización por duración del episodio: -  0.3021000772210855\n",
      "Recompensa por acortar distancias: +  0.9156971064361227\n",
      "Penalización por duración del episodio: -  0.30235541496076457\n",
      "Recompensa por acortar distancias: +  0.9156970917121691\n",
      "Penalización por parar muy lejos: -  0.16593284815469897\n",
      "Penalización por duración del episodio: -  0.30244143997642947\n",
      "Recompensa por acortar distancias: +  0.9156970917121691\n",
      "Penalización por duración del episodio: -  0.3025329070519616\n",
      "Step: 7360, Mean Reward (últimos 10 pasos): 0.6131641864776611\n",
      "Recompensa por acortar distancias: +  0.9156970917121691\n",
      "Penalización por duración del episodio: -  0.30268587007295367\n",
      "Recompensa por acortar distancias: +  0.9156970917121691\n",
      "Penalización por parar muy lejos: -  0.16593284815469897\n",
      "Penalización por duración del episodio: -  0.30301053745924694\n",
      "Recompensa por acortar distancias: +  0.9156970917121691\n",
      "Penalización por parar muy lejos: -  0.16593284815469897\n",
      "Penalización por duración del episodio: -  0.3033468891260715\n",
      "Recompensa por acortar distancias: +  0.9156971211600738\n",
      "Penalización por duración del episodio: -  0.303450801911991\n",
      "Recompensa por acortar distancias: +  0.9156971211600738\n",
      "Penalización por duración del episodio: -  0.30368693018964266\n",
      "Recompensa por acortar distancias: +  0.9156971211600738\n",
      "Penalización por duración del episodio: -  0.30400490865850405\n",
      "Recompensa por acortar distancias: +  0.9156970917121691\n",
      "Penalización por duración del episodio: -  0.30410175351502805\n",
      "Recompensa por acortar distancias: +  0.9156971064361227\n",
      "Penalización por parar muy lejos: -  0.16593287455224134\n",
      "Penalización por duración del episodio: -  0.3042181457019762\n",
      "Recompensa por acortar distancias: +  0.9156971432459964\n",
      "Penalización por duración del episodio: -  0.3043413319359333\n",
      "Recompensa por acortar distancias: +  0.9156971874178257\n",
      "Penalización por duración del episodio: -  0.3044445024929763\n",
      "Step: 7370, Mean Reward (últimos 10 pasos): 0.6112526655197144\n",
      "Recompensa por acortar distancias: +  0.9156971874178257\n",
      "Penalización por parar muy lejos: -  0.16593301973878447\n",
      "Penalización por duración del episodio: -  0.30453977489283146\n",
      "Recompensa por acortar distancias: +  0.9156971874178257\n",
      "Penalización por parar muy lejos: -  0.16593301973878447\n",
      "Penalización por duración del episodio: -  0.30463531152280465\n",
      "Recompensa por acortar distancias: +  0.9156971874178257\n",
      "Penalización por duración del episodio: -  0.3047506970463501\n",
      "Recompensa por acortar distancias: +  0.9156971874178257\n",
      "Penalización por duración del episodio: -  0.30483901052141027\n",
      "Recompensa por acortar distancias: +  0.9156971874178257\n",
      "Penalización por duración del episodio: -  0.3049999476230387\n",
      "steer input from model: -0.9 , throttle:  1.0\n",
      "reward: 0.610697239794787\n",
      "Recompensa por acortar distancias: +  0.9156971874178257\n",
      "Penalización por duración del episodio: -  0.305340918278185\n",
      "Recompensa por acortar distancias: +  0.9156972757614211\n",
      "Penalización por parar muy lejos: -  0.16593317812422026\n",
      "Penalización por duración del episodio: -  0.3056823959530498\n",
      "Recompensa por acortar distancias: +  0.9156972757614211\n",
      "Penalización por duración del episodio: -  0.3060155353075362\n",
      "Recompensa por acortar distancias: +  0.9156973420190626\n",
      "Penalización por parar muy lejos: -  0.1659332969133766\n",
      "Penalización por duración del episodio: -  0.30634201263548233\n",
      "Recompensa por acortar distancias: +  0.9156974598103085\n",
      "Penalización por duración del episodio: -  0.3066763543011279\n",
      "Step: 7380, Mean Reward (últimos 10 pasos): 0.6090211272239685\n",
      "Recompensa por acortar distancias: +  0.9156974818961505\n",
      "Penalización por parar muy lejos: -  0.16593354769070812\n",
      "Penalización por duración del episodio: -  0.3070147088086275\n",
      "Recompensa por acortar distancias: +  0.9156974818961505\n",
      "Penalización por duración del episodio: -  0.3073452770782515\n",
      "Recompensa por acortar distancias: +  0.9156971211600738\n",
      "Penalización por parar muy lejos: -  0.16593290094978708\n",
      "Penalización por duración del episodio: -  0.30741991306199834\n",
      "Recompensa por acortar distancias: +  0.9156971137980985\n",
      "Penalización por parar muy lejos: -  0.1659328877510138\n",
      "Penalización por duración del episodio: -  0.307675215439616\n",
      "Recompensa por acortar distancias: +  0.9156971137980985\n",
      "Penalización por duración del episodio: -  0.308001371609073\n",
      "Recompensa por acortar distancias: +  0.9156971137980985\n",
      "Penalización por parar muy lejos: -  0.1659328877510138\n",
      "Penalización por duración del episodio: -  0.30833378545519363\n",
      "Recompensa por acortar distancias: +  0.9156970328163313\n",
      "Penalización por duración del episodio: -  0.30842374967327313\n",
      "Recompensa por acortar distancias: +  0.9156970917121691\n",
      "Penalización por parar muy lejos: -  0.16593284815469897\n",
      "Penalización por duración del episodio: -  0.30850281852163847\n",
      "Recompensa por acortar distancias: +  0.9156971579699418\n",
      "Penalización por parar muy lejos: -  0.1659329669436661\n",
      "Penalización por duración del episodio: -  0.30860283149015766\n",
      "Recompensa por acortar distancias: +  0.9156972095037325\n",
      "Penalización por parar muy lejos: -  0.16593305933513205\n",
      "Penalización por duración del episodio: -  0.30899524859093047\n",
      "Step: 7390, Mean Reward (últimos 10 pasos): 0.44076889753341675\n",
      "Recompensa por acortar distancias: +  0.9156972095037325\n",
      "Penalización por duración del episodio: -  0.30934037868811365\n",
      "Recompensa por acortar distancias: +  0.9156972095037325\n",
      "Penalización por parar muy lejos: -  0.16593305933513205\n",
      "Penalización por duración del episodio: -  0.3094251304295704\n",
      "Recompensa por acortar distancias: +  0.9156971211600738\n",
      "Penalización por duración del episodio: -  0.30966822914186626\n",
      "Recompensa por acortar distancias: +  0.9156971579699418\n",
      "Penalización por parar muy lejos: -  0.1659329669436661\n",
      "Penalización por duración del episodio: -  0.31000525691878206\n",
      "Recompensa por acortar distancias: +  0.9156971579699418\n",
      "Penalización por duración del episodio: -  0.3103307756280704\n",
      "steer input from model: 0.1 , throttle:  1.0\n",
      "reward: 0.6053663823418713\n",
      "Recompensa por acortar distancias: +  0.9156972978473069\n",
      "Penalización por duración del episodio: -  0.31066994106715934\n",
      "Recompensa por acortar distancias: +  0.9156974082766567\n",
      "Penalización por duración del episodio: -  0.3107595912686592\n",
      "Recompensa por acortar distancias: +  0.9156974156386088\n",
      "Penalización por duración del episodio: -  0.31100382821003514\n",
      "Recompensa por acortar distancias: +  0.9156974156386088\n",
      "Penalización por duración del episodio: -  0.31108208066396303\n",
      "Recompensa por acortar distancias: +  0.9156974156386088\n",
      "Penalización por parar muy lejos: -  0.16593342890140797\n",
      "Penalización por duración del episodio: -  0.31118011583201466\n",
      "Step: 7400, Mean Reward (últimos 10 pasos): 0.4385838806629181\n",
      "Recompensa por acortar distancias: +  0.9156974156386088\n",
      "Penalización por duración del episodio: -  0.3113281690149279\n",
      "Recompensa por acortar distancias: +  0.9156974156386088\n",
      "Penalización por duración del episodio: -  0.31139468207428994\n",
      "Recompensa por acortar distancias: +  0.9156974156386088\n",
      "Penalización por duración del episodio: -  0.31167579855466127\n",
      "Recompensa por acortar distancias: +  0.9156973714668881\n",
      "Penalización por parar muy lejos: -  0.16593334970857904\n",
      "Penalización por duración del episodio: -  0.31200121371044476\n",
      "Recompensa por acortar distancias: +  0.9156973420190626\n",
      "Penalización por parar muy lejos: -  0.1659332969133766\n",
      "Penalización por duración del episodio: -  0.31233547879274\n",
      "Recompensa por acortar distancias: +  0.9156974377244613\n",
      "Penalización por parar muy lejos: -  0.16593346849783375\n",
      "Penalización por duración del episodio: -  0.31242254417903426\n",
      "Recompensa por acortar distancias: +  0.9156974598103085\n",
      "Penalización por parar muy lejos: -  0.16593350809426713\n",
      "Penalización por duración del episodio: -  0.312662735233994\n",
      "Recompensa por acortar distancias: +  0.9156975555155857\n",
      "Penalización por duración del episodio: -  0.3130060508296385\n",
      "Recompensa por acortar distancias: +  0.9156975996872189\n",
      "Penalización por duración del episodio: -  0.31334770427736447\n",
      "Recompensa por acortar distancias: +  0.9156975996872189\n",
      "Penalización por parar muy lejos: -  0.16593375887185433\n",
      "Penalización por duración del episodio: -  0.31368328802657675\n",
      "Step: 7410, Mean Reward (últimos 10 pasos): 0.43608054518699646\n",
      "Recompensa por acortar distancias: +  0.9156974082766567\n",
      "Penalización por parar muy lejos: -  0.16593341570260103\n",
      "Penalización por duración del episodio: -  0.3140115223721205\n",
      "Recompensa por acortar distancias: +  0.9156974156386088\n",
      "Penalización por duración del episodio: -  0.31435033843928106\n",
      "Recompensa por acortar distancias: +  0.9156974598103085\n",
      "Penalización por parar muy lejos: -  0.16593350809426713\n",
      "Penalización por duración del episodio: -  0.3146865604258167\n",
      "Recompensa por acortar distancias: +  0.9156975555155857\n",
      "Penalización por parar muy lejos: -  0.16593367967889924\n",
      "Penalización por duración del episodio: -  0.3150278179653728\n",
      "Recompensa por acortar distancias: +  0.9156976512207643\n",
      "Penalización por parar muy lejos: -  0.1659338512636735\n",
      "Penalización por duración del episodio: -  0.31511910791447284\n",
      "steer input from model: -0.1 , throttle:  0.0\n",
      "reward: 0.4346446920426179\n",
      "Recompensa por acortar distancias: +  0.9156976512207643\n",
      "Penalización por parar muy lejos: -  0.1659338512636735\n",
      "Penalización por duración del episodio: -  0.3153562259233358\n",
      "Recompensa por acortar distancias: +  0.9156976512207643\n",
      "Penalización por duración del episodio: -  0.31569694802415654\n",
      "Recompensa por acortar distancias: +  0.9156976512207643\n",
      "Penalización por parar muy lejos: -  0.1659338512636735\n",
      "Penalización por duración del episodio: -  0.3158059090755059\n",
      "Recompensa por acortar distancias: +  0.9156972389515999\n",
      "Penalización por duración del episodio: -  0.31602378883693194\n",
      "Recompensa por acortar distancias: +  0.9156972536755301\n",
      "Penalización por parar muy lejos: -  0.16593313852784994\n",
      "Penalización por duración del episodio: -  0.31636661086380147\n",
      "Step: 7420, Mean Reward (últimos 10 pasos): 0.433397501707077\n",
      "Recompensa por acortar distancias: +  0.9156972536755301\n",
      "Penalización por parar muy lejos: -  0.16593313852784994\n",
      "Penalización por duración del episodio: -  0.31649802830307316\n",
      "Recompensa por acortar distancias: +  0.9156973199331874\n",
      "Penalización por duración del episodio: -  0.3167156021400943\n",
      "Recompensa por acortar distancias: +  0.9156973199331874\n",
      "Penalización por parar muy lejos: -  0.16593325731698358\n",
      "Penalización por duración del episodio: -  0.3170491161051389\n",
      "Recompensa por acortar distancias: +  0.9156974598103085\n",
      "Penalización por parar muy lejos: -  0.16593350809426713\n",
      "Penalización por duración del episodio: -  0.317395855656731\n",
      "Recompensa por acortar distancias: +  0.9156974892580966\n",
      "Penalización por parar muy lejos: -  0.16593356088952343\n",
      "Penalización por duración del episodio: -  0.31773695762262005\n",
      "Recompensa por acortar distancias: +  0.9156974892580966\n",
      "Penalización por duración del episodio: -  0.3180795482025663\n",
      "Recompensa por acortar distancias: +  0.9156973420190626\n",
      "Penalización por parar muy lejos: -  0.1659332969133766\n",
      "Penalización por duración del episodio: -  0.318421280197603\n",
      "Recompensa por acortar distancias: +  0.9156973420190626\n",
      "Penalización por duración del episodio: -  0.31851212849168575\n",
      "Recompensa por acortar distancias: +  0.9156973861907973\n",
      "Penalización por parar muy lejos: -  0.1659333761061853\n",
      "Penalización por duración del episodio: -  0.31860645331070947\n",
      "Recompensa por acortar distancias: +  0.9156973861907973\n",
      "Penalización por duración del episodio: -  0.31871606474548175\n",
      "Step: 7430, Mean Reward (últimos 10 pasos): 0.5969813466072083\n",
      "Recompensa por acortar distancias: +  0.9156973935527511\n",
      "Penalización por parar muy lejos: -  0.16593338930498974\n",
      "Penalización por duración del episodio: -  0.3191040768693471\n",
      "Recompensa por acortar distancias: +  0.9156974818961505\n",
      "Penalización por duración del episodio: -  0.3194539874259038\n",
      "Recompensa por acortar distancias: +  0.9156975702394657\n",
      "Penalización por parar muy lejos: -  0.1659337060765476\n",
      "Penalización por duración del episodio: -  0.31953867804990443\n",
      "Recompensa por acortar distancias: +  0.9156975702394657\n",
      "Penalización por parar muy lejos: -  0.1659337060765476\n",
      "Penalización por duración del episodio: -  0.31980237960989927\n",
      "Recompensa por acortar distancias: +  0.9156975702394657\n",
      "Penalización por duración del episodio: -  0.3201402572283636\n",
      "steer input from model: -0.05 , throttle:  0.7\n",
      "reward: 0.5955573130111022\n",
      "Recompensa por acortar distancias: +  0.9156975702394657\n",
      "Penalización por parar muy lejos: -  0.1659337060765476\n",
      "Penalización por duración del episodio: -  0.32029427646311\n",
      "Recompensa por acortar distancias: +  0.9156975702394657\n",
      "Penalización por duración del episodio: -  0.3204741388223475\n",
      "Recompensa por acortar distancias: +  0.9156974818961505\n",
      "Penalización por parar muy lejos: -  0.16593354769070812\n",
      "Penalización por duración del episodio: -  0.32054411095708746\n",
      "Recompensa por acortar distancias: +  0.9156974818961505\n",
      "Penalización por parar muy lejos: -  0.16593354769070812\n",
      "Penalización por duración del episodio: -  0.32081695260717547\n",
      "Recompensa por acortar distancias: +  0.9156974818961505\n",
      "Penalización por parar muy lejos: -  0.16593354769070812\n",
      "Penalización por duración del episodio: -  0.32114211041737556\n",
      "Step: 7440, Mean Reward (últimos 10 pasos): 0.4286218285560608\n",
      "Recompensa por acortar distancias: +  0.9156975849633434\n",
      "Penalización por duración del episodio: -  0.3214811869615112\n",
      "Recompensa por acortar distancias: +  0.9156977174781378\n",
      "Penalización por duración del episodio: -  0.32183083814078445\n",
      "Recompensa por acortar distancias: +  0.9156977174781378\n",
      "Penalización por duración del episodio: -  0.32216892745848813\n",
      "Recompensa por acortar distancias: +  0.9156977174781378\n",
      "Penalización por parar muy lejos: -  0.16593397005321583\n",
      "Penalización por duración del episodio: -  0.3225016394735358\n",
      "Recompensa por acortar distancias: +  0.9156975776014049\n",
      "Penalización por duración del episodio: -  0.32285421274083087\n",
      "Recompensa por acortar distancias: +  0.9156976070491556\n",
      "Penalización por duración del episodio: -  0.32319829378288556\n",
      "Recompensa por acortar distancias: +  0.9156976806684916\n",
      "Penalización por duración del episodio: -  0.32352375536849654\n",
      "Recompensa por acortar distancias: +  0.9156977616496939\n",
      "Penalización por parar muy lejos: -  0.16593404924628194\n",
      "Penalización por duración del episodio: -  0.32385475996834373\n",
      "Recompensa por acortar distancias: +  0.9156977616496939\n",
      "Penalización por duración del episodio: -  0.3241981640391674\n",
      "Recompensa por acortar distancias: +  0.9156977616496939\n",
      "Penalización por duración del episodio: -  0.3245433881271608\n",
      "Step: 7450, Mean Reward (últimos 10 pasos): 0.5911543965339661\n",
      "Recompensa por acortar distancias: +  0.9156975260678185\n",
      "Penalización por duración del episodio: -  0.3246398661706766\n",
      "Recompensa por acortar distancias: +  0.9156975260678185\n",
      "Penalización por parar muy lejos: -  0.1659336268836127\n",
      "Penalización por duración del episodio: -  0.32489096806694373\n",
      "Recompensa por acortar distancias: +  0.9156975260678185\n",
      "Penalización por duración del episodio: -  0.32524290070672524\n",
      "Recompensa por acortar distancias: +  0.9156975260678185\n",
      "Penalización por duración del episodio: -  0.32558272272598116\n",
      "Recompensa por acortar distancias: +  0.915696870852585\n",
      "Penalización por parar muy lejos: -  0.1659324521919673\n",
      "Penalización por duración del episodio: -  0.3259234406672241\n",
      "steer input from model: 0.9 , throttle:  0.0\n",
      "reward: 0.4238409779933936\n",
      "Recompensa por acortar distancias: +  0.9156270234363348\n",
      "Penalización por duración del episodio: -  0.3259913129923425\n",
      "Recompensa por acortar distancias: +  0.9156270234363348\n",
      "Penalización por parar muy lejos: -  0.16580731311295788\n",
      "Penalización por duración del episodio: -  0.32626338884444944\n",
      "Recompensa por acortar distancias: +  0.9156270234363348\n",
      "Penalización por duración del episodio: -  0.32660430109966804\n",
      "Recompensa por acortar distancias: +  0.9149483222184637\n",
      "Penalización por duración del episodio: -  0.32695520764982955\n",
      "Recompensa por acortar distancias: +  0.9147173697102373\n",
      "Penalización por parar muy lejos: -  0.16419292988561285\n",
      "Penalización por duración del episodio: -  0.327300622863515\n",
      "Step: 7460, Mean Reward (últimos 10 pasos): 0.4232238233089447\n",
      "Recompensa por acortar distancias: +  0.9140219660941615\n",
      "Penalización por parar muy lejos: -  0.16297771247349813\n",
      "Penalización por duración del episodio: -  0.32765086307775376\n",
      "Recompensa por acortar distancias: +  0.913362446238922\n",
      "Penalización por duración del episodio: -  0.32799845231388164\n",
      "Recompensa por acortar distancias: +  0.912597027093245\n",
      "Penalización por duración del episodio: -  0.3283487014615211\n",
      "Recompensa por acortar distancias: +  0.9122256792339488\n",
      "Penalización por duración del episodio: -  0.3286879466874186\n",
      "Recompensa por acortar distancias: +  0.9122256792339488\n",
      "Penalización por duración del episodio: -  0.32902778653153525\n",
      "Recompensa por acortar distancias: +  0.9122256792339488\n",
      "Penalización por parar muy lejos: -  0.15991219014755292\n",
      "Penalización por duración del episodio: -  0.32913692454661897\n",
      "Recompensa por acortar distancias: +  0.9098974990634242\n",
      "Penalización por duración del episodio: -  0.32923202803969726\n",
      "Recompensa por acortar distancias: +  0.9093626578950137\n",
      "Penalización por duración del episodio: -  0.3293871698287485\n",
      "Recompensa por acortar distancias: +  0.9093626578950137\n",
      "Penalización por parar muy lejos: -  0.1552344846224924\n",
      "Penalización por duración del episodio: -  0.3294617208348036\n",
      "Recompensa por acortar distancias: +  0.9093626578950137\n",
      "Penalización por parar muy lejos: -  0.1552344846224924\n",
      "Penalización por duración del episodio: -  0.3297407509568393\n",
      "Step: 7470, Mean Reward (últimos 10 pasos): 0.4243874251842499\n",
      "Recompensa por acortar distancias: +  0.9093626578950137\n",
      "Penalización por duración del episodio: -  0.330086432032907\n",
      "Recompensa por acortar distancias: +  0.9070670050686378\n",
      "Penalización por parar muy lejos: -  0.1516571565965115\n",
      "Penalización por duración del episodio: -  0.33018480169336234\n",
      "Recompensa por acortar distancias: +  0.9066655383647703\n",
      "Penalización por duración del episodio: -  0.33042978070572876\n",
      "Recompensa por acortar distancias: +  0.9062392463660393\n",
      "Penalización por duración del episodio: -  0.3307652142556632\n",
      "Recompensa por acortar distancias: +  0.9062392463660393\n",
      "Penalización por parar muy lejos: -  0.1504030942521141\n",
      "Penalización por duración del episodio: -  0.33112156667822557\n",
      "steer input from model: 0.05 , throttle:  0.0\n",
      "reward: 0.4247145854356996\n",
      "Recompensa por acortar distancias: +  0.9036616905300942\n",
      "Penalización por duración del episodio: -  0.33146116932919006\n",
      "Recompensa por acortar distancias: +  0.903152321072766\n",
      "Penalización por duración del episodio: -  0.33153636981999435\n",
      "Recompensa por acortar distancias: +  0.903152321072766\n",
      "Penalización por duración del episodio: -  0.33180568373835545\n",
      "Recompensa por acortar distancias: +  0.903152321072766\n",
      "Penalización por parar muy lejos: -  0.1458848758553285\n",
      "Penalización por duración del episodio: -  0.33192564972190447\n",
      "Recompensa por acortar distancias: +  0.9011914066094374\n",
      "Penalización por duración del episodio: -  0.33205479626227175\n",
      "Step: 7480, Mean Reward (últimos 10 pasos): 0.5691366195678711\n",
      "Recompensa por acortar distancias: +  0.9011914066094374\n",
      "Penalización por duración del episodio: -  0.3321718351548066\n",
      "Recompensa por acortar distancias: +  0.9002168043774268\n",
      "Penalización por parar muy lejos: -  0.14180674165976384\n",
      "Penalización por duración del episodio: -  0.3322995592297613\n",
      "Recompensa por acortar distancias: +  0.9002168043774268\n",
      "Penalización por duración del episodio: -  0.3324544723701544\n",
      "Recompensa por acortar distancias: +  0.899390674647788\n",
      "Penalización por parar muy lejos: -  0.14069524799809605\n",
      "Penalización por duración del episodio: -  0.3325842990882601\n",
      "Recompensa por acortar distancias: +  0.899390674647788\n",
      "Penalización por parar muy lejos: -  0.14069524799809605\n",
      "Penalización por duración del episodio: -  0.3327063119632916\n",
      "Recompensa por acortar distancias: +  0.8984998754522092\n",
      "Penalización por duración del episodio: -  0.3328613837287922\n",
      "Recompensa por acortar distancias: +  0.8984998754522092\n",
      "Penalización por parar muy lejos: -  0.13951387194443957\n",
      "Penalización por duración del episodio: -  0.33300618640701624\n",
      "Recompensa por acortar distancias: +  0.8984998754522092\n",
      "Penalización por parar muy lejos: -  0.13951387194443957\n",
      "Penalización por duración del episodio: -  0.3331504009026491\n",
      "Recompensa por acortar distancias: +  0.8984998754522092\n",
      "Penalización por parar muy lejos: -  0.13951387194443957\n",
      "Penalización por duración del episodio: -  0.33324816463891055\n",
      "Recompensa por acortar distancias: +  0.8984998754522092\n",
      "Penalización por parar muy lejos: -  0.13951387194443957\n",
      "Penalización por duración del episodio: -  0.33335906671866483\n",
      "Step: 7490, Mean Reward (últimos 10 pasos): 0.4256269335746765\n",
      "Recompensa por acortar distancias: +  0.8984998754522092\n",
      "Penalización por parar muy lejos: -  0.13951387194443957\n",
      "Penalización por duración del episodio: -  0.33347659017768044\n",
      "Recompensa por acortar distancias: +  0.8984998754522092\n",
      "Penalización por parar muy lejos: -  0.13951387194443957\n",
      "Penalización por duración del episodio: -  0.33359116089554597\n",
      "Recompensa por acortar distancias: +  0.8984998754522092\n",
      "Penalización por duración del episodio: -  0.33371410592835987\n",
      "Recompensa por acortar distancias: +  0.8984998754522092\n",
      "Penalización por duración del episodio: -  0.33385780014756566\n",
      "Recompensa por acortar distancias: +  0.8984998754522092\n",
      "Penalización por parar muy lejos: -  0.13951387194443957\n",
      "Penalización por duración del episodio: -  0.3340081174946345\n",
      "steer input from model: -0.05 , throttle:  0.0\n",
      "reward: 0.4249778860131352\n",
      "Recompensa por acortar distancias: +  0.893520333710641\n",
      "Penalización por parar muy lejos: -  0.13321980955012316\n",
      "Penalización por duración del episodio: -  0.33412775487585544\n",
      "Recompensa por acortar distancias: +  0.893520333710641\n",
      "Penalización por duración del episodio: -  0.3342524431742278\n",
      "Recompensa por acortar distancias: +  0.8923782499531414\n",
      "Penalización por parar muy lejos: -  0.13184621380392542\n",
      "Penalización por duración del episodio: -  0.33436350125380143\n",
      "Recompensa por acortar distancias: +  0.8923782499531414\n",
      "Penalización por duración del episodio: -  0.33450110375028574\n",
      "Recompensa por acortar distancias: +  0.8923782499531414\n",
      "Penalización por duración del episodio: -  0.33460824824066177\n",
      "Step: 7500, Mean Reward (últimos 10 pasos): 0.5577700138092041\n",
      "Recompensa por acortar distancias: +  0.8923782499531414\n",
      "Penalización por parar muy lejos: -  0.13184621380392542\n",
      "Penalización por duración del episodio: -  0.3347057578623281\n",
      "Recompensa por acortar distancias: +  0.8923782499531414\n",
      "Penalización por duración del episodio: -  0.33482896038638893\n",
      "Recompensa por acortar distancias: +  0.8923782499531414\n",
      "Penalización por parar muy lejos: -  0.13184621380392542\n",
      "Penalización por duración del episodio: -  0.334939157686603\n",
      "Recompensa por acortar distancias: +  0.8923782499531414\n",
      "Penalización por duración del episodio: -  0.33505597022230793\n",
      "Recompensa por acortar distancias: +  0.8893881061575423\n",
      "Penalización por duración del episodio: -  0.3352166769035807\n",
      "Recompensa por acortar distancias: +  0.8893881061575423\n",
      "Penalización por duración del episodio: -  0.33533818718329134\n",
      "Recompensa por acortar distancias: +  0.8879988511964975\n",
      "Penalización por duración del episodio: -  0.3354162760140355\n",
      "Recompensa por acortar distancias: +  0.8879988511964975\n",
      "Penalización por parar muy lejos: -  0.1268016501564354\n",
      "Penalización por duración del episodio: -  0.3355919104585272\n",
      "Recompensa por acortar distancias: +  0.8879988511964975\n",
      "Penalización por duración del episodio: -  0.3359527194705247\n",
      "Recompensa por acortar distancias: +  0.8879988511964975\n",
      "Penalización por parar muy lejos: -  0.1268016501564354\n",
      "Penalización por duración del episodio: -  0.3362945729622677\n",
      "Step: 7510, Mean Reward (últimos 10 pasos): 0.42490261793136597\n",
      "Recompensa por acortar distancias: +  0.8843399993191334\n",
      "Penalización por parar muy lejos: -  0.12283929585180843\n",
      "Penalización por duración del episodio: -  0.3366609778328644\n",
      "Recompensa por acortar distancias: +  0.8835925672950239\n",
      "Penalización por duración del episodio: -  0.33699974501353813\n",
      "Recompensa por acortar distancias: +  0.8807419355482109\n",
      "Penalización por parar muy lejos: -  0.11914780163992582\n",
      "Penalización por duración del episodio: -  0.33735455690449107\n",
      "Recompensa por acortar distancias: +  0.8807419355482109\n",
      "Penalización por duración del episodio: -  0.33769952169536355\n",
      "Recompensa por acortar distancias: +  0.8807419355482109\n",
      "Penalización por duración del episodio: -  0.33804955692384175\n",
      "steer input from model: -0.1 , throttle:  0.3\n",
      "reward: 0.5426923786243691\n",
      "Recompensa por acortar distancias: +  0.8760013196272026\n",
      "Penalización por parar muy lejos: -  0.11456838571320578\n",
      "Penalización por duración del episodio: -  0.3383888858151305\n",
      "Recompensa por acortar distancias: +  0.8760013196272026\n",
      "Penalización por duración del episodio: -  0.33874322207774094\n",
      "Recompensa por acortar distancias: +  0.8736073772713254\n",
      "Penalización por duración del episodio: -  0.3390866414493156\n",
      "Recompensa por acortar distancias: +  0.8719260762872385\n",
      "Penalización por duración del episodio: -  0.3394216076119521\n",
      "Recompensa por acortar distancias: +  0.8704969036397207\n",
      "Penalización por duración del episodio: -  0.33951248494599456\n",
      "Step: 7520, Mean Reward (últimos 10 pasos): 0.5309844017028809\n",
      "Recompensa por acortar distancias: +  0.8704969036397207\n",
      "Penalización por duración del episodio: -  0.3397622539877346\n",
      "Recompensa por acortar distancias: +  0.8704969036397207\n",
      "Penalización por parar muy lejos: -  0.10961881993253235\n",
      "Penalización por duración del episodio: -  0.3401120450881802\n",
      "Recompensa por acortar distancias: +  0.8704969036397207\n",
      "Penalización por parar muy lejos: -  0.10961881993253235\n",
      "Penalización por duración del episodio: -  0.34045795791683986\n",
      "Recompensa por acortar distancias: +  0.8655869511709565\n",
      "Penalización por parar muy lejos: -  0.10550417784428842\n",
      "Penalización por duración del episodio: -  0.340806344045294\n",
      "Recompensa por acortar distancias: +  0.8655869511709565\n",
      "Penalización por duración del episodio: -  0.3411612472268937\n",
      "Recompensa por acortar distancias: +  0.8614209909678495\n",
      "Penalización por parar muy lejos: -  0.10221453163254658\n",
      "Penalización por duración del episodio: -  0.3415268856389115\n",
      "Recompensa por acortar distancias: +  0.8597524100444505\n",
      "Penalización por parar muy lejos: -  0.10094531671661781\n",
      "Penalización por duración del episodio: -  0.3418736957837\n",
      "Recompensa por acortar distancias: +  0.8597524100444505\n",
      "Penalización por parar muy lejos: -  0.10094531671661781\n",
      "Penalización por duración del episodio: -  0.3419709844563285\n",
      "Recompensa por acortar distancias: +  0.8597524100444505\n",
      "Penalización por parar muy lejos: -  0.10094531671661781\n",
      "Penalización por duración del episodio: -  0.342232600507034\n",
      "Recompensa por acortar distancias: +  0.8597524100444505\n",
      "Penalización por duración del episodio: -  0.3423250320730843\n",
      "Step: 7530, Mean Reward (últimos 10 pasos): 0.517427384853363\n",
      "Recompensa por acortar distancias: +  0.8597524100444505\n",
      "Penalización por parar muy lejos: -  0.10094531671661781\n",
      "Penalización por duración del episodio: -  0.3425732088894841\n",
      "Recompensa por acortar distancias: +  0.8546007233854614\n",
      "Penalización por parar muy lejos: -  0.09718956792618103\n",
      "Penalización por duración del episodio: -  0.3429299457219456\n",
      "Recompensa por acortar distancias: +  0.8546007233854614\n",
      "Penalización por duración del episodio: -  0.34328511321173005\n",
      "Recompensa por acortar distancias: +  0.8508993209881166\n",
      "Penalización por parar muy lejos: -  0.09463352888511141\n",
      "Penalización por duración del episodio: -  0.3433789976731664\n",
      "Recompensa por acortar distancias: +  0.8500640154631092\n",
      "Penalización por parar muy lejos: -  0.09407222259049848\n",
      "Penalización por duración del episodio: -  0.34364175216191817\n",
      "steer input from model: -0.05 , throttle:  0.0\n",
      "reward: 0.4123500407106925\n",
      "Recompensa por acortar distancias: +  0.8493217651026268\n",
      "Penalización por duración del episodio: -  0.34372449636944563\n",
      "Recompensa por acortar distancias: +  0.8484276260538494\n",
      "Penalización por duración del episodio: -  0.344003958562596\n",
      "Recompensa por acortar distancias: +  0.8484276260538494\n",
      "Penalización por parar muy lejos: -  0.09298857233160299\n",
      "Penalización por duración del episodio: -  0.3443580890044483\n",
      "Recompensa por acortar distancias: +  0.8484276260538494\n",
      "Penalización por duración del episodio: -  0.344698643291299\n",
      "Recompensa por acortar distancias: +  0.8430082150438767\n",
      "Penalización por duración del episodio: -  0.34506297830552773\n",
      "Step: 7540, Mean Reward (últimos 10 pasos): 0.49794524908065796\n",
      "Recompensa por acortar distancias: +  0.8430082150438767\n",
      "Penalización por parar muy lejos: -  0.0895438917681647\n",
      "Penalización por duración del episodio: -  0.34514962456901677\n",
      "Recompensa por acortar distancias: +  0.8430082150438767\n",
      "Penalización por duración del episodio: -  0.34526866679665513\n",
      "Recompensa por acortar distancias: +  0.8430082150438767\n",
      "Penalización por parar muy lejos: -  0.0895438917681647\n",
      "Penalización por duración del episodio: -  0.34539100048350624\n",
      "Recompensa por acortar distancias: +  0.8395195904820613\n",
      "Penalización por duración del episodio: -  0.34551660569386594\n",
      "Recompensa por acortar distancias: +  0.8395195904820613\n",
      "Penalización por parar muy lejos: -  0.08743672282185083\n",
      "Penalización por duración del episodio: -  0.34564542477168575\n",
      "Recompensa por acortar distancias: +  0.8378998813999836\n",
      "Penalización por duración del episodio: -  0.3457315198817799\n",
      "Recompensa por acortar distancias: +  0.8369462774370627\n",
      "Penalización por parar muy lejos: -  0.08593426472264483\n",
      "Penalización por duración del episodio: -  0.34612188691382545\n",
      "Recompensa por acortar distancias: +  0.8350716664310035\n",
      "Penalización por parar muy lejos: -  0.08486626967723344\n",
      "Penalización por duración del episodio: -  0.3462235207988328\n",
      "Recompensa por acortar distancias: +  0.8350716664310035\n",
      "Penalización por duración del episodio: -  0.346313774863132\n",
      "Recompensa por acortar distancias: +  0.8350716664310035\n",
      "Penalización por parar muy lejos: -  0.08486626967723344\n",
      "Penalización por duración del episodio: -  0.3464660223625715\n",
      "Step: 7550, Mean Reward (últimos 10 pasos): 0.4037393629550934\n",
      "Recompensa por acortar distancias: +  0.8350716664310035\n",
      "Penalización por duración del episodio: -  0.3468261921019696\n",
      "Recompensa por acortar distancias: +  0.8350716664310035\n",
      "Penalización por duración del episodio: -  0.34691919377275116\n",
      "Recompensa por acortar distancias: +  0.8350716664310035\n",
      "Penalización por duración del episodio: -  0.34702854969265645\n",
      "Recompensa por acortar distancias: +  0.8350716664310035\n",
      "Penalización por duración del episodio: -  0.3475256003489837\n",
      "Recompensa por acortar distancias: +  0.8275398942596697\n",
      "Penalización por parar muy lejos: -  0.080786493968018\n",
      "Penalización por duración del episodio: -  0.3478790807531747\n",
      "steer input from model: 0.9 , throttle:  0.0\n",
      "reward: 0.398874319538477\n",
      "Recompensa por acortar distancias: +  0.8240346495263838\n",
      "Penalización por parar muy lejos: -  0.07899546431297738\n",
      "Penalización por duración del episodio: -  0.3482226584298276\n",
      "Recompensa por acortar distancias: +  0.8212492039219622\n",
      "Penalización por duración del episodio: -  0.3485864738156442\n",
      "Recompensa por acortar distancias: +  0.8212492039219622\n",
      "Penalización por duración del episodio: -  0.34866646793259043\n",
      "Recompensa por acortar distancias: +  0.8212492039219622\n",
      "Penalización por parar muy lejos: -  0.07761757478623246\n",
      "Penalización por duración del episodio: -  0.34875706243124877\n",
      "Recompensa por acortar distancias: +  0.8212492039219622\n",
      "Penalización por parar muy lejos: -  0.07761757478623246\n",
      "Penalización por duración del episodio: -  0.3488476786932916\n",
      "Step: 7560, Mean Reward (últimos 10 pasos): 0.39478394389152527\n",
      "Recompensa por acortar distancias: +  0.8212492039219622\n",
      "Penalización por parar muy lejos: -  0.07761757478623246\n",
      "Penalización por duración del episodio: -  0.3493032919492081\n",
      "Recompensa por acortar distancias: +  0.8149030082994635\n",
      "Penalización por parar muy lejos: -  0.07461896608995057\n",
      "Penalización por duración del episodio: -  0.34965737297718286\n",
      "Recompensa por acortar distancias: +  0.8134842078839649\n",
      "Penalización por parar muy lejos: -  0.07397394753304287\n",
      "Penalización por duración del episodio: -  0.35000443295685507\n",
      "Recompensa por acortar distancias: +  0.8100055302805976\n",
      "Penalización por duración del episodio: -  0.35036561986882153\n",
      "Recompensa por acortar distancias: +  0.8076823840999022\n",
      "Penalización por parar muy lejos: -  0.0714265813248704\n",
      "Penalización por duración del episodio: -  0.3507374134029082\n",
      "Recompensa por acortar distancias: +  0.806642909541191\n",
      "Penalización por duración del episodio: -  0.3508332137054512\n",
      "Recompensa por acortar distancias: +  0.806642909541191\n",
      "Penalización por duración del episodio: -  0.3509359935834467\n",
      "Recompensa por acortar distancias: +  0.806642909541191\n",
      "Penalización por parar muy lejos: -  0.07098491348020008\n",
      "Penalización por duración del episodio: -  0.35109896443596805\n",
      "Recompensa por acortar distancias: +  0.806642909541191\n",
      "Penalización por parar muy lejos: -  0.07098491348020008\n",
      "Penalización por duración del episodio: -  0.35146414815009747\n",
      "Recompensa por acortar distancias: +  0.806642909541191\n",
      "Penalización por duración del episodio: -  0.3515383645054389\n",
      "Step: 7570, Mean Reward (últimos 10 pasos): 0.4551045596599579\n",
      "Recompensa por acortar distancias: +  0.8001019708520488\n",
      "Penalización por parar muy lejos: -  0.06830209417989051\n",
      "Penalización por duración del episodio: -  0.35182628704056074\n",
      "Recompensa por acortar distancias: +  0.7987525739630543\n",
      "Penalización por duración del episodio: -  0.3518998206192467\n",
      "Recompensa por acortar distancias: +  0.7987525739630543\n",
      "Penalización por parar muy lejos: -  0.06776848679757527\n",
      "Penalización por duración del episodio: -  0.35217049378387766\n",
      "Recompensa por acortar distancias: +  0.7987525739630543\n",
      "Penalización por duración del episodio: -  0.3522730067424063\n",
      "Recompensa por acortar distancias: +  0.7987525739630543\n",
      "Penalización por parar muy lejos: -  0.06776848679757527\n",
      "Penalización por duración del episodio: -  0.3525346681980165\n",
      "steer input from model: 0.05 , throttle:  0.0\n",
      "reward: 0.37844941896746254\n",
      "Recompensa por acortar distancias: +  0.7946730100325928\n",
      "Penalización por parar muy lejos: -  0.06619435999711935\n",
      "Penalización por duración del episodio: -  0.35289975996192235\n",
      "Recompensa por acortar distancias: +  0.7912935445408676\n",
      "Penalización por parar muy lejos: -  0.0649331502490541\n",
      "Penalización por duración del episodio: -  0.3530434334892631\n",
      "Recompensa por acortar distancias: +  0.7912935445408676\n",
      "Penalización por parar muy lejos: -  0.0649331502490541\n",
      "Penalización por duración del episodio: -  0.3531724388590131\n",
      "Recompensa por acortar distancias: +  0.7912935445408676\n",
      "Penalización por duración del episodio: -  0.35328269963890896\n",
      "Recompensa por acortar distancias: +  0.7912935445408676\n",
      "Penalización por duración del episodio: -  0.3536162077790521\n",
      "Step: 7580, Mean Reward (últimos 10 pasos): 0.4376773238182068\n",
      "Recompensa por acortar distancias: +  0.7912935445408676\n",
      "Penalización por duración del episodio: -  0.35397317658012434\n",
      "Recompensa por acortar distancias: +  0.7842808159593834\n",
      "Penalización por duración del episodio: -  0.3543450137985213\n",
      "Recompensa por acortar distancias: +  0.7828053543407317\n",
      "Penalización por duración del episodio: -  0.354712917865362\n",
      "Recompensa por acortar distancias: +  0.7828053543407317\n",
      "Penalización por duración del episodio: -  0.3548497145196589\n",
      "Recompensa por acortar distancias: +  0.7787063760416197\n",
      "Penalización por duración del episodio: -  0.35508212401029343\n",
      "Recompensa por acortar distancias: +  0.7767771098862485\n",
      "Penalización por parar muy lejos: -  0.05991646871899213\n",
      "Penalización por duración del episodio: -  0.35519373478498745\n",
      "Recompensa por acortar distancias: +  0.7767771098862485\n",
      "Penalización por parar muy lejos: -  0.05991646871899213\n",
      "Penalización por duración del episodio: -  0.35528050733462846\n",
      "Recompensa por acortar distancias: +  0.7755902180711257\n",
      "Penalización por parar muy lejos: -  0.05953279434103399\n",
      "Penalización por duración del episodio: -  0.3554078219031255\n",
      "Recompensa por acortar distancias: +  0.7755902180711257\n",
      "Penalización por duración del episodio: -  0.35554311639562974\n",
      "Recompensa por acortar distancias: +  0.7755902180711257\n",
      "Penalización por duración del episodio: -  0.3558070529400067\n",
      "Step: 7590, Mean Reward (últimos 10 pasos): 0.41978317499160767\n",
      "Recompensa por acortar distancias: +  0.7755902180711257\n",
      "Penalización por duración del episodio: -  0.3561747300261386\n",
      "Recompensa por acortar distancias: +  0.7755902180711257\n",
      "Penalización por parar muy lejos: -  0.05953279434103399\n",
      "Penalización por duración del episodio: -  0.35652313734086927\n",
      "Recompensa por acortar distancias: +  0.7670859135444216\n",
      "Penalización por duración del episodio: -  0.3568812891105239\n",
      "Recompensa por acortar distancias: +  0.7670859135444216\n",
      "Penalización por duración del episodio: -  0.3572403618877651\n",
      "Recompensa por acortar distancias: +  0.7630206943840344\n",
      "Penalización por duración del episodio: -  0.35736571717753934\n",
      "steer input from model: -0.05 , throttle:  1.0\n",
      "reward: 0.40565497720649507\n",
      "Recompensa por acortar distancias: +  0.7616213163334483\n",
      "Penalización por duración del episodio: -  0.3576009807406994\n",
      "Recompensa por acortar distancias: +  0.7601535087840973\n",
      "Penalización por duración del episodio: -  0.3577257348020092\n",
      "Recompensa por acortar distancias: +  0.7601535087840973\n",
      "Penalización por parar muy lejos: -  0.05486362334064037\n",
      "Penalización por duración del episodio: -  0.3579561335058616\n",
      "Recompensa por acortar distancias: +  0.7601535087840973\n",
      "Penalización por parar muy lejos: -  0.05486362334064037\n",
      "Penalización por duración del episodio: -  0.35831094889068477\n",
      "Recompensa por acortar distancias: +  0.7601535087840973\n",
      "Penalización por duración del episodio: -  0.35865836777583\n",
      "Step: 7600, Mean Reward (últimos 10 pasos): 0.4014951288700104\n",
      "Recompensa por acortar distancias: +  0.7530043481699302\n",
      "Penalización por parar muy lejos: -  0.05288505243465382\n",
      "Penalización por duración del episodio: -  0.3590218131551157\n",
      "Recompensa por acortar distancias: +  0.7512925855445916\n",
      "Penalización por parar muy lejos: -  0.05242701293248786\n",
      "Penalización por duración del episodio: -  0.35939657428057503\n",
      "Recompensa por acortar distancias: +  0.7474319612236834\n",
      "Penalización por parar muy lejos: -  0.05141519744155621\n",
      "Penalización por duración del episodio: -  0.35975111683034094\n",
      "Recompensa por acortar distancias: +  0.7446482797302044\n",
      "Penalización por parar muy lejos: -  0.050703324382778706\n",
      "Penalización por duración del episodio: -  0.3601092407071877\n",
      "Recompensa por acortar distancias: +  0.7446482797302044\n",
      "Penalización por parar muy lejos: -  0.050703324382778706\n",
      "Penalización por duración del episodio: -  0.3604771224289264\n",
      "Recompensa por acortar distancias: +  0.7446482797302044\n",
      "Penalización por parar muy lejos: -  0.050703324382778706\n",
      "Penalización por duración del episodio: -  0.3605670639965416\n",
      "Recompensa por acortar distancias: +  0.7446482797302044\n",
      "Penalización por duración del episodio: -  0.36071617649035675\n",
      "Recompensa por acortar distancias: +  0.7380030161148419\n",
      "Penalización por parar muy lejos: -  0.049061019376182825\n",
      "Penalización por duración del episodio: -  0.36085472499092425\n",
      "Recompensa por acortar distancias: +  0.7380030161148419\n",
      "Penalización por duración del episodio: -  0.36121381728014934\n",
      "Recompensa por acortar distancias: +  0.7362740518322711\n",
      "Penalización por parar muy lejos: -  0.04864639621572474\n",
      "Penalización por duración del episodio: -  0.3613159209141164\n",
      "Step: 7610, Mean Reward (últimos 10 pasos): 0.32631173729896545\n",
      "Recompensa por acortar distancias: +  0.7362740518322711\n",
      "Penalización por duración del episodio: -  0.361411197398041\n",
      "Recompensa por acortar distancias: +  0.7362740518322711\n",
      "Penalización por parar muy lejos: -  0.04864639621572474\n",
      "Penalización por duración del episodio: -  0.3615539234333195\n",
      "Recompensa por acortar distancias: +  0.7318719405465176\n",
      "Penalización por duración del episodio: -  0.3616832707483729\n",
      "Recompensa por acortar distancias: +  0.7318719405465176\n",
      "Penalización por duración del episodio: -  0.36193052898441164\n",
      "Recompensa por acortar distancias: +  0.7289061291245829\n",
      "Penalización por duración del episodio: -  0.3620367842977706\n",
      "steer input from model: -0.25 , throttle:  1.0\n",
      "reward: 0.36686934482681227\n",
      "Recompensa por acortar distancias: +  0.7276103741172955\n",
      "Penalización por duración del episodio: -  0.3621580442715245\n",
      "Recompensa por acortar distancias: +  0.7276103741172955\n",
      "Penalización por duración del episodio: -  0.3622799056714944\n",
      "Recompensa por acortar distancias: +  0.7276103741172955\n",
      "Penalización por duración del episodio: -  0.36240737098419984\n",
      "Recompensa por acortar distancias: +  0.7276103741172955\n",
      "Penalización por duración del episodio: -  0.3625286129185628\n",
      "Recompensa por acortar distancias: +  0.7276103741172955\n",
      "Penalización por duración del episodio: -  0.3626574826360565\n",
      "Step: 7620, Mean Reward (últimos 10 pasos): 0.3649528920650482\n",
      "Recompensa por acortar distancias: +  0.7276103741172955\n",
      "Penalización por duración del episodio: -  0.3627957638776103\n",
      "Recompensa por acortar distancias: +  0.7276103741172955\n",
      "Penalización por duración del episodio: -  0.36303820623816585\n",
      "Recompensa por acortar distancias: +  0.7276103741172955\n",
      "Penalización por duración del episodio: -  0.3631415635016702\n",
      "Recompensa por acortar distancias: +  0.7276103741172955\n",
      "Penalización por duración del episodio: -  0.36327273284103956\n",
      "Recompensa por acortar distancias: +  0.7187536292256334\n",
      "Penalización por duración del episodio: -  0.36337756382730974\n",
      "Recompensa por acortar distancias: +  0.7187536292256334\n",
      "Penalización por duración del episodio: -  0.3635048973255686\n",
      "Recompensa por acortar distancias: +  0.7170383719506179\n",
      "Penalización por duración del episodio: -  0.3636372153594207\n",
      "Recompensa por acortar distancias: +  0.7170383719506179\n",
      "Penalización por duración del episodio: -  0.36373300917081225\n",
      "Recompensa por acortar distancias: +  0.7170383719506179\n",
      "Penalización por duración del episodio: -  0.36411967634027914\n",
      "Recompensa por acortar distancias: +  0.7170383719506179\n",
      "Penalización por duración del episodio: -  0.36448539476333813\n",
      "Step: 7630, Mean Reward (últimos 10 pasos): 0.35255298018455505\n",
      "Recompensa por acortar distancias: +  0.7111535734003775\n",
      "Penalización por duración del episodio: -  0.36484521438351064\n",
      "Recompensa por acortar distancias: +  0.7111535734003775\n",
      "Penalización por duración del episodio: -  0.36520814218265757\n",
      "Recompensa por acortar distancias: +  0.7049609853302586\n",
      "Penalización por duración del episodio: -  0.3655695587996539\n",
      "Recompensa por acortar distancias: +  0.7034850454910818\n",
      "Penalización por duración del episodio: -  0.36565585260543493\n",
      "Recompensa por acortar distancias: +  0.7034850454910818\n",
      "Penalización por duración del episodio: -  0.36592756435333373\n",
      "steer input from model: 0.9 , throttle:  0.3\n",
      "reward: 0.3375574811377481\n",
      "Recompensa por acortar distancias: +  0.7034850454910818\n",
      "Penalización por duración del episodio: -  0.36602247478379374\n",
      "Recompensa por acortar distancias: +  0.699531626187587\n",
      "Penalización por duración del episodio: -  0.36630382059261374\n",
      "Recompensa por acortar distancias: +  0.6978086298515572\n",
      "Penalización por duración del episodio: -  0.3664234361039799\n",
      "Recompensa por acortar distancias: +  0.6978086298515572\n",
      "Penalización por duración del episodio: -  0.3666632923199634\n",
      "Recompensa por acortar distancias: +  0.6946318690829629\n",
      "Penalización por duración del episodio: -  0.36701668129162063\n",
      "Step: 7640, Mean Reward (últimos 10 pasos): 0.3276152014732361\n",
      "Recompensa por acortar distancias: +  0.6946318690829629\n",
      "Penalización por duración del episodio: -  0.3673853073004153\n",
      "Recompensa por acortar distancias: +  0.6946318690829629\n",
      "Penalización por duración del episodio: -  0.36773863331887696\n",
      "Recompensa por acortar distancias: +  0.686994523370835\n",
      "Penalización por duración del episodio: -  0.36782566896298063\n",
      "Recompensa por acortar distancias: +  0.686994523370835\n",
      "Penalización por duración del episodio: -  0.36793332234646875\n",
      "Recompensa por acortar distancias: +  0.6851437744277883\n",
      "Penalización por duración del episodio: -  0.36810120738461294\n",
      "Recompensa por acortar distancias: +  0.6851437744277883\n",
      "Penalización por duración del episodio: -  0.3681884674416601\n",
      "Recompensa por acortar distancias: +  0.6851437744277883\n",
      "Penalización por duración del episodio: -  0.3684612953254693\n",
      "Recompensa por acortar distancias: +  0.6851437744277883\n",
      "Penalización por duración del episodio: -  0.3688185383654593\n",
      "Recompensa por acortar distancias: +  0.6788399102656167\n",
      "Penalización por duración del episodio: -  0.36919010071997627\n",
      "Recompensa por acortar distancias: +  0.6775266828976784\n",
      "Penalización por duración del episodio: -  0.3695522695517442\n",
      "Step: 7650, Mean Reward (últimos 10 pasos): 0.3079744279384613\n",
      "Recompensa por acortar distancias: +  0.6775266828976784\n",
      "Penalización por duración del episodio: -  0.3699229097592617\n",
      "Recompensa por acortar distancias: +  0.6700245105926204\n",
      "Penalización por duración del episodio: -  0.37028420803228085\n",
      "Recompensa por acortar distancias: +  0.6682020126244642\n",
      "Penalización por duración del episodio: -  0.3706523198983733\n",
      "Recompensa por acortar distancias: +  0.6682020126244642\n",
      "Penalización por duración del episodio: -  0.3710311089463774\n",
      "Recompensa por acortar distancias: +  0.6607803073842338\n",
      "Penalización por duración del episodio: -  0.3711564890669567\n",
      "steer input from model: 0.25 , throttle:  0.0\n",
      "reward: 0.28962381831727707\n",
      "Recompensa por acortar distancias: +  0.6607803073842338\n",
      "Penalización por duración del episodio: -  0.3712801779562149\n",
      "Recompensa por acortar distancias: +  0.6594815437821682\n",
      "Penalización por duración del episodio: -  0.3713965864710477\n",
      "Recompensa por acortar distancias: +  0.6594815437821682\n",
      "Penalización por duración del episodio: -  0.37175033949156777\n",
      "Recompensa por acortar distancias: +  0.6594815437821682\n",
      "Penalización por duración del episodio: -  0.37212513623562704\n",
      "Recompensa por acortar distancias: +  0.6594815437821682\n",
      "Penalización por duración del episodio: -  0.3722904532545691\n",
      "Step: 7660, Mean Reward (últimos 10 pasos): 0.28719109296798706\n",
      "Recompensa por acortar distancias: +  0.6512843835669161\n",
      "Penalización por duración del episodio: -  0.37243601757474415\n",
      "Recompensa por acortar distancias: +  0.6512843835669161\n",
      "Penalización por duración del episodio: -  0.3725297517543588\n",
      "Recompensa por acortar distancias: +  0.6512843835669161\n",
      "Penalización por duración del episodio: -  0.3728469641894239\n",
      "Recompensa por acortar distancias: +  0.6490485939443408\n",
      "Penalización por duración del episodio: -  0.3732116185750477\n",
      "Recompensa por acortar distancias: +  0.6445192733597875\n",
      "Penalización por duración del episodio: -  0.37356677042592806\n",
      "Recompensa por acortar distancias: +  0.6418860218840162\n",
      "Penalización por duración del episodio: -  0.3736671929016059\n",
      "Recompensa por acortar distancias: +  0.6418860218840162\n",
      "Penalización por duración del episodio: -  0.3737605892141741\n",
      "Recompensa por acortar distancias: +  0.6418860218840162\n",
      "Penalización por duración del episodio: -  0.37386589386165425\n",
      "Recompensa por acortar distancias: +  0.6418860218840162\n",
      "Penalización por duración del episodio: -  0.3739633066964385\n",
      "Recompensa por acortar distancias: +  0.6418860218840162\n",
      "Penalización por duración del episodio: -  0.374080603006583\n",
      "Step: 7670, Mean Reward (últimos 10 pasos): 0.26780542731285095\n",
      "Recompensa por acortar distancias: +  0.6418860218840162\n",
      "Penalización por duración del episodio: -  0.3741891821278452\n",
      "Recompensa por acortar distancias: +  0.6418860218840162\n",
      "Penalización por duración del episodio: -  0.3743072607378666\n",
      "Recompensa por acortar distancias: +  0.6418860218840162\n",
      "Penalización por duración del episodio: -  0.37466585397333113\n",
      "Recompensa por acortar distancias: +  0.6418860218840162\n",
      "Penalización por duración del episodio: -  0.37480479782345166\n",
      "Recompensa por acortar distancias: +  0.6337298826350383\n",
      "Penalización por duración del episodio: -  0.3749067004866274\n",
      "steer input from model: 0.05 , throttle:  0.3\n",
      "reward: 0.2588231821484109\n",
      "Recompensa por acortar distancias: +  0.6337298826350383\n",
      "Penalización por duración del episodio: -  0.37540334878821224\n",
      "Recompensa por acortar distancias: +  0.6318627227702752\n",
      "Penalización por duración del episodio: -  0.3757772934720859\n",
      "Recompensa por acortar distancias: +  0.6269934545537255\n",
      "Penalización por duración del episodio: -  0.3758912038898351\n",
      "Recompensa por acortar distancias: +  0.6255044626026424\n",
      "Penalización por duración del episodio: -  0.37599069028627446\n",
      "Recompensa por acortar distancias: +  0.6255044626026424\n",
      "Penalización por duración del episodio: -  0.3761468881399548\n",
      "Step: 7680, Mean Reward (últimos 10 pasos): 0.24935758113861084\n",
      "Recompensa por acortar distancias: +  0.6239289846857734\n",
      "Penalización por duración del episodio: -  0.3762446165040455\n",
      "Recompensa por acortar distancias: +  0.6239289846857734\n",
      "Penalización por duración del episodio: -  0.37652478180655047\n",
      "Recompensa por acortar distancias: +  0.6239289846857734\n",
      "Penalización por duración del episodio: -  0.37688552441301926\n",
      "Recompensa por acortar distancias: +  0.6239289846857734\n",
      "Penalización por duración del episodio: -  0.37704053099197793\n",
      "Recompensa por acortar distancias: +  0.6239289846857734\n",
      "Penalización por duración del episodio: -  0.37718461862134023\n",
      "Recompensa por acortar distancias: +  0.6168461550509595\n",
      "Penalización por duración del episodio: -  0.37763303746322746\n",
      "Recompensa por acortar distancias: +  0.6151343947997991\n",
      "Penalización por duración del episodio: -  0.37799434948384797\n",
      "Recompensa por acortar distancias: +  0.6151343947997991\n",
      "Penalización por duración del episodio: -  0.3781351940982159\n",
      "Recompensa por acortar distancias: +  0.6111400015637667\n",
      "Penalización por duración del episodio: -  0.37835398015844224\n",
      "Recompensa por acortar distancias: +  0.6088415768377625\n",
      "Penalización por duración del episodio: -  0.37845471016683363\n",
      "Step: 7690, Mean Reward (últimos 10 pasos): 0.2303868681192398\n",
      "Recompensa por acortar distancias: +  0.6088415768377625\n",
      "Penalización por duración del episodio: -  0.37871432807887295\n",
      "Recompensa por acortar distancias: +  0.6078406304112252\n",
      "Penalización por duración del episodio: -  0.379083654198256\n",
      "Recompensa por acortar distancias: +  0.6078406304112252\n",
      "Penalización por duración del episodio: -  0.3791838706671866\n",
      "Recompensa por acortar distancias: +  0.6078406304112252\n",
      "Penalización por duración del episodio: -  0.3792877178593215\n",
      "Recompensa por acortar distancias: +  0.6078406304112252\n",
      "Penalización por duración del episodio: -  0.37939479835279366\n",
      "steer input from model: -0.1 , throttle:  0.0\n",
      "reward: 0.2284458320584315\n",
      "Recompensa por acortar distancias: +  0.6078406304112252\n",
      "Penalización por duración del episodio: -  0.37947580697135963\n",
      "Recompensa por acortar distancias: +  0.6078406304112252\n",
      "Penalización por duración del episodio: -  0.37963443602013236\n",
      "Recompensa por acortar distancias: +  0.6010581944074254\n",
      "Penalización por duración del episodio: -  0.37981399360788787\n",
      "Recompensa por acortar distancias: +  0.5996155300391282\n",
      "Penalización por duración del episodio: -  0.37989930552323875\n",
      "Recompensa por acortar distancias: +  0.5996155300391282\n",
      "Penalización por duración del episodio: -  0.3800275007678021\n",
      "Step: 7700, Mean Reward (últimos 10 pasos): 0.2195880264043808\n",
      "Recompensa por acortar distancias: +  0.5996155300391282\n",
      "Penalización por duración del episodio: -  0.38018367409475007\n",
      "Recompensa por acortar distancias: +  0.5996155300391282\n",
      "Penalización por duración del episodio: -  0.3805447034983147\n",
      "Recompensa por acortar distancias: +  0.5955704870840008\n",
      "Penalización por duración del episodio: -  0.3806632810657733\n",
      "Recompensa por acortar distancias: +  0.5942387384628135\n",
      "Penalización por duración del episodio: -  0.3807881072446405\n",
      "Recompensa por acortar distancias: +  0.5942387384628135\n",
      "Penalización por duración del episodio: -  0.3809110319631593\n",
      "Recompensa por acortar distancias: +  0.593022738921679\n",
      "Penalización por duración del episodio: -  0.38101075471532175\n",
      "Recompensa por acortar distancias: +  0.593022738921679\n",
      "Penalización por duración del episodio: -  0.38126175903567894\n",
      "Recompensa por acortar distancias: +  0.593022738921679\n",
      "Penalización por duración del episodio: -  0.38163688216740144\n",
      "Recompensa por acortar distancias: +  0.593022738921679\n",
      "Penalización por duración del episodio: -  0.38176969197147603\n",
      "Recompensa por acortar distancias: +  0.593022738921679\n",
      "Penalización por duración del episodio: -  0.38190733697888707\n",
      "Step: 7710, Mean Reward (últimos 10 pasos): 0.21111540496349335\n",
      "Recompensa por acortar distancias: +  0.593022738921679\n",
      "Penalización por duración del episodio: -  0.38208743694323033\n",
      "Recompensa por acortar distancias: +  0.5857159516036589\n",
      "Penalización por duración del episodio: -  0.38222785048919194\n",
      "Recompensa por acortar distancias: +  0.5857159516036589\n",
      "Penalización por duración del episodio: -  0.3827153155821094\n",
      "Recompensa por acortar distancias: +  0.5839434688683217\n",
      "Penalización por duración del episodio: -  0.3828269354464405\n",
      "Recompensa por acortar distancias: +  0.5839434688683217\n",
      "Penalización por duración del episodio: -  0.3829760328055157\n",
      "steer input from model: -0.25 , throttle:  0.3\n",
      "reward: 0.20096743606280604\n",
      "Recompensa por acortar distancias: +  0.5803557239060251\n",
      "Penalización por duración del episodio: -  0.3834565997851749\n",
      "Recompensa por acortar distancias: +  0.5789665266380435\n",
      "Penalización por duración del episodio: -  0.38381469638072324\n",
      "Recompensa por acortar distancias: +  0.5789665266380435\n",
      "Penalización por duración del episodio: -  0.3841772115230745\n",
      "Recompensa por acortar distancias: +  0.5735346311376296\n",
      "Penalización por duración del episodio: -  0.3845489174845514\n",
      "Recompensa por acortar distancias: +  0.5724170447896961\n",
      "Penalización por duración del episodio: -  0.3849267699381274\n",
      "Step: 7720, Mean Reward (últimos 10 pasos): 0.18749026954174042\n",
      "Recompensa por acortar distancias: +  0.5689327965590821\n",
      "Penalización por duración del episodio: -  0.3853016441854868\n",
      "Recompensa por acortar distancias: +  0.5668986417778142\n",
      "Penalización por duración del episodio: -  0.38540569750815673\n",
      "Recompensa por acortar distancias: +  0.5668986417778142\n",
      "Penalización por duración del episodio: -  0.3855359285682736\n",
      "Recompensa por acortar distancias: +  0.5658259384140353\n",
      "Penalización por duración del episodio: -  0.3856693280542961\n",
      "Recompensa por acortar distancias: +  0.5658259384140353\n",
      "Penalización por duración del episodio: -  0.38580050185107\n",
      "Recompensa por acortar distancias: +  0.5658259384140353\n",
      "Penalización por duración del episodio: -  0.3860382160995011\n",
      "Recompensa por acortar distancias: +  0.5658259384140353\n",
      "Penalización por duración del episodio: -  0.3864143576354615\n",
      "Recompensa por acortar distancias: +  0.5658259384140353\n",
      "Penalización por duración del episodio: -  0.3865481299256416\n",
      "Recompensa por acortar distancias: +  0.5596364820005049\n",
      "Penalización por duración del episodio: -  0.38677658810502435\n",
      "Recompensa por acortar distancias: +  0.5596364820005049\n",
      "Penalización por duración del episodio: -  0.38693337414051765\n",
      "Step: 7730, Mean Reward (últimos 10 pasos): 0.1727031022310257\n",
      "Recompensa por acortar distancias: +  0.5580173179013989\n",
      "Penalización por duración del episodio: -  0.3871490186572061\n",
      "Recompensa por acortar distancias: +  0.5580173179013989\n",
      "Penalización por duración del episodio: -  0.3875187744243341\n",
      "Recompensa por acortar distancias: +  0.553955827375957\n",
      "Penalización por duración del episodio: -  0.3876203663905619\n",
      "Recompensa por acortar distancias: +  0.553955827375957\n",
      "Penalización por duración del episodio: -  0.38790565367163476\n",
      "Recompensa por acortar distancias: +  0.5517468212688506\n",
      "Penalización por duración del episodio: -  0.3880082112849086\n",
      "steer input from model: -0.25 , throttle:  1.0\n",
      "reward: 0.16373860998394196\n",
      "Recompensa por acortar distancias: +  0.5517468212688506\n",
      "Penalización por duración del episodio: -  0.3882877305492728\n",
      "Recompensa por acortar distancias: +  0.5517468212688506\n",
      "Penalización por duración del episodio: -  0.38865074075600037\n",
      "Recompensa por acortar distancias: +  0.5517468212688506\n",
      "Penalización por duración del episodio: -  0.3890295149494842\n",
      "Recompensa por acortar distancias: +  0.5456708494122954\n",
      "Penalización por duración del episodio: -  0.3890951449252354\n",
      "Recompensa por acortar distancias: +  0.5456708494122954\n",
      "Penalización por duración del episodio: -  0.3894219151440662\n",
      "Step: 7740, Mean Reward (últimos 10 pasos): 0.15624892711639404\n",
      "Recompensa por acortar distancias: +  0.5456708494122954\n",
      "Penalización por duración del episodio: -  0.38978451045191265\n",
      "Recompensa por acortar distancias: +  0.5414510498293962\n",
      "Penalización por duración del episodio: -  0.38992914374099275\n",
      "Recompensa por acortar distancias: +  0.540469608944956\n",
      "Penalización por duración del episodio: -  0.39015896462890004\n",
      "Recompensa por acortar distancias: +  0.5396101438789989\n",
      "Penalización por duración del episodio: -  0.3905243381977626\n",
      "Recompensa por acortar distancias: +  0.5386967949186753\n",
      "Penalización por duración del episodio: -  0.39089303055867747\n",
      "Recompensa por acortar distancias: +  0.5386967949186753\n",
      "Penalización por duración del episodio: -  0.39100021651999345\n",
      "Recompensa por acortar distancias: +  0.5386967949186753\n",
      "Penalización por duración del episodio: -  0.39109645498362594\n",
      "Recompensa por acortar distancias: +  0.5338638013269763\n",
      "Penalización por duración del episodio: -  0.3912555557198909\n",
      "Recompensa por acortar distancias: +  0.5338638013269763\n",
      "Penalización por duración del episodio: -  0.3913767478475855\n",
      "Recompensa por acortar distancias: +  0.5326663160462578\n",
      "Penalización por duración del episodio: -  0.39162390975117\n",
      "Step: 7750, Mean Reward (últimos 10 pasos): 0.14104241132736206\n",
      "Recompensa por acortar distancias: +  0.5326663160462578\n",
      "Penalización por duración del episodio: -  0.3917177204212958\n",
      "Recompensa por acortar distancias: +  0.5326663160462578\n",
      "Penalización por duración del episodio: -  0.3919997913688365\n",
      "Recompensa por acortar distancias: +  0.5292317862560478\n",
      "Penalización por duración del episodio: -  0.3923733966180835\n",
      "Recompensa por acortar distancias: +  0.5274202931689357\n",
      "Penalización por duración del episodio: -  0.3924892315040034\n",
      "Recompensa por acortar distancias: +  0.5266413444865728\n",
      "Penalización por duración del episodio: -  0.39275532747098435\n",
      "steer input from model: 0.1 , throttle:  0.0\n",
      "reward: 0.1338860170155885\n",
      "Recompensa por acortar distancias: +  0.5266413444865728\n",
      "Penalización por duración del episodio: -  0.393141433872768\n",
      "Recompensa por acortar distancias: +  0.5266413444865728\n",
      "Penalización por duración del episodio: -  0.393243792397715\n",
      "Recompensa por acortar distancias: +  0.5266413444865728\n",
      "Penalización por duración del episodio: -  0.3935138695594734\n",
      "Recompensa por acortar distancias: +  0.5215296454869176\n",
      "Penalización por duración del episodio: -  0.3938801052681105\n",
      "Recompensa por acortar distancias: +  0.5207480249610867\n",
      "Penalización por duración del episodio: -  0.39425507504158486\n",
      "Step: 7760, Mean Reward (últimos 10 pasos): 0.1264929473400116\n",
      "Recompensa por acortar distancias: +  0.5178429144035944\n",
      "Penalización por duración del episodio: -  0.39434158524649354\n",
      "Recompensa por acortar distancias: +  0.5167431493965824\n",
      "Penalización por duración del episodio: -  0.39447321667815405\n",
      "Recompensa por acortar distancias: +  0.5160371349800749\n",
      "Penalización por duración del episodio: -  0.394631986316183\n",
      "Recompensa por acortar distancias: +  0.5153103216902263\n",
      "Penalización por duración del episodio: -  0.3950005676622132\n",
      "Recompensa por acortar distancias: +  0.5134705065759066\n",
      "Penalización por duración del episodio: -  0.3953692741262073\n",
      "Recompensa por acortar distancias: +  0.5134705065759066\n",
      "Penalización por duración del episodio: -  0.39546633424373734\n",
      "Recompensa por acortar distancias: +  0.5134705065759066\n",
      "Penalización por duración del episodio: -  0.3955526858584608\n",
      "Recompensa por acortar distancias: +  0.5134705065759066\n",
      "Penalización por duración del episodio: -  0.3957505684216802\n",
      "Recompensa por acortar distancias: +  0.5134705065759066\n",
      "Penalización por duración del episodio: -  0.39611606617040446\n",
      "Recompensa por acortar distancias: +  0.507800953329049\n",
      "Penalización por duración del episodio: -  0.39648908506651537\n",
      "Step: 7770, Mean Reward (últimos 10 pasos): 0.11131186783313751\n",
      "Recompensa por acortar distancias: +  0.507800953329049\n",
      "Penalización por duración del episodio: -  0.3968536070733447\n",
      "Recompensa por acortar distancias: +  0.5047265134969643\n",
      "Penalización por duración del episodio: -  0.39700983571139165\n",
      "Recompensa por acortar distancias: +  0.5034522759662134\n",
      "Penalización por duración del episodio: -  0.39713275482560956\n",
      "Recompensa por acortar distancias: +  0.5021338094869068\n",
      "Penalización por duración del episodio: -  0.39761926157840555\n",
      "Recompensa por acortar distancias: +  0.501131824705972\n",
      "Penalización por duración del episodio: -  0.39778991692852894\n",
      "steer input from model: -0.05 , throttle:  0.0\n",
      "reward: 0.10334190777744301\n",
      "Recompensa por acortar distancias: +  0.501131824705972\n",
      "Penalización por duración del episodio: -  0.397921554745497\n",
      "Recompensa por acortar distancias: +  0.501131824705972\n",
      "Penalización por duración del episodio: -  0.39839851478413657\n",
      "Recompensa por acortar distancias: +  0.501131824705972\n",
      "Penalización por duración del episodio: -  0.39850043458729034\n",
      "Recompensa por acortar distancias: +  0.49655267098379435\n",
      "Penalización por duración del episodio: -  0.3987640439163054\n",
      "Recompensa por acortar distancias: +  0.496219373275588\n",
      "Penalización por duración del episodio: -  0.3991292627964709\n",
      "Step: 7780, Mean Reward (últimos 10 pasos): 0.09709011018276215\n",
      "Recompensa por acortar distancias: +  0.496219373275588\n",
      "Penalización por duración del episodio: -  0.39949725926525814\n",
      "Recompensa por acortar distancias: +  0.49591447267107536\n",
      "Penalización por duración del episodio: -  0.3996029915405622\n",
      "Recompensa por acortar distancias: +  0.49591092643170137\n",
      "Penalización por duración del episodio: -  0.39969855617091116\n",
      "Recompensa por acortar distancias: +  0.4959071477501992\n",
      "Penalización por duración del episodio: -  0.399865598091376\n",
      "Recompensa por acortar distancias: +  0.4959071477501992\n",
      "Penalización por duración del episodio: -  0.4002357270654319\n",
      "Recompensa por acortar distancias: +  0.4959071477501992\n",
      "Penalización por duración del episodio: -  0.40061605158382974\n",
      "Recompensa por acortar distancias: +  0.4959071477501992\n",
      "Penalización por duración del episodio: -  0.4009875621406574\n",
      "Recompensa por acortar distancias: +  0.4955009363447743\n",
      "Penalización por duración del episodio: -  0.4013621137783592\n",
      "Recompensa por acortar distancias: +  0.4954037828512352\n",
      "Penalización por duración del episodio: -  0.40174982849826285\n",
      "Recompensa por acortar distancias: +  0.4954037828512352\n",
      "Penalización por duración del episodio: -  0.40188851002080606\n",
      "Step: 7790, Mean Reward (últimos 10 pasos): 0.09351526945829391\n",
      "Recompensa por acortar distancias: +  0.4953031312206496\n",
      "Penalización por duración del episodio: -  0.4020076396696215\n",
      "Recompensa por acortar distancias: +  0.4953031312206496\n",
      "Penalización por duración del episodio: -  0.40212124371336516\n",
      "Recompensa por acortar distancias: +  0.4953065760653328\n",
      "Penalización por duración del episodio: -  0.40224120998533314\n",
      "Recompensa por acortar distancias: +  0.4953065760653328\n",
      "Penalización por duración del episodio: -  0.4023634410999478\n",
      "Recompensa por acortar distancias: +  0.4953084474863335\n",
      "Penalización por duración del episodio: -  0.4025078110928642\n",
      "steer input from model: 0.0 , throttle:  0.7\n",
      "reward: 0.0928006363934693\n",
      "Recompensa por acortar distancias: +  0.4953084474863335\n",
      "Penalización por duración del episodio: -  0.40269695102867054\n",
      "Recompensa por acortar distancias: +  0.4953084474863335\n",
      "Penalización por duración del episodio: -  0.40287220540209645\n",
      "Recompensa por acortar distancias: +  0.4953084474863335\n",
      "Penalización por duración del episodio: -  0.4032591569478697\n",
      "Recompensa por acortar distancias: +  0.4953084474863335\n",
      "Penalización por duración del episodio: -  0.40340774554463166\n",
      "Recompensa por acortar distancias: +  0.4953084474863335\n",
      "Penalización por duración del episodio: -  0.40349255060442957\n",
      "Step: 7800, Mean Reward (últimos 10 pasos): 0.09181589633226395\n",
      "Recompensa por acortar distancias: +  0.4953084474863335\n",
      "Penalización por duración del episodio: -  0.4036449031840877\n",
      "Recompensa por acortar distancias: +  0.4953204090879993\n",
      "Penalización por duración del episodio: -  0.4037698383624703\n",
      "Recompensa por acortar distancias: +  0.4953231685414614\n",
      "Penalización por duración del episodio: -  0.404030441352268\n",
      "Recompensa por acortar distancias: +  0.4953231685414614\n",
      "Penalización por duración del episodio: -  0.40413104277626155\n",
      "Recompensa por acortar distancias: +  0.4953231685414614\n",
      "Penalización por duración del episodio: -  0.4044138354434256\n",
      "Recompensa por acortar distancias: +  0.49533107738697935\n",
      "Penalización por duración del episodio: -  0.40448031386105743\n",
      "Recompensa por acortar distancias: +  0.49533107738697935\n",
      "Penalización por duración del episodio: -  0.40479532421876857\n",
      "Recompensa por acortar distancias: +  0.4953352672284684\n",
      "Penalización por duración del episodio: -  0.4048914597931361\n",
      "Recompensa por acortar distancias: +  0.4953352672284684\n",
      "Penalización por duración del episodio: -  0.4051829672001074\n",
      "Recompensa por acortar distancias: +  0.4953352672284684\n",
      "Penalización por duración del episodio: -  0.4052619155905969\n",
      "Step: 7810, Mean Reward (últimos 10 pasos): 0.0900733545422554\n",
      "Recompensa por acortar distancias: +  0.4953352672284684\n",
      "Penalización por duración del episodio: -  0.4053801950670836\n",
      "Recompensa por acortar distancias: +  0.4953352672284684\n",
      "Penalización por duración del episodio: -  0.4055518295979984\n",
      "Recompensa por acortar distancias: +  0.4953352672284684\n",
      "Penalización por duración del episodio: -  0.4056491030557483\n",
      "Recompensa por acortar distancias: +  0.4953352672284684\n",
      "Penalización por duración del episodio: -  0.4058305355650365\n",
      "Recompensa por acortar distancias: +  0.4952471853368762\n",
      "Penalización por duración del episodio: -  0.40630824305474683\n",
      "steer input from model: -0.25 , throttle:  0.0\n",
      "reward: 0.08893894228212934\n",
      "Recompensa por acortar distancias: +  0.4952237568785854\n",
      "Penalización por duración del episodio: -  0.4066831305310217\n",
      "Recompensa por acortar distancias: +  0.49518463598918583\n",
      "Penalización por duración del episodio: -  0.4068252049307572\n",
      "Recompensa por acortar distancias: +  0.49518463598918583\n",
      "Penalización por duración del episodio: -  0.40706698297088667\n",
      "Recompensa por acortar distancias: +  0.4950975558671819\n",
      "Penalización por duración del episodio: -  0.4074352401932003\n",
      "Recompensa por acortar distancias: +  0.4950975558671819\n",
      "Penalización por duración del episodio: -  0.40754384659632065\n",
      "Step: 7820, Mean Reward (últimos 10 pasos): 0.0875537097454071\n",
      "Recompensa por acortar distancias: +  0.4950975558671819\n",
      "Penalización por duración del episodio: -  0.40764439630593036\n",
      "Recompensa por acortar distancias: +  0.4950975558671819\n",
      "Penalización por duración del episodio: -  0.4077421210400478\n",
      "Recompensa por acortar distancias: +  0.4950975558671819\n",
      "Penalización por duración del episodio: -  0.407879871531401\n",
      "Recompensa por acortar distancias: +  0.4950975558671819\n",
      "Penalización por duración del episodio: -  0.40819638280636733\n",
      "Recompensa por acortar distancias: +  0.49474394609810335\n",
      "Penalización por duración del episodio: -  0.4082936072227803\n",
      "Recompensa por acortar distancias: +  0.49474394609810335\n",
      "Penalización por duración del episodio: -  0.40839474435805173\n",
      "Recompensa por acortar distancias: +  0.49463245627383845\n",
      "Penalización por duración del episodio: -  0.4085757138137601\n",
      "Recompensa por acortar distancias: +  0.49463245627383845\n",
      "Penalización por duración del episodio: -  0.40895265842914735\n",
      "Recompensa por acortar distancias: +  0.49463245627383845\n",
      "Penalización por duración del episodio: -  0.4093278539634087\n",
      "Recompensa por acortar distancias: +  0.49423329175692804\n",
      "Penalización por duración del episodio: -  0.40943309391649224\n",
      "Step: 7830, Mean Reward (últimos 10 pasos): 0.08480019867420197\n",
      "Recompensa por acortar distancias: +  0.49413308607132833\n",
      "Penalización por duración del episodio: -  0.4097025035465116\n",
      "Recompensa por acortar distancias: +  0.49413308607132833\n",
      "Penalización por duración del episodio: -  0.41008275457956817\n",
      "Recompensa por acortar distancias: +  0.49413308607132833\n",
      "Penalización por duración del episodio: -  0.4104460764113086\n",
      "Recompensa por acortar distancias: +  0.49413308607132833\n",
      "Penalización por duración del episodio: -  0.41083553986198884\n",
      "Recompensa por acortar distancias: +  0.4933192295375948\n",
      "Penalización por duración del episodio: -  0.41121018731830183\n",
      "steer input from model: 0.0 , throttle:  0.0\n",
      "reward: 0.082109042219293\n",
      "Recompensa por acortar distancias: +  0.4933192295375948\n",
      "Penalización por duración del episodio: -  0.4115932351387739\n",
      "Recompensa por acortar distancias: +  0.4932235098952117\n",
      "Penalización por duración del episodio: -  0.41196830988224814\n",
      "Recompensa por acortar distancias: +  0.4932299400561737\n",
      "Penalización por duración del episodio: -  0.41206636165987226\n",
      "Recompensa por acortar distancias: +  0.4932299400561737\n",
      "Penalización por duración del episodio: -  0.4121654370854314\n",
      "Recompensa por acortar distancias: +  0.4932299400561737\n",
      "Penalización por duración del episodio: -  0.4122730233125303\n",
      "Step: 7840, Mean Reward (últimos 10 pasos): 0.08095691353082657\n",
      "Recompensa por acortar distancias: +  0.4932299400561737\n",
      "Penalización por duración del episodio: -  0.41273526445559056\n",
      "Recompensa por acortar distancias: +  0.4932299400561737\n",
      "Penalización por duración del episodio: -  0.41311392098831135\n",
      "Recompensa por acortar distancias: +  0.4932299400561737\n",
      "Penalización por duración del episodio: -  0.4132149731776434\n",
      "Recompensa por acortar distancias: +  0.4931272782465173\n",
      "Penalización por duración del episodio: -  0.4133172640978518\n",
      "Recompensa por acortar distancias: +  0.4931272782465173\n",
      "Penalización por duración del episodio: -  0.4134558780905049\n",
      "Recompensa por acortar distancias: +  0.49310520487077664\n",
      "Penalización por duración del episodio: -  0.413552624041283\n",
      "Recompensa por acortar distancias: +  0.49310520487077664\n",
      "Penalización por duración del episodio: -  0.4136851488367086\n",
      "Recompensa por acortar distancias: +  0.49310520487077664\n",
      "Penalización por duración del episodio: -  0.41383596752147667\n",
      "Recompensa por acortar distancias: +  0.49310520487077664\n",
      "Penalización por duración del episodio: -  0.4139585069513831\n",
      "Recompensa por acortar distancias: +  0.49310520487077664\n",
      "Penalización por duración del episodio: -  0.4142610867546935\n",
      "Step: 7850, Mean Reward (últimos 10 pasos): 0.0788441151380539\n",
      "Recompensa por acortar distancias: +  0.49303388969653433\n",
      "Penalización por duración del episodio: -  0.4146408028809869\n",
      "Recompensa por acortar distancias: +  0.4930072098966708\n",
      "Penalización por duración del episodio: -  0.41472268193692785\n",
      "Recompensa por acortar distancias: +  0.4930072098966708\n",
      "Penalización por duración del episodio: -  0.41486346543369373\n",
      "Recompensa por acortar distancias: +  0.4930072098966708\n",
      "Penalización por duración del episodio: -  0.4150106183186022\n",
      "Recompensa por acortar distancias: +  0.4930072098966708\n",
      "Penalización por duración del episodio: -  0.41539832153470085\n",
      "steer input from model: -0.05 , throttle:  0.0\n",
      "reward: 0.07760888836196994\n",
      "Recompensa por acortar distancias: +  0.4929831701021767\n",
      "Penalización por duración del episodio: -  0.4157855387914695\n",
      "Recompensa por acortar distancias: +  0.4929835097817442\n",
      "Penalización por duración del episodio: -  0.41615775795590676\n",
      "Recompensa por acortar distancias: +  0.49298542867345807\n",
      "Penalización por duración del episodio: -  0.41653600619164877\n",
      "Recompensa por acortar distancias: +  0.4929861974220598\n",
      "Penalización por duración del episodio: -  0.41691059699726624\n",
      "Recompensa por acortar distancias: +  0.4929861974220598\n",
      "Penalización por duración del episodio: -  0.41699598415521744\n",
      "Step: 7860, Mean Reward (últimos 10 pasos): 0.0759902149438858\n",
      "Recompensa por acortar distancias: +  0.4929861974220598\n",
      "Penalización por duración del episodio: -  0.4172901071470313\n",
      "Recompensa por acortar distancias: +  0.4929861974220598\n",
      "Penalización por duración del episodio: -  0.4174104595523017\n",
      "Recompensa por acortar distancias: +  0.4929861974220598\n",
      "Penalización por duración del episodio: -  0.41767768875450784\n",
      "Recompensa por acortar distancias: +  0.49292964979389575\n",
      "Penalización por duración del episodio: -  0.41782021492273624\n",
      "Recompensa por acortar distancias: +  0.49292964979389575\n",
      "Penalización por duración del episodio: -  0.418068927730496\n",
      "Recompensa por acortar distancias: +  0.49292964979389575\n",
      "Penalización por duración del episodio: -  0.4184578330145173\n",
      "Recompensa por acortar distancias: +  0.4928528826112252\n",
      "Penalización por duración del episodio: -  0.41883271996759697\n",
      "Recompensa por acortar distancias: +  0.4928536036800791\n",
      "Penalización por duración del episodio: -  0.4192106321188981\n",
      "Recompensa por acortar distancias: +  0.4928540565828456\n",
      "Penalización por duración del episodio: -  0.4196011517089776\n",
      "Recompensa por acortar distancias: +  0.4928540565828456\n",
      "Penalización por duración del episodio: -  0.41999063368148476\n",
      "Step: 7870, Mean Reward (últimos 10 pasos): 0.07286342233419418\n",
      "Recompensa por acortar distancias: +  0.4928259587558188\n",
      "Penalización por duración del episodio: -  0.4200766328092152\n",
      "Recompensa por acortar distancias: +  0.49283979611058104\n",
      "Penalización por duración del episodio: -  0.42037712477102673\n",
      "Recompensa por acortar distancias: +  0.49283979611058104\n",
      "Penalización por duración del episodio: -  0.42075708924010824\n",
      "Recompensa por acortar distancias: +  0.4928783166942097\n",
      "Penalización por duración del episodio: -  0.420863476147342\n",
      "Recompensa por acortar distancias: +  0.4929250075211294\n",
      "Penalización por duración del episodio: -  0.42113172485698575\n",
      "steer input from model: 0.0 , throttle:  1.0\n",
      "reward: 0.07179328266414364\n",
      "Recompensa por acortar distancias: +  0.49292018051222974\n",
      "Penalización por duración del episodio: -  0.4215231363429018\n",
      "Recompensa por acortar distancias: +  0.4929481473857989\n",
      "Penalización por duración del episodio: -  0.4216326690210699\n",
      "Recompensa por acortar distancias: +  0.4929481473857989\n",
      "Penalización por duración del episodio: -  0.42175440236066547\n",
      "Recompensa por acortar distancias: +  0.4929481473857989\n",
      "Penalización por duración del episodio: -  0.42189443914865626\n",
      "Recompensa por acortar distancias: +  0.4929481473857989\n",
      "Penalización por duración del episodio: -  0.4220406471654234\n",
      "Step: 7880, Mean Reward (últimos 10 pasos): 0.07090750336647034\n",
      "Recompensa por acortar distancias: +  0.4929481473857989\n",
      "Penalización por duración del episodio: -  0.422162255285538\n",
      "Recompensa por acortar distancias: +  0.4929481473857989\n",
      "Penalización por duración del episodio: -  0.42266090056112154\n",
      "Recompensa por acortar distancias: +  0.49300502283420683\n",
      "Penalización por duración del episodio: -  0.4228147904136678\n",
      "Recompensa por acortar distancias: +  0.49300502283420683\n",
      "Penalización por duración del episodio: -  0.42294477937487285\n",
      "Recompensa por acortar distancias: +  0.4930065424552365\n",
      "Penalización por duración del episodio: -  0.4230475503586383\n",
      "Recompensa por acortar distancias: +  0.4930065424552365\n",
      "Penalización por duración del episodio: -  0.4231837506474271\n",
      "Recompensa por acortar distancias: +  0.4930065424552365\n",
      "Penalización por duración del episodio: -  0.42343424205968905\n",
      "Recompensa por acortar distancias: +  0.4930065424552365\n",
      "Penalización por duración del episodio: -  0.4238178719965646\n",
      "Recompensa por acortar distancias: +  0.49297749089913856\n",
      "Penalización por duración del episodio: -  0.4239647060836487\n",
      "Recompensa por acortar distancias: +  0.49297749089913856\n",
      "Penalización por duración del episodio: -  0.4241917754188622\n",
      "Step: 7890, Mean Reward (últimos 10 pasos): 0.06878571212291718\n",
      "Recompensa por acortar distancias: +  0.49292594908598214\n",
      "Penalización por duración del episodio: -  0.42456293479372714\n",
      "Recompensa por acortar distancias: +  0.49292594908598214\n",
      "Penalización por duración del episodio: -  0.42494428178276006\n",
      "Recompensa por acortar distancias: +  0.49292594908598214\n",
      "Penalización por duración del episodio: -  0.4250726312010093\n",
      "Recompensa por acortar distancias: +  0.4929417530807417\n",
      "Penalización por duración del episodio: -  0.42532226823979935\n",
      "Recompensa por acortar distancias: +  0.4929417530807417\n",
      "Penalización por duración del episodio: -  0.42543093148637423\n",
      "steer input from model: -0.05 , throttle:  0.0\n",
      "reward: 0.06751082159436744\n",
      "Recompensa por acortar distancias: +  0.4929417530807417\n",
      "Penalización por duración del episodio: -  0.42571697763369337\n",
      "Recompensa por acortar distancias: +  0.4929417530807417\n",
      "Penalización por duración del episodio: -  0.42581348382793105\n",
      "Recompensa por acortar distancias: +  0.4929417530807417\n",
      "Penalización por duración del episodio: -  0.42596642122771006\n",
      "Recompensa por acortar distancias: +  0.49288518175760854\n",
      "Penalización por duración del episodio: -  0.4260931365273435\n",
      "Recompensa por acortar distancias: +  0.49288518175760854\n",
      "Penalización por duración del episodio: -  0.4264702673660389\n",
      "Step: 7900, Mean Reward (últimos 10 pasos): 0.06641491502523422\n",
      "Recompensa por acortar distancias: +  0.4928277286494199\n",
      "Penalización por duración del episodio: -  0.4266117528707862\n",
      "Recompensa por acortar distancias: +  0.4928277286494199\n",
      "Penalización por duración del episodio: -  0.4267168789971433\n",
      "Recompensa por acortar distancias: +  0.4928277286494199\n",
      "Penalización por duración del episodio: -  0.4268382794782364\n",
      "Recompensa por acortar distancias: +  0.4928277286494199\n",
      "Penalización por duración del episodio: -  0.42699421042745606\n",
      "Recompensa por acortar distancias: +  0.4928277286494199\n",
      "Penalización por duración del episodio: -  0.4272393824341343\n",
      "Recompensa por acortar distancias: +  0.4928277286494199\n",
      "Penalización por duración del episodio: -  0.42763197938822833\n",
      "Recompensa por acortar distancias: +  0.4926105753828697\n",
      "Penalización por duración del episodio: -  0.42802486596325273\n",
      "Recompensa por acortar distancias: +  0.49260914518389975\n",
      "Penalización por duración del episodio: -  0.4283959323259786\n",
      "Recompensa por acortar distancias: +  0.49260914518389975\n",
      "Penalización por duración del episodio: -  0.42851069814187887\n",
      "Recompensa por acortar distancias: +  0.49251443052752847\n",
      "Penalización por duración del episodio: -  0.4286334827837041\n",
      "Step: 7910, Mean Reward (últimos 10 pasos): 0.06388095021247864\n",
      "Recompensa por acortar distancias: +  0.49251443052752847\n",
      "Penalización por duración del episodio: -  0.42875723972227764\n",
      "Recompensa por acortar distancias: +  0.4924485346146853\n",
      "Penalización por duración del episodio: -  0.42914853929477664\n",
      "Recompensa por acortar distancias: +  0.4924028462205774\n",
      "Penalización por duración del episodio: -  0.4292545643833017\n",
      "Recompensa por acortar distancias: +  0.4924028462205774\n",
      "Penalización por duración del episodio: -  0.42935445072211426\n",
      "Recompensa por acortar distancias: +  0.4924028462205774\n",
      "Penalización por duración del episodio: -  0.4294653897145589\n",
      "steer input from model: 0.25 , throttle:  0.3\n",
      "reward: 0.06293745650601851\n",
      "Recompensa por acortar distancias: +  0.4924028462205774\n",
      "Penalización por duración del episodio: -  0.4299147734616853\n",
      "Recompensa por acortar distancias: +  0.4924028462205774\n",
      "Penalización por duración del episodio: -  0.43005665586678377\n",
      "Recompensa por acortar distancias: +  0.4919571066062804\n",
      "Penalización por duración del episodio: -  0.43018415530688675\n",
      "Recompensa por acortar distancias: +  0.4919571066062804\n",
      "Penalización por duración del episodio: -  0.43028993947615063\n",
      "Recompensa por acortar distancias: +  0.49178945920005174\n",
      "Penalización por duración del episodio: -  0.4306669510042816\n",
      "Step: 7920, Mean Reward (últimos 10 pasos): 0.061122506856918335\n",
      "Recompensa por acortar distancias: +  0.49178945920005174\n",
      "Penalización por duración del episodio: -  0.4310622801268899\n",
      "Recompensa por acortar distancias: +  0.49114069685196715\n",
      "Penalización por duración del episodio: -  0.43118268888162\n",
      "Recompensa por acortar distancias: +  0.49094358201800964\n",
      "Penalización por duración del episodio: -  0.43145529341766187\n",
      "Recompensa por acortar distancias: +  0.49094358201800964\n",
      "Penalización por duración del episodio: -  0.4318297851614075\n",
      "Recompensa por acortar distancias: +  0.49094358201800964\n",
      "Penalización por duración del episodio: -  0.43221593378501066\n",
      "Recompensa por acortar distancias: +  0.4896784665471389\n",
      "Penalización por duración del episodio: -  0.4325993674667098\n",
      "Recompensa por acortar distancias: +  0.48935475900825914\n",
      "Penalización por duración del episodio: -  0.43271998436547227\n",
      "Recompensa por acortar distancias: +  0.48935475900825914\n",
      "Penalización por duración del episodio: -  0.4329726151010803\n",
      "Recompensa por acortar distancias: +  0.48935475900825914\n",
      "Penalización por duración del episodio: -  0.43306810330191103\n",
      "Recompensa por acortar distancias: +  0.488760249206905\n",
      "Penalización por duración del episodio: -  0.4333495276576632\n",
      "Step: 7930, Mean Reward (últimos 10 pasos): 0.0554107204079628\n",
      "Recompensa por acortar distancias: +  0.4887488764359253\n",
      "Penalización por duración del episodio: -  0.43350038221991555\n",
      "Recompensa por acortar distancias: +  0.48874541516011233\n",
      "Penalización por duración del episodio: -  0.43374114506236483\n",
      "Recompensa por acortar distancias: +  0.4887421266512176\n",
      "Penalización por duración del episodio: -  0.4338619422963462\n",
      "Recompensa por acortar distancias: +  0.48873918963232205\n",
      "Penalización por duración del episodio: -  0.43396985129950905\n",
      "Recompensa por acortar distancias: +  0.48873918963232205\n",
      "Penalización por duración del episodio: -  0.4341114320637821\n",
      "steer input from model: 0.25 , throttle:  0.0\n",
      "reward: 0.054627757568539936\n",
      "Recompensa por acortar distancias: +  0.48873918963232205\n",
      "Penalización por duración del episodio: -  0.43452831839685174\n",
      "Recompensa por acortar distancias: +  0.48873918963232205\n",
      "Penalización por duración del episodio: -  0.43492242763135924\n",
      "Recompensa por acortar distancias: +  0.48849123180627396\n",
      "Penalización por duración del episodio: -  0.4353041651690915\n",
      "Recompensa por acortar distancias: +  0.4883815106899127\n",
      "Penalización por duración del episodio: -  0.4356796134722671\n",
      "Recompensa por acortar distancias: +  0.4878925214200172\n",
      "Penalización por duración del episodio: -  0.43607057868588583\n",
      "Step: 7940, Mean Reward (últimos 10 pasos): 0.05182194337248802\n",
      "Recompensa por acortar distancias: +  0.48775489847552994\n",
      "Penalización por duración del episodio: -  0.436213073020319\n",
      "Recompensa por acortar distancias: +  0.48775101458426995\n",
      "Penalización por duración del episodio: -  0.43645157215662117\n",
      "Recompensa por acortar distancias: +  0.48775101458426995\n",
      "Penalización por duración del episodio: -  0.4368598207907252\n",
      "Recompensa por acortar distancias: +  0.48775101458426995\n",
      "Penalización por duración del episodio: -  0.4372335186574969\n",
      "Recompensa por acortar distancias: +  0.48755881147919694\n",
      "Penalización por duración del episodio: -  0.4376242923112299\n",
      "Recompensa por acortar distancias: +  0.48747308195231637\n",
      "Penalización por duración del episodio: -  0.4377250785384567\n",
      "Recompensa por acortar distancias: +  0.48747308195231637\n",
      "Penalización por duración del episodio: -  0.43800517221508833\n",
      "Recompensa por acortar distancias: +  0.48736857775090414\n",
      "Penalización por duración del episodio: -  0.43814503139611466\n",
      "Recompensa por acortar distancias: +  0.48736857775090414\n",
      "Penalización por duración del episodio: -  0.4383047869037102\n",
      "Recompensa por acortar distancias: +  0.4873680297381587\n",
      "Penalización por duración del episodio: -  0.43838865515673336\n",
      "Step: 7950, Mean Reward (últimos 10 pasos): 0.04897937551140785\n",
      "Recompensa por acortar distancias: +  0.4873680297381587\n",
      "Penalización por duración del episodio: -  0.43854404495231736\n",
      "Recompensa por acortar distancias: +  0.4873676068152999\n",
      "Penalización por duración del episodio: -  0.43866760931279625\n",
      "Recompensa por acortar distancias: +  0.48736708858590594\n",
      "Penalización por duración del episodio: -  0.43915438513761607\n",
      "Recompensa por acortar distancias: +  0.48736708858590594\n",
      "Penalización por duración del episodio: -  0.4395353797253976\n",
      "Recompensa por acortar distancias: +  0.48736708858590594\n",
      "Penalización por duración del episodio: -  0.43993134897659025\n",
      "steer input from model: 0.9 , throttle:  0.7\n",
      "reward: 0.047435739609315686\n",
      "Recompensa por acortar distancias: +  0.48726371130135526\n",
      "Penalización por duración del episodio: -  0.4403092921466464\n",
      "Recompensa por acortar distancias: +  0.4872665942947352\n",
      "Penalización por duración del episodio: -  0.4406838432178274\n",
      "Recompensa por acortar distancias: +  0.48712016432424193\n",
      "Penalización por duración del episodio: -  0.4408026122743161\n",
      "Recompensa por acortar distancias: +  0.48712016432424193\n",
      "Penalización por duración del episodio: -  0.44108431770021955\n",
      "Recompensa por acortar distancias: +  0.4870992093470067\n",
      "Penalización por duración del episodio: -  0.4414654041382374\n",
      "Step: 7960, Mean Reward (últimos 10 pasos): 0.04563380405306816\n",
      "Recompensa por acortar distancias: +  0.4870992093470067\n",
      "Penalización por duración del episodio: -  0.44184775902688583\n",
      "Recompensa por acortar distancias: +  0.4870992093470067\n",
      "Penalización por duración del episodio: -  0.4422344171224116\n",
      "Recompensa por acortar distancias: +  0.48695362771537626\n",
      "Penalización por duración del episodio: -  0.4423466689522421\n",
      "Recompensa por acortar distancias: +  0.48695362771537626\n",
      "Penalización por duración del episodio: -  0.44262529792920186\n",
      "Recompensa por acortar distancias: +  0.48690996139969284\n",
      "Penalización por duración del episodio: -  0.44300374249329005\n",
      "Recompensa por acortar distancias: +  0.48673535174815247\n",
      "Penalización por duración del episodio: -  0.4431054033342101\n",
      "Recompensa por acortar distancias: +  0.48673535174815247\n",
      "Penalización por duración del episodio: -  0.4432419469887591\n",
      "Recompensa por acortar distancias: +  0.48664905175593937\n",
      "Penalización por duración del episodio: -  0.4433941213693191\n",
      "Recompensa por acortar distancias: +  0.48664905175593937\n",
      "Penalización por duración del episodio: -  0.4435475421145208\n",
      "Recompensa por acortar distancias: +  0.4865940998805488\n",
      "Penalización por duración del episodio: -  0.44378427590981495\n",
      "Step: 7970, Mean Reward (últimos 10 pasos): 0.042809825390577316\n",
      "Recompensa por acortar distancias: +  0.48659375442213476\n",
      "Penalización por duración del episodio: -  0.4438856729694948\n",
      "Recompensa por acortar distancias: +  0.48659375442213476\n",
      "Penalización por duración del episodio: -  0.44398947605507977\n",
      "Recompensa por acortar distancias: +  0.48659375442213476\n",
      "Penalización por duración del episodio: -  0.4441571062573289\n",
      "Recompensa por acortar distancias: +  0.48659375442213476\n",
      "Penalización por duración del episodio: -  0.44452697352833803\n",
      "Recompensa por acortar distancias: +  0.48659375442213476\n",
      "Penalización por duración del episodio: -  0.4449021544432161\n",
      "steer input from model: 0.0 , throttle:  0.0\n",
      "reward: 0.041691599978918636\n",
      "Recompensa por acortar distancias: +  0.4865344310640287\n",
      "Penalización por duración del episodio: -  0.4452946061000221\n",
      "Recompensa por acortar distancias: +  0.4865340320025611\n",
      "Penalización por duración del episodio: -  0.4454055126062509\n",
      "Recompensa por acortar distancias: +  0.4865340320025611\n",
      "Penalización por duración del episodio: -  0.44568517635700217\n",
      "Recompensa por acortar distancias: +  0.4865378201091243\n",
      "Penalización por duración del episodio: -  0.44606701825050543\n",
      "Recompensa por acortar distancias: +  0.48648743127117117\n",
      "Penalización por duración del episodio: -  0.4461860159522402\n",
      "Step: 7980, Mean Reward (últimos 10 pasos): 0.04030141606926918\n",
      "Recompensa por acortar distancias: +  0.48648743127117117\n",
      "Penalización por duración del episodio: -  0.4462973311339601\n",
      "Recompensa por acortar distancias: +  0.48648743127117117\n",
      "Penalización por duración del episodio: -  0.44681944827387077\n",
      "Recompensa por acortar distancias: +  0.48648743127117117\n",
      "Penalización por duración del episodio: -  0.4469454447883318\n",
      "Recompensa por acortar distancias: +  0.48648743127117117\n",
      "Penalización por duración del episodio: -  0.44705077909763946\n",
      "Recompensa por acortar distancias: +  0.48648743127117117\n",
      "Penalización por duración del episodio: -  0.4471913992319719\n",
      "Recompensa por acortar distancias: +  0.48648743127117117\n",
      "Penalización por duración del episodio: -  0.44737129026996564\n",
      "Recompensa por acortar distancias: +  0.486394516404424\n",
      "Penalización por duración del episodio: -  0.44759706947693273\n",
      "Recompensa por acortar distancias: +  0.48639265216060945\n",
      "Penalización por duración del episodio: -  0.447687081843272\n",
      "Recompensa por acortar distancias: +  0.48639265216060945\n",
      "Penalización por duración del episodio: -  0.4479897380881767\n",
      "Recompensa por acortar distancias: +  0.48639265216060945\n",
      "Penalización por duración del episodio: -  0.44810281370032673\n",
      "Step: 7990, Mean Reward (últimos 10 pasos): 0.038289837539196014\n",
      "Recompensa por acortar distancias: +  0.48639265216060945\n",
      "Penalización por duración del episodio: -  0.4482547944062157\n",
      "Recompensa por acortar distancias: +  0.4863374218760697\n",
      "Penalización por duración del episodio: -  0.448405033369383\n",
      "Recompensa por acortar distancias: +  0.4863374218760697\n",
      "Penalización por duración del episodio: -  0.4485619339877144\n",
      "Recompensa por acortar distancias: +  0.4863374218760697\n",
      "Penalización por duración del episodio: -  0.44871686319678783\n",
      "Recompensa por acortar distancias: +  0.4862955511935434\n",
      "Penalización por duración del episodio: -  0.44885380130357144\n",
      "steer input from model: -0.05 , throttle:  1.0\n",
      "reward: 0.037441749889971954\n",
      "Recompensa por acortar distancias: +  0.48624802849976156\n",
      "Penalización por duración del episodio: -  0.4491452555388089\n",
      "Recompensa por acortar distancias: +  0.48624802849976156\n",
      "Penalización por duración del episodio: -  0.4495216106116163\n",
      "Recompensa por acortar distancias: +  0.48624802849976156\n",
      "Penalización por duración del episodio: -  0.4499090045532636\n",
      "Recompensa por acortar distancias: +  0.48624664076221663\n",
      "Penalización por duración del episodio: -  0.4500350986020227\n",
      "Recompensa por acortar distancias: +  0.48624664076221663\n",
      "Penalización por duración del episodio: -  0.4502849689333439\n",
      "Step: 8000, Mean Reward (últimos 10 pasos): 0.03596167266368866\n",
      "Recompensa por acortar distancias: +  0.4862461583299008\n",
      "Penalización por duración del episodio: -  0.45068244550861714\n",
      "Recompensa por acortar distancias: +  0.4862461583299008\n",
      "Penalización por duración del episodio: -  0.4510646775509349\n",
      "Recompensa por acortar distancias: +  0.48618310286036376\n",
      "Penalización por duración del episodio: -  0.4511567836238821\n",
      "Recompensa por acortar distancias: +  0.48618310286036376\n",
      "Penalización por duración del episodio: -  0.4512935084539609\n",
      "Recompensa por acortar distancias: +  0.48618310286036376\n",
      "Penalización por duración del episodio: -  0.4514269697018984\n",
      "Recompensa por acortar distancias: +  0.48618310286036376\n",
      "Penalización por duración del episodio: -  0.4515560804039349\n",
      "Recompensa por acortar distancias: +  0.48618310286036376\n",
      "Penalización por duración del episodio: -  0.4518678989508836\n",
      "Recompensa por acortar distancias: +  0.48618310286036376\n",
      "Penalización por duración del episodio: -  0.45223071227353223\n",
      "Recompensa por acortar distancias: +  0.4859595802272691\n",
      "Penalización por duración del episodio: -  0.4523436385907081\n",
      "Recompensa por acortar distancias: +  0.4859083191105095\n",
      "Penalización por duración del episodio: -  0.4524452410323785\n",
      "Step: 8010, Mean Reward (últimos 10 pasos): 0.03346307948231697\n",
      "Recompensa por acortar distancias: +  0.4859083191105095\n",
      "Penalización por duración del episodio: -  0.45261819046845747\n",
      "Recompensa por acortar distancias: +  0.4859083191105095\n",
      "Penalización por duración del episodio: -  0.45301588755247973\n",
      "Recompensa por acortar distancias: +  0.4857722495934413\n",
      "Penalización por duración del episodio: -  0.4534203687570697\n",
      "Recompensa por acortar distancias: +  0.4856819208946242\n",
      "Penalización por duración del episodio: -  0.4536080781773245\n",
      "Recompensa por acortar distancias: +  0.4856819208946242\n",
      "Penalización por duración del episodio: -  0.4537939629144893\n",
      "steer input from model: 0.0 , throttle:  0.0\n",
      "reward: 0.031887957980134884\n",
      "Recompensa por acortar distancias: +  0.4856819208946242\n",
      "Penalización por duración del episodio: -  0.45418093706075274\n",
      "Recompensa por acortar distancias: +  0.4856819208946242\n",
      "Penalización por duración del episodio: -  0.4543064061766681\n",
      "Recompensa por acortar distancias: +  0.4856819208946242\n",
      "Penalización por duración del episodio: -  0.45459875846238595\n",
      "Recompensa por acortar distancias: +  0.4856819208946242\n",
      "Penalización por duración del episodio: -  0.45475064222407746\n",
      "Recompensa por acortar distancias: +  0.4851862524898521\n",
      "Penalización por duración del episodio: -  0.45496329835978344\n",
      "Step: 8020, Mean Reward (últimos 10 pasos): 0.030222954228520393\n",
      "Recompensa por acortar distancias: +  0.4851326615235646\n",
      "Penalización por duración del episodio: -  0.45533386446828417\n",
      "Recompensa por acortar distancias: +  0.4851326615235646\n",
      "Penalización por duración del episodio: -  0.4557199680288979\n",
      "Recompensa por acortar distancias: +  0.48512856435072943\n",
      "Penalización por duración del episodio: -  0.45610572263505716\n",
      "Recompensa por acortar distancias: +  0.485128457157281\n",
      "Penalización por duración del episodio: -  0.456489116453822\n",
      "Recompensa por acortar distancias: +  0.485128457157281\n",
      "Penalización por duración del episodio: -  0.45688523419077287\n",
      "Recompensa por acortar distancias: +  0.48512643239239944\n",
      "Penalización por duración del episodio: -  0.4572807615133794\n",
      "Recompensa por acortar distancias: +  0.485126283512648\n",
      "Penalización por duración del episodio: -  0.45767552013301305\n",
      "Recompensa por acortar distancias: +  0.485126283512648\n",
      "Penalización por duración del episodio: -  0.45781541919690166\n",
      "Recompensa por acortar distancias: +  0.48512487213273564\n",
      "Penalización por duración del episodio: -  0.4580764635277452\n",
      "Recompensa por acortar distancias: +  0.4851279390556324\n",
      "Penalización por duración del episodio: -  0.4581915817641618\n",
      "Step: 8030, Mean Reward (últimos 10 pasos): 0.026936357840895653\n",
      "Recompensa por acortar distancias: +  0.4850889802853929\n",
      "Penalización por duración del episodio: -  0.4584540976115052\n",
      "Recompensa por acortar distancias: +  0.48509403622074254\n",
      "Penalización por duración del episodio: -  0.45861791905467664\n",
      "Recompensa por acortar distancias: +  0.48509403622074254\n",
      "Penalización por duración del episodio: -  0.45876061526667944\n",
      "Recompensa por acortar distancias: +  0.48509403622074254\n",
      "Penalización por duración del episodio: -  0.45891376740872253\n",
      "Recompensa por acortar distancias: +  0.48509403622074254\n",
      "Penalización por duración del episodio: -  0.45921091178059387\n",
      "steer input from model: -0.1 , throttle:  1.0\n",
      "reward: 0.025883124440148675\n",
      "Recompensa por acortar distancias: +  0.48509403622074254\n",
      "Penalización por duración del episodio: -  0.45959592999281995\n",
      "Recompensa por acortar distancias: +  0.48502969088757203\n",
      "Penalización por duración del episodio: -  0.45999811188171147\n",
      "Recompensa por acortar distancias: +  0.4850311498924121\n",
      "Penalización por duración del episodio: -  0.4603781581043131\n",
      "Recompensa por acortar distancias: +  0.4850311498924121\n",
      "Penalización por duración del episodio: -  0.4607609812540461\n",
      "Recompensa por acortar distancias: +  0.4850271123204586\n",
      "Penalización por duración del episodio: -  0.46089147834274163\n",
      "Step: 8040, Mean Reward (últimos 10 pasos): 0.024135634303092957\n",
      "Recompensa por acortar distancias: +  0.48501938257901517\n",
      "Penalización por duración del episodio: -  0.4611549057758697\n",
      "Recompensa por acortar distancias: +  0.48501938257901517\n",
      "Penalización por duración del episodio: -  0.4615497439007147\n",
      "Recompensa por acortar distancias: +  0.48501938257901517\n",
      "Penalización por duración del episodio: -  0.4619484999097919\n",
      "Recompensa por acortar distancias: +  0.48490956504840754\n",
      "Penalización por duración del episodio: -  0.4623501612631578\n",
      "Recompensa por acortar distancias: +  0.48489040772241493\n",
      "Penalización por duración del episodio: -  0.4624586092210302\n",
      "Recompensa por acortar distancias: +  0.48489040772241493\n",
      "Penalización por duración del episodio: -  0.46273668556481484\n",
      "Recompensa por acortar distancias: +  0.48489040772241493\n",
      "Penalización por duración del episodio: -  0.4628751811734714\n",
      "Recompensa por acortar distancias: +  0.48482037696804714\n",
      "Penalización por duración del episodio: -  0.46301266292079213\n",
      "Recompensa por acortar distancias: +  0.48482037696804714\n",
      "Penalización por duración del episodio: -  0.4631431492257131\n",
      "Recompensa por acortar distancias: +  0.4847865944880309\n",
      "Penalización por duración del episodio: -  0.46324233333962733\n",
      "Step: 8050, Mean Reward (últimos 10 pasos): 0.021544260904192924\n",
      "Recompensa por acortar distancias: +  0.4847865944880309\n",
      "Penalización por duración del episodio: -  0.4635121980697692\n",
      "Recompensa por acortar distancias: +  0.48474889380943487\n",
      "Penalización por duración del episodio: -  0.4636495930487881\n",
      "Recompensa por acortar distancias: +  0.48474889380943487\n",
      "Penalización por duración del episodio: -  0.4638952090557552\n",
      "Recompensa por acortar distancias: +  0.48474889380943487\n",
      "Penalización por duración del episodio: -  0.46402808321049954\n",
      "Recompensa por acortar distancias: +  0.48474889380943487\n",
      "Penalización por duración del episodio: -  0.4642802432747509\n",
      "steer input from model: -0.1 , throttle:  0.0\n",
      "reward: 0.02046865053468394\n",
      "Recompensa por acortar distancias: +  0.48474889380943487\n",
      "Penalización por duración del episodio: -  0.4646761851334145\n",
      "Recompensa por acortar distancias: +  0.4847451005269418\n",
      "Penalización por duración del episodio: -  0.4650737314739053\n",
      "Recompensa por acortar distancias: +  0.48474545186700463\n",
      "Penalización por duración del episodio: -  0.46546125553773604\n",
      "Recompensa por acortar distancias: +  0.4847448325557175\n",
      "Penalización por duración del episodio: -  0.46584111478569146\n",
      "Recompensa por acortar distancias: +  0.48473007628718023\n",
      "Penalización por duración del episodio: -  0.46623845154750543\n",
      "Step: 8060, Mean Reward (últimos 10 pasos): 0.018491623923182487\n",
      "Recompensa por acortar distancias: +  0.48473007628718023\n",
      "Penalización por duración del episodio: -  0.46662543492927094\n",
      "Recompensa por acortar distancias: +  0.48473007628718023\n",
      "Penalización por duración del episodio: -  0.4670211169535631\n",
      "Recompensa por acortar distancias: +  0.4847097998599236\n",
      "Penalización por duración del episodio: -  0.4674134099526174\n",
      "Recompensa por acortar distancias: +  0.48469515679735314\n",
      "Penalización por duración del episodio: -  0.46780639024307924\n",
      "Recompensa por acortar distancias: +  0.4846512039480183\n",
      "Penalización por duración del episodio: -  0.4679142859489442\n",
      "Recompensa por acortar distancias: +  0.4846420037135546\n",
      "Penalización por duración del episodio: -  0.4681806278991792\n",
      "Recompensa por acortar distancias: +  0.4846477322725612\n",
      "Penalización por duración del episodio: -  0.4682600567366401\n",
      "Recompensa por acortar distancias: +  0.48462385933344676\n",
      "Penalización por duración del episodio: -  0.46840815603697306\n",
      "Recompensa por acortar distancias: +  0.48462385933344676\n",
      "Penalización por duración del episodio: -  0.4685650890710505\n",
      "Recompensa por acortar distancias: +  0.48462385933344676\n",
      "Penalización por duración del episodio: -  0.4689627747253366\n",
      "Step: 8070, Mean Reward (últimos 10 pasos): 0.01566108502447605\n",
      "Recompensa por acortar distancias: +  0.48462385933344676\n",
      "Penalización por duración del episodio: -  0.4691171348096018\n",
      "Recompensa por acortar distancias: +  0.48462385933344676\n",
      "Penalización por duración del episodio: -  0.46935590966970914\n",
      "Recompensa por acortar distancias: +  0.48462385933344676\n",
      "Penalización por duración del episodio: -  0.4694699638850427\n",
      "Recompensa por acortar distancias: +  0.4846090854194897\n",
      "Penalización por duración del episodio: -  0.46976046705103863\n",
      "Recompensa por acortar distancias: +  0.4845762565808634\n",
      "Penalización por duración del episodio: -  0.4701609482823839\n",
      "steer input from model: -0.25 , throttle:  0.0\n",
      "reward: 0.014415308298479479\n",
      "Recompensa por acortar distancias: +  0.4845762565808634\n",
      "Penalización por duración del episodio: -  0.47053883141352937\n",
      "Recompensa por acortar distancias: +  0.48455639737159567\n",
      "Penalización por duración del episodio: -  0.4706489205548538\n",
      "Recompensa por acortar distancias: +  0.48455639737159567\n",
      "Penalización por duración del episodio: -  0.4707858914934309\n",
      "Recompensa por acortar distancias: +  0.48457477979241\n",
      "Penalización por duración del episodio: -  0.4709090556411191\n",
      "Recompensa por acortar distancias: +  0.48457477979241\n",
      "Penalización por duración del episodio: -  0.4710209899398163\n",
      "Step: 8080, Mean Reward (últimos 10 pasos): 0.01355378981679678\n",
      "Recompensa por acortar distancias: +  0.4845440293069878\n",
      "Penalización por duración del episodio: -  0.47132335717764745\n",
      "Recompensa por acortar distancias: +  0.4845440293069878\n",
      "Penalización por duración del episodio: -  0.47171468122235144\n",
      "Recompensa por acortar distancias: +  0.4845440293069878\n",
      "Penalización por duración del episodio: -  0.4720954812647682\n",
      "Recompensa por acortar distancias: +  0.4844206355292048\n",
      "Penalización por duración del episodio: -  0.4722663438533626\n",
      "Recompensa por acortar distancias: +  0.4844206355292048\n",
      "Penalización por duración del episodio: -  0.472384243127367\n",
      "Recompensa por acortar distancias: +  0.48433706801928406\n",
      "Penalización por duración del episodio: -  0.47246920667386294\n",
      "Recompensa por acortar distancias: +  0.48433706801928406\n",
      "Penalización por duración del episodio: -  0.47258641596191553\n",
      "Recompensa por acortar distancias: +  0.48433706801928406\n",
      "Penalización por duración del episodio: -  0.4728730043027339\n",
      "Recompensa por acortar distancias: +  0.48433706801928406\n",
      "Penalización por duración del episodio: -  0.47327780026130106\n",
      "Recompensa por acortar distancias: +  0.4840091541389951\n",
      "Penalización por duración del episodio: -  0.47367440493105567\n",
      "Step: 8090, Mean Reward (últimos 10 pasos): 0.010334748774766922\n",
      "Recompensa por acortar distancias: +  0.4839113006705553\n",
      "Penalización por duración del episodio: -  0.4737782645529706\n",
      "Recompensa por acortar distancias: +  0.4839113006705553\n",
      "Penalización por duración del episodio: -  0.47387932078196243\n",
      "Recompensa por acortar distancias: +  0.4839113006705553\n",
      "Penalización por duración del episodio: -  0.47407185721052336\n",
      "Recompensa por acortar distancias: +  0.4839113006705553\n",
      "Penalización por duración del episodio: -  0.4742450217525538\n",
      "Recompensa por acortar distancias: +  0.4839113006705553\n",
      "Penalización por duración del episodio: -  0.47445983642341905\n",
      "steer input from model: -0.05 , throttle:  0.0\n",
      "reward: 0.009451464247136276\n",
      "Recompensa por acortar distancias: +  0.4839113006705553\n",
      "Penalización por duración del episodio: -  0.4745815481305994\n",
      "Recompensa por acortar distancias: +  0.4839113006705553\n",
      "Penalización por duración del episodio: -  0.47469727009250345\n",
      "Recompensa por acortar distancias: +  0.4830671834290397\n",
      "Penalización por duración del episodio: -  0.47482757871158465\n",
      "Recompensa por acortar distancias: +  0.48295394628577254\n",
      "Penalización por duración del episodio: -  0.47523492367347475\n",
      "Recompensa por acortar distancias: +  0.48295394628577254\n",
      "Penalización por duración del episodio: -  0.47563069439116684\n",
      "Step: 8100, Mean Reward (últimos 10 pasos): 0.007323252037167549\n",
      "Recompensa por acortar distancias: +  0.48293985427773195\n",
      "Penalización por duración del episodio: -  0.47602014458271913\n",
      "Recompensa por acortar distancias: +  0.482938342082452\n",
      "Penalización por duración del episodio: -  0.4761195931095893\n",
      "Recompensa por acortar distancias: +  0.482938342082452\n",
      "Penalización por duración del episodio: -  0.4762428909786428\n",
      "Recompensa por acortar distancias: +  0.482938342082452\n",
      "Penalización por duración del episodio: -  0.47636199305919114\n",
      "Recompensa por acortar distancias: +  0.482938342082452\n",
      "Penalización por duración del episodio: -  0.47680888016730866\n",
      "Recompensa por acortar distancias: +  0.482938342082452\n",
      "Penalización por duración del episodio: -  0.4769159506765326\n",
      "Recompensa por acortar distancias: +  0.482938342082452\n",
      "Penalización por duración del episodio: -  0.47706216048152633\n",
      "Recompensa por acortar distancias: +  0.48261073298473156\n",
      "Penalización por duración del episodio: -  0.4775669480379266\n",
      "Recompensa por acortar distancias: +  0.4824745714304707\n",
      "Penalización por duración del episodio: -  0.47796870997782853\n",
      "Recompensa por acortar distancias: +  0.48237377355014677\n",
      "Penalización por duración del episodio: -  0.4783553594489942\n",
      "Step: 8110, Mean Reward (últimos 10 pasos): 0.0040184142999351025\n",
      "Recompensa por acortar distancias: +  0.48237212455349515\n",
      "Penalización por duración del episodio: -  0.47845877696662964\n",
      "Recompensa por acortar distancias: +  0.48237212455349515\n",
      "Penalización por duración del episodio: -  0.47873869708179456\n",
      "Recompensa por acortar distancias: +  0.48237212455349515\n",
      "Penalización por duración del episodio: -  0.4791087792097666\n",
      "Recompensa por acortar distancias: +  0.48237212455349515\n",
      "Penalización por duración del episodio: -  0.47926297102045157\n",
      "Recompensa por acortar distancias: +  0.48237212455349515\n",
      "Penalización por duración del episodio: -  0.4794892915703929\n",
      "steer input from model: -0.9 , throttle:  0.3\n",
      "reward: 0.002882832983102268\n",
      "Recompensa por acortar distancias: +  0.48216251461955856\n",
      "Penalización por duración del episodio: -  0.4795988162512307\n",
      "Recompensa por acortar distancias: +  0.48216251461955856\n",
      "Penalización por duración del episodio: -  0.4798996948835729\n",
      "Recompensa por acortar distancias: +  0.482077091334182\n",
      "Penalización por duración del episodio: -  0.4803111846439462\n",
      "Recompensa por acortar distancias: +  0.48202797490733756\n",
      "Penalización por duración del episodio: -  0.4806885687559504\n",
      "Recompensa por acortar distancias: +  0.48202789752140973\n",
      "Penalización por duración del episodio: -  0.4810772359416202\n",
      "Step: 8120, Mean Reward (últimos 10 pasos): 0.0009506616042926908\n",
      "Recompensa por acortar distancias: +  0.4820184504919356\n",
      "Penalización por duración del episodio: -  0.48118546667566137\n",
      "Recompensa por acortar distancias: +  0.4820184504919356\n",
      "Penalización por duración del episodio: -  0.4814727235304787\n",
      "Recompensa por acortar distancias: +  0.4820184504919356\n",
      "Penalización por duración del episodio: -  0.4818710201650777\n",
      "Recompensa por acortar distancias: +  0.48180283909489613\n",
      "Penalización por duración del episodio: -  0.48225320135827926\n",
      "Recompensa por acortar distancias: +  0.4817076581690182\n",
      "Penalización por duración del episodio: -  0.48264883391787594\n",
      "Recompensa por acortar distancias: +  0.4817076581690182\n",
      "Penalización por duración del episodio: -  0.48302928272727413\n",
      "Recompensa por acortar distancias: +  0.48169964017406486\n",
      "Penalización por duración del episodio: -  0.48313100064910264\n",
      "Recompensa por acortar distancias: +  0.4816996163641458\n",
      "Penalización por duración del episodio: -  0.48326816874933715\n",
      "Recompensa por acortar distancias: +  0.4816996163641458\n",
      "Penalización por duración del episodio: -  0.483381029641251\n",
      "Recompensa por acortar distancias: +  0.48169971160382236\n",
      "Penalización por duración del episodio: -  0.4834996497184953\n",
      "Step: 8130, Mean Reward (últimos 10 pasos): -0.0017999381525442004\n",
      "Recompensa por acortar distancias: +  0.48169971160382236\n",
      "Penalización por duración del episodio: -  0.4836316444996986\n",
      "Recompensa por acortar distancias: +  0.48169971160382236\n",
      "Penalización por duración del episodio: -  0.48375408511298407\n",
      "Recompensa por acortar distancias: +  0.48169971160382236\n",
      "Penalización por duración del episodio: -  0.4841989340510358\n",
      "Recompensa por acortar distancias: +  0.48169971160382236\n",
      "Penalización por duración del episodio: -  0.48432917815776294\n",
      "Recompensa por acortar distancias: +  0.48169971160382236\n",
      "Penalización por duración del episodio: -  0.484484833165815\n",
      "steer input from model: -0.9 , throttle:  0.3\n",
      "reward: -0.0027851215619926206\n",
      "Recompensa por acortar distancias: +  0.48169971160382236\n",
      "Penalización por duración del episodio: -  0.4846394788613858\n",
      "Recompensa por acortar distancias: +  0.4816205857490791\n",
      "Penalización por duración del episodio: -  0.48498029925809133\n",
      "Recompensa por acortar distancias: +  0.48163164533703146\n",
      "Penalización por duración del episodio: -  0.4853753689636146\n",
      "Recompensa por acortar distancias: +  0.48163164533703146\n",
      "Penalización por duración del episodio: -  0.48578880628323584\n",
      "Recompensa por acortar distancias: +  0.48154216914477654\n",
      "Penalización por duración del episodio: -  0.48587040501405115\n",
      "Step: 8140, Mean Reward (últimos 10 pasos): -0.004328235983848572\n",
      "Recompensa por acortar distancias: +  0.48154635364232734\n",
      "Penalización por duración del episodio: -  0.4861761701803971\n",
      "Recompensa por acortar distancias: +  0.48154635364232734\n",
      "Penalización por duración del episodio: -  0.486572943554418\n",
      "Recompensa por acortar distancias: +  0.48154635364232734\n",
      "Penalización por duración del episodio: -  0.48672792428303885\n",
      "Recompensa por acortar distancias: +  0.48154635364232734\n",
      "Penalización por duración del episodio: -  0.4868560265386981\n",
      "Recompensa por acortar distancias: +  0.48154635364232734\n",
      "Penalización por duración del episodio: -  0.4869765956460121\n",
      "Recompensa por acortar distancias: +  0.48154635364232734\n",
      "Penalización por duración del episodio: -  0.48710127625150157\n",
      "Recompensa por acortar distancias: +  0.4814964731716021\n",
      "Penalización por duración del episodio: -  0.4873493198864559\n",
      "Recompensa por acortar distancias: +  0.4814958541322754\n",
      "Penalización por duración del episodio: -  0.4874675719849476\n",
      "Recompensa por acortar distancias: +  0.4814958541322754\n",
      "Penalización por duración del episodio: -  0.4875547787439011\n",
      "Recompensa por acortar distancias: +  0.4814958541322754\n",
      "Penalización por duración del episodio: -  0.4876791152084773\n",
      "Step: 8150, Mean Reward (últimos 10 pasos): -0.006183261051774025\n",
      "Recompensa por acortar distancias: +  0.4814958541322754\n",
      "Penalización por duración del episodio: -  0.48812961151122075\n",
      "Recompensa por acortar distancias: +  0.4814981398162252\n",
      "Penalización por duración del episodio: -  0.48851586529691926\n",
      "Recompensa por acortar distancias: +  0.4814741818393644\n",
      "Penalización por duración del episodio: -  0.48890981205334255\n",
      "Recompensa por acortar distancias: +  0.4814741818393644\n",
      "Penalización por duración del episodio: -  0.4890034112281064\n",
      "Recompensa por acortar distancias: +  0.4814741818393644\n",
      "Penalización por duración del episodio: -  0.48929556878545405\n",
      "steer input from model: -0.05 , throttle:  1.0\n",
      "reward: -0.007821386946089637\n",
      "Recompensa por acortar distancias: +  0.4814741818393644\n",
      "Penalización por duración del episodio: -  0.4894524726796474\n",
      "Recompensa por acortar distancias: +  0.4813515183348107\n",
      "Penalización por duración del episodio: -  0.48958050674999365\n",
      "Recompensa por acortar distancias: +  0.4813515183348107\n",
      "Penalización por duración del episodio: -  0.48972347875035893\n",
      "Recompensa por acortar distancias: +  0.4813211266080301\n",
      "Penalización por duración del episodio: -  0.48986661329839054\n",
      "Recompensa por acortar distancias: +  0.4813211266080301\n",
      "Penalización por duración del episodio: -  0.4899957182258303\n",
      "Step: 8160, Mean Reward (últimos 10 pasos): -0.008674591779708862\n",
      "Recompensa por acortar distancias: +  0.4813211266080301\n",
      "Penalización por duración del episodio: -  0.49049815502701954\n",
      "Recompensa por acortar distancias: +  0.48131843623855897\n",
      "Penalización por duración del episodio: -  0.4906089264685284\n",
      "Recompensa por acortar distancias: +  0.4813177576942175\n",
      "Penalización por duración del episodio: -  0.490894346946152\n",
      "Recompensa por acortar distancias: +  0.4813182576742519\n",
      "Penalización por duración del episodio: -  0.4912774651012508\n",
      "Recompensa por acortar distancias: +  0.4813182576742519\n",
      "Penalización por duración del episodio: -  0.4916595149581417\n",
      "Recompensa por acortar distancias: +  0.4813182576742519\n",
      "Penalización por duración del episodio: -  0.49177101058926675\n",
      "Recompensa por acortar distancias: +  0.4811875201245274\n",
      "Penalización por duración del episodio: -  0.49205728832780354\n",
      "Recompensa por acortar distancias: +  0.4811938411798084\n",
      "Penalización por duración del episodio: -  0.4921382410120357\n",
      "Recompensa por acortar distancias: +  0.4811938411798084\n",
      "Penalización por duración del episodio: -  0.4924706071539565\n",
      "Recompensa por acortar distancias: +  0.4811938411798084\n",
      "Penalización por duración del episodio: -  0.4925514427157805\n",
      "Step: 8170, Mean Reward (últimos 10 pasos): -0.01135760173201561\n",
      "Recompensa por acortar distancias: +  0.4811938411798084\n",
      "Penalización por duración del episodio: -  0.49268585765131145\n",
      "Recompensa por acortar distancias: +  0.48120562026215874\n",
      "Penalización por duración del episodio: -  0.49285197680576465\n",
      "Recompensa por acortar distancias: +  0.48120562026215874\n",
      "Penalización por duración del episodio: -  0.4930002613558174\n",
      "Recompensa por acortar distancias: +  0.4811959065353342\n",
      "Penalización por duración del episodio: -  0.4931325165056583\n",
      "Recompensa por acortar distancias: +  0.4811921210426997\n",
      "Penalización por duración del episodio: -  0.49325107795974227\n",
      "steer input from model: -0.05 , throttle:  0.7\n",
      "reward: -0.012058956917042563\n",
      "Recompensa por acortar distancias: +  0.4811921210426997\n",
      "Penalización por duración del episodio: -  0.4933474771165562\n",
      "Recompensa por acortar distancias: +  0.481183573932052\n",
      "Penalización por duración del episodio: -  0.493645533343886\n",
      "Recompensa por acortar distancias: +  0.481183573932052\n",
      "Penalización por duración del episodio: -  0.49404713030270564\n",
      "Recompensa por acortar distancias: +  0.481183573932052\n",
      "Penalización por duración del episodio: -  0.49444546305200016\n",
      "Recompensa por acortar distancias: +  0.4810543210609495\n",
      "Penalización por duración del episodio: -  0.4948505911009652\n",
      "Step: 8180, Mean Reward (últimos 10 pasos): -0.01379626989364624\n",
      "Recompensa por acortar distancias: +  0.4810101283019538\n",
      "Penalización por duración del episodio: -  0.4952405579001021\n",
      "Recompensa por acortar distancias: +  0.4810101283019538\n",
      "Penalización por duración del episodio: -  0.49563220525281004\n",
      "Recompensa por acortar distancias: +  0.4806554423850138\n",
      "Penalización por duración del episodio: -  0.4957558935974745\n",
      "Recompensa por acortar distancias: +  0.4805826256730796\n",
      "Penalización por duración del episodio: -  0.4958740515267249\n",
      "Recompensa por acortar distancias: +  0.4805826256730796\n",
      "Penalización por duración del episodio: -  0.4960137496588774\n",
      "Recompensa por acortar distancias: +  0.4805251406306895\n",
      "Penalización por duración del episodio: -  0.4963966457027031\n",
      "Recompensa por acortar distancias: +  0.4805251406306895\n",
      "Penalización por duración del episodio: -  0.4967988988031622\n",
      "Recompensa por acortar distancias: +  0.4805251406306895\n",
      "Penalización por duración del episodio: -  0.4969198318552992\n",
      "Recompensa por acortar distancias: +  0.4805251406306895\n",
      "Penalización por duración del episodio: -  0.4970229143058059\n",
      "Recompensa por acortar distancias: +  0.4805251406306895\n",
      "Penalización por duración del episodio: -  0.49758572666598816\n",
      "Step: 8190, Mean Reward (últimos 10 pasos): -0.01706058531999588\n",
      "Recompensa por acortar distancias: +  0.4798675069176521\n",
      "Penalización por duración del episodio: -  0.4979694954915549\n",
      "Recompensa por acortar distancias: +  0.47974067879697946\n",
      "Penalización por duración del episodio: -  0.49805512813116753\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 802          |\n",
      "|    ep_rew_mean          | 255          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 58           |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 140          |\n",
      "|    total_timesteps      | 8192         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012971616 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.5          |\n",
      "|    entropy_loss         | -3.98        |\n",
      "|    explained_variance   | 0.293        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 12           |\n",
      "|    n_updates            | 80           |\n",
      "|    policy_gradient_loss | -0.00258     |\n",
      "|    value_loss           | 24.2         |\n",
      "------------------------------------------\n",
      "Penalización por duración del episodio\n",
      "Recompensa por acortar distancias: +  0.915697018092366\n",
      "Penalización por parar muy lejos: -  0.16593271616703767\n",
      "Penalización por duración del episodio: -  0.2692304299116448\n",
      "Recompensa por acortar distancias: +  0.915697018092366\n",
      "Penalización por parar muy lejos: -  0.16593271616703767\n",
      "Penalización por duración del episodio: -  0.2695399363711356\n",
      "Recompensa por acortar distancias: +  0.9156964291318408\n",
      "Penalización por parar muy lejos: -  0.16593166026877465\n",
      "Penalización por duración del episodio: -  0.26983830395256936\n",
      "Recompensa por acortar distancias: +  0.9156963849596507\n",
      "Penalización por duración del episodio: -  0.2701536004955736\n",
      "Recompensa por acortar distancias: +  0.9156963849596507\n",
      "Penalización por parar muy lejos: -  0.1659315810766219\n",
      "Penalización por duración del episodio: -  0.27047267609225684\n",
      "Recompensa por acortar distancias: +  0.9156962082706805\n",
      "Penalización por parar muy lejos: -  0.16593126430831365\n",
      "Penalización por duración del episodio: -  0.27079198872210475\n",
      "Recompensa por acortar distancias: +  0.9156961935465845\n",
      "Penalización por parar muy lejos: -  0.1659312379109765\n",
      "Penalización por duración del episodio: -  0.2711022616013704\n",
      "Step: 8200, Mean Reward (últimos 10 pasos): 0.4786626994609833\n",
      "Recompensa por acortar distancias: +  0.9156961935465845\n",
      "Penalización por duración del episodio: -  0.27141947142076206\n",
      "Recompensa por acortar distancias: +  0.9156961935465845\n",
      "Penalización por duración del episodio: -  0.2715282307945096\n",
      "Recompensa por acortar distancias: +  0.9156962377188657\n",
      "Penalización por parar muy lejos: -  0.16593131710299808\n",
      "Penalización por duración del episodio: -  0.2717281712789549\n",
      "Recompensa por acortar distancias: +  0.9156962892531669\n",
      "Penalización por parar muy lejos: -  0.16593140949372814\n",
      "Penalización por duración del episodio: -  0.2720300656497576\n",
      "Recompensa por acortar distancias: +  0.9156962892531669\n",
      "Penalización por duración del episodio: -  0.27233864286304177\n",
      "Recompensa por acortar distancias: +  0.9156962892531669\n",
      "Penalización por parar muy lejos: -  0.16593140949372814\n",
      "Penalización por duración del episodio: -  0.27246495843270124\n",
      "Recompensa por acortar distancias: +  0.9156962892531669\n",
      "Penalización por duración del episodio: -  0.27259987693761506\n",
      "Recompensa por acortar distancias: +  0.9156962892531669\n",
      "Penalización por duración del episodio: -  0.2727307229560283\n",
      "Recompensa por acortar distancias: +  0.9156962818911256\n",
      "Penalización por duración del episodio: -  0.2728145761973126\n",
      "Recompensa por acortar distancias: +  0.9156962818911256\n",
      "Penalización por parar muy lejos: -  0.16593139629504988\n",
      "Penalización por duración del episodio: -  0.2732563032919153\n",
      "Step: 8210, Mean Reward (últimos 10 pasos): 0.47650858759880066\n",
      "Recompensa por acortar distancias: +  0.9156965101141344\n",
      "Penalización por parar muy lejos: -  0.16593180545446665\n",
      "Penalización por duración del episodio: -  0.27356739760531734\n",
      "Recompensa por acortar distancias: +  0.9156965174761578\n",
      "Penalización por parar muy lejos: -  0.16593181865317094\n",
      "Penalización por duración del episodio: -  0.2736698367520627\n",
      "Recompensa por acortar distancias: +  0.9156966426304628\n",
      "Penalización por parar muy lejos: -  0.1659320430312731\n",
      "Penalización por duración del episodio: -  0.27374532853446043\n",
      "steer input from model: 0.05 , throttle:  0.0\n",
      "reward: 0.4760192710647293\n",
      "Recompensa por acortar distancias: +  0.9156966426304628\n",
      "Penalización por parar muy lejos: -  0.1659320430312731\n",
      "Penalización por duración del episodio: -  0.2738826527478991\n",
      "Recompensa por acortar distancias: +  0.9156966426304628\n",
      "Penalización por duración del episodio: -  0.27419311877699293\n",
      "Recompensa por acortar distancias: +  0.9156966426304628\n",
      "Penalización por duración del episodio: -  0.2745123884172818\n",
      "Recompensa por acortar distancias: +  0.9156969150245438\n",
      "Penalización por parar muy lejos: -  0.1659325313844531\n",
      "Penalización por duración del episodio: -  0.27481492117152756\n",
      "Recompensa por acortar distancias: +  0.9156969886444285\n",
      "Penalización por duración del episodio: -  0.27513061773809555\n",
      "Recompensa por acortar distancias: +  0.9156969886444285\n",
      "Penalización por parar muy lejos: -  0.1659326633719967\n",
      "Penalización por duración del episodio: -  0.2754353812442055\n",
      "Recompensa por acortar distancias: +  0.9156970917121691\n",
      "Penalización por parar muy lejos: -  0.16593284815469897\n",
      "Penalización por duración del episodio: -  0.27553062080248836\n",
      "Step: 8220, Mean Reward (últimos 10 pasos): 0.47423362731933594\n",
      "Recompensa por acortar distancias: +  0.9156971358840228\n",
      "Penalización por duración del episodio: -  0.2756202304721286\n",
      "Recompensa por acortar distancias: +  0.9156972021417641\n",
      "Penalización por duración del episodio: -  0.2760445350462999\n",
      "Recompensa por acortar distancias: +  0.9156972021417641\n",
      "Penalización por duración del episodio: -  0.2763628604806725\n",
      "Recompensa por acortar distancias: +  0.9156972021417641\n",
      "Penalización por duración del episodio: -  0.2764492658578948\n",
      "Recompensa por acortar distancias: +  0.9156972021417641\n",
      "Penalización por duración del episodio: -  0.27657001814334026\n",
      "Recompensa por acortar distancias: +  0.9156972757614211\n",
      "Penalización por duración del episodio: -  0.2766566305182341\n",
      "Recompensa por acortar distancias: +  0.9156972757614211\n",
      "Penalización por parar muy lejos: -  0.16593317812422026\n",
      "Penalización por duración del episodio: -  0.27675250806842566\n",
      "Recompensa por acortar distancias: +  0.9156974303625111\n",
      "Penalización por duración del episodio: -  0.27699231792643086\n",
      "Recompensa por acortar distancias: +  0.9156974303625111\n",
      "Penalización por parar muy lejos: -  0.1659334552990243\n",
      "Penalización por duración del episodio: -  0.27707322859613204\n",
      "Recompensa por acortar distancias: +  0.9156974303625111\n",
      "Penalización por parar muy lejos: -  0.1659334552990243\n",
      "Penalización por duración del episodio: -  0.2771641511060196\n",
      "Step: 8230, Mean Reward (últimos 10 pasos): 0.4725998342037201\n",
      "Recompensa por acortar distancias: +  0.9156974303625111\n",
      "Penalización por duración del episodio: -  0.2772874801441887\n",
      "Recompensa por acortar distancias: +  0.9156973935527511\n",
      "Penalización por parar muy lejos: -  0.16593338930498974\n",
      "Penalización por duración del episodio: -  0.27741750047002467\n",
      "Recompensa por acortar distancias: +  0.9156973935527511\n",
      "Penalización por parar muy lejos: -  0.16593338930498974\n",
      "Penalización por duración del episodio: -  0.2775062172013362\n",
      "steer input from model: 0.05 , throttle:  0.0\n",
      "reward: 0.4722577870464251\n",
      "Recompensa por acortar distancias: +  0.9156975555155857\n",
      "Penalización por duración del episodio: -  0.277643248394104\n",
      "Recompensa por acortar distancias: +  0.9156975555155857\n",
      "Penalización por duración del episodio: -  0.277753134825556\n",
      "Recompensa por acortar distancias: +  0.9156975187058752\n",
      "Penalización por parar muy lejos: -  0.16593361368479315\n",
      "Penalización por duración del episodio: -  0.2778574651344364\n",
      "Recompensa por acortar distancias: +  0.9156975187058752\n",
      "Penalización por duración del episodio: -  0.2782234932800783\n",
      "Recompensa por acortar distancias: +  0.9156975187058752\n",
      "Penalización por parar muy lejos: -  0.16593361368479315\n",
      "Penalización por duración del episodio: -  0.278336011146359\n",
      "Recompensa por acortar distancias: +  0.9156975187058752\n",
      "Penalización por parar muy lejos: -  0.16593361368479315\n",
      "Penalización por duración del episodio: -  0.2784393359479177\n",
      "Recompensa por acortar distancias: +  0.9156975187058752\n",
      "Penalización por duración del episodio: -  0.27884797550717744\n",
      "Step: 8240, Mean Reward (últimos 10 pasos): 0.6368495225906372\n",
      "Recompensa por acortar distancias: +  0.91569745244836\n",
      "Penalización por duración del episodio: -  0.2791560289904621\n",
      "Recompensa por acortar distancias: +  0.91569745244836\n",
      "Penalización por duración del episodio: -  0.2794634891617592\n",
      "Recompensa por acortar distancias: +  0.9156974745342036\n",
      "Penalización por duración del episodio: -  0.2796795127822478\n",
      "Recompensa por acortar distancias: +  0.9156976364968971\n",
      "Penalización por duración del episodio: -  0.27978736591452585\n",
      "Recompensa por acortar distancias: +  0.9156976364968971\n",
      "Penalización por duración del episodio: -  0.2798983776212388\n",
      "Recompensa por acortar distancias: +  0.9156976364968971\n",
      "Penalización por parar muy lejos: -  0.1659338248660067\n",
      "Penalización por duración del episodio: -  0.2801204721770417\n",
      "Recompensa por acortar distancias: +  0.9156976364968971\n",
      "Penalización por duración del episodio: -  0.2804431252548072\n",
      "Recompensa por acortar distancias: +  0.9156976364968971\n",
      "Penalización por parar muy lejos: -  0.1659338248660067\n",
      "Penalización por duración del episodio: -  0.28075016546340564\n",
      "Recompensa por acortar distancias: +  0.9156975407917033\n",
      "Penalización por duración del episodio: -  0.28086086605320476\n",
      "Recompensa por acortar distancias: +  0.9156974671722563\n",
      "Penalización por duración del episodio: -  0.2809533865180617\n",
      "Step: 8250, Mean Reward (últimos 10 pasos): 0.6347441077232361\n",
      "Recompensa por acortar distancias: +  0.9156974671722563\n",
      "Penalización por duración del episodio: -  0.28103804906225316\n",
      "Recompensa por acortar distancias: +  0.9156974671722563\n",
      "Penalización por parar muy lejos: -  0.16593352129307995\n",
      "Penalización por duración del episodio: -  0.2813762664340446\n",
      "Recompensa por acortar distancias: +  0.9156974745342036\n",
      "Penalización por parar muy lejos: -  0.16593353449189358\n",
      "Penalización por duración del episodio: -  0.2816923899193598\n",
      "steer input from model: 0.0 , throttle:  0.0\n",
      "reward: 0.46807155012295015\n",
      "Recompensa por acortar distancias: +  0.915697658582697\n",
      "Penalización por duración del episodio: -  0.281780633012222\n",
      "Recompensa por acortar distancias: +  0.915697658582697\n",
      "Penalización por parar muy lejos: -  0.16593386446250816\n",
      "Penalización por duración del episodio: -  0.28189743498361625\n",
      "Recompensa por acortar distancias: +  0.915697658582697\n",
      "Penalización por parar muy lejos: -  0.16593386446250816\n",
      "Penalización por duración del episodio: -  0.28232175762400885\n",
      "Recompensa por acortar distancias: +  0.915697658582697\n",
      "Penalización por duración del episodio: -  0.28241268114750756\n",
      "Recompensa por acortar distancias: +  0.915697658582697\n",
      "Penalización por parar muy lejos: -  0.16593386446250816\n",
      "Penalización por duración del episodio: -  0.28252405524781626\n",
      "Recompensa por acortar distancias: +  0.915697658582697\n",
      "Penalización por duración del episodio: -  0.2826233179547135\n",
      "Recompensa por acortar distancias: +  0.915697658582697\n",
      "Penalización por parar muy lejos: -  0.16593386446250816\n",
      "Penalización por duración del episodio: -  0.2827256671327883\n",
      "Step: 8260, Mean Reward (últimos 10 pasos): 0.4670381247997284\n",
      "Recompensa por acortar distancias: +  0.9156975481536447\n",
      "Penalización por duración del episodio: -  0.2829518856713281\n",
      "Recompensa por acortar distancias: +  0.9156974818961505\n",
      "Penalización por parar muy lejos: -  0.16593354769070812\n",
      "Penalización por duración del episodio: -  0.2830454479768422\n",
      "Recompensa por acortar distancias: +  0.9156974818961505\n",
      "Penalización por parar muy lejos: -  0.16593354769070812\n",
      "Penalización por duración del episodio: -  0.2832648799846642\n",
      "Recompensa por acortar distancias: +  0.9156974818961505\n",
      "Penalización por parar muy lejos: -  0.16593354769070812\n",
      "Penalización por duración del episodio: -  0.283354263768641\n",
      "Recompensa por acortar distancias: +  0.9156974818961505\n",
      "Penalización por parar muy lejos: -  0.16593354769070812\n",
      "Penalización por duración del episodio: -  0.28343781022520925\n",
      "Recompensa por acortar distancias: +  0.9156974818961505\n",
      "Penalización por parar muy lejos: -  0.16593354769070812\n",
      "Penalización por duración del episodio: -  0.28352755633035515\n",
      "Recompensa por acortar distancias: +  0.9156973199331874\n",
      "Penalización por duración del episodio: -  0.28390584363354415\n",
      "Recompensa por acortar distancias: +  0.9156974818961505\n",
      "Penalización por parar muy lejos: -  0.16593354769070812\n",
      "Penalización por duración del episodio: -  0.28399723057959403\n",
      "Recompensa por acortar distancias: +  0.9156974818961505\n",
      "Penalización por duración del episodio: -  0.28407992167913404\n",
      "Recompensa por acortar distancias: +  0.9156974818961505\n",
      "Penalización por duración del episodio: -  0.28419210999329886\n",
      "Step: 8270, Mean Reward (últimos 10 pasos): 0.6315053701400757\n",
      "Recompensa por acortar distancias: +  0.9156974818961505\n",
      "Penalización por parar muy lejos: -  0.16593354769070812\n",
      "Penalización por duración del episodio: -  0.28429361362188293\n",
      "Recompensa por acortar distancias: +  0.9156974818961505\n",
      "Penalización por duración del episodio: -  0.2843904761928983\n",
      "Recompensa por acortar distancias: +  0.9156974818961505\n",
      "Penalización por duración del episodio: -  0.28447973446954705\n",
      "steer input from model: -0.25 , throttle:  1.0\n",
      "reward: 0.6312177474266034\n",
      "Recompensa por acortar distancias: +  0.9156974818961505\n",
      "Penalización por parar muy lejos: -  0.16593354769070812\n",
      "Penalización por duración del episodio: -  0.2846021341474512\n",
      "Recompensa por acortar distancias: +  0.9156974818961505\n",
      "Penalización por duración del episodio: -  0.2848782200493616\n",
      "Recompensa por acortar distancias: +  0.9156972610374945\n",
      "Penalización por duración del episodio: -  0.28495948187740533\n",
      "Recompensa por acortar distancias: +  0.9156974303625111\n",
      "Penalización por parar muy lejos: -  0.1659334552990243\n",
      "Penalización por duración del episodio: -  0.2850922539247765\n",
      "Recompensa por acortar distancias: +  0.9156974303625111\n",
      "Penalización por parar muy lejos: -  0.1659334552990243\n",
      "Penalización por duración del episodio: -  0.28520419185418716\n",
      "Recompensa por acortar distancias: +  0.9156974303625111\n",
      "Penalización por duración del episodio: -  0.2855200911606168\n",
      "Recompensa por acortar distancias: +  0.9156974303625111\n",
      "Penalización por parar muy lejos: -  0.1659334552990243\n",
      "Penalización por duración del episodio: -  0.28563968512406307\n",
      "Step: 8280, Mean Reward (últimos 10 pasos): 0.46412429213523865\n",
      "Recompensa por acortar distancias: +  0.9156974303625111\n",
      "Penalización por duración del episodio: -  0.2857623894258567\n",
      "Recompensa por acortar distancias: +  0.9156974303625111\n",
      "Penalización por duración del episodio: -  0.2859053694159092\n",
      "Recompensa por acortar distancias: +  0.9156975407917033\n",
      "Penalización por parar muy lejos: -  0.16593365328125428\n",
      "Penalización por duración del episodio: -  0.28602861930292706\n",
      "Recompensa por acortar distancias: +  0.9156975407917033\n",
      "Penalización por duración del episodio: -  0.2861341593954023\n",
      "Recompensa por acortar distancias: +  0.9156975407917033\n",
      "Penalización por duración del episodio: -  0.28646735721107547\n",
      "Recompensa por acortar distancias: +  0.9156975407917033\n",
      "Penalización por parar muy lejos: -  0.16593365328125428\n",
      "Penalización por duración del episodio: -  0.28657217530725143\n",
      "Recompensa por acortar distancias: +  0.9156975407917033\n",
      "Penalización por parar muy lejos: -  0.16593365328125428\n",
      "Penalización por duración del episodio: -  0.28677879346781865\n",
      "Recompensa por acortar distancias: +  0.9156975407917033\n",
      "Penalización por duración del episodio: -  0.286891283942588\n",
      "Recompensa por acortar distancias: +  0.9156973567429766\n",
      "Penalización por duración del episodio: -  0.28699850241493463\n",
      "Recompensa por acortar distancias: +  0.9156973567429766\n",
      "Penalización por duración del episodio: -  0.2871179104621471\n",
      "Step: 8290, Mean Reward (últimos 10 pasos): 0.6285794377326965\n",
      "Recompensa por acortar distancias: +  0.9156975260678185\n",
      "Penalización por duración del episodio: -  0.2872095749919667\n",
      "Recompensa por acortar distancias: +  0.9156975260678185\n",
      "Penalización por duración del episodio: -  0.2874330212585191\n",
      "Recompensa por acortar distancias: +  0.9156975260678185\n",
      "Penalización por duración del episodio: -  0.2877480499997193\n",
      "steer input from model: 0.9 , throttle:  1.0\n",
      "reward: 0.6279494760680993\n",
      "Recompensa por acortar distancias: +  0.915697665944629\n",
      "Penalización por duración del episodio: -  0.2878297911878101\n",
      "Recompensa por acortar distancias: +  0.915697665944629\n",
      "Penalización por duración del episodio: -  0.28806952354715065\n",
      "Recompensa por acortar distancias: +  0.9156977910973861\n",
      "Penalización por duración del episodio: -  0.2881561411143973\n",
      "Recompensa por acortar distancias: +  0.9156977910973861\n",
      "Penalización por duración del episodio: -  0.2882687480459552\n",
      "Recompensa por acortar distancias: +  0.9156977910973861\n",
      "Penalización por parar muy lejos: -  0.16593410204167613\n",
      "Penalización por duración del episodio: -  0.2883574610030284\n",
      "Recompensa por acortar distancias: +  0.9156977910973861\n",
      "Penalización por duración del episodio: -  0.28846666959907147\n",
      "Recompensa por acortar distancias: +  0.9156977910973861\n",
      "Penalización por parar muy lejos: -  0.16593410204167613\n",
      "Penalización por duración del episodio: -  0.28872137146486637\n",
      "Step: 8300, Mean Reward (últimos 10 pasos): 0.4610423147678375\n",
      "Recompensa por acortar distancias: +  0.9156977910973861\n",
      "Penalización por parar muy lejos: -  0.16593410204167613\n",
      "Penalización por duración del episodio: -  0.2888075227697671\n",
      "Recompensa por acortar distancias: +  0.9156977910973861\n",
      "Penalización por parar muy lejos: -  0.16593410204167613\n",
      "Penalización por duración del episodio: -  0.2889092503165967\n",
      "Recompensa por acortar distancias: +  0.9156977910973861\n",
      "Penalización por duración del episodio: -  0.289351508354355\n",
      "Recompensa por acortar distancias: +  0.9156977027542811\n",
      "Penalización por parar muy lejos: -  0.16593394365553388\n",
      "Penalización por duración del episodio: -  0.28946576058795465\n",
      "Recompensa por acortar distancias: +  0.9156977027542811\n",
      "Penalización por parar muy lejos: -  0.16593394365553388\n",
      "Penalización por duración del episodio: -  0.28966993371178823\n",
      "Recompensa por acortar distancias: +  0.9156977027542811\n",
      "Penalización por duración del episodio: -  0.2899992484316011\n",
      "Recompensa por acortar distancias: +  0.9156977027542811\n",
      "Penalización por parar muy lejos: -  0.16593394365553388\n",
      "Penalización por duración del episodio: -  0.29011243429453515\n",
      "Recompensa por acortar distancias: +  0.9156977027542811\n",
      "Penalización por duración del episodio: -  0.29027827855346194\n",
      "Recompensa por acortar distancias: +  0.9156976364968971\n",
      "Penalización por parar muy lejos: -  0.1659338248660067\n",
      "Penalización por duración del episodio: -  0.29039203481353004\n",
      "Recompensa por acortar distancias: +  0.9156976364968971\n",
      "Penalización por parar muy lejos: -  0.1659338248660067\n",
      "Penalización por duración del episodio: -  0.29065113398032616\n",
      "Step: 8310, Mean Reward (últimos 10 pasos): 0.45911267399787903\n",
      "Recompensa por acortar distancias: +  0.9156977248400653\n",
      "Penalización por duración del episodio: -  0.2909748160817586\n",
      "Recompensa por acortar distancias: +  0.9156977248400653\n",
      "Penalización por parar muy lejos: -  0.1659339832520581\n",
      "Penalización por duración del episodio: -  0.29108145193432833\n",
      "Recompensa por acortar distancias: +  0.9156977248400653\n",
      "Penalización por parar muy lejos: -  0.1659339832520581\n",
      "Penalización por duración del episodio: -  0.29122456128314983\n",
      "steer input from model: 0.9 , throttle:  0.0\n",
      "reward: 0.45853918030485735\n",
      "Recompensa por acortar distancias: +  0.9156977248400653\n",
      "Penalización por parar muy lejos: -  0.1659339832520581\n",
      "Penalización por duración del episodio: -  0.29131144400785886\n",
      "Recompensa por acortar distancias: +  0.9156977248400653\n",
      "Penalización por parar muy lejos: -  0.1659339832520581\n",
      "Penalización por duración del episodio: -  0.2914146570683529\n",
      "Recompensa por acortar distancias: +  0.9156977248400653\n",
      "Penalización por duración del episodio: -  0.2915310295500305\n",
      "Recompensa por acortar distancias: +  0.9156973420190626\n",
      "Penalización por parar muy lejos: -  0.1659332969133766\n",
      "Penalización por duración del episodio: -  0.2916239305132897\n",
      "Recompensa por acortar distancias: +  0.9156973420190626\n",
      "Penalización por duración del episodio: -  0.2917348444802922\n",
      "Recompensa por acortar distancias: +  0.9156975039819871\n",
      "Penalización por duración del episodio: -  0.2919308972938163\n",
      "Recompensa por acortar distancias: +  0.9156975039819871\n",
      "Penalización por parar muy lejos: -  0.16593358728715663\n",
      "Penalización por duración del episodio: -  0.2920466663344931\n",
      "Step: 8320, Mean Reward (últimos 10 pasos): 0.45771723985671997\n",
      "Recompensa por acortar distancias: +  0.9156975039819871\n",
      "Penalización por parar muy lejos: -  0.16593358728715663\n",
      "Penalización por duración del episodio: -  0.29217039570984765\n",
      "Recompensa por acortar distancias: +  0.9156975039819871\n",
      "Penalización por parar muy lejos: -  0.16593358728715663\n",
      "Penalización por duración del episodio: -  0.29227840859991755\n",
      "Recompensa por acortar distancias: +  0.9156975039819871\n",
      "Penalización por parar muy lejos: -  0.16593358728715663\n",
      "Penalización por duración del episodio: -  0.2925834159954516\n",
      "Recompensa por acortar distancias: +  0.9156975187058752\n",
      "Penalización por parar muy lejos: -  0.16593361368479315\n",
      "Penalización por duración del episodio: -  0.2926796232587514\n",
      "Recompensa por acortar distancias: +  0.9156975187058752\n",
      "Penalización por duración del episodio: -  0.29280433435270375\n",
      "Recompensa por acortar distancias: +  0.9156975187058752\n",
      "Penalización por duración del episodio: -  0.29292840992725566\n",
      "Recompensa por acortar distancias: +  0.9156975187058752\n",
      "Penalización por parar muy lejos: -  0.16593361368479315\n",
      "Penalización por duración del episodio: -  0.29306334847568116\n",
      "Recompensa por acortar distancias: +  0.9156975187058752\n",
      "Penalización por duración del episodio: -  0.2931592874999504\n",
      "Recompensa por acortar distancias: +  0.9156975187058752\n",
      "Penalización por duración del episodio: -  0.29325323870560804\n",
      "Recompensa por acortar distancias: +  0.9156975187058752\n",
      "Penalización por parar muy lejos: -  0.16593361368479315\n",
      "Penalización por duración del episodio: -  0.29336021085566744\n",
      "Step: 8330, Mean Reward (últimos 10 pasos): 0.4564037024974823\n",
      "Recompensa por acortar distancias: +  0.9156975187058752\n",
      "Penalización por duración del episodio: -  0.29347181315997106\n",
      "Recompensa por acortar distancias: +  0.9156975187058752\n",
      "Penalización por duración del episodio: -  0.2935585497041412\n",
      "Recompensa por acortar distancias: +  0.9156975187058752\n",
      "Penalización por duración del episodio: -  0.2936744343894618\n",
      "steer input from model: 0.9 , throttle:  0.3\n",
      "reward: 0.6220230843164134\n",
      "Recompensa por acortar distancias: +  0.9156975187058752\n",
      "Penalización por parar muy lejos: -  0.16593361368479315\n",
      "Penalización por duración del episodio: -  0.29380651665831964\n",
      "Recompensa por acortar distancias: +  0.9156975187058752\n",
      "Penalización por parar muy lejos: -  0.16593361368479315\n",
      "Penalización por duración del episodio: -  0.29418737703624487\n",
      "Recompensa por acortar distancias: +  0.9156975187058752\n",
      "Penalización por parar muy lejos: -  0.16593361368479315\n",
      "Penalización por duración del episodio: -  0.2945215706220561\n",
      "Recompensa por acortar distancias: +  0.9156975849633434\n",
      "Penalización por duración del episodio: -  0.294852237696526\n",
      "Recompensa por acortar distancias: +  0.9156975849633434\n",
      "Penalización por parar muy lejos: -  0.16593373247419926\n",
      "Penalización por duración del episodio: -  0.2949587613552394\n",
      "Recompensa por acortar distancias: +  0.9156974598103085\n",
      "Penalización por duración del episodio: -  0.29516380068381803\n",
      "Recompensa por acortar distancias: +  0.9156975407917033\n",
      "Penalización por duración del episodio: -  0.29524967242274464\n",
      "Step: 8340, Mean Reward (últimos 10 pasos): 0.6204478740692139\n",
      "Recompensa por acortar distancias: +  0.9156975407917033\n",
      "Penalización por parar muy lejos: -  0.16593365328125428\n",
      "Penalización por duración del episodio: -  0.29534568082420964\n",
      "Recompensa por acortar distancias: +  0.9156975407917033\n",
      "Penalización por parar muy lejos: -  0.16593365328125428\n",
      "Penalización por duración del episodio: -  0.29547537130305046\n",
      "Recompensa por acortar distancias: +  0.9156975407917033\n",
      "Penalización por duración del episodio: -  0.29581487965016773\n",
      "Recompensa por acortar distancias: +  0.9156976217730275\n",
      "Penalización por parar muy lejos: -  0.1659337984683432\n",
      "Penalización por duración del episodio: -  0.29591147651077504\n",
      "Recompensa por acortar distancias: +  0.9156976291349626\n",
      "Penalización por duración del episodio: -  0.29613669842692913\n",
      "Recompensa por acortar distancias: +  0.915697665944629\n",
      "Penalización por parar muy lejos: -  0.16593387766134368\n",
      "Penalización por duración del episodio: -  0.2964541897912714\n",
      "Recompensa por acortar distancias: +  0.915697665944629\n",
      "Penalización por duración del episodio: -  0.2967831134034958\n",
      "Recompensa por acortar distancias: +  0.9156975849633434\n",
      "Penalización por parar muy lejos: -  0.16593373247419926\n",
      "Penalización por duración del episodio: -  0.2971101018776399\n",
      "Recompensa por acortar distancias: +  0.9156976291349626\n",
      "Penalización por duración del episodio: -  0.29743014883995106\n",
      "Recompensa por acortar distancias: +  0.9156976291349626\n",
      "Penalización por duración del episodio: -  0.2977494572960425\n",
      "Step: 8350, Mean Reward (últimos 10 pasos): 0.6179481744766235\n",
      "Recompensa por acortar distancias: +  0.9156977174781378\n",
      "Penalización por parar muy lejos: -  0.16593397005321583\n",
      "Penalización por duración del episodio: -  0.29785123531937485\n",
      "Recompensa por acortar distancias: +  0.915697746925844\n",
      "Penalización por parar muy lejos: -  0.16593402284858985\n",
      "Penalización por duración del episodio: -  0.29794484450551273\n",
      "Recompensa por acortar distancias: +  0.915697746925844\n",
      "Penalización por duración del episodio: -  0.29837709626048986\n",
      "steer input from model: -0.1 , throttle:  0.7\n",
      "reward: 0.6173206506653541\n",
      "Recompensa por acortar distancias: +  0.9156977542877692\n",
      "Penalización por parar muy lejos: -  0.16593403604743545\n",
      "Penalización por duración del episodio: -  0.29869719887315505\n",
      "Recompensa por acortar distancias: +  0.9156977542877692\n",
      "Penalización por duración del episodio: -  0.2990169838097618\n",
      "Recompensa por acortar distancias: +  0.9156974671722563\n",
      "Penalización por parar muy lejos: -  0.16593352129307995\n",
      "Penalización por duración del episodio: -  0.29934314557849623\n",
      "Recompensa por acortar distancias: +  0.9156974745342036\n",
      "Penalización por duración del episodio: -  0.29967394426641125\n",
      "Recompensa por acortar distancias: +  0.9156976217730275\n",
      "Penalización por duración del episodio: -  0.3000027890405429\n",
      "Recompensa por acortar distancias: +  0.915697746925844\n",
      "Penalización por duración del episodio: -  0.3003229222792686\n",
      "Recompensa por acortar distancias: +  0.9156977910973861\n",
      "Penalización por duración del episodio: -  0.3004190804365122\n",
      "Step: 8360, Mean Reward (últimos 10 pasos): 0.6152787208557129\n",
      "Recompensa por acortar distancias: +  0.9156977910973861\n",
      "Penalización por duración del episodio: -  0.3006415209589791\n",
      "Recompensa por acortar distancias: +  0.9156977910973861\n",
      "Penalización por duración del episodio: -  0.30097236565178476\n",
      "Recompensa por acortar distancias: +  0.915697562877526\n",
      "Penalización por parar muy lejos: -  0.165933692877723\n",
      "Penalización por duración del episodio: -  0.3012985038154039\n",
      "Recompensa por acortar distancias: +  0.915697562877526\n",
      "Penalización por parar muy lejos: -  0.165933692877723\n",
      "Penalización por duración del episodio: -  0.3016398796427661\n",
      "Recompensa por acortar distancias: +  0.9156976291349626\n",
      "Penalización por parar muy lejos: -  0.16593381166717452\n",
      "Penalización por duración del episodio: -  0.30198359086363813\n",
      "Recompensa por acortar distancias: +  0.9156976291349626\n",
      "Penalización por parar muy lejos: -  0.16593381166717452\n",
      "Penalización por duración del episodio: -  0.30207524081165077\n",
      "Recompensa por acortar distancias: +  0.915697665944629\n",
      "Penalización por duración del episodio: -  0.3021948693515748\n",
      "Recompensa por acortar distancias: +  0.9156976512207643\n",
      "Penalización por parar muy lejos: -  0.1659338512636735\n",
      "Penalización por duración del episodio: -  0.30263563565410895\n",
      "Recompensa por acortar distancias: +  0.9156976806684916\n",
      "Penalización por parar muy lejos: -  0.16593390405901723\n",
      "Penalización por duración del episodio: -  0.3029684088869925\n",
      "Recompensa por acortar distancias: +  0.9156976806684916\n",
      "Penalización por duración del episodio: -  0.3032959579350232\n",
      "Step: 8370, Mean Reward (últimos 10 pasos): 0.6124017238616943\n",
      "Recompensa por acortar distancias: +  0.915697665944629\n",
      "Penalización por duración del episodio: -  0.30361645285114364\n",
      "Recompensa por acortar distancias: +  0.915697665944629\n",
      "Penalización por duración del episodio: -  0.303736320235703\n",
      "Recompensa por acortar distancias: +  0.9156977910973861\n",
      "Penalización por duración del episodio: -  0.30382581467387043\n",
      "steer input from model: -0.9 , throttle:  0.7\n",
      "reward: 0.6118719764235157\n",
      "Recompensa por acortar distancias: +  0.9156977910973861\n",
      "Penalización por duración del episodio: -  0.3039118185665036\n",
      "Recompensa por acortar distancias: +  0.9156977690116177\n",
      "Penalización por duración del episodio: -  0.3040006812989676\n",
      "Recompensa por acortar distancias: +  0.9156978352689072\n",
      "Penalización por parar muy lejos: -  0.16593418123479267\n",
      "Penalización por duración del episodio: -  0.30430645820374624\n",
      "Recompensa por acortar distancias: +  0.9156979015261495\n",
      "Penalización por parar muy lejos: -  0.16593430002452422\n",
      "Penalización por duración del episodio: -  0.30439998988855366\n",
      "Recompensa por acortar distancias: +  0.9156979604214363\n",
      "Penalización por duración del episodio: -  0.30463168023720877\n",
      "Recompensa por acortar distancias: +  0.9156979604214363\n",
      "Penalización por parar muy lejos: -  0.16593440561545394\n",
      "Penalización por duración del episodio: -  0.30470729579393296\n",
      "Recompensa por acortar distancias: +  0.9156979604214363\n",
      "Penalización por parar muy lejos: -  0.16593440561545394\n",
      "Penalización por duración del episodio: -  0.3049682102000104\n",
      "Step: 8380, Mean Reward (últimos 10 pasos): 0.4447953402996063\n",
      "Recompensa por acortar distancias: +  0.9156979604214363\n",
      "Penalización por parar muy lejos: -  0.16593440561545394\n",
      "Penalización por duración del episodio: -  0.30528937425681\n",
      "Recompensa por acortar distancias: +  0.9156975776014049\n",
      "Penalización por duración del episodio: -  0.30560592632609385\n",
      "Recompensa por acortar distancias: +  0.9156975776014049\n",
      "Penalización por parar muy lejos: -  0.165933719275373\n",
      "Penalización por duración del episodio: -  0.3057004207251615\n",
      "Recompensa por acortar distancias: +  0.9156975776014049\n",
      "Penalización por duración del episodio: -  0.3057891971042662\n",
      "Recompensa por acortar distancias: +  0.9156975776014049\n",
      "Penalización por parar muy lejos: -  0.165933719275373\n",
      "Penalización por duración del episodio: -  0.305947888790144\n",
      "Recompensa por acortar distancias: +  0.9156975776014049\n",
      "Penalización por parar muy lejos: -  0.165933719275373\n",
      "Penalización por duración del episodio: -  0.3062807693921012\n",
      "Recompensa por acortar distancias: +  0.9156976733065607\n",
      "Penalización por duración del episodio: -  0.30638672973930825\n",
      "Recompensa por acortar distancias: +  0.9156976733065607\n",
      "Penalización por parar muy lejos: -  0.16593389086018007\n",
      "Penalización por duración del episodio: -  0.30648842835499385\n",
      "Recompensa por acortar distancias: +  0.9156977322019921\n",
      "Penalización por duración del episodio: -  0.3066220941409977\n",
      "Recompensa por acortar distancias: +  0.9156977322019921\n",
      "Penalización por parar muy lejos: -  0.16593399645090115\n",
      "Penalización por duración del episodio: -  0.3069594465340285\n",
      "Step: 8390, Mean Reward (últimos 10 pasos): 0.4428042769432068\n",
      "Recompensa por acortar distancias: +  0.9156977322019921\n",
      "Penalización por duración del episodio: -  0.3073000202184596\n",
      "Recompensa por acortar distancias: +  0.9156977322019921\n",
      "Penalización por duración del episodio: -  0.307625533898625\n",
      "Recompensa por acortar distancias: +  0.9156974818961505\n",
      "Penalización por parar muy lejos: -  0.16593354769070812\n",
      "Penalización por duración del episodio: -  0.30796065447601534\n",
      "steer input from model: -0.9 , throttle:  0.0\n",
      "reward: 0.44180327972942707\n",
      "Recompensa por acortar distancias: +  0.9156974818961505\n",
      "Penalización por parar muy lejos: -  0.16593354769070812\n",
      "Penalización por duración del episodio: -  0.30829665377690585\n",
      "Recompensa por acortar distancias: +  0.9156974598103085\n",
      "Penalización por duración del episodio: -  0.30838802056425263\n",
      "Recompensa por acortar distancias: +  0.9156974745342036\n",
      "Penalización por duración del episodio: -  0.3084622019637455\n",
      "Recompensa por acortar distancias: +  0.9156974745342036\n",
      "Penalización por parar muy lejos: -  0.16593353449189358\n",
      "Penalización por duración del episodio: -  0.30858288036399306\n",
      "Recompensa por acortar distancias: +  0.9156975260678185\n",
      "Penalización por duración del episodio: -  0.3086772399216743\n",
      "Recompensa por acortar distancias: +  0.915697562877526\n",
      "Penalización por parar muy lejos: -  0.165933692877723\n",
      "Penalización por duración del episodio: -  0.3087899347384194\n",
      "Recompensa por acortar distancias: +  0.915697562877526\n",
      "Penalización por duración del episodio: -  0.3088847466753389\n",
      "Step: 8400, Mean Reward (últimos 10 pasos): 0.6068128347396851\n",
      "Recompensa por acortar distancias: +  0.915697562877526\n",
      "Penalización por parar muy lejos: -  0.165933692877723\n",
      "Penalización por duración del episodio: -  0.30898784684009767\n",
      "Recompensa por acortar distancias: +  0.915697562877526\n",
      "Penalización por duración del episodio: -  0.3092976689127843\n",
      "Recompensa por acortar distancias: +  0.915697562877526\n",
      "Penalización por duración del episodio: -  0.3094151655641264\n",
      "Recompensa por acortar distancias: +  0.915697562877526\n",
      "Penalización por parar muy lejos: -  0.165933692877723\n",
      "Penalización por duración del episodio: -  0.3095453035325819\n",
      "Recompensa por acortar distancias: +  0.915697562877526\n",
      "Penalización por parar muy lejos: -  0.165933692877723\n",
      "Penalización por duración del episodio: -  0.3096543406290691\n",
      "Recompensa por acortar distancias: +  0.915697562877526\n",
      "Penalización por duración del episodio: -  0.30976478545910174\n",
      "Recompensa por acortar distancias: +  0.9156972904853456\n",
      "Penalización por parar muy lejos: -  0.16593320452180466\n",
      "Penalización por duración del episodio: -  0.30986505480632454\n",
      "Recompensa por acortar distancias: +  0.9156972904853456\n",
      "Penalización por duración del episodio: -  0.30995863628571724\n",
      "Recompensa por acortar distancias: +  0.9156973052092677\n",
      "Penalización por parar muy lejos: -  0.16593323091939247\n",
      "Penalización por duración del episodio: -  0.31028462808544705\n",
      "Recompensa por acortar distancias: +  0.9156973052092677\n",
      "Penalización por duración del episodio: -  0.31037182378362194\n",
      "Step: 8410, Mean Reward (últimos 10 pasos): 0.60532546043396\n",
      "Recompensa por acortar distancias: +  0.9156973052092677\n",
      "Penalización por duración del episodio: -  0.31049065266969716\n",
      "Recompensa por acortar distancias: +  0.9156973052092677\n",
      "Penalización por parar muy lejos: -  0.16593323091939247\n",
      "Penalización por duración del episodio: -  0.3106232858961686\n",
      "Recompensa por acortar distancias: +  0.9156973493810199\n",
      "Penalización por parar muy lejos: -  0.16593331011217594\n",
      "Penalización por duración del episodio: -  0.3109678937405795\n",
      "steer input from model: 0.9 , throttle:  0.0\n",
      "reward: 0.43879614552826446\n",
      "Recompensa por acortar distancias: +  0.9156974230005601\n",
      "Penalización por duración del episodio: -  0.3113014095582882\n",
      "Recompensa por acortar distancias: +  0.9156974230005601\n",
      "Penalización por duración del episodio: -  0.3116426908402753\n",
      "Recompensa por acortar distancias: +  0.9156974230005601\n",
      "Penalización por duración del episodio: -  0.31198724226357344\n",
      "Recompensa por acortar distancias: +  0.9156348842610276\n",
      "Penalización por parar muy lejos: -  0.1658213881431366\n",
      "Penalización por duración del episodio: -  0.3123294772435868\n",
      "Recompensa por acortar distancias: +  0.9156348842610276\n",
      "Penalización por parar muy lejos: -  0.1658213881431366\n",
      "Penalización por duración del episodio: -  0.3126730647636499\n",
      "Recompensa por acortar distancias: +  0.9155156628315719\n",
      "Penalización por duración del episodio: -  0.3127654495657797\n",
      "Recompensa por acortar distancias: +  0.9155088246952564\n",
      "Penalización por parar muy lejos: -  0.16559593355204558\n",
      "Penalización por duración del episodio: -  0.3128935492512824\n",
      "Step: 8420, Mean Reward (últimos 10 pasos): 0.43701934814453125\n",
      "Recompensa por acortar distancias: +  0.9155059476592868\n",
      "Penalización por duración del episodio: -  0.3129960331643606\n",
      "Recompensa por acortar distancias: +  0.9155059476592868\n",
      "Penalización por parar muy lejos: -  0.16559079447212183\n",
      "Penalización por duración del episodio: -  0.31312891728131126\n",
      "Recompensa por acortar distancias: +  0.9155053501098945\n",
      "Penalización por duración del episodio: -  0.3132226319294307\n",
      "Recompensa por acortar distancias: +  0.9155053501098945\n",
      "Penalización por duración del episodio: -  0.3133464064302938\n",
      "Recompensa por acortar distancias: +  0.9155053501098945\n",
      "Penalización por duración del episodio: -  0.3136698453268767\n",
      "Recompensa por acortar distancias: +  0.9155053501098945\n",
      "Penalización por parar muy lejos: -  0.16558972714078554\n",
      "Penalización por duración del episodio: -  0.31374687176857524\n",
      "Recompensa por acortar distancias: +  0.9155053501098945\n",
      "Penalización por duración del episodio: -  0.3138462575107412\n",
      "Recompensa por acortar distancias: +  0.9155053501098945\n",
      "Penalización por parar muy lejos: -  0.16558972714078554\n",
      "Penalización por duración del episodio: -  0.31401004841840946\n",
      "Recompensa por acortar distancias: +  0.9155053501098945\n",
      "Penalización por parar muy lejos: -  0.16558972714078554\n",
      "Penalización por duración del episodio: -  0.3141001873298886\n",
      "Recompensa por acortar distancias: +  0.9155053501098945\n",
      "Penalización por duración del episodio: -  0.31434556457330975\n",
      "Step: 8430, Mean Reward (últimos 10 pasos): 0.6011598110198975\n",
      "Recompensa por acortar distancias: +  0.9151742135231716\n",
      "Penalización por parar muy lejos: -  0.16500015334512314\n",
      "Penalización por duración del episodio: -  0.31467596345894205\n",
      "Recompensa por acortar distancias: +  0.9150581004489045\n",
      "Penalización por parar muy lejos: -  0.16479431173441536\n",
      "Penalización por duración del episodio: -  0.31501806879815153\n",
      "Recompensa por acortar distancias: +  0.9150581004489045\n",
      "Penalización por duración del episodio: -  0.3153513768888828\n",
      "steer input from model: -0.05 , throttle:  0.7\n",
      "reward: 0.5997067235600216\n",
      "Recompensa por acortar distancias: +  0.9148091514571043\n",
      "Penalización por duración del episodio: -  0.31568891312228786\n",
      "Recompensa por acortar distancias: +  0.9148091514571043\n",
      "Penalización por parar muy lejos: -  0.16435453420436733\n",
      "Penalización por duración del episodio: -  0.3160440784508191\n",
      "Recompensa por acortar distancias: +  0.9147145500724697\n",
      "Penalización por parar muy lejos: -  0.16418796973894426\n",
      "Penalización por duración del episodio: -  0.3163901867983911\n",
      "Recompensa por acortar distancias: +  0.9146849350508831\n",
      "Penalización por duración del episodio: -  0.3167226294765967\n",
      "Recompensa por acortar distancias: +  0.9145700775748401\n",
      "Penalización por parar muy lejos: -  0.1639341815641352\n",
      "Penalización por duración del episodio: -  0.31683609487116127\n",
      "Recompensa por acortar distancias: +  0.914520663069063\n",
      "Penalización por duración del episodio: -  0.31705018473388175\n",
      "Recompensa por acortar distancias: +  0.9144845211682855\n",
      "Penalización por parar muy lejos: -  0.16378422043880472\n",
      "Penalización por duración del episodio: -  0.31713027026771984\n",
      "Step: 8440, Mean Reward (últimos 10 pasos): 0.4335700273513794\n",
      "Recompensa por acortar distancias: +  0.9144529537193142\n",
      "Penalización por parar muy lejos: -  0.1637289519959653\n",
      "Penalización por duración del episodio: -  0.3172557741880886\n",
      "Recompensa por acortar distancias: +  0.9144172112782435\n",
      "Penalización por duración del episodio: -  0.3173457371697493\n",
      "Recompensa por acortar distancias: +  0.9144172112782435\n",
      "Penalización por duración del episodio: -  0.31770740003554165\n",
      "Recompensa por acortar distancias: +  0.9144172112782435\n",
      "Penalización por duración del episodio: -  0.3177757222033746\n",
      "Recompensa por acortar distancias: +  0.9144172112782435\n",
      "Penalización por duración del episodio: -  0.3180555533107083\n",
      "Recompensa por acortar distancias: +  0.9142268847030377\n",
      "Penalización por duración del episodio: -  0.3181500129224726\n",
      "Recompensa por acortar distancias: +  0.9142268847030377\n",
      "Penalización por duración del episodio: -  0.3182386939353722\n",
      "Recompensa por acortar distancias: +  0.9141774249957567\n",
      "Penalización por parar muy lejos: -  0.16324797287148748\n",
      "Penalización por duración del episodio: -  0.3183856142703134\n",
      "Recompensa por acortar distancias: +  0.9141774249957567\n",
      "Penalización por parar muy lejos: -  0.16324797287148748\n",
      "Penalización por duración del episodio: -  0.31871576966060866\n",
      "Recompensa por acortar distancias: +  0.914002710701187\n",
      "Penalización por duración del episodio: -  0.3190505825071217\n",
      "Step: 8450, Mean Reward (últimos 10 pasos): 0.5949521064758301\n",
      "Recompensa por acortar distancias: +  0.9139082135031882\n",
      "Penalización por duración del episodio: -  0.3191330249681086\n",
      "Recompensa por acortar distancias: +  0.9138508618980203\n",
      "Penalización por parar muy lejos: -  0.16268118006774288\n",
      "Penalización por duración del episodio: -  0.31940106313010685\n",
      "Recompensa por acortar distancias: +  0.9138024002003788\n",
      "Penalización por parar muy lejos: -  0.16259736931140426\n",
      "Penalización por duración del episodio: -  0.3194934595088722\n",
      "steer input from model: 0.05 , throttle:  0.0\n",
      "reward: 0.4317115713801024\n",
      "Recompensa por acortar distancias: +  0.9138024002003788\n",
      "Penalización por duración del episodio: -  0.31973452080538795\n",
      "Recompensa por acortar distancias: +  0.9138024002003788\n",
      "Penalización por duración del episodio: -  0.3197897718677686\n",
      "Recompensa por acortar distancias: +  0.9138024002003788\n",
      "Penalización por duración del episodio: -  0.3198784984176182\n",
      "Recompensa por acortar distancias: +  0.9138024002003788\n",
      "Penalización por duración del episodio: -  0.3199771154799477\n",
      "Recompensa por acortar distancias: +  0.9138024002003788\n",
      "Penalización por parar muy lejos: -  0.16259736931140426\n",
      "Penalización por duración del episodio: -  0.3200726562167301\n",
      "Recompensa por acortar distancias: +  0.9138024002003788\n",
      "Penalización por duración del episodio: -  0.32017556551845516\n",
      "Recompensa por acortar distancias: +  0.9138024002003788\n",
      "Penalización por parar muy lejos: -  0.16259736931140426\n",
      "Penalización por duración del episodio: -  0.3204028872800931\n",
      "Step: 8460, Mean Reward (últimos 10 pasos): 0.4308021366596222\n",
      "Recompensa por acortar distancias: +  0.9137205909417889\n",
      "Penalización por parar muy lejos: -  0.1624560621687094\n",
      "Penalización por duración del episodio: -  0.320751192857334\n",
      "Recompensa por acortar distancias: +  0.91369172374883\n",
      "Penalización por duración del episodio: -  0.32109340415501647\n",
      "Recompensa por acortar distancias: +  0.9135852704872579\n",
      "Penalización por duración del episodio: -  0.3214346273244593\n",
      "Recompensa por acortar distancias: +  0.9135360859591852\n",
      "Penalización por duración del episodio: -  0.3217699067517327\n",
      "Recompensa por acortar distancias: +  0.9134999363915308\n",
      "Penalización por parar muy lejos: -  0.16207602717655187\n",
      "Penalización por duración del episodio: -  0.32210018999065554\n",
      "Recompensa por acortar distancias: +  0.9134999363915308\n",
      "Penalización por parar muy lejos: -  0.16207602717655187\n",
      "Penalización por duración del episodio: -  0.3224459232072867\n",
      "Recompensa por acortar distancias: +  0.9134674594348644\n",
      "Penalización por duración del episodio: -  0.32279160586647093\n",
      "Recompensa por acortar distancias: +  0.9134672031327896\n",
      "Penalización por duración del episodio: -  0.32289300904934454\n",
      "Recompensa por acortar distancias: +  0.9134672031327896\n",
      "Penalización por parar muy lejos: -  0.16201978624210256\n",
      "Penalización por duración del episodio: -  0.32300923534308956\n",
      "Recompensa por acortar distancias: +  0.9134672031327896\n",
      "Penalización por parar muy lejos: -  0.16201978624210256\n",
      "Penalización por duración del episodio: -  0.32313007235692837\n",
      "Step: 8470, Mean Reward (últimos 10 pasos): 0.4283173382282257\n",
      "Recompensa por acortar distancias: +  0.9134672031327896\n",
      "Penalización por duración del episodio: -  0.32321822136613554\n",
      "Recompensa por acortar distancias: +  0.9134672031327896\n",
      "Penalización por duración del episodio: -  0.3232977242598919\n",
      "Recompensa por acortar distancias: +  0.913453972489466\n",
      "Penalización por duración del episodio: -  0.32339528220515956\n",
      "steer input from model: -0.9 , throttle:  1.0\n",
      "reward: 0.5900586902843065\n",
      "Recompensa por acortar distancias: +  0.913453972489466\n",
      "Penalización por duración del episodio: -  0.323499001970076\n",
      "Recompensa por acortar distancias: +  0.9134335688319781\n",
      "Penalización por parar muy lejos: -  0.16196203362351472\n",
      "Penalización por duración del episodio: -  0.32362185512158975\n",
      "Recompensa por acortar distancias: +  0.9134335688319781\n",
      "Penalización por duración del episodio: -  0.32374245155474535\n",
      "Recompensa por acortar distancias: +  0.9134361402643565\n",
      "Penalización por duración del episodio: -  0.32415679449102414\n",
      "Recompensa por acortar distancias: +  0.913412813861434\n",
      "Penalización por duración del episodio: -  0.3245060929912119\n",
      "Recompensa por acortar distancias: +  0.913412813861434\n",
      "Penalización por parar muy lejos: -  0.16192641419878928\n",
      "Penalización por duración del episodio: -  0.32486760878413823\n",
      "Recompensa por acortar distancias: +  0.9134149559345479\n",
      "Penalización por duración del episodio: -  0.32522890960391637\n",
      "Step: 8480, Mean Reward (últimos 10 pasos): 0.5881860256195068\n",
      "Recompensa por acortar distancias: +  0.9134150992405443\n",
      "Penalización por duración del episodio: -  0.3253204225059075\n",
      "Recompensa por acortar distancias: +  0.9134150992405443\n",
      "Penalización por parar muy lejos: -  0.16193033564994047\n",
      "Penalización por duración del episodio: -  0.3254163346301127\n",
      "Recompensa por acortar distancias: +  0.9134150992405443\n",
      "Penalización por duración del episodio: -  0.32551649094020624\n",
      "Recompensa por acortar distancias: +  0.9134150992405443\n",
      "Penalización por parar muy lejos: -  0.16193033564994047\n",
      "Penalización por duración del episodio: -  0.3256072604089742\n",
      "Recompensa por acortar distancias: +  0.9134150992405443\n",
      "Penalización por parar muy lejos: -  0.16193033564994047\n",
      "Penalización por duración del episodio: -  0.3257353933237039\n",
      "Recompensa por acortar distancias: +  0.9134152274615169\n",
      "Penalización por duración del episodio: -  0.3258817423825145\n",
      "Recompensa por acortar distancias: +  0.9134152274615169\n",
      "Penalización por parar muy lejos: -  0.1619305556676215\n",
      "Penalización por duración del episodio: -  0.32623729013878056\n",
      "Recompensa por acortar distancias: +  0.9134154989877151\n",
      "Penalización por parar muy lejos: -  0.16193102158821282\n",
      "Penalización por duración del episodio: -  0.32658977640107645\n",
      "Recompensa por acortar distancias: +  0.9134154989877151\n",
      "Penalización por duración del episodio: -  0.3266994592109958\n",
      "Recompensa por acortar distancias: +  0.9134154989877151\n",
      "Penalización por parar muy lejos: -  0.16193102158821282\n",
      "Penalización por duración del episodio: -  0.32693179280885454\n",
      "Step: 8490, Mean Reward (últimos 10 pasos): 0.42455267906188965\n",
      "Recompensa por acortar distancias: +  0.9134154989877151\n",
      "Penalización por parar muy lejos: -  0.16193102158821282\n",
      "Penalización por duración del episodio: -  0.32702698950457443\n",
      "Recompensa por acortar distancias: +  0.9134154989877151\n",
      "Penalización por duración del episodio: -  0.3271168423549342\n",
      "Recompensa por acortar distancias: +  0.913415838394379\n",
      "Penalización por duración del episodio: -  0.3272882711937394\n",
      "steer input from model: -0.25 , throttle:  1.0\n",
      "reward: 0.5861275672006396\n",
      "Recompensa por acortar distancias: +  0.9134159364449688\n",
      "Penalización por parar muy lejos: -  0.1619317722403293\n",
      "Penalización por duración del episodio: -  0.3273765544067895\n",
      "Recompensa por acortar distancias: +  0.9134159364449688\n",
      "Penalización por duración del episodio: -  0.3276395655651348\n",
      "Recompensa por acortar distancias: +  0.9134159364449688\n",
      "Penalización por duración del episodio: -  0.3277329716881178\n",
      "Recompensa por acortar distancias: +  0.9134159364449688\n",
      "Penalización por parar muy lejos: -  0.1619317722403293\n",
      "Penalización por duración del episodio: -  0.3277996874445322\n",
      "Recompensa por acortar distancias: +  0.9134159364449688\n",
      "Penalización por parar muy lejos: -  0.1619317722403293\n",
      "Penalización por duración del episodio: -  0.3278883093338091\n",
      "Recompensa por acortar distancias: +  0.9134160420377992\n",
      "Penalización por parar muy lejos: -  0.16193195343264014\n",
      "Penalización por duración del episodio: -  0.3283291052541962\n",
      "Recompensa por acortar distancias: +  0.9134162155114819\n",
      "Penalización por parar muy lejos: -  0.16193225110607726\n",
      "Penalización por duración del episodio: -  0.3284124839728387\n",
      "Step: 8500, Mean Reward (últimos 10 pasos): 0.4230714738368988\n",
      "Recompensa por acortar distancias: +  0.9134162155114819\n",
      "Penalización por duración del episodio: -  0.32852515207609934\n",
      "Recompensa por acortar distancias: +  0.9134162155114819\n",
      "Penalización por parar muy lejos: -  0.16193225110607726\n",
      "Penalización por duración del episodio: -  0.3286806553182012\n",
      "Recompensa por acortar distancias: +  0.9134162155114819\n",
      "Penalización por duración del episodio: -  0.3290157278940324\n",
      "Recompensa por acortar distancias: +  0.9134162155114819\n",
      "Penalización por parar muy lejos: -  0.16193225110607726\n",
      "Penalización por duración del episodio: -  0.32913079152557\n",
      "Recompensa por acortar distancias: +  0.9134165549156034\n",
      "Penalización por duración del episodio: -  0.32935498730342805\n",
      "Recompensa por acortar distancias: +  0.9134166755923341\n",
      "Penalización por parar muy lejos: -  0.16193304058993988\n",
      "Penalización por duración del episodio: -  0.329460572615769\n",
      "Recompensa por acortar distancias: +  0.9134166755923341\n",
      "Penalización por parar muy lejos: -  0.16193304058993988\n",
      "Penalización por duración del episodio: -  0.3296966744944051\n",
      "Recompensa por acortar distancias: +  0.9134166755923341\n",
      "Penalización por duración del episodio: -  0.33004438284098886\n",
      "Recompensa por acortar distancias: +  0.9134167359306422\n",
      "Penalización por duración del episodio: -  0.3301352169287943\n",
      "Recompensa por acortar distancias: +  0.9134166755923341\n",
      "Penalización por duración del episodio: -  0.3303890965606254\n",
      "Step: 8510, Mean Reward (últimos 10 pasos): 0.5830276012420654\n",
      "Recompensa por acortar distancias: +  0.9134194134047513\n",
      "Penalización por duración del episodio: -  0.33051710220440156\n",
      "Recompensa por acortar distancias: +  0.9133992814881354\n",
      "Penalización por duración del episodio: -  0.33073151221835706\n",
      "Recompensa por acortar distancias: +  0.9133992814881354\n",
      "Penalización por parar muy lejos: -  0.16190319767160996\n",
      "Penalización por duración del episodio: -  0.33087320335190396\n",
      "steer input from model: 0.9 , throttle:  0.0\n",
      "reward: 0.4206228804646215\n",
      "Recompensa por acortar distancias: +  0.9133992814881354\n",
      "Penalización por parar muy lejos: -  0.16190319767160996\n",
      "Penalización por duración del episodio: -  0.33109095107444675\n",
      "Recompensa por acortar distancias: +  0.9133992814881354\n",
      "Penalización por parar muy lejos: -  0.16190319767160996\n",
      "Penalización por duración del episodio: -  0.33119679694543624\n",
      "Recompensa por acortar distancias: +  0.9133992814881354\n",
      "Penalización por parar muy lejos: -  0.16190319767160996\n",
      "Penalización por duración del episodio: -  0.33131882815491437\n",
      "Recompensa por acortar distancias: +  0.9133992814881354\n",
      "Penalización por parar muy lejos: -  0.16190319767160996\n",
      "Penalización por duración del episodio: -  0.3314356465479922\n",
      "Recompensa por acortar distancias: +  0.9133992814881354\n",
      "Penalización por duración del episodio: -  0.3317814954721428\n",
      "Recompensa por acortar distancias: +  0.913366121346386\n",
      "Penalización por parar muy lejos: -  0.16184633241145455\n",
      "Penalización por duración del episodio: -  0.33213514159300084\n",
      "Recompensa por acortar distancias: +  0.913366121346386\n",
      "Penalización por duración del episodio: -  0.33248916759640573\n",
      "Step: 8520, Mean Reward (últimos 10 pasos): 0.5808769464492798\n",
      "Recompensa por acortar distancias: +  0.91332515893836\n",
      "Penalización por duración del episodio: -  0.33283360970543285\n",
      "Recompensa por acortar distancias: +  0.9133042822777353\n",
      "Penalización por parar muy lejos: -  0.16174038220618256\n",
      "Penalización por duración del episodio: -  0.33317681624924794\n",
      "Recompensa por acortar distancias: +  0.9133042822777353\n",
      "Penalización por duración del episodio: -  0.3335150273151975\n",
      "Recompensa por acortar distancias: +  0.9131827374018653\n",
      "Penalización por parar muy lejos: -  0.16153249882521248\n",
      "Penalización por duración del episodio: -  0.3336150335944813\n",
      "Recompensa por acortar distancias: +  0.9131827374018653\n",
      "Penalización por duración del episodio: -  0.3338604195146664\n",
      "Recompensa por acortar distancias: +  0.9131341095731925\n",
      "Penalización por duración del episodio: -  0.3341986743395097\n",
      "Recompensa por acortar distancias: +  0.9131341095731925\n",
      "Penalización por duración del episodio: -  0.3345518766254951\n",
      "Recompensa por acortar distancias: +  0.9129098386091062\n",
      "Penalización por duración del episodio: -  0.3346411763317188\n",
      "Recompensa por acortar distancias: +  0.9128466351335763\n",
      "Penalización por duración del episodio: -  0.33475750718743896\n",
      "Recompensa por acortar distancias: +  0.9127683716524126\n",
      "Penalización por parar muy lejos: -  0.16082737823661067\n",
      "Penalización por duración del episodio: -  0.33489671969042384\n",
      "Step: 8530, Mean Reward (últimos 10 pasos): 0.4170442819595337\n",
      "Recompensa por acortar distancias: +  0.9127683716524126\n",
      "Penalización por duración del episodio: -  0.33502567233668595\n",
      "Recompensa por acortar distancias: +  0.9127194199551972\n",
      "Penalización por duración del episodio: -  0.3351387545447248\n",
      "Recompensa por acortar distancias: +  0.9127194199551972\n",
      "Penalización por parar muy lejos: -  0.160744442108677\n",
      "Penalización por duración del episodio: -  0.3352477909780711\n",
      "steer input from model: 0.0 , throttle:  0.0\n",
      "reward: 0.4167271868684491\n",
      "Recompensa por acortar distancias: +  0.9127194199551972\n",
      "Penalización por duración del episodio: -  0.3355850528292307\n",
      "Recompensa por acortar distancias: +  0.9127194199551972\n",
      "Penalización por parar muy lejos: -  0.160744442108677\n",
      "Penalización por duración del episodio: -  0.3359392416532233\n",
      "Recompensa por acortar distancias: +  0.9127194199551972\n",
      "Penalización por parar muy lejos: -  0.160744442108677\n",
      "Penalización por duración del episodio: -  0.33606781835690736\n",
      "Recompensa por acortar distancias: +  0.9127194199551972\n",
      "Penalización por duración del episodio: -  0.3361836443589646\n",
      "Recompensa por acortar distancias: +  0.9122566996280417\n",
      "Penalización por parar muy lejos: -  0.15996425089408914\n",
      "Penalización por duración del episodio: -  0.33664809297313075\n",
      "Recompensa por acortar distancias: +  0.9121868496979648\n",
      "Penalización por duración del episodio: -  0.3367358266321445\n",
      "Recompensa por acortar distancias: +  0.9121868496979648\n",
      "Penalización por duración del episodio: -  0.3368305588187335\n",
      "Step: 8540, Mean Reward (últimos 10 pasos): 0.5753563046455383\n",
      "Recompensa por acortar distancias: +  0.9121868496979648\n",
      "Penalización por duración del episodio: -  0.3369882600801489\n",
      "Recompensa por acortar distancias: +  0.9118691092641384\n",
      "Penalización por duración del episodio: -  0.3373481558890211\n",
      "Recompensa por acortar distancias: +  0.9117526605807753\n",
      "Penalización por parar muy lejos: -  0.15912207775350368\n",
      "Penalización por duración del episodio: -  0.33743472121344187\n",
      "Recompensa por acortar distancias: +  0.9117526605807753\n",
      "Penalización por duración del episodio: -  0.3375195701769525\n",
      "Recompensa por acortar distancias: +  0.9117526605807753\n",
      "Penalización por parar muy lejos: -  0.15912207775350368\n",
      "Penalización por duración del episodio: -  0.3377027371614623\n",
      "Recompensa por acortar distancias: +  0.9117526605807753\n",
      "Penalización por duración del episodio: -  0.33804275465189787\n",
      "Recompensa por acortar distancias: +  0.9117526605807753\n",
      "Penalización por parar muy lejos: -  0.15912207775350368\n",
      "Penalización por duración del episodio: -  0.33838212824494335\n",
      "Recompensa por acortar distancias: +  0.9109420632230532\n",
      "Penalización por duración del episodio: -  0.33873018073141387\n",
      "Recompensa por acortar distancias: +  0.9109420632230532\n",
      "Penalización por duración del episodio: -  0.3390738982136224\n",
      "Recompensa por acortar distancias: +  0.9102368046692361\n",
      "Penalización por duración del episodio: -  0.3391756315319255\n",
      "Step: 8550, Mean Reward (últimos 10 pasos): 0.5710611939430237\n",
      "Recompensa por acortar distancias: +  0.910047940881733\n",
      "Penalización por duración del episodio: -  0.339418539191398\n",
      "Recompensa por acortar distancias: +  0.9099001729913915\n",
      "Penalización por duración del episodio: -  0.33953921204982435\n",
      "Recompensa por acortar distancias: +  0.9099001729913915\n",
      "Penalización por duración del episodio: -  0.33964584727424646\n",
      "steer input from model: 0.0 , throttle:  0.7\n",
      "reward: 0.5702543257171451\n",
      "Recompensa por acortar distancias: +  0.9099001729913915\n",
      "Penalización por duración del episodio: -  0.33976889125665916\n",
      "Recompensa por acortar distancias: +  0.9099001729913915\n",
      "Penalización por duración del episodio: -  0.3401165613192398\n",
      "Recompensa por acortar distancias: +  0.9099001729913915\n",
      "Penalización por duración del episodio: -  0.34024304364079233\n",
      "Recompensa por acortar distancias: +  0.9099001729913915\n",
      "Penalización por duración del episodio: -  0.34046284577230934\n",
      "Recompensa por acortar distancias: +  0.9087364467299046\n",
      "Penalización por duración del episodio: -  0.34056924132738603\n",
      "Recompensa por acortar distancias: +  0.9084585708583824\n",
      "Penalización por parar muy lejos: -  0.15380785041413478\n",
      "Penalización por duración del episodio: -  0.3408248608421757\n",
      "Recompensa por acortar distancias: +  0.9084585708583824\n",
      "Penalización por duración del episodio: -  0.34091448429071297\n",
      "Step: 8560, Mean Reward (últimos 10 pasos): 0.5675441026687622\n",
      "Recompensa por acortar distancias: +  0.9084585708583824\n",
      "Penalización por duración del episodio: -  0.34119168130378047\n",
      "Recompensa por acortar distancias: +  0.9077093400880261\n",
      "Penalización por duración del episodio: -  0.34153204898109946\n",
      "Recompensa por acortar distancias: +  0.9072348546443351\n",
      "Penalización por parar muy lejos: -  0.15191372253193255\n",
      "Penalización por duración del episodio: -  0.3416322402682495\n",
      "Recompensa por acortar distancias: +  0.9072348546443351\n",
      "Penalización por parar muy lejos: -  0.15191372253193255\n",
      "Penalización por duración del episodio: -  0.34173691330216355\n",
      "Recompensa por acortar distancias: +  0.9072348546443351\n",
      "Penalización por parar muy lejos: -  0.15191372253193255\n",
      "Penalización por duración del episodio: -  0.34187633503618886\n",
      "Recompensa por acortar distancias: +  0.9072348546443351\n",
      "Penalización por duración del episodio: -  0.3419779590655162\n",
      "Recompensa por acortar distancias: +  0.9072348546443351\n",
      "Penalización por duración del episodio: -  0.34208043467851434\n",
      "Recompensa por acortar distancias: +  0.9072348546443351\n",
      "Penalización por parar muy lejos: -  0.15191372253193255\n",
      "Penalización por duración del episodio: -  0.34219092138936974\n",
      "Recompensa por acortar distancias: +  0.9072348546443351\n",
      "Penalización por parar muy lejos: -  0.15191372253193255\n",
      "Penalización por duración del episodio: -  0.3422879313384572\n",
      "Recompensa por acortar distancias: +  0.9072348546443351\n",
      "Penalización por parar muy lejos: -  0.15191372253193255\n",
      "Penalización por duración del episodio: -  0.34240202546926524\n",
      "Step: 8570, Mean Reward (últimos 10 pasos): 0.4129191040992737\n",
      "Recompensa por acortar distancias: +  0.9072348546443351\n",
      "Penalización por duración del episodio: -  0.342598097358527\n",
      "Recompensa por acortar distancias: +  0.9056774135608\n",
      "Penalización por parar muy lejos: -  0.14956238125693516\n",
      "Penalización por duración del episodio: -  0.3429398200073813\n",
      "Recompensa por acortar distancias: +  0.9053949305881877\n",
      "Penalización por parar muy lejos: -  0.1491428316078656\n",
      "Penalización por duración del episodio: -  0.34330299578966106\n",
      "steer input from model: 0.0 , throttle:  0.0\n",
      "reward: 0.412949103190661\n",
      "Recompensa por acortar distancias: +  0.9045238175129173\n",
      "Penalización por duración del episodio: -  0.3436564384853607\n",
      "Recompensa por acortar distancias: +  0.9038943139379761\n",
      "Penalización por parar muy lejos: -  0.14694871277063082\n",
      "Penalización por duración del episodio: -  0.3440127768927614\n",
      "Recompensa por acortar distancias: +  0.9036563934526256\n",
      "Penalización por duración del episodio: -  0.34436900024441613\n",
      "Recompensa por acortar distancias: +  0.9036563934526256\n",
      "Penalización por parar muy lejos: -  0.14660609758785942\n",
      "Penalización por duración del episodio: -  0.3447211978401113\n",
      "Recompensa por acortar distancias: +  0.9036563934526256\n",
      "Penalización por duración del episodio: -  0.34483497756504367\n",
      "Recompensa por acortar distancias: +  0.902728642847416\n",
      "Penalización por duración del episodio: -  0.3450760500241502\n",
      "Recompensa por acortar distancias: +  0.9027059338939109\n",
      "Penalización por parar muy lejos: -  0.14525142487620288\n",
      "Penalización por duración del episodio: -  0.34543931757996627\n",
      "Step: 8580, Mean Reward (últimos 10 pasos): 0.4120151996612549\n",
      "Recompensa por acortar distancias: +  0.9027059338939109\n",
      "Penalización por duración del episodio: -  0.34552536150277186\n",
      "Recompensa por acortar distancias: +  0.9027059338939109\n",
      "Penalización por parar muy lejos: -  0.14525142487620288\n",
      "Penalización por duración del episodio: -  0.3457942114647106\n",
      "Recompensa por acortar distancias: +  0.9026389561963909\n",
      "Penalización por duración del episodio: -  0.3458995814203933\n",
      "Recompensa por acortar distancias: +  0.9026088807799296\n",
      "Penalización por parar muy lejos: -  0.1451143454584158\n",
      "Penalización por duración del episodio: -  0.3460017564443484\n",
      "Recompensa por acortar distancias: +  0.9026088807799296\n",
      "Penalización por duración del episodio: -  0.34612614970746136\n",
      "Recompensa por acortar distancias: +  0.9025738829519601\n",
      "Penalización por duración del episodio: -  0.34626101242822255\n",
      "Recompensa por acortar distancias: +  0.9025738829519601\n",
      "Penalización por parar muy lejos: -  0.14506497018025874\n",
      "Penalización por duración del episodio: -  0.34650550766782034\n",
      "Recompensa por acortar distancias: +  0.9025738829519601\n",
      "Penalización por duración del episodio: -  0.34686237483319615\n",
      "Recompensa por acortar distancias: +  0.9025738829519601\n",
      "Penalización por duración del episodio: -  0.3472149452007222\n",
      "Recompensa por acortar distancias: +  0.9025738829519601\n",
      "Penalización por parar muy lejos: -  0.14506497018025874\n",
      "Penalización por duración del episodio: -  0.34756885103398616\n",
      "Step: 8590, Mean Reward (últimos 10 pasos): 0.40994006395339966\n",
      "Recompensa por acortar distancias: +  0.9021140366397418\n",
      "Penalización por parar muy lejos: -  0.1444189691265497\n",
      "Penalización por duración del episodio: -  0.3476688995036605\n",
      "Recompensa por acortar distancias: +  0.9021140366397418\n",
      "Penalización por parar muy lejos: -  0.1444189691265497\n",
      "Penalización por duración del episodio: -  0.34773902903973103\n",
      "Recompensa por acortar distancias: +  0.9021140366397418\n",
      "Penalización por duración del episodio: -  0.34791655348299894\n",
      "steer input from model: 0.25 , throttle:  0.3\n",
      "reward: 0.5541974831567429\n",
      "Recompensa por acortar distancias: +  0.9021140366397418\n",
      "Penalización por duración del episodio: -  0.34827312530870336\n",
      "Recompensa por acortar distancias: +  0.9018427450360877\n",
      "Penalización por duración del episodio: -  0.3483679263118664\n",
      "Recompensa por acortar distancias: +  0.9017737932709472\n",
      "Penalización por parar muy lejos: -  0.14394426048190034\n",
      "Penalización por duración del episodio: -  0.348479752483767\n",
      "Recompensa por acortar distancias: +  0.9017737932709472\n",
      "Penalización por duración del episodio: -  0.34858841198171525\n",
      "Recompensa por acortar distancias: +  0.9017737932709472\n",
      "Penalización por parar muy lejos: -  0.14394426048190034\n",
      "Penalización por duración del episodio: -  0.34869832718629257\n",
      "Recompensa por acortar distancias: +  0.9017737932709472\n",
      "Penalización por duración del episodio: -  0.34899537526105495\n",
      "Recompensa por acortar distancias: +  0.9017737932709472\n",
      "Penalización por duración del episodio: -  0.34935786353389137\n",
      "Step: 8600, Mean Reward (últimos 10 pasos): 0.5524159073829651\n",
      "Recompensa por acortar distancias: +  0.9013455742366985\n",
      "Penalización por duración del episodio: -  0.34949642914286927\n",
      "Recompensa por acortar distancias: +  0.9013455742366985\n",
      "Penalización por parar muy lejos: -  0.14335072157720405\n",
      "Penalización por duración del episodio: -  0.3496213691931384\n",
      "Recompensa por acortar distancias: +  0.901305951725531\n",
      "Penalización por parar muy lejos: -  0.14329602119388185\n",
      "Penalización por duración del episodio: -  0.34974241507059034\n",
      "Recompensa por acortar distancias: +  0.901305951725531\n",
      "Penalización por parar muy lejos: -  0.14329602119388185\n",
      "Penalización por duración del episodio: -  0.34984366476232337\n",
      "Recompensa por acortar distancias: +  0.901305951725531\n",
      "Penalización por duración del episodio: -  0.35006866190415936\n",
      "Recompensa por acortar distancias: +  0.901305951725531\n",
      "Penalización por duración del episodio: -  0.3504263029174069\n",
      "Recompensa por acortar distancias: +  0.9012435184890366\n",
      "Penalización por duración del episodio: -  0.3505141179353351\n",
      "Recompensa por acortar distancias: +  0.9012435184890366\n",
      "Penalización por parar muy lejos: -  0.14320990465420994\n",
      "Penalización por duración del episodio: -  0.35077527816988635\n",
      "Recompensa por acortar distancias: +  0.9012377973968335\n",
      "Penalización por parar muy lejos: -  0.14320201791434792\n",
      "Penalización por duración del episodio: -  0.35087156108646445\n",
      "Recompensa por acortar distancias: +  0.9012377973968335\n",
      "Penalización por parar muy lejos: -  0.14320201791434792\n",
      "Penalización por duración del episodio: -  0.35113905800292894\n",
      "Step: 8610, Mean Reward (últimos 10 pasos): 0.406896710395813\n",
      "Recompensa por acortar distancias: +  0.9012377973968335\n",
      "Penalización por duración del episodio: -  0.35148804377229004\n",
      "Recompensa por acortar distancias: +  0.9012377973968335\n",
      "Penalización por duración del episodio: -  0.3515957979759353\n",
      "Recompensa por acortar distancias: +  0.9011612472910375\n",
      "Penalización por duración del episodio: -  0.3518590511348079\n",
      "steer input from model: 0.9 , throttle:  0.3\n",
      "reward: 0.5493021961562297\n",
      "Recompensa por acortar distancias: +  0.9011333356153213\n",
      "Penalización por parar muy lejos: -  0.143058148445568\n",
      "Penalización por duración del episodio: -  0.3522103876308077\n",
      "Recompensa por acortar distancias: +  0.9011333356153213\n",
      "Penalización por duración del episodio: -  0.35232417311654574\n",
      "Recompensa por acortar distancias: +  0.9011333356153213\n",
      "Penalización por parar muy lejos: -  0.143058148445568\n",
      "Penalización por duración del episodio: -  0.3525779605096518\n",
      "Recompensa por acortar distancias: +  0.9009561107401064\n",
      "Penalización por duración del episodio: -  0.3526729998404724\n",
      "Recompensa por acortar distancias: +  0.9009561107401064\n",
      "Penalización por duración del episodio: -  0.35278137152886285\n",
      "Recompensa por acortar distancias: +  0.9009048387290668\n",
      "Penalización por duración del episodio: -  0.35293187265809256\n",
      "Recompensa por acortar distancias: +  0.9008314284879378\n",
      "Penalización por parar muy lejos: -  0.14264378240627035\n",
      "Penalización por duración del episodio: -  0.35328070594962696\n",
      "Step: 8620, Mean Reward (últimos 10 pasos): 0.4049069285392761\n",
      "Recompensa por acortar distancias: +  0.9008314284879378\n",
      "Penalización por duración del episodio: -  0.3536570915687515\n",
      "Recompensa por acortar distancias: +  0.9008314284879378\n",
      "Penalización por duración del episodio: -  0.3540078143130804\n",
      "Recompensa por acortar distancias: +  0.9003628755257594\n",
      "Penalización por duración del episodio: -  0.3541483710072769\n",
      "Recompensa por acortar distancias: +  0.9003628755257594\n",
      "Penalización por parar muy lejos: -  0.1420048842501038\n",
      "Penalización por duración del episodio: -  0.3543765259467196\n",
      "Recompensa por acortar distancias: +  0.9002443723465865\n",
      "Penalización por parar muy lejos: -  0.14184409963450892\n",
      "Penalización por duración del episodio: -  0.35473505804712396\n",
      "Recompensa por acortar distancias: +  0.9002443723465865\n",
      "Penalización por duración del episodio: -  0.355083734640271\n",
      "Recompensa por acortar distancias: +  0.8997158677389162\n",
      "Penalización por parar muy lejos: -  0.14113092747503006\n",
      "Penalización por duración del episodio: -  0.3551912611696588\n",
      "Recompensa por acortar distancias: +  0.8996256884910642\n",
      "Penalización por parar muy lejos: -  0.14100987072277113\n",
      "Penalización por duración del episodio: -  0.3554260652104959\n",
      "Recompensa por acortar distancias: +  0.8996256884910642\n",
      "Penalización por duración del episodio: -  0.3557773033762584\n",
      "Recompensa por acortar distancias: +  0.8996256884910642\n",
      "Penalización por parar muy lejos: -  0.14100987072277113\n",
      "Penalización por duración del episodio: -  0.35585424795623244\n",
      "Step: 8630, Mean Reward (últimos 10 pasos): 0.4027615785598755\n",
      "Recompensa por acortar distancias: +  0.8996256884910642\n",
      "Penalización por duración del episodio: -  0.3561459015865354\n",
      "Recompensa por acortar distancias: +  0.8987477970628646\n",
      "Penalización por duración del episodio: -  0.3562546219055885\n",
      "Recompensa por acortar distancias: +  0.8987477970628646\n",
      "Penalización por duración del episodio: -  0.3563753879920409\n",
      "steer input from model: 0.1 , throttle:  0.7\n",
      "reward: 0.5423724090708237\n",
      "Recompensa por acortar distancias: +  0.8985541076850598\n",
      "Penalización por parar muy lejos: -  0.13958529364959302\n",
      "Penalización por duración del episodio: -  0.35646110827364164\n",
      "Recompensa por acortar distancias: +  0.8985541076850598\n",
      "Penalización por duración del episodio: -  0.3568624160165423\n",
      "Recompensa por acortar distancias: +  0.8985541076850598\n",
      "Penalización por parar muy lejos: -  0.13958529364959302\n",
      "Penalización por duración del episodio: -  0.35722450224406405\n",
      "Recompensa por acortar distancias: +  0.8982174435212975\n",
      "Penalización por parar muy lejos: -  0.1391429599766578\n",
      "Penalización por duración del episodio: -  0.357316095040184\n",
      "Recompensa por acortar distancias: +  0.8982111919972263\n",
      "Penalización por duración del episodio: -  0.3574459962074133\n",
      "Recompensa por acortar distancias: +  0.8982086721095259\n",
      "Penalización por duración del episodio: -  0.35758344901689804\n",
      "Recompensa por acortar distancias: +  0.8982086721095259\n",
      "Penalización por duración del episodio: -  0.35795369516755404\n",
      "Step: 8640, Mean Reward (últimos 10 pasos): 0.5402549505233765\n",
      "Recompensa por acortar distancias: +  0.8982086721095259\n",
      "Penalización por duración del episodio: -  0.35830228766066435\n",
      "Recompensa por acortar distancias: +  0.8982086721095259\n",
      "Penalización por parar muy lejos: -  0.1391314685141317\n",
      "Penalización por duración del episodio: -  0.35845948144017703\n",
      "Recompensa por acortar distancias: +  0.8982086721095259\n",
      "Penalización por duración del episodio: -  0.3586340513525236\n",
      "Recompensa por acortar distancias: +  0.8980650736420347\n",
      "Penalización por parar muy lejos: -  0.13894357727639112\n",
      "Penalización por duración del episodio: -  0.3587878098402926\n",
      "Recompensa por acortar distancias: +  0.8980650736420347\n",
      "Penalización por parar muy lejos: -  0.13894357727639112\n",
      "Penalización por duración del episodio: -  0.35888914671115796\n",
      "Recompensa por acortar distancias: +  0.8979701357331884\n",
      "Penalización por parar muy lejos: -  0.1388196014082115\n",
      "Penalización por duración del episodio: -  0.35936422200484036\n",
      "Recompensa por acortar distancias: +  0.8979701357331884\n",
      "Penalización por parar muy lejos: -  0.1388196014082115\n",
      "Penalización por duración del episodio: -  0.3597292554554443\n",
      "Recompensa por acortar distancias: +  0.8976012324216852\n",
      "Penalización por duración del episodio: -  0.36008894102259265\n",
      "Recompensa por acortar distancias: +  0.8975219736216499\n",
      "Penalización por duración del episodio: -  0.3604586714089402\n",
      "Recompensa por acortar distancias: +  0.8975219736216499\n",
      "Penalización por duración del episodio: -  0.36081835637823023\n",
      "Step: 8650, Mean Reward (últimos 10 pasos): 0.5367036461830139\n",
      "Recompensa por acortar distancias: +  0.8970012012935267\n",
      "Penalización por duración del episodio: -  0.3611870707203006\n",
      "Recompensa por acortar distancias: +  0.8968639728040377\n",
      "Penalización por parar muy lejos: -  0.13738934989129703\n",
      "Penalización por duración del episodio: -  0.36154480972017444\n",
      "Recompensa por acortar distancias: +  0.8968639728040377\n",
      "Penalización por parar muy lejos: -  0.13738934989129703\n",
      "Penalización por duración del episodio: -  0.3619001035870576\n",
      "steer input from model: 0.25 , throttle:  0.0\n",
      "reward: 0.3975745193256831\n",
      "Recompensa por acortar distancias: +  0.8966918905251992\n",
      "Penalización por duración del episodio: -  0.36227047558313624\n",
      "Recompensa por acortar distancias: +  0.8966907067077341\n",
      "Penalización por duración del episodio: -  0.3626255595462951\n",
      "Recompensa por acortar distancias: +  0.8966907067077341\n",
      "Penalización por duración del episodio: -  0.36298058947772815\n",
      "Recompensa por acortar distancias: +  0.896652924259425\n",
      "Penalización por parar muy lejos: -  0.13711941355010748\n",
      "Penalización por duración del episodio: -  0.3630750188520617\n",
      "Recompensa por acortar distancias: +  0.896652924259425\n",
      "Penalización por duración del episodio: -  0.36335027387131213\n",
      "Recompensa por acortar distancias: +  0.8966274654640848\n",
      "Penalización por duración del episodio: -  0.363720285329239\n",
      "Recompensa por acortar distancias: +  0.8966274654640848\n",
      "Penalización por parar muy lejos: -  0.13708691422681374\n",
      "Penalización por duración del episodio: -  0.36383109839980393\n",
      "Step: 8660, Mean Reward (últimos 10 pasos): 0.39570945501327515\n",
      "Recompensa por acortar distancias: +  0.8966291714342348\n",
      "Penalización por duración del episodio: -  0.3640892768040699\n",
      "Recompensa por acortar distancias: +  0.8966291493363351\n",
      "Penalización por parar muy lejos: -  0.1370890633483975\n",
      "Penalización por duración del episodio: -  0.3642713810983011\n",
      "Recompensa por acortar distancias: +  0.896629759236833\n",
      "Penalización por duración del episodio: -  0.3644152105711582\n",
      "Recompensa por acortar distancias: +  0.896629759236833\n",
      "Penalización por parar muy lejos: -  0.13708984177737968\n",
      "Penalización por duración del episodio: -  0.3648268993710917\n",
      "Recompensa por acortar distancias: +  0.8966180468230184\n",
      "Penalización por parar muy lejos: -  0.13707489433438774\n",
      "Penalización por duración del episodio: -  0.36519870715813996\n",
      "Recompensa por acortar distancias: +  0.8966180468230184\n",
      "Penalización por duración del episodio: -  0.365326893052081\n",
      "Recompensa por acortar distancias: +  0.8966180468230184\n",
      "Penalización por parar muy lejos: -  0.13707489433438774\n",
      "Penalización por duración del episodio: -  0.3655613141975445\n",
      "Recompensa por acortar distancias: +  0.8965056673574487\n",
      "Penalización por parar muy lejos: -  0.136931620777352\n",
      "Penalización por duración del episodio: -  0.36592201034645444\n",
      "Recompensa por acortar distancias: +  0.8964709937946825\n",
      "Penalización por duración del episodio: -  0.3662950487727423\n",
      "Recompensa por acortar distancias: +  0.8964709937946825\n",
      "Penalización por duración del episodio: -  0.36665069667387956\n",
      "Step: 8670, Mean Reward (últimos 10 pasos): 0.5298203229904175\n",
      "Recompensa por acortar distancias: +  0.8962834034218132\n",
      "Penalización por parar muy lejos: -  0.1366490294470223\n",
      "Penalización por duración del episodio: -  0.36701540182244935\n",
      "Recompensa por acortar distancias: +  0.8962834034218132\n",
      "Penalización por duración del episodio: -  0.3673911643323527\n",
      "Recompensa por acortar distancias: +  0.8962834034218132\n",
      "Penalización por duración del episodio: -  0.367755618452027\n",
      "steer input from model: 0.25 , throttle:  1.0\n",
      "reward: 0.5285277849697863\n",
      "Recompensa por acortar distancias: +  0.8960117667586364\n",
      "Penalización por parar muy lejos: -  0.13630505533219117\n",
      "Penalización por duración del episodio: -  0.36810988087192603\n",
      "Recompensa por acortar distancias: +  0.8960117667586364\n",
      "Penalización por parar muy lejos: -  0.13630505533219117\n",
      "Penalización por duración del episodio: -  0.3684736173913203\n",
      "Recompensa por acortar distancias: +  0.8957708566533228\n",
      "Penalización por parar muy lejos: -  0.13600126272065333\n",
      "Penalización por duración del episodio: -  0.36882785716670863\n",
      "Recompensa por acortar distancias: +  0.8957066367337179\n",
      "Penalización por duración del episodio: -  0.36896354311228274\n",
      "Recompensa por acortar distancias: +  0.8956205456854501\n",
      "Penalización por duración del episodio: -  0.36907971274260226\n",
      "Recompensa por acortar distancias: +  0.8956205456854501\n",
      "Penalización por parar muy lejos: -  0.13581232018840028\n",
      "Penalización por duración del episodio: -  0.3692564555790933\n",
      "Recompensa por acortar distancias: +  0.8955744130377825\n",
      "Penalización por duración del episodio: -  0.3693882859741385\n",
      "Step: 8680, Mean Reward (últimos 10 pasos): 0.5261861085891724\n",
      "Recompensa por acortar distancias: +  0.8955744130377825\n",
      "Penalización por parar muy lejos: -  0.1357544234975664\n",
      "Penalización por duración del episodio: -  0.36949752910084016\n",
      "Recompensa por acortar distancias: +  0.8955744130377825\n",
      "Penalización por duración del episodio: -  0.3699069889265094\n",
      "Recompensa por acortar distancias: +  0.8955744130377825\n",
      "Penalización por duración del episodio: -  0.3702741235242348\n",
      "Recompensa por acortar distancias: +  0.8955090331985854\n",
      "Penalización por parar muy lejos: -  0.13567244578961576\n",
      "Penalización por duración del episodio: -  0.3706414470934271\n",
      "Recompensa por acortar distancias: +  0.8954803665476981\n",
      "Penalización por duración del episodio: -  0.3709973088643291\n",
      "Recompensa por acortar distancias: +  0.8953845970950611\n",
      "Penalización por duración del episodio: -  0.37135403983417137\n",
      "Recompensa por acortar distancias: +  0.8953125068631138\n",
      "Penalización por duración del episodio: -  0.37171514285794627\n",
      "Recompensa por acortar distancias: +  0.8953125068631138\n",
      "Penalización por duración del episodio: -  0.3720705960911773\n",
      "Recompensa por acortar distancias: +  0.8953125068631138\n",
      "Penalización por parar muy lejos: -  0.135426550882803\n",
      "Penalización por duración del episodio: -  0.3724372490972288\n",
      "Recompensa por acortar distancias: +  0.8950255753206652\n",
      "Penalización por duración del episodio: -  0.3725422912389044\n",
      "Step: 8690, Mean Reward (últimos 10 pasos): 0.5224832892417908\n",
      "Recompensa por acortar distancias: +  0.8949424536174813\n",
      "Penalización por parar muy lejos: -  0.1349656585541729\n",
      "Penalización por duración del episodio: -  0.37267134085364484\n",
      "Recompensa por acortar distancias: +  0.8949424536174813\n",
      "Penalización por duración del episodio: -  0.37281248908629777\n",
      "Recompensa por acortar distancias: +  0.8949424536174813\n",
      "Penalización por duración del episodio: -  0.3729291488158906\n",
      "steer input from model: -0.05 , throttle:  0.7\n",
      "reward: 0.5220133048015907\n",
      "Recompensa por acortar distancias: +  0.8949424536174813\n",
      "Penalización por duración del episodio: -  0.37317423536361044\n",
      "Recompensa por acortar distancias: +  0.8949424536174813\n",
      "Penalización por duración del episodio: -  0.3732809401929952\n",
      "Recompensa por acortar distancias: +  0.8947237890150088\n",
      "Penalización por duración del episodio: -  0.37354082684112566\n",
      "Recompensa por acortar distancias: +  0.894634231274748\n",
      "Penalización por parar muy lejos: -  0.13458387455036286\n",
      "Penalización por duración del episodio: -  0.37366422995345433\n",
      "Recompensa por acortar distancias: +  0.894634231274748\n",
      "Penalización por duración del episodio: -  0.3737699812623657\n",
      "Recompensa por acortar distancias: +  0.8945502469652876\n",
      "Penalización por duración del episodio: -  0.37389852180878813\n",
      "Recompensa por acortar distancias: +  0.8945502469652876\n",
      "Penalización por parar muy lejos: -  0.1344801749400609\n",
      "Penalización por duración del episodio: -  0.3740353193946974\n",
      "Step: 8700, Mean Reward (últimos 10 pasos): 0.38603475689888\n",
      "Recompensa por acortar distancias: +  0.8945502469652876\n",
      "Penalización por parar muy lejos: -  0.1344801749400609\n",
      "Penalización por duración del episodio: -  0.37415706318309166\n",
      "Recompensa por acortar distancias: +  0.8945502469652876\n",
      "Penalización por duración del episodio: -  0.3742868410234981\n",
      "Recompensa por acortar distancias: +  0.8945502469652876\n",
      "Penalización por duración del episodio: -  0.3746356792065304\n",
      "Recompensa por acortar distancias: +  0.8945502469652876\n",
      "Penalización por parar muy lejos: -  0.1344801749400609\n",
      "Penalización por duración del episodio: -  0.3750134590338747\n",
      "Recompensa por acortar distancias: +  0.8944912005073533\n",
      "Penalización por parar muy lejos: -  0.13440735132171802\n",
      "Penalización por duración del episodio: -  0.37514332792004335\n",
      "Recompensa por acortar distancias: +  0.8944912005073533\n",
      "Penalización por duración del episodio: -  0.3753691756866092\n",
      "Recompensa por acortar distancias: +  0.8944912005073533\n",
      "Penalización por parar muy lejos: -  0.13440735132171802\n",
      "Penalización por duración del episodio: -  0.3757449355087702\n",
      "Recompensa por acortar distancias: +  0.8944903634613849\n",
      "Penalización por duración del episodio: -  0.3761112670996893\n",
      "Recompensa por acortar distancias: +  0.8944796703588557\n",
      "Penalización por duración del episodio: -  0.37647160649708244\n",
      "Recompensa por acortar distancias: +  0.8944796703588557\n",
      "Penalización por parar muy lejos: -  0.13439313895510535\n",
      "Penalización por duración del episodio: -  0.3768287065476637\n",
      "Step: 8710, Mean Reward (últimos 10 pasos): 0.38325783610343933\n",
      "Recompensa por acortar distancias: +  0.8944796703588557\n",
      "Penalización por parar muy lejos: -  0.13439313895510535\n",
      "Penalización por duración del episodio: -  0.3772016341337401\n",
      "Recompensa por acortar distancias: +  0.8944527578552173\n",
      "Penalización por parar muy lejos: -  0.13435997615729758\n",
      "Penalización por duración del episodio: -  0.37755530935315906\n",
      "Recompensa por acortar distancias: +  0.8944528073736606\n",
      "Penalización por duración del episodio: -  0.3779263675370286\n",
      "steer input from model: -0.25 , throttle:  0.3\n",
      "reward: 0.516526439836632\n",
      "Recompensa por acortar distancias: +  0.8944528073736606\n",
      "Penalización por parar muy lejos: -  0.13436003716295422\n",
      "Penalización por duración del episodio: -  0.3780201578709378\n",
      "Recompensa por acortar distancias: +  0.8944530189522332\n",
      "Penalización por parar muy lejos: -  0.13436029782375064\n",
      "Penalización por duración del episodio: -  0.37812594360185525\n",
      "Recompensa por acortar distancias: +  0.8944530189522332\n",
      "Penalización por duración del episodio: -  0.37822753573132467\n",
      "Recompensa por acortar distancias: +  0.8944363301061954\n",
      "Penalización por duración del episodio: -  0.37866119402373183\n",
      "Recompensa por acortar distancias: +  0.894438671276992\n",
      "Penalización por parar muy lejos: -  0.13434262377098133\n",
      "Penalización por duración del episodio: -  0.37874625927657823\n",
      "Recompensa por acortar distancias: +  0.894438671276992\n",
      "Penalización por duración del episodio: -  0.37886456308590066\n",
      "Recompensa por acortar distancias: +  0.894438671276992\n",
      "Penalización por duración del episodio: -  0.3789894689908576\n",
      "Step: 8720, Mean Reward (últimos 10 pasos): 0.5154492259025574\n",
      "Recompensa por acortar distancias: +  0.894438671276992\n",
      "Penalización por duración del episodio: -  0.3791174944128029\n",
      "Recompensa por acortar distancias: +  0.894438671276992\n",
      "Penalización por parar muy lejos: -  0.13434262377098133\n",
      "Penalización por duración del episodio: -  0.37921732147864934\n",
      "Recompensa por acortar distancias: +  0.894438671276992\n",
      "Penalización por duración del episodio: -  0.37936676408742154\n",
      "Recompensa por acortar distancias: +  0.894438671276992\n",
      "Penalización por duración del episodio: -  0.37947653119513536\n",
      "Recompensa por acortar distancias: +  0.894438671276992\n",
      "Penalización por duración del episodio: -  0.3797960616395021\n",
      "Recompensa por acortar distancias: +  0.8943816057043659\n",
      "Penalización por parar muy lejos: -  0.13427236846068086\n",
      "Penalización por duración del episodio: -  0.37992672036161407\n",
      "Recompensa por acortar distancias: +  0.8943816057043659\n",
      "Penalización por parar muy lejos: -  0.13427236846068086\n",
      "Penalización por duración del episodio: -  0.38016072966668607\n",
      "Recompensa por acortar distancias: +  0.8943816057043659\n",
      "Penalización por duración del episodio: -  0.38054049955917246\n",
      "Recompensa por acortar distancias: +  0.894338653493481\n",
      "Penalización por parar muy lejos: -  0.1342195311192348\n",
      "Penalización por duración del episodio: -  0.38063742514202775\n",
      "Recompensa por acortar distancias: +  0.894335724577605\n",
      "Penalización por duración del episodio: -  0.3809211859520583\n",
      "Step: 8730, Mean Reward (últimos 10 pasos): 0.5134145617485046\n",
      "Recompensa por acortar distancias: +  0.8943359724117211\n",
      "Penalización por parar muy lejos: -  0.13421623421713288\n",
      "Penalización por duración del episodio: -  0.3812955449220888\n",
      "Recompensa por acortar distancias: +  0.8943359724117211\n",
      "Penalización por parar muy lejos: -  0.13421623421713288\n",
      "Penalización por duración del episodio: -  0.38167317339271134\n",
      "Recompensa por acortar distancias: +  0.8943359724117211\n",
      "Penalización por duración del episodio: -  0.38177989975234233\n",
      "steer input from model: 0.25 , throttle:  0.3\n",
      "reward: 0.5125560726593787\n",
      "Recompensa por acortar distancias: +  0.8942730466493739\n",
      "Penalización por duración del episodio: -  0.38204569328129095\n",
      "Recompensa por acortar distancias: +  0.8942446942496028\n",
      "Penalización por parar muy lejos: -  0.13410407505210903\n",
      "Penalización por duración del episodio: -  0.3821846541851657\n",
      "Recompensa por acortar distancias: +  0.8942446942496028\n",
      "Penalización por parar muy lejos: -  0.13410407505210903\n",
      "Penalización por duración del episodio: -  0.3824231155899601\n",
      "Recompensa por acortar distancias: +  0.8942446942496028\n",
      "Penalización por parar muy lejos: -  0.13410407505210903\n",
      "Penalización por duración del episodio: -  0.3827950637174471\n",
      "Recompensa por acortar distancias: +  0.8941555669130282\n",
      "Penalización por parar muy lejos: -  0.13399471743168775\n",
      "Penalización por duración del episodio: -  0.3831575189437789\n",
      "Recompensa por acortar distancias: +  0.8940765072985208\n",
      "Penalización por duración del episodio: -  0.383544839517222\n",
      "Recompensa por acortar distancias: +  0.8940765072985208\n",
      "Penalización por duración del episodio: -  0.3839182380346635\n",
      "Step: 8740, Mean Reward (últimos 10 pasos): 0.5101582407951355\n",
      "Recompensa por acortar distancias: +  0.8940765072985208\n",
      "Penalización por duración del episodio: -  0.3841043766927364\n",
      "Recompensa por acortar distancias: +  0.8940765072985208\n",
      "Penalización por parar muy lejos: -  0.13389784368161042\n",
      "Penalización por duración del episodio: -  0.38427618677433373\n",
      "Recompensa por acortar distancias: +  0.8940765072985208\n",
      "Penalización por duración del episodio: -  0.3843876793792542\n",
      "Recompensa por acortar distancias: +  0.8937022413287414\n",
      "Penalización por parar muy lejos: -  0.13344090984946447\n",
      "Penalización por duración del episodio: -  0.38451762931548233\n",
      "Recompensa por acortar distancias: +  0.8937022413287414\n",
      "Penalización por parar muy lejos: -  0.13344090984946447\n",
      "Penalización por duración del episodio: -  0.38467553005582206\n",
      "Recompensa por acortar distancias: +  0.8936626844316083\n",
      "Penalización por parar muy lejos: -  0.13339277551426923\n",
      "Penalización por duración del episodio: -  0.38484416792222936\n",
      "Recompensa por acortar distancias: +  0.8936626844316083\n",
      "Penalización por parar muy lejos: -  0.13339277551426923\n",
      "Penalización por duración del episodio: -  0.38497805945324526\n",
      "Recompensa por acortar distancias: +  0.8936626844316083\n",
      "Penalización por duración del episodio: -  0.3854093005407567\n",
      "Recompensa por acortar distancias: +  0.8936133776027202\n",
      "Penalización por duración del episodio: -  0.38551631859293467\n",
      "Recompensa por acortar distancias: +  0.8936133776027202\n",
      "Penalización por duración del episodio: -  0.38563279215941276\n",
      "Step: 8750, Mean Reward (últimos 10 pasos): 0.5079805850982666\n",
      "Recompensa por acortar distancias: +  0.8936174982291843\n",
      "Penalización por duración del episodio: -  0.38614893857467414\n",
      "Recompensa por acortar distancias: +  0.8936174982291843\n",
      "Penalización por parar muy lejos: -  0.1333378284909672\n",
      "Penalización por duración del episodio: -  0.386516950852252\n",
      "Recompensa por acortar distancias: +  0.8936174982291843\n",
      "Penalización por duración del episodio: -  0.3866267799488651\n",
      "steer input from model: 0.1 , throttle:  0.7\n",
      "reward: 0.5069907182803193\n",
      "Recompensa por acortar distancias: +  0.8935593068563773\n",
      "Penalización por parar muy lejos: -  0.1332671254827945\n",
      "Penalización por duración del episodio: -  0.3867484105020605\n",
      "Recompensa por acortar distancias: +  0.8935593068563773\n",
      "Penalización por duración del episodio: -  0.38725542901718196\n",
      "Recompensa por acortar distancias: +  0.8935310126590286\n",
      "Penalización por duración del episodio: -  0.38762012869741347\n",
      "Recompensa por acortar distancias: +  0.8934493632477144\n",
      "Penalización por parar muy lejos: -  0.133133722452613\n",
      "Penalización por duración del episodio: -  0.3877326823857431\n",
      "Recompensa por acortar distancias: +  0.89340091841724\n",
      "Penalización por duración del episodio: -  0.38788971839142233\n",
      "Recompensa por acortar distancias: +  0.8933478883776239\n",
      "Penalización por duración del episodio: -  0.3883775087188446\n",
      "Recompensa por acortar distancias: +  0.8933478883776239\n",
      "Penalización por duración del episodio: -  0.3884612114715398\n",
      "Step: 8760, Mean Reward (últimos 10 pasos): 0.5048866868019104\n",
      "Recompensa por acortar distancias: +  0.8933478883776239\n",
      "Penalización por parar muy lejos: -  0.13301080293052456\n",
      "Penalización por duración del episodio: -  0.3885860330520827\n",
      "Recompensa por acortar distancias: +  0.8933478883776239\n",
      "Penalización por parar muy lejos: -  0.13301080293052456\n",
      "Penalización por duración del episodio: -  0.3887085805180021\n",
      "Recompensa por acortar distancias: +  0.8933478883776239\n",
      "Penalización por duración del episodio: -  0.38888545593111595\n",
      "Recompensa por acortar distancias: +  0.8933478883776239\n",
      "Penalización por duración del episodio: -  0.38912286928650797\n",
      "Recompensa por acortar distancias: +  0.8929009117649673\n",
      "Penalización por duración del episodio: -  0.3892430410308187\n",
      "Recompensa por acortar distancias: +  0.8929009117649673\n",
      "Penalización por duración del episodio: -  0.3893521044414526\n",
      "Recompensa por acortar distancias: +  0.8927987946909892\n",
      "Penalización por parar muy lejos: -  0.13234910755458262\n",
      "Penalización por duración del episodio: -  0.38946210299549927\n",
      "Recompensa por acortar distancias: +  0.8927987946909892\n",
      "Penalización por duración del episodio: -  0.3895906869935985\n",
      "Recompensa por acortar distancias: +  0.8927987946909892\n",
      "Penalización por parar muy lejos: -  0.13234910755458262\n",
      "Penalización por duración del episodio: -  0.3897257167164438\n",
      "Recompensa por acortar distancias: +  0.8927987946909892\n",
      "Penalización por duración del episodio: -  0.3898308989740884\n",
      "Step: 8770, Mean Reward (últimos 10 pasos): 0.502967894077301\n",
      "Recompensa por acortar distancias: +  0.8927987946909892\n",
      "Penalización por duración del episodio: -  0.3899448088309155\n",
      "Recompensa por acortar distancias: +  0.8927987946909892\n",
      "Penalización por duración del episodio: -  0.39006991082820597\n",
      "Recompensa por acortar distancias: +  0.8923408387895041\n",
      "Penalización por duración del episodio: -  0.39023384265148503\n",
      "steer input from model: -0.05 , throttle:  0.3\n",
      "reward: 0.5021069961380191\n",
      "Recompensa por acortar distancias: +  0.8923408387895041\n",
      "Penalización por parar muy lejos: -  0.1318016391610284\n",
      "Penalización por duración del episodio: -  0.3905976183484174\n",
      "Recompensa por acortar distancias: +  0.8922050357240604\n",
      "Penalización por parar muy lejos: -  0.13164005420466418\n",
      "Penalización por duración del episodio: -  0.3907401692732999\n",
      "Recompensa por acortar distancias: +  0.8922050357240604\n",
      "Penalización por parar muy lejos: -  0.13164005420466418\n",
      "Penalización por duración del episodio: -  0.39095686627742565\n",
      "Recompensa por acortar distancias: +  0.8922050357240604\n",
      "Penalización por duración del episodio: -  0.39105500287840406\n",
      "Recompensa por acortar distancias: +  0.8922050357240604\n",
      "Penalización por parar muy lejos: -  0.13164005420466418\n",
      "Penalización por duración del episodio: -  0.39133757942121306\n",
      "Recompensa por acortar distancias: +  0.8922050357240604\n",
      "Penalización por parar muy lejos: -  0.13164005420466418\n",
      "Penalización por duración del episodio: -  0.3914442523511262\n",
      "Recompensa por acortar distancias: +  0.8922050357240604\n",
      "Penalización por parar muy lejos: -  0.13164005420466418\n",
      "Penalización por duración del episodio: -  0.3915889131614463\n",
      "Step: 8780, Mean Reward (últimos 10 pasos): 0.36897605657577515\n",
      "Recompensa por acortar distancias: +  0.8921417556495455\n",
      "Penalización por duración del episodio: -  0.3917420918270641\n",
      "Recompensa por acortar distancias: +  0.8921417556495455\n",
      "Penalización por parar muy lejos: -  0.1315648790386063\n",
      "Penalización por duración del episodio: -  0.3918737124236038\n",
      "Recompensa por acortar distancias: +  0.8921407737369846\n",
      "Penalización por duración del episodio: -  0.3919705445879428\n",
      "Recompensa por acortar distancias: +  0.8921407737369846\n",
      "Penalización por parar muy lejos: -  0.13156371314322696\n",
      "Penalización por duración del episodio: -  0.39248329649806163\n",
      "Recompensa por acortar distancias: +  0.8921392503804502\n",
      "Penalización por parar muy lejos: -  0.13156190438830648\n",
      "Penalización por duración del episodio: -  0.3925843380523404\n",
      "Recompensa por acortar distancias: +  0.8921392503804502\n",
      "Penalización por parar muy lejos: -  0.13156190438830648\n",
      "Penalización por duración del episodio: -  0.3926948842845053\n",
      "Recompensa por acortar distancias: +  0.8921392503804502\n",
      "Penalización por duración del episodio: -  0.3928742674190208\n",
      "Recompensa por acortar distancias: +  0.892124043308935\n",
      "Penalización por parar muy lejos: -  0.13154385068391297\n",
      "Penalización por duración del episodio: -  0.3929874302517573\n",
      "Recompensa por acortar distancias: +  0.892124043308935\n",
      "Penalización por duración del episodio: -  0.3932347132031696\n",
      "Recompensa por acortar distancias: +  0.892124043308935\n",
      "Penalización por parar muy lejos: -  0.13154385068391297\n",
      "Penalización por duración del episodio: -  0.39360944479845106\n",
      "Step: 8790, Mean Reward (últimos 10 pasos): 0.3669707477092743\n",
      "Recompensa por acortar distancias: +  0.892124043308935\n",
      "Penalización por duración del episodio: -  0.39374369976560764\n",
      "Recompensa por acortar distancias: +  0.892124043308935\n",
      "Penalización por duración del episodio: -  0.3938662283283791\n",
      "Recompensa por acortar distancias: +  0.892124043308935\n",
      "Penalización por duración del episodio: -  0.39403385590689266\n",
      "steer input from model: 0.1 , throttle:  0.7\n",
      "reward: 0.49809018740204236\n",
      "Recompensa por acortar distancias: +  0.8920617177678706\n",
      "Penalización por parar muy lejos: -  0.13146990365418024\n",
      "Penalización por duración del episodio: -  0.394348429817157\n",
      "Recompensa por acortar distancias: +  0.8920467857866223\n",
      "Penalización por duración del episodio: -  0.39445475945071806\n",
      "Recompensa por acortar distancias: +  0.8920467857866223\n",
      "Penalización por duración del episodio: -  0.3945796662522222\n",
      "Recompensa por acortar distancias: +  0.8920467857866223\n",
      "Penalización por parar muy lejos: -  0.13145219820186196\n",
      "Penalización por duración del episodio: -  0.3946898111684711\n",
      "Recompensa por acortar distancias: +  0.8920467857866223\n",
      "Penalización por parar muy lejos: -  0.13145219820186196\n",
      "Penalización por duración del episodio: -  0.39509326586711313\n",
      "Recompensa por acortar distancias: +  0.892046381697939\n",
      "Penalización por parar muy lejos: -  0.1314517191156523\n",
      "Penalización por duración del episodio: -  0.39545505412277215\n",
      "Recompensa por acortar distancias: +  0.892046381697939\n",
      "Penalización por duración del episodio: -  0.3955682650699364\n",
      "Step: 8800, Mean Reward (últimos 10 pasos): 0.4964781105518341\n",
      "Recompensa por acortar distancias: +  0.892046381697939\n",
      "Penalización por duración del episodio: -  0.3958349287348038\n",
      "Recompensa por acortar distancias: +  0.892046381697939\n",
      "Penalización por parar muy lejos: -  0.1314517191156523\n",
      "Penalización por duración del episodio: -  0.39621110765346845\n",
      "Recompensa por acortar distancias: +  0.8920468730328681\n",
      "Penalización por duración del episodio: -  0.39630635661876434\n",
      "Recompensa por acortar distancias: +  0.8920468730328681\n",
      "Penalización por parar muy lejos: -  0.13145230164112445\n",
      "Penalización por duración del episodio: -  0.3964371649308053\n",
      "Recompensa por acortar distancias: +  0.892046891400491\n",
      "Penalización por duración del episodio: -  0.39655088339369254\n",
      "Recompensa por acortar distancias: +  0.892046891400491\n",
      "Penalización por parar muy lejos: -  0.1314523234178201\n",
      "Penalización por duración del episodio: -  0.3966746782481725\n",
      "Recompensa por acortar distancias: +  0.892046891400491\n",
      "Penalización por parar muy lejos: -  0.1314523234178201\n",
      "Penalización por duración del episodio: -  0.39695869696906577\n",
      "Recompensa por acortar distancias: +  0.892046891400491\n",
      "Penalización por duración del episodio: -  0.3973249136519866\n",
      "Recompensa por acortar distancias: +  0.8920473597739439\n",
      "Penalización por duración del episodio: -  0.39769653940817523\n",
      "Recompensa por acortar distancias: +  0.8920475342655578\n",
      "Penalización por parar muy lejos: -  0.13145308560409644\n",
      "Penalización por duración del episodio: -  0.3980646270183537\n",
      "Step: 8810, Mean Reward (últimos 10 pasos): 0.36252981424331665\n",
      "Recompensa por acortar distancias: +  0.8920475342655578\n",
      "Penalización por parar muy lejos: -  0.13145308560409644\n",
      "Penalización por duración del episodio: -  0.398446076263564\n",
      "Recompensa por acortar distancias: +  0.8920475342655578\n",
      "Penalización por parar muy lejos: -  0.13145308560409644\n",
      "Penalización por duración del episodio: -  0.398828077578459\n",
      "Recompensa por acortar distancias: +  0.8919850228583008\n",
      "Penalización por duración del episodio: -  0.3992013788331765\n",
      "steer input from model: 0.0 , throttle:  0.3\n",
      "reward: 0.4927836440251243\n",
      "Recompensa por acortar distancias: +  0.8919850228583008\n",
      "Penalización por duración del episodio: -  0.39956601134925046\n",
      "Recompensa por acortar distancias: +  0.8919032645327531\n",
      "Penalización por parar muy lejos: -  0.13128223200138642\n",
      "Penalización por duración del episodio: -  0.39966580042760785\n",
      "Recompensa por acortar distancias: +  0.8919032645327531\n",
      "Penalización por parar muy lejos: -  0.13128223200138642\n",
      "Penalización por duración del episodio: -  0.3998344168421148\n",
      "Recompensa por acortar distancias: +  0.8918814945124197\n",
      "Penalización por duración del episodio: -  0.3999603769053983\n",
      "Recompensa por acortar distancias: +  0.8918599413864097\n",
      "Penalización por duración del episodio: -  0.4003006638885241\n",
      "Recompensa por acortar distancias: +  0.8918599413864097\n",
      "Penalización por parar muy lejos: -  0.13123100181898134\n",
      "Penalización por duración del episodio: -  0.4006642167535563\n",
      "Recompensa por acortar distancias: +  0.8918599413864097\n",
      "Penalización por duración del episodio: -  0.40079830270703937\n",
      "Step: 8820, Mean Reward (últimos 10 pasos): 0.49106162786483765\n",
      "Recompensa por acortar distancias: +  0.8918599413864097\n",
      "Penalización por parar muy lejos: -  0.13123100181898134\n",
      "Penalización por duración del episodio: -  0.4010403523020747\n",
      "Recompensa por acortar distancias: +  0.8917202811912393\n",
      "Penalización por parar muy lejos: -  0.13106608989527332\n",
      "Penalización por duración del episodio: -  0.40141640968034514\n",
      "Recompensa por acortar distancias: +  0.8916862705301911\n",
      "Penalización por parar muy lejos: -  0.1310259847538243\n",
      "Penalización por duración del episodio: -  0.40178713342897726\n",
      "Recompensa por acortar distancias: +  0.8916862705301911\n",
      "Penalización por parar muy lejos: -  0.1310259847538243\n",
      "Penalización por duración del episodio: -  0.40218099609221103\n",
      "Recompensa por acortar distancias: +  0.891649527922444\n",
      "Penalización por duración del episodio: -  0.40254819528852054\n",
      "Recompensa por acortar distancias: +  0.8916493206183105\n",
      "Penalización por parar muy lejos: -  0.13098243801124654\n",
      "Penalización por duración del episodio: -  0.4029155783524572\n",
      "Recompensa por acortar distancias: +  0.8916493206183105\n",
      "Penalización por duración del episodio: -  0.403289708624054\n",
      "Recompensa por acortar distancias: +  0.8916459438152518\n",
      "Penalización por parar muy lejos: -  0.13097845959621435\n",
      "Penalización por duración del episodio: -  0.40365566979972967\n",
      "Recompensa por acortar distancias: +  0.8916293625090567\n",
      "Penalización por parar muy lejos: -  0.13095892723019725\n",
      "Penalización por duración del episodio: -  0.4040340121829947\n",
      "Recompensa por acortar distancias: +  0.8916390148603073\n",
      "Penalización por duración del episodio: -  0.4044125548379832\n",
      "Step: 8830, Mean Reward (últimos 10 pasos): 0.4872264564037323\n",
      "Recompensa por acortar distancias: +  0.8916391715032165\n",
      "Penalización por duración del episodio: -  0.40454568159702703\n",
      "Recompensa por acortar distancias: +  0.8916436034936822\n",
      "Penalización por parar muy lejos: -  0.13097570244655068\n",
      "Penalización por duración del episodio: -  0.4046898218937651\n",
      "Recompensa por acortar distancias: +  0.8916436034936822\n",
      "Penalización por parar muy lejos: -  0.13097570244655068\n",
      "Penalización por duración del episodio: -  0.40482134645314927\n",
      "steer input from model: -0.9 , throttle:  0.0\n",
      "reward: 0.3558465545939823\n",
      "Recompensa por acortar distancias: +  0.8916326015445323\n",
      "Penalización por duración del episodio: -  0.40516591857718165\n",
      "Recompensa por acortar distancias: +  0.8916326015445323\n",
      "Penalización por duración del episodio: -  0.4052367347796566\n",
      "Recompensa por acortar distancias: +  0.8916326015445323\n",
      "Penalización por duración del episodio: -  0.40553978804688395\n",
      "Recompensa por acortar distancias: +  0.8916326015445323\n",
      "Penalización por duración del episodio: -  0.4056398541999132\n",
      "Recompensa por acortar distancias: +  0.8916326015445323\n",
      "Penalización por duración del episodio: -  0.40591881507905436\n",
      "Recompensa por acortar distancias: +  0.8916326015445323\n",
      "Penalización por duración del episodio: -  0.4062849222425234\n",
      "Recompensa por acortar distancias: +  0.8915602766306596\n",
      "Penalización por parar muy lejos: -  0.13087760063837217\n",
      "Penalización por duración del episodio: -  0.40636233401232036\n",
      "Step: 8840, Mean Reward (últimos 10 pasos): 0.35432034730911255\n",
      "Recompensa por acortar distancias: +  0.8915602766306596\n",
      "Penalización por parar muy lejos: -  0.13087760063837217\n",
      "Penalización por duración del episodio: -  0.4064714027819965\n",
      "Recompensa por acortar distancias: +  0.8915602766306596\n",
      "Penalización por duración del episodio: -  0.40656764725410316\n",
      "Recompensa por acortar distancias: +  0.8915602766306596\n",
      "Penalización por duración del episodio: -  0.4066778034041287\n",
      "Recompensa por acortar distancias: +  0.8915602766306596\n",
      "Penalización por parar muy lejos: -  0.13087760063837217\n",
      "Penalización por duración del episodio: -  0.4070386075791909\n",
      "Recompensa por acortar distancias: +  0.8915303765907745\n",
      "Penalización por duración del episodio: -  0.40715160643176435\n",
      "Recompensa por acortar distancias: +  0.8915303120338967\n",
      "Penalización por parar muy lejos: -  0.13084235436413497\n",
      "Penalización por duración del episodio: -  0.40726220934168805\n",
      "Recompensa por acortar distancias: +  0.8915303120338967\n",
      "Penalización por duración del episodio: -  0.40741846678718885\n",
      "Recompensa por acortar distancias: +  0.8915303120338967\n",
      "Penalización por duración del episodio: -  0.4078016149919834\n",
      "Recompensa por acortar distancias: +  0.8915303120338967\n",
      "Penalización por parar muy lejos: -  0.13084235436413497\n",
      "Penalización por duración del episodio: -  0.40817216421579594\n",
      "Recompensa por acortar distancias: +  0.8915211722839084\n",
      "Penalización por duración del episodio: -  0.4085734784759909\n",
      "Step: 8850, Mean Reward (últimos 10 pasos): 0.4829477071762085\n",
      "Recompensa por acortar distancias: +  0.8915211722839084\n",
      "Penalización por parar muy lejos: -  0.13083160691262982\n",
      "Penalización por duración del episodio: -  0.408959516208104\n",
      "Recompensa por acortar distancias: +  0.8915126636847306\n",
      "Penalización por duración del episodio: -  0.4091213181978326\n",
      "Recompensa por acortar distancias: +  0.8915126636847306\n",
      "Penalización por duración del episodio: -  0.40925407104409683\n",
      "steer input from model: 0.9 , throttle:  0.7\n",
      "reward: 0.48225859264063375\n",
      "Recompensa por acortar distancias: +  0.8915126083423296\n",
      "Penalización por parar muy lejos: -  0.13082153795766258\n",
      "Penalización por duración del episodio: -  0.4097117177526399\n",
      "Recompensa por acortar distancias: +  0.8915125437761637\n",
      "Penalización por duración del episodio: -  0.41010556602808157\n",
      "Recompensa por acortar distancias: +  0.8915125437761637\n",
      "Penalización por parar muy lejos: -  0.13082146204989376\n",
      "Penalización por duración del episodio: -  0.4104721998506472\n",
      "Recompensa por acortar distancias: +  0.8915124423149776\n",
      "Penalización por parar muy lejos: -  0.13082134276633264\n",
      "Penalización por duración del episodio: -  0.4108546417234908\n",
      "Recompensa por acortar distancias: +  0.8915125207168105\n",
      "Penalización por duración del episodio: -  0.41123571934284486\n",
      "Recompensa por acortar distancias: +  0.8915127236389704\n",
      "Penalización por duración del episodio: -  0.4113393358927488\n",
      "Recompensa por acortar distancias: +  0.8915127835931811\n",
      "Penalización por duración del episodio: -  0.41142365389707325\n",
      "Step: 8860, Mean Reward (últimos 10 pasos): 0.48008912801742554\n",
      "Recompensa por acortar distancias: +  0.8915128619947974\n",
      "Penalización por duración del episodio: -  0.41152368760145436\n",
      "Recompensa por acortar distancias: +  0.8915128619947974\n",
      "Penalización por duración del episodio: -  0.41164064150332824\n",
      "Recompensa por acortar distancias: +  0.8915129127252284\n",
      "Penalización por duración del episodio: -  0.4119839736701514\n",
      "Recompensa por acortar distancias: +  0.8915083376789323\n",
      "Penalización por parar muy lejos: -  0.13081651728155955\n",
      "Penalización por duración del episodio: -  0.4123731881707503\n",
      "Recompensa por acortar distancias: +  0.8915083376789323\n",
      "Penalización por duración del episodio: -  0.4124756656353775\n",
      "Recompensa por acortar distancias: +  0.8915083376789323\n",
      "Penalización por duración del episodio: -  0.4125931742206627\n",
      "Recompensa por acortar distancias: +  0.8915083376789323\n",
      "Penalización por duración del episodio: -  0.4127439328409418\n",
      "Recompensa por acortar distancias: +  0.8915083376789323\n",
      "Penalización por duración del episodio: -  0.4128776119684415\n",
      "Recompensa por acortar distancias: +  0.8915083376789323\n",
      "Penalización por parar muy lejos: -  0.13081651728155955\n",
      "Penalización por duración del episodio: -  0.4131346210326589\n",
      "Recompensa por acortar distancias: +  0.8915222652159547\n",
      "Penalización por duración del episodio: -  0.4132554573800157\n",
      "Step: 8870, Mean Reward (últimos 10 pasos): 0.47826680541038513\n",
      "Recompensa por acortar distancias: +  0.8915222375469083\n",
      "Penalización por duración del episodio: -  0.41336398950009223\n",
      "Recompensa por acortar distancias: +  0.8915222375469083\n",
      "Penalización por duración del episodio: -  0.41351411451374104\n",
      "Recompensa por acortar distancias: +  0.8915222375469083\n",
      "Penalización por parar muy lejos: -  0.1308328594781067\n",
      "Penalización por duración del episodio: -  0.4136362615868479\n",
      "steer input from model: -0.25 , throttle:  0.0\n",
      "reward: 0.34705311648195364\n",
      "Recompensa por acortar distancias: +  0.8915222375469083\n",
      "Penalización por parar muy lejos: -  0.1308328594781067\n",
      "Penalización por duración del episodio: -  0.4137741899920283\n",
      "Recompensa por acortar distancias: +  0.8915222375469083\n",
      "Penalización por duración del episodio: -  0.4139105992257128\n",
      "Recompensa por acortar distancias: +  0.8915222375469083\n",
      "Penalización por duración del episodio: -  0.41406239069699596\n",
      "Recompensa por acortar distancias: +  0.8915224496761056\n",
      "Penalización por parar muy lejos: -  0.13083310890794603\n",
      "Penalización por duración del episodio: -  0.41417019841110864\n",
      "Recompensa por acortar distancias: +  0.8915224496761056\n",
      "Penalización por duración del episodio: -  0.41464826201886806\n",
      "Recompensa por acortar distancias: +  0.8915226433589676\n",
      "Penalización por duración del episodio: -  0.4150216160361098\n",
      "Recompensa por acortar distancias: +  0.8915226433589676\n",
      "Penalización por duración del episodio: -  0.4154107812765044\n",
      "Step: 8880, Mean Reward (últimos 10 pasos): 0.47611185908317566\n",
      "Recompensa por acortar distancias: +  0.8914946115232927\n",
      "Penalización por parar muy lejos: -  0.13080038282608927\n",
      "Penalización por duración del episodio: -  0.4155199418061093\n",
      "Recompensa por acortar distancias: +  0.8914946115232927\n",
      "Penalización por parar muy lejos: -  0.13080038282608927\n",
      "Penalización por duración del episodio: -  0.4156550939447547\n",
      "Recompensa por acortar distancias: +  0.8914729583644957\n",
      "Penalización por duración del episodio: -  0.41618406360654264\n",
      "Recompensa por acortar distancias: +  0.8914729583644957\n",
      "Penalización por duración del episodio: -  0.416290623462898\n",
      "Recompensa por acortar distancias: +  0.8914308267020289\n",
      "Penalización por parar muy lejos: -  0.13072545242311864\n",
      "Penalización por duración del episodio: -  0.4165657606185416\n",
      "Recompensa por acortar distancias: +  0.8913994735687166\n",
      "Penalización por duración del episodio: -  0.4166763005942838\n",
      "Recompensa por acortar distancias: +  0.8913772035391186\n",
      "Penalización por duración del episodio: -  0.4169403996329474\n",
      "Recompensa por acortar distancias: +  0.8913772035391186\n",
      "Penalización por duración del episodio: -  0.41733357642553454\n",
      "Recompensa por acortar distancias: +  0.8913772035391186\n",
      "Penalización por parar muy lejos: -  0.1306625174055488\n",
      "Penalización por duración del episodio: -  0.4174605305359826\n",
      "Recompensa por acortar distancias: +  0.8913772035391186\n",
      "Penalización por duración del episodio: -  0.4175731210901865\n",
      "Step: 8890, Mean Reward (últimos 10 pasos): 0.4738040864467621\n",
      "Recompensa por acortar distancias: +  0.8913772035391186\n",
      "Penalización por duración del episodio: -  0.41769484196801665\n",
      "Recompensa por acortar distancias: +  0.8912465310679799\n",
      "Penalización por parar muy lejos: -  0.1305093750272586\n",
      "Penalización por duración del episodio: -  0.4181042063114435\n",
      "Recompensa por acortar distancias: +  0.8911981267550952\n",
      "Penalización por duración del episodio: -  0.41847345771261346\n",
      "steer input from model: 0.25 , throttle:  0.7\n",
      "reward: 0.4727246690424818\n",
      "Recompensa por acortar distancias: +  0.8911981267550952\n",
      "Penalización por duración del episodio: -  0.418844738839107\n",
      "Recompensa por acortar distancias: +  0.891003773886351\n",
      "Penalización por duración del episodio: -  0.4190029140683565\n",
      "Recompensa por acortar distancias: +  0.891003773886351\n",
      "Penalización por duración del episodio: -  0.41921997215234885\n",
      "Recompensa por acortar distancias: +  0.890904754559993\n",
      "Penalización por duración del episodio: -  0.4193433194259625\n",
      "Recompensa por acortar distancias: +  0.890904754559993\n",
      "Penalización por parar muy lejos: -  0.13011030930481018\n",
      "Penalización por duración del episodio: -  0.4194522493479558\n",
      "Recompensa por acortar distancias: +  0.890904754559993\n",
      "Penalización por duración del episodio: -  0.4199564839603535\n",
      "Recompensa por acortar distancias: +  0.890904754559993\n",
      "Penalización por parar muy lejos: -  0.13011030930481018\n",
      "Penalización por duración del episodio: -  0.4203328003640321\n",
      "Step: 8900, Mean Reward (últimos 10 pasos): 0.3404616415500641\n",
      "Recompensa por acortar distancias: +  0.8908432760162392\n",
      "Penalización por parar muy lejos: -  0.13003875209156923\n",
      "Penalización por duración del episodio: -  0.42046280289948873\n",
      "Recompensa por acortar distancias: +  0.8908432760162392\n",
      "Penalización por duración del episodio: -  0.42070325357478716\n",
      "Recompensa por acortar distancias: +  0.8908424831144736\n",
      "Penalización por duración del episodio: -  0.42081568015817683\n",
      "Recompensa por acortar distancias: +  0.8908424831144736\n",
      "Penalización por parar muy lejos: -  0.13003782965270566\n",
      "Penalización por duración del episodio: -  0.4210769984971261\n",
      "Recompensa por acortar distancias: +  0.8908424831144736\n",
      "Penalización por duración del episodio: -  0.42118373878086374\n",
      "Recompensa por acortar distancias: +  0.8908157626163978\n",
      "Penalización por parar muy lejos: -  0.13000675049217641\n",
      "Penalización por duración del episodio: -  0.4214674485643188\n",
      "Recompensa por acortar distancias: +  0.890810220246516\n",
      "Penalización por duración del episodio: -  0.42157615756744027\n",
      "Recompensa por acortar distancias: +  0.8908106330340357\n",
      "Penalización por parar muy lejos: -  0.13000078565586948\n",
      "Penalización por duración del episodio: -  0.42184185482900766\n",
      "Recompensa por acortar distancias: +  0.8908106330340357\n",
      "Penalización por parar muy lejos: -  0.13000078565586948\n",
      "Penalización por duración del episodio: -  0.4222277565977889\n",
      "Recompensa por acortar distancias: +  0.8908106330340357\n",
      "Penalización por duración del episodio: -  0.4223330925381912\n",
      "Step: 8910, Mean Reward (últimos 10 pasos): 0.4684775471687317\n",
      "Recompensa por acortar distancias: +  0.8908106330340357\n",
      "Penalización por parar muy lejos: -  0.13000078565586948\n",
      "Penalización por duración del episodio: -  0.4224518496875196\n",
      "Recompensa por acortar distancias: +  0.8908106330340357\n",
      "Penalización por parar muy lejos: -  0.13000078565586948\n",
      "Penalización por duración del episodio: -  0.422598801964101\n",
      "Recompensa por acortar distancias: +  0.8908106330340357\n",
      "Penalización por parar muy lejos: -  0.13000078565586948\n",
      "Penalización por duración del episodio: -  0.4229802809016285\n",
      "steer input from model: -0.9 , throttle:  0.0\n",
      "reward: 0.3378295664765378\n",
      "Recompensa por acortar distancias: +  0.8907833211735453\n",
      "Penalización por parar muy lejos: -  0.1299690346408036\n",
      "Penalización por duración del episodio: -  0.42336865580674454\n",
      "Recompensa por acortar distancias: +  0.8907833211735453\n",
      "Penalización por parar muy lejos: -  0.1299690346408036\n",
      "Penalización por duración del episodio: -  0.42349959817343125\n",
      "Recompensa por acortar distancias: +  0.8907831773622233\n",
      "Penalización por parar muy lejos: -  0.1299688674908923\n",
      "Penalización por duración del episodio: -  0.42374560980674825\n",
      "Recompensa por acortar distancias: +  0.8907830753024747\n",
      "Penalización por duración del episodio: -  0.4238822889286529\n",
      "Recompensa por acortar distancias: +  0.8907831634449898\n",
      "Penalización por parar muy lejos: -  0.12996885131510413\n",
      "Penalización por duración del episodio: -  0.42411874521318865\n",
      "Recompensa por acortar distancias: +  0.8907831727231458\n",
      "Penalización por duración del episodio: -  0.42449232244825347\n",
      "Recompensa por acortar distancias: +  0.8907831727231458\n",
      "Penalización por duración del episodio: -  0.4246080600426315\n",
      "Step: 8920, Mean Reward (últimos 10 pasos): 0.4661751091480255\n",
      "Recompensa por acortar distancias: +  0.8907831727231458\n",
      "Penalización por duración del episodio: -  0.42488328891227517\n",
      "Recompensa por acortar distancias: +  0.8907831727231458\n",
      "Penalización por parar muy lejos: -  0.12996886209896272\n",
      "Penalización por duración del episodio: -  0.4250047816969399\n",
      "Recompensa por acortar distancias: +  0.8907831727231458\n",
      "Penalización por parar muy lejos: -  0.12996886209896272\n",
      "Penalización por duración del episodio: -  0.42525200170472055\n",
      "Recompensa por acortar distancias: +  0.890783455706567\n",
      "Penalización por parar muy lejos: -  0.12996919100701515\n",
      "Penalización por duración del episodio: -  0.42562666704515056\n",
      "Recompensa por acortar distancias: +  0.890783455706567\n",
      "Penalización por duración del episodio: -  0.42600695624071466\n",
      "Recompensa por acortar distancias: +  0.8907836598253569\n",
      "Penalización por duración del episodio: -  0.4263965464116612\n",
      "Recompensa por acortar distancias: +  0.8907838825000185\n",
      "Penalización por duración del episodio: -  0.4267902000064469\n",
      "Recompensa por acortar distancias: +  0.890787408129079\n",
      "Penalización por parar muy lejos: -  0.12997378500988468\n",
      "Penalización por duración del episodio: -  0.42717629794696066\n",
      "Recompensa por acortar distancias: +  0.890787408129079\n",
      "Penalización por parar muy lejos: -  0.12997378500988468\n",
      "Penalización por duración del episodio: -  0.4275818289722395\n",
      "Recompensa por acortar distancias: +  0.8907614042671796\n",
      "Penalización por parar muy lejos: -  0.12994356526020548\n",
      "Penalización por duración del episodio: -  0.4279688846624774\n",
      "Step: 8930, Mean Reward (últimos 10 pasos): 0.3328489661216736\n",
      "Recompensa por acortar distancias: +  0.8907614042671796\n",
      "Penalización por parar muy lejos: -  0.12994356526020548\n",
      "Penalización por duración del episodio: -  0.4283661985103476\n",
      "Recompensa por acortar distancias: +  0.8907613485884991\n",
      "Penalización por duración del episodio: -  0.4284661676011492\n",
      "Recompensa por acortar distancias: +  0.8907613485884991\n",
      "Penalización por duración del episodio: -  0.42860168370137836\n",
      "steer input from model: -0.9 , throttle:  1.0\n",
      "reward: 0.46215966488712074\n",
      "Recompensa por acortar distancias: +  0.8907502169922381\n",
      "Penalización por duración del episodio: -  0.4287482353071915\n",
      "Recompensa por acortar distancias: +  0.8907690320110323\n",
      "Penalización por duración del episodio: -  0.42888486573284534\n",
      "Recompensa por acortar distancias: +  0.8907690320110323\n",
      "Penalización por duración del episodio: -  0.42902700277773653\n",
      "Recompensa por acortar distancias: +  0.8907763391740493\n",
      "Penalización por parar muy lejos: -  0.12996091999325568\n",
      "Penalización por duración del episodio: -  0.42951265090856083\n",
      "Recompensa por acortar distancias: +  0.8907763391740493\n",
      "Penalización por parar muy lejos: -  0.12996091999325568\n",
      "Penalización por duración del episodio: -  0.42990684404730223\n",
      "Recompensa por acortar distancias: +  0.8907763391740493\n",
      "Penalización por parar muy lejos: -  0.12996091999325568\n",
      "Penalización por duración del episodio: -  0.42999467731920765\n",
      "Recompensa por acortar distancias: +  0.8907763391740493\n",
      "Penalización por parar muy lejos: -  0.12996091999325568\n",
      "Penalización por duración del episodio: -  0.4301522050651632\n",
      "Step: 8940, Mean Reward (últimos 10 pasos): 0.33066320419311523\n",
      "Recompensa por acortar distancias: +  0.8907715466514057\n",
      "Penalización por duración del episodio: -  0.430289951165361\n",
      "Recompensa por acortar distancias: +  0.8907715466514057\n",
      "Penalización por duración del episodio: -  0.4303938479351161\n",
      "Recompensa por acortar distancias: +  0.8907636267541739\n",
      "Penalización por parar muy lejos: -  0.12994614758863707\n",
      "Penalización por duración del episodio: -  0.43066549538699633\n",
      "Recompensa por acortar distancias: +  0.8907636267541739\n",
      "Penalización por parar muy lejos: -  0.12994614758863707\n",
      "Penalización por duración del episodio: -  0.430790372998811\n",
      "Recompensa por acortar distancias: +  0.8907636267541739\n",
      "Penalización por duración del episodio: -  0.43089314158272124\n",
      "Recompensa por acortar distancias: +  0.8907636267541739\n",
      "Penalización por parar muy lejos: -  0.12994614758863707\n",
      "Penalización por duración del episodio: -  0.4310104575187617\n",
      "Recompensa por acortar distancias: +  0.8907636267541739\n",
      "Penalización por parar muy lejos: -  0.12994614758863707\n",
      "Penalización por duración del episodio: -  0.4311446451035894\n",
      "Recompensa por acortar distancias: +  0.8907350144221892\n",
      "Penalización por duración del episodio: -  0.4314109744394747\n",
      "Recompensa por acortar distancias: +  0.8907068550663997\n",
      "Penalización por parar muy lejos: -  0.1298802121557444\n",
      "Penalización por duración del episodio: -  0.43154157177875246\n",
      "Recompensa por acortar distancias: +  0.890702765466274\n",
      "Penalización por parar muy lejos: -  0.12987546469610264\n",
      "Penalización por duración del episodio: -  0.43163946461665\n",
      "Step: 8950, Mean Reward (últimos 10 pasos): 0.3291878402233124\n",
      "Recompensa por acortar distancias: +  0.890702765466274\n",
      "Penalización por duración del episodio: -  0.43181259892149615\n",
      "Recompensa por acortar distancias: +  0.890702765466274\n",
      "Penalización por duración del episodio: -  0.43219849813102734\n",
      "Recompensa por acortar distancias: +  0.890702765466274\n",
      "Penalización por duración del episodio: -  0.43230142357707424\n",
      "steer input from model: -0.1 , throttle:  1.0\n",
      "reward: 0.4584013418891998\n",
      "Recompensa por acortar distancias: +  0.890702765466274\n",
      "Penalización por duración del episodio: -  0.43258325655635854\n",
      "Recompensa por acortar distancias: +  0.890605731563667\n",
      "Penalización por parar muy lejos: -  0.1297629107222419\n",
      "Penalización por duración del episodio: -  0.43271576468763434\n",
      "Recompensa por acortar distancias: +  0.890605731563667\n",
      "Penalización por duración del episodio: -  0.43282416843737204\n",
      "Recompensa por acortar distancias: +  0.8906066142414777\n",
      "Penalización por parar muy lejos: -  0.12976393381100876\n",
      "Penalización por duración del episodio: -  0.43293664076002547\n",
      "Recompensa por acortar distancias: +  0.8906066142414777\n",
      "Penalización por parar muy lejos: -  0.12976393381100876\n",
      "Penalización por duración del episodio: -  0.43335921111235065\n",
      "Recompensa por acortar distancias: +  0.8906066142414777\n",
      "Penalización por duración del episodio: -  0.43344507642528907\n",
      "Recompensa por acortar distancias: +  0.8906241085557397\n",
      "Penalización por duración del episodio: -  0.4337377662728271\n",
      "Step: 8960, Mean Reward (últimos 10 pasos): 0.456886351108551\n",
      "Recompensa por acortar distancias: +  0.8906239320454419\n",
      "Penalización por parar muy lejos: -  0.12978400927809874\n",
      "Penalización por duración del episodio: -  0.4341264552260421\n",
      "Recompensa por acortar distancias: +  0.8906249632336476\n",
      "Penalización por parar muy lejos: -  0.12978520484260472\n",
      "Penalización por duración del episodio: -  0.4345093025638088\n",
      "Recompensa por acortar distancias: +  0.8906249632336476\n",
      "Penalización por duración del episodio: -  0.43490248788519426\n",
      "Recompensa por acortar distancias: +  0.8906249632336476\n",
      "Penalización por duración del episodio: -  0.435281648596247\n",
      "Recompensa por acortar distancias: +  0.8906474242983394\n",
      "Penalización por parar muy lejos: -  0.12981125108684646\n",
      "Penalización por duración del episodio: -  0.4356583820490539\n",
      "Recompensa por acortar distancias: +  0.8906474242983394\n",
      "Penalización por duración del episodio: -  0.43604863937710336\n",
      "Recompensa por acortar distancias: +  0.8906603389713678\n",
      "Penalización por duración del episodio: -  0.4361738410262015\n",
      "Recompensa por acortar distancias: +  0.8906763399786342\n",
      "Penalización por duración del episodio: -  0.43643696453575326\n",
      "Recompensa por acortar distancias: +  0.8906719150651826\n",
      "Penalización por duración del episodio: -  0.43654935985164645\n",
      "Recompensa por acortar distancias: +  0.8906719150651826\n",
      "Penalización por parar muy lejos: -  0.12983966142786665\n",
      "Penalización por duración del episodio: -  0.436635669288355\n",
      "Step: 8970, Mean Reward (últimos 10 pasos): 0.32419657707214355\n",
      "Recompensa por acortar distancias: +  0.8906719150651826\n",
      "Penalización por duración del episodio: -  0.43683635340840793\n",
      "Recompensa por acortar distancias: +  0.8906719150651826\n",
      "Penalización por parar muy lejos: -  0.12983966142786665\n",
      "Penalización por duración del episodio: -  0.4369255556003761\n",
      "Recompensa por acortar distancias: +  0.8906719150651826\n",
      "Penalización por duración del episodio: -  0.437042126396669\n",
      "steer input from model: 0.25 , throttle:  0.7\n",
      "reward: 0.4536297886685136\n",
      "Recompensa por acortar distancias: +  0.8906719150651826\n",
      "Penalización por parar muy lejos: -  0.12983966142786665\n",
      "Penalización por duración del episodio: -  0.4371682955918964\n",
      "Recompensa por acortar distancias: +  0.8906719150651826\n",
      "Penalización por duración del episodio: -  0.437607328856901\n",
      "Recompensa por acortar distancias: +  0.8906491008201425\n",
      "Penalización por parar muy lejos: -  0.12981319557749907\n",
      "Penalización por duración del episodio: -  0.43771789611730866\n",
      "Recompensa por acortar distancias: +  0.8906219764804232\n",
      "Penalización por parar muy lejos: -  0.12978174203961368\n",
      "Penalización por duración del episodio: -  0.43797976033663366\n",
      "Recompensa por acortar distancias: +  0.8906219764804232\n",
      "Penalización por parar muy lejos: -  0.12978174203961368\n",
      "Penalización por duración del episodio: -  0.43808423281996794\n",
      "Recompensa por acortar distancias: +  0.8906219764804232\n",
      "Penalización por parar muy lejos: -  0.12978174203961368\n",
      "Penalización por duración del episodio: -  0.4381955251482297\n",
      "Recompensa por acortar distancias: +  0.8906219764804232\n",
      "Penalización por parar muy lejos: -  0.12978174203961368\n",
      "Penalización por duración del episodio: -  0.4383710453489714\n",
      "Step: 8980, Mean Reward (últimos 10 pasos): 0.32246917486190796\n",
      "Recompensa por acortar distancias: +  0.8906219764804232\n",
      "Penalización por parar muy lejos: -  0.12978174203961368\n",
      "Penalización por duración del episodio: -  0.4384856586287375\n",
      "Recompensa por acortar distancias: +  0.8905893916046754\n",
      "Penalización por duración del episodio: -  0.43875374723625066\n",
      "Recompensa por acortar distancias: +  0.890589033839232\n",
      "Penalización por parar muy lejos: -  0.1297435594833024\n",
      "Penalización por duración del episodio: -  0.4388907700284552\n",
      "Recompensa por acortar distancias: +  0.8905891081801879\n",
      "Penalización por parar muy lejos: -  0.12974364562694876\n",
      "Penalización por duración del episodio: -  0.4389949730058081\n",
      "Recompensa por acortar distancias: +  0.8905891081801879\n",
      "Penalización por duración del episodio: -  0.43912361505709013\n",
      "Recompensa por acortar distancias: +  0.8905891081801879\n",
      "Penalización por parar muy lejos: -  0.12974364562694876\n",
      "Penalización por duración del episodio: -  0.43925076193497625\n",
      "Recompensa por acortar distancias: +  0.8905891081801879\n",
      "Penalización por parar muy lejos: -  0.12974364562694876\n",
      "Penalización por duración del episodio: -  0.43933700696314704\n",
      "Recompensa por acortar distancias: +  0.8905891081801879\n",
      "Penalización por duración del episodio: -  0.4395193104417537\n",
      "Recompensa por acortar distancias: +  0.8905891081801879\n",
      "Penalización por duración del episodio: -  0.4398922197233284\n",
      "Recompensa por acortar distancias: +  0.8904579204272424\n",
      "Penalización por parar muy lejos: -  0.12959178541195548\n",
      "Penalización por duración del episodio: -  0.4400397058325404\n",
      "Step: 8990, Mean Reward (últimos 10 pasos): 0.3208264410495758\n",
      "Recompensa por acortar distancias: +  0.8904579204272424\n",
      "Penalización por duración del episodio: -  0.4401714042612485\n",
      "Recompensa por acortar distancias: +  0.8904579204272424\n",
      "Penalización por duración del episodio: -  0.44066603138283955\n",
      "Recompensa por acortar distancias: +  0.890392693660645\n",
      "Penalización por duración del episodio: -  0.44105482944695257\n",
      "steer input from model: 0.0 , throttle:  0.3\n",
      "reward: 0.44933786421369243\n",
      "Recompensa por acortar distancias: +  0.8901165316491764\n",
      "Penalización por duración del episodio: -  0.4411973079303488\n",
      "Recompensa por acortar distancias: +  0.8901165316491764\n",
      "Penalización por duración del episodio: -  0.4413388379150266\n",
      "Recompensa por acortar distancias: +  0.8900307144969146\n",
      "Penalización por parar muy lejos: -  0.1290994075394347\n",
      "Penalización por duración del episodio: -  0.4418304429721276\n",
      "Recompensa por acortar distancias: +  0.8900307144969146\n",
      "Penalización por parar muy lejos: -  0.1290994075394347\n",
      "Penalización por duración del episodio: -  0.4422007844775228\n",
      "Recompensa por acortar distancias: +  0.8900307144969146\n",
      "Penalización por parar muy lejos: -  0.1290994075394347\n",
      "Penalización por duración del episodio: -  0.44259151209870556\n",
      "Recompensa por acortar distancias: +  0.8899733708230239\n",
      "Penalización por parar muy lejos: -  0.12903356472601207\n",
      "Penalización por duración del episodio: -  0.44298367563083824\n",
      "Recompensa por acortar distancias: +  0.8899733708230239\n",
      "Penalización por duración del episodio: -  0.4430908422440634\n",
      "Step: 9000, Mean Reward (últimos 10 pasos): 0.4468825161457062\n",
      "Recompensa por acortar distancias: +  0.8899723669353833\n",
      "Penalización por parar muy lejos: -  0.12903241257073458\n",
      "Penalización por duración del episodio: -  0.44335706969680877\n",
      "Recompensa por acortar distancias: +  0.8899719980630243\n",
      "Penalización por duración del episodio: -  0.44346607884584904\n",
      "Recompensa por acortar distancias: +  0.8899718673231939\n",
      "Penalización por parar muy lejos: -  0.12903183917579272\n",
      "Penalización por duración del episodio: -  0.4435787477523468\n",
      "Recompensa por acortar distancias: +  0.8899718673231939\n",
      "Penalización por parar muy lejos: -  0.12903183917579272\n",
      "Penalización por duración del episodio: -  0.44374268028105257\n",
      "Recompensa por acortar distancias: +  0.8899718112917965\n",
      "Penalización por duración del episodio: -  0.44385524570948703\n",
      "Recompensa por acortar distancias: +  0.8899718112917965\n",
      "Penalización por duración del episodio: -  0.44396880568494146\n",
      "Recompensa por acortar distancias: +  0.8899718112917965\n",
      "Penalización por duración del episodio: -  0.44408946405520094\n",
      "Recompensa por acortar distancias: +  0.8899718112917965\n",
      "Penalización por duración del episodio: -  0.4441952721586061\n",
      "Recompensa por acortar distancias: +  0.8899718112917965\n",
      "Penalización por duración del episodio: -  0.44431734977762005\n",
      "Recompensa por acortar distancias: +  0.8899718112917965\n",
      "Penalización por duración del episodio: -  0.44451895531672087\n",
      "Step: 9010, Mean Reward (últimos 10 pasos): 0.44545286893844604\n",
      "Recompensa por acortar distancias: +  0.8899718112917965\n",
      "Penalización por parar muy lejos: -  0.1290317748699533\n",
      "Penalización por duración del episodio: -  0.4446566582754304\n",
      "Recompensa por acortar distancias: +  0.8899718112917965\n",
      "Penalización por duración del episodio: -  0.44490499839056774\n",
      "Recompensa por acortar distancias: +  0.8899722782193452\n",
      "Penalización por duración del episodio: -  0.4450536246816931\n",
      "steer input from model: -0.05 , throttle:  0.7\n",
      "reward: 0.4449186535376521\n",
      "Recompensa por acortar distancias: +  0.8899602729604459\n",
      "Penalización por parar muy lejos: -  0.12901853380744324\n",
      "Penalización por duración del episodio: -  0.4452825511170322\n",
      "Recompensa por acortar distancias: +  0.8899602729604459\n",
      "Penalización por duración del episodio: -  0.4454263435185574\n",
      "Recompensa por acortar distancias: +  0.8899602729604459\n",
      "Penalización por duración del episodio: -  0.4456755165665964\n",
      "Recompensa por acortar distancias: +  0.8899602729604459\n",
      "Penalización por duración del episodio: -  0.4460663761191608\n",
      "Recompensa por acortar distancias: +  0.8898998743771295\n",
      "Penalización por duración del episodio: -  0.4464500197335225\n",
      "Recompensa por acortar distancias: +  0.8898822037845951\n",
      "Penalización por duración del episodio: -  0.44656728719679706\n",
      "Recompensa por acortar distancias: +  0.8898822037845951\n",
      "Penalización por duración del episodio: -  0.44666784898910367\n",
      "Step: 9020, Mean Reward (últimos 10 pasos): 0.4432143568992615\n",
      "Recompensa por acortar distancias: +  0.8898822037845951\n",
      "Penalización por parar muy lejos: -  0.12892900617138953\n",
      "Penalización por duración del episodio: -  0.44683435770182317\n",
      "Recompensa por acortar distancias: +  0.8898822037845951\n",
      "Penalización por parar muy lejos: -  0.12892900617138953\n",
      "Penalización por duración del episodio: -  0.4469218066623627\n",
      "Recompensa por acortar distancias: +  0.8898822037845951\n",
      "Penalización por parar muy lejos: -  0.12892900617138953\n",
      "Penalización por duración del episodio: -  0.44722535467127694\n",
      "Recompensa por acortar distancias: +  0.8897744023724198\n",
      "Penalización por parar muy lejos: -  0.12880556069047955\n",
      "Penalización por duración del episodio: -  0.4476223296577285\n",
      "Recompensa por acortar distancias: +  0.8897272765613594\n",
      "Penalización por duración del episodio: -  0.4480018956107328\n",
      "Recompensa por acortar distancias: +  0.8896321573347831\n",
      "Penalización por parar muy lejos: -  0.12864298881876043\n",
      "Penalización por duración del episodio: -  0.44839835208167866\n",
      "Recompensa por acortar distancias: +  0.8895804303357292\n",
      "Penalización por parar muy lejos: -  0.12858395886645865\n",
      "Penalización por duración del episodio: -  0.4485397481393396\n",
      "Recompensa por acortar distancias: +  0.8895804303357292\n",
      "Penalización por parar muy lejos: -  0.12858395886645865\n",
      "Penalización por duración del episodio: -  0.4486496178598511\n",
      "Recompensa por acortar distancias: +  0.8895795123012039\n",
      "Penalización por parar muy lejos: -  0.1285829116487012\n",
      "Penalización por duración del episodio: -  0.4487939835564591\n",
      "Recompensa por acortar distancias: +  0.8895789830231589\n",
      "Penalización por parar muy lejos: -  0.1285823078989104\n",
      "Penalización por duración del episodio: -  0.4488825605894613\n",
      "Step: 9030, Mean Reward (últimos 10 pasos): 0.3121141195297241\n",
      "Recompensa por acortar distancias: +  0.8895789830231589\n",
      "Penalización por parar muy lejos: -  0.1285823078989104\n",
      "Penalización por duración del episodio: -  0.44918995709024895\n",
      "Recompensa por acortar distancias: +  0.8895789830231589\n",
      "Penalización por duración del episodio: -  0.4492926416308528\n",
      "Recompensa por acortar distancias: +  0.8895789830231589\n",
      "Penalización por duración del episodio: -  0.4494337536491387\n",
      "steer input from model: 0.05 , throttle:  0.7\n",
      "reward: 0.4401452293740202\n",
      "Recompensa por acortar distancias: +  0.8895789830231589\n",
      "Penalización por parar muy lejos: -  0.1285823078989104\n",
      "Penalización por duración del episodio: -  0.4495519235285621\n",
      "Recompensa por acortar distancias: +  0.8895789830231589\n",
      "Penalización por duración del episodio: -  0.44995453433164856\n",
      "Recompensa por acortar distancias: +  0.8895552896999511\n",
      "Penalización por parar muy lejos: -  0.12855528589197257\n",
      "Penalización por duración del episodio: -  0.45009154176934596\n",
      "Recompensa por acortar distancias: +  0.8895238650556354\n",
      "Penalización por parar muy lejos: -  0.12851946168512118\n",
      "Penalización por duración del episodio: -  0.45032967938141666\n",
      "Recompensa por acortar distancias: +  0.8895238650556354\n",
      "Penalización por parar muy lejos: -  0.12851946168512118\n",
      "Penalización por duración del episodio: -  0.4505055545497748\n",
      "Recompensa por acortar distancias: +  0.8895238650556354\n",
      "Penalización por duración del episodio: -  0.4507203160790113\n",
      "Recompensa por acortar distancias: +  0.8895238650556354\n",
      "Penalización por parar muy lejos: -  0.12851946168512118\n",
      "Penalización por duración del episodio: -  0.4508240735049423\n",
      "Step: 9040, Mean Reward (últimos 10 pasos): 0.31018033623695374\n",
      "Recompensa por acortar distancias: +  0.8895238650556354\n",
      "Penalización por parar muy lejos: -  0.12851946168512118\n",
      "Penalización por duración del episodio: -  0.45109732340423037\n",
      "Recompensa por acortar distancias: +  0.8893920465161567\n",
      "Penalización por parar muy lejos: -  0.12836937785249714\n",
      "Penalización por duración del episodio: -  0.45121997049114454\n",
      "Recompensa por acortar distancias: +  0.8893920465161567\n",
      "Penalización por parar muy lejos: -  0.12836937785249714\n",
      "Penalización por duración del episodio: -  0.451350434532561\n",
      "Recompensa por acortar distancias: +  0.8893920465161567\n",
      "Penalización por duración del episodio: -  0.4514875535556801\n",
      "Recompensa por acortar distancias: +  0.8893920465161567\n",
      "Penalización por duración del episodio: -  0.4518583679272119\n",
      "Recompensa por acortar distancias: +  0.8893920465161567\n",
      "Penalización por duración del episodio: -  0.45195654388544937\n",
      "Recompensa por acortar distancias: +  0.8893920465161567\n",
      "Penalización por duración del episodio: -  0.4520820019612796\n",
      "Recompensa por acortar distancias: +  0.8893920465161567\n",
      "Penalización por duración del episodio: -  0.45220440091142117\n",
      "Recompensa por acortar distancias: +  0.8891894749760795\n",
      "Penalización por duración del episodio: -  0.4526301284187243\n",
      "Recompensa por acortar distancias: +  0.8891572683851161\n",
      "Penalización por parar muy lejos: -  0.12810282466103615\n",
      "Penalización por duración del episodio: -  0.4530052711972077\n",
      "Step: 9050, Mean Reward (últimos 10 pasos): 0.30804917216300964\n",
      "Recompensa por acortar distancias: +  0.8891572683851161\n",
      "Penalización por parar muy lejos: -  0.12810282466103615\n",
      "Penalización por duración del episodio: -  0.45338622239264015\n",
      "Recompensa por acortar distancias: +  0.889100010275922\n",
      "Penalización por duración del episodio: -  0.4535045400279196\n",
      "Recompensa por acortar distancias: +  0.8890997751921667\n",
      "Penalización por duración del episodio: -  0.4536294162096234\n",
      "steer input from model: -0.1 , throttle:  1.0\n",
      "reward: 0.43547035898254327\n",
      "Recompensa por acortar distancias: +  0.8890997751921667\n",
      "Penalización por duración del episodio: -  0.4537808850853109\n",
      "Recompensa por acortar distancias: +  0.8890997751921667\n",
      "Penalización por parar muy lejos: -  0.12803769754691346\n",
      "Penalización por duración del episodio: -  0.45388936858162693\n",
      "Recompensa por acortar distancias: +  0.8890997751921667\n",
      "Penalización por parar muy lejos: -  0.12803769754691346\n",
      "Penalización por duración del episodio: -  0.4541578924656461\n",
      "Recompensa por acortar distancias: +  0.8890997751921667\n",
      "Penalización por parar muy lejos: -  0.12803769754691346\n",
      "Penalización por duración del episodio: -  0.45454394925453284\n",
      "Recompensa por acortar distancias: +  0.8890997751921667\n",
      "Penalización por parar muy lejos: -  0.12803769754691346\n",
      "Penalización por duración del episodio: -  0.4549370960310203\n",
      "Recompensa por acortar distancias: +  0.889098327066616\n",
      "Penalización por parar muy lejos: -  0.12803605788616484\n",
      "Penalización por duración del episodio: -  0.4550709953862206\n",
      "Recompensa por acortar distancias: +  0.889098327066616\n",
      "Penalización por parar muy lejos: -  0.12803605788616484\n",
      "Penalización por duración del episodio: -  0.4553140090262925\n",
      "Step: 9060, Mean Reward (últimos 10 pasos): 0.30574825406074524\n",
      "Recompensa por acortar distancias: +  0.8890985480478837\n",
      "Penalización por duración del episodio: -  0.45546487373445727\n",
      "Recompensa por acortar distancias: +  0.8890985480478837\n",
      "Penalización por parar muy lejos: -  0.12803630809297795\n",
      "Penalización por duración del episodio: -  0.4557008017369099\n",
      "Recompensa por acortar distancias: +  0.8890985480478837\n",
      "Penalización por duración del episodio: -  0.45608399274205425\n",
      "Recompensa por acortar distancias: +  0.8890986514857916\n",
      "Penalización por duración del episodio: -  0.45617466913081206\n",
      "Recompensa por acortar distancias: +  0.8890986514857916\n",
      "Penalización por parar muy lejos: -  0.128036425211204\n",
      "Penalización por duración del episodio: -  0.4564695012964981\n",
      "Recompensa por acortar distancias: +  0.8890986514857916\n",
      "Penalización por duración del episodio: -  0.4568583691006101\n",
      "Recompensa por acortar distancias: +  0.8890986514857916\n",
      "Penalización por duración del episodio: -  0.45695829359538237\n",
      "Recompensa por acortar distancias: +  0.8890587934296396\n",
      "Penalización por duración del episodio: -  0.45710644143273765\n",
      "Recompensa por acortar distancias: +  0.8890587934296396\n",
      "Penalización por parar muy lejos: -  0.12799130951833088\n",
      "Penalización por duración del episodio: -  0.45723793491125453\n",
      "Recompensa por acortar distancias: +  0.8890667321828225\n",
      "Penalización por parar muy lejos: -  0.12800029325126866\n",
      "Penalización por duración del episodio: -  0.4573212455993024\n",
      "Step: 9070, Mean Reward (últimos 10 pasos): 0.30374518036842346\n",
      "Recompensa por acortar distancias: +  0.8890667321828225\n",
      "Penalización por parar muy lejos: -  0.12800029325126866\n",
      "Penalización por duración del episodio: -  0.45761362698608643\n",
      "Recompensa por acortar distancias: +  0.8890667321828225\n",
      "Penalización por duración del episodio: -  0.4580049089972671\n",
      "Recompensa por acortar distancias: +  0.8891005885801033\n",
      "Penalización por duración del episodio: -  0.4583783609755355\n",
      "steer input from model: 0.1 , throttle:  0.7\n",
      "reward: 0.4307222276045678\n",
      "Recompensa por acortar distancias: +  0.8891134281336922\n",
      "Penalización por parar muy lejos: -  0.12805315808615492\n",
      "Penalización por duración del episodio: -  0.4587594608830968\n",
      "Recompensa por acortar distancias: +  0.8891134281336922\n",
      "Penalización por duración del episodio: -  0.4591624682003006\n",
      "Recompensa por acortar distancias: +  0.8891134281336922\n",
      "Penalización por duración del episodio: -  0.45956277545293833\n",
      "Recompensa por acortar distancias: +  0.8891534663954217\n",
      "Penalización por parar muy lejos: -  0.12809851605923328\n",
      "Penalización por duración del episodio: -  0.45964463506899733\n",
      "Recompensa por acortar distancias: +  0.8891534663954217\n",
      "Penalización por duración del episodio: -  0.45978500474271566\n",
      "Recompensa por acortar distancias: +  0.8891534663954217\n",
      "Penalización por parar muy lejos: -  0.12809851605923328\n",
      "Penalización por duración del episodio: -  0.4599558623818843\n",
      "Recompensa por acortar distancias: +  0.8891534663954217\n",
      "Penalización por duración del episodio: -  0.4603399902967752\n",
      "Step: 9080, Mean Reward (últimos 10 pasos): 0.42881348729133606\n",
      "Recompensa por acortar distancias: +  0.8891122669386813\n",
      "Penalización por duración del episodio: -  0.460478892783935\n",
      "Recompensa por acortar distancias: +  0.8890840847163667\n",
      "Penalización por parar muy lejos: -  0.12801993373532017\n",
      "Penalización por duración del episodio: -  0.46073460880596245\n",
      "Recompensa por acortar distancias: +  0.8890723849492435\n",
      "Penalización por parar muy lejos: -  0.1280066907634576\n",
      "Penalización por duración del episodio: -  0.46086871249649636\n",
      "Recompensa por acortar distancias: +  0.8890715807857084\n",
      "Penalización por duración del episodio: -  0.4611355209082095\n",
      "Recompensa por acortar distancias: +  0.8890713315410039\n",
      "Penalización por duración del episodio: -  0.4615246507077792\n",
      "Recompensa por acortar distancias: +  0.8890713315410039\n",
      "Penalización por parar muy lejos: -  0.12800549852752524\n",
      "Penalización por duración del episodio: -  0.4616190163446482\n",
      "Recompensa por acortar distancias: +  0.8890713315410039\n",
      "Penalización por parar muy lejos: -  0.12800549852752524\n",
      "Penalización por duración del episodio: -  0.461756214640792\n",
      "Recompensa por acortar distancias: +  0.8890713315410039\n",
      "Penalización por duración del episodio: -  0.4619005060465427\n",
      "Recompensa por acortar distancias: +  0.8890713315410039\n",
      "Penalización por duración del episodio: -  0.4623126871516496\n",
      "Recompensa por acortar distancias: +  0.8889764842338825\n",
      "Penalización por duración del episodio: -  0.4624348662937579\n",
      "Step: 9090, Mean Reward (últimos 10 pasos): 0.42654162645339966\n",
      "Recompensa por acortar distancias: +  0.8889530872893548\n",
      "Penalización por parar muy lejos: -  0.12787179406595847\n",
      "Penalización por duración del episodio: -  0.4626973340622215\n",
      "Recompensa por acortar distancias: +  0.8889530872893548\n",
      "Penalización por duración del episodio: -  0.46280485088652057\n",
      "Recompensa por acortar distancias: +  0.8889530872893548\n",
      "Penalización por duración del episodio: -  0.46309727214959384\n",
      "steer input from model: 0.25 , throttle:  0.7\n",
      "reward: 0.425855815139761\n",
      "Recompensa por acortar distancias: +  0.8888210120938612\n",
      "Penalización por parar muy lejos: -  0.12772273822008237\n",
      "Penalización por duración del episodio: -  0.46348930734952737\n",
      "Recompensa por acortar distancias: +  0.888723308518114\n",
      "Penalización por parar muy lejos: -  0.1276126680818337\n",
      "Penalización por duración del episodio: -  0.4638987073948485\n",
      "Recompensa por acortar distancias: +  0.888723308518114\n",
      "Penalización por parar muy lejos: -  0.1276126680818337\n",
      "Penalización por duración del episodio: -  0.46427572458367783\n",
      "Recompensa por acortar distancias: +  0.888723308518114\n",
      "Penalización por parar muy lejos: -  0.1276126680818337\n",
      "Penalización por duración del episodio: -  0.46466258602954874\n",
      "Recompensa por acortar distancias: +  0.888723308518114\n",
      "Penalización por parar muy lejos: -  0.1276126680818337\n",
      "Penalización por duración del episodio: -  0.4650570761946577\n",
      "Recompensa por acortar distancias: +  0.888660183418612\n",
      "Penalización por duración del episodio: -  0.4651478092626092\n",
      "Recompensa por acortar distancias: +  0.888660183418612\n",
      "Penalización por parar muy lejos: -  0.12754164107711885\n",
      "Penalización por duración del episodio: -  0.46544315698124844\n",
      "Step: 9100, Mean Reward (últimos 10 pasos): 0.2956753969192505\n",
      "Recompensa por acortar distancias: +  0.888660183418612\n",
      "Penalización por parar muy lejos: -  0.12754164107711885\n",
      "Penalización por duración del episodio: -  0.46558688017542016\n",
      "Recompensa por acortar distancias: +  0.8886594426932232\n",
      "Penalización por parar muy lejos: -  0.127540808038297\n",
      "Penalización por duración del episodio: -  0.4657364703636472\n",
      "Recompensa por acortar distancias: +  0.8886594426932232\n",
      "Penalización por duración del episodio: -  0.4658731868062389\n",
      "Recompensa por acortar distancias: +  0.8886593955131161\n",
      "Penalización por parar muy lejos: -  0.12754075497865683\n",
      "Penalización por duración del episodio: -  0.46600414751576963\n",
      "Recompensa por acortar distancias: +  0.8886593955131161\n",
      "Penalización por duración del episodio: -  0.46614349048923576\n",
      "Recompensa por acortar distancias: +  0.8886594804372961\n",
      "Penalización por duración del episodio: -  0.46661380448783424\n",
      "Recompensa por acortar distancias: +  0.8886594804372961\n",
      "Penalización por duración del episodio: -  0.46699501102920205\n",
      "Recompensa por acortar distancias: +  0.8886594804372961\n",
      "Penalización por parar muy lejos: -  0.12754085048602273\n",
      "Penalización por duración del episodio: -  0.46738686213171726\n",
      "Recompensa por acortar distancias: +  0.8886594804372961\n",
      "Penalización por duración del episodio: -  0.4674954761130605\n",
      "Recompensa por acortar distancias: +  0.8886592917168189\n",
      "Penalización por parar muy lejos: -  0.12754063824751471\n",
      "Penalización por duración del episodio: -  0.46778673107549906\n",
      "Step: 9110, Mean Reward (últimos 10 pasos): 0.29333192110061646\n",
      "Recompensa por acortar distancias: +  0.8886592822807876\n",
      "Penalización por parar muy lejos: -  0.12754062763559723\n",
      "Penalización por duración del episodio: -  0.4681823791155209\n",
      "Recompensa por acortar distancias: +  0.8886592822807876\n",
      "Penalización por duración del episodio: -  0.4685762920267391\n",
      "Recompensa por acortar distancias: +  0.8886593105888794\n",
      "Penalización por parar muy lejos: -  0.12754065947135196\n",
      "Penalización por duración del episodio: -  0.4689675009760451\n",
      "steer input from model: 0.9 , throttle:  0.0\n",
      "reward: 0.2921511501414823\n",
      "Recompensa por acortar distancias: +  0.8886593105888794\n",
      "Penalización por duración del episodio: -  0.4693488552420959\n",
      "Recompensa por acortar distancias: +  0.8886593105888794\n",
      "Penalización por duración del episodio: -  0.46945974418356307\n",
      "Recompensa por acortar distancias: +  0.8886346801693438\n",
      "Penalización por parar muy lejos: -  0.12751296492945818\n",
      "Penalización por duración del episodio: -  0.46974623210095223\n",
      "Recompensa por acortar distancias: +  0.8886079210381057\n",
      "Penalización por duración del episodio: -  0.46984780195099973\n",
      "Recompensa por acortar distancias: +  0.8886079210381057\n",
      "Penalización por duración del episodio: -  0.47014741872373456\n",
      "Recompensa por acortar distancias: +  0.8886079210381057\n",
      "Penalización por duración del episodio: -  0.47056235891066506\n",
      "Recompensa por acortar distancias: +  0.8885605572822605\n",
      "Penalización por duración del episodio: -  0.47094034919006\n",
      "Step: 9120, Mean Reward (últimos 10 pasos): 0.4176202118396759\n",
      "Recompensa por acortar distancias: +  0.888550603603449\n",
      "Penalización por parar muy lejos: -  0.12741850789054343\n",
      "Penalización por duración del episodio: -  0.4713269513983024\n",
      "Recompensa por acortar distancias: +  0.888550603603449\n",
      "Penalización por parar muy lejos: -  0.12741850789054343\n",
      "Penalización por duración del episodio: -  0.47172253574637596\n",
      "Recompensa por acortar distancias: +  0.888550603603449\n",
      "Penalización por parar muy lejos: -  0.12741850789054343\n",
      "Penalización por duración del episodio: -  0.4718392145055872\n",
      "Recompensa por acortar distancias: +  0.888516817626812\n",
      "Penalización por duración del episodio: -  0.47210811970336464\n",
      "Recompensa por acortar distancias: +  0.888516817626812\n",
      "Penalización por parar muy lejos: -  0.12738058492074275\n",
      "Penalización por duración del episodio: -  0.4722014503601748\n",
      "Recompensa por acortar distancias: +  0.888516817626812\n",
      "Penalización por parar muy lejos: -  0.12738058492074275\n",
      "Penalización por duración del episodio: -  0.47233602176705264\n",
      "Recompensa por acortar distancias: +  0.888516817626812\n",
      "Penalización por parar muy lejos: -  0.12738058492074275\n",
      "Penalización por duración del episodio: -  0.47248532841659463\n",
      "Recompensa por acortar distancias: +  0.888516817626812\n",
      "Penalización por duración del episodio: -  0.472885359649768\n",
      "Recompensa por acortar distancias: +  0.8884906573334853\n",
      "Penalización por parar muy lejos: -  0.1273512348996042\n",
      "Penalización por duración del episodio: -  0.47327791318665435\n",
      "Recompensa por acortar distancias: +  0.8884545730203174\n",
      "Penalización por parar muy lejos: -  0.12731077017542888\n",
      "Penalización por duración del episodio: -  0.4733900612971035\n",
      "Step: 9130, Mean Reward (últimos 10 pasos): 0.28775373101234436\n",
      "Recompensa por acortar distancias: +  0.8884480987820804\n",
      "Penalización por duración del episodio: -  0.4736570011032457\n",
      "Recompensa por acortar distancias: +  0.8884480278944419\n",
      "Penalización por duración del episodio: -  0.4740614009583632\n",
      "Recompensa por acortar distancias: +  0.8884480278944419\n",
      "Penalización por parar muy lejos: -  0.1273034329149571\n",
      "Penalización por duración del episodio: -  0.47443307844591376\n",
      "steer input from model: -0.05 , throttle:  0.0\n",
      "reward: 0.2867115165335711\n",
      "Recompensa por acortar distancias: +  0.8884480278944419\n",
      "Penalización por duración del episodio: -  0.47455385017285656\n",
      "Recompensa por acortar distancias: +  0.8884480278944419\n",
      "Penalización por parar muy lejos: -  0.1273034329149571\n",
      "Penalización por duración del episodio: -  0.4746423545840322\n",
      "Recompensa por acortar distancias: +  0.8884181712453705\n",
      "Penalización por parar muy lejos: -  0.1272699721708247\n",
      "Penalización por duración del episodio: -  0.47480433242002607\n",
      "Recompensa por acortar distancias: +  0.8884181712453705\n",
      "Penalización por duración del episodio: -  0.474932063517141\n",
      "Recompensa por acortar distancias: +  0.8884179254437393\n",
      "Penalización por duración del episodio: -  0.4751877198548399\n",
      "Recompensa por acortar distancias: +  0.8884179254437393\n",
      "Penalización por parar muy lejos: -  0.12726969676133448\n",
      "Penalización por duración del episodio: -  0.47530729103662855\n",
      "Recompensa por acortar distancias: +  0.8884179254437393\n",
      "Penalización por duración del episodio: -  0.47557888449225166\n",
      "Step: 9140, Mean Reward (últimos 10 pasos): 0.41283905506134033\n",
      "Recompensa por acortar distancias: +  0.8883892153926503\n",
      "Penalización por parar muy lejos: -  0.12723753561198925\n",
      "Penalización por duración del episodio: -  0.47596717116262977\n",
      "Recompensa por acortar distancias: +  0.8883950212721775\n",
      "Penalización por duración del episodio: -  0.4763504318264288\n",
      "Recompensa por acortar distancias: +  0.8883951820175279\n",
      "Penalización por duración del episodio: -  0.4767287957693067\n",
      "Recompensa por acortar distancias: +  0.8883951820175279\n",
      "Penalización por duración del episodio: -  0.47712359689616024\n",
      "Recompensa por acortar distancias: +  0.888354705620895\n",
      "Penalización por duración del episodio: -  0.4772390961351621\n",
      "Recompensa por acortar distancias: +  0.8883564885547827\n",
      "Penalización por parar muy lejos: -  0.12720089212265576\n",
      "Penalización por duración del episodio: -  0.47751817082869386\n",
      "Recompensa por acortar distancias: +  0.8883564885547827\n",
      "Penalización por parar muy lejos: -  0.12720089212265576\n",
      "Penalización por duración del episodio: -  0.4779174724015498\n",
      "Recompensa por acortar distancias: +  0.8883311089601619\n",
      "Penalización por parar muy lejos: -  0.12717248784277846\n",
      "Penalización por duración del episodio: -  0.47831718890004893\n",
      "Recompensa por acortar distancias: +  0.888330910292677\n",
      "Penalización por duración del episodio: -  0.4784356814369375\n",
      "Recompensa por acortar distancias: +  0.888330910292677\n",
      "Penalización por parar muy lejos: -  0.12717226554216993\n",
      "Penalización por duración del episodio: -  0.4785765763076082\n",
      "Step: 9150, Mean Reward (últimos 10 pasos): 0.2825820744037628\n",
      "Recompensa por acortar distancias: +  0.8883309765152063\n",
      "Penalización por duración del episodio: -  0.47871206039387315\n",
      "Recompensa por acortar distancias: +  0.8883309765152063\n",
      "Penalización por duración del episodio: -  0.47910041938291514\n",
      "Recompensa por acortar distancias: +  0.8883309765152063\n",
      "Penalización por duración del episodio: -  0.4791868504416968\n",
      "steer input from model: -0.1 , throttle:  0.7\n",
      "reward: 0.40914412607350953\n",
      "Recompensa por acortar distancias: +  0.8883309765152063\n",
      "Penalización por duración del episodio: -  0.47948151435751674\n",
      "Recompensa por acortar distancias: +  0.8883309765152063\n",
      "Penalización por duración del episodio: -  0.4796193218509037\n",
      "Recompensa por acortar distancias: +  0.8883309765152063\n",
      "Penalización por duración del episodio: -  0.479879581104558\n",
      "Recompensa por acortar distancias: +  0.8882918140873469\n",
      "Penalización por duración del episodio: -  0.4799817871507204\n",
      "Recompensa por acortar distancias: +  0.888265300015648\n",
      "Penalización por parar muy lejos: -  0.1270988874382488\n",
      "Penalización por duración del episodio: -  0.4801004196751786\n",
      "Recompensa por acortar distancias: +  0.888265300015648\n",
      "Penalización por parar muy lejos: -  0.1270988874382488\n",
      "Penalización por duración del episodio: -  0.48023834805448645\n",
      "Recompensa por acortar distancias: +  0.888265300015648\n",
      "Penalización por duración del episodio: -  0.4803813737466337\n",
      "Step: 9160, Mean Reward (últimos 10 pasos): 0.4078839123249054\n",
      "Recompensa por acortar distancias: +  0.888265300015648\n",
      "Penalización por duración del episodio: -  0.48064585445705804\n",
      "Recompensa por acortar distancias: +  0.888265300015648\n",
      "Penalización por duración del episodio: -  0.48103935798447445\n",
      "Recompensa por acortar distancias: +  0.8882002053050496\n",
      "Penalización por duración del episodio: -  0.48143633733796426\n",
      "Recompensa por acortar distancias: +  0.8882002053050496\n",
      "Penalización por parar muy lejos: -  0.1270261588802458\n",
      "Penalización por duración del episodio: -  0.48155322860480515\n",
      "Recompensa por acortar distancias: +  0.8882002053050496\n",
      "Penalización por parar muy lejos: -  0.1270261588802458\n",
      "Penalización por duración del episodio: -  0.481825036262698\n",
      "Recompensa por acortar distancias: +  0.8882002053050496\n",
      "Penalización por duración del episodio: -  0.48191104575612353\n",
      "Recompensa por acortar distancias: +  0.8882002053050496\n",
      "Penalización por parar muy lejos: -  0.1270261588802458\n",
      "Penalización por duración del episodio: -  0.4820367492865839\n",
      "Recompensa por acortar distancias: +  0.8881811170086444\n",
      "Penalización por duración del episodio: -  0.4821674436047528\n",
      "Recompensa por acortar distancias: +  0.8881811170086444\n",
      "Penalización por parar muy lejos: -  0.12700484580343455\n",
      "Penalización por duración del episodio: -  0.48230453983376176\n",
      "Recompensa por acortar distancias: +  0.8881811170086444\n",
      "Penalización por parar muy lejos: -  0.12700484580343455\n",
      "Penalización por duración del episodio: -  0.48259667736339373\n",
      "Step: 9170, Mean Reward (últimos 10 pasos): 0.27857959270477295\n",
      "Recompensa por acortar distancias: +  0.8881810554441619\n",
      "Penalización por duración del episodio: -  0.4829883161342907\n",
      "Recompensa por acortar distancias: +  0.888154314714978\n",
      "Penalización por duración del episodio: -  0.4833902224369618\n",
      "Recompensa por acortar distancias: +  0.8881039819006002\n",
      "Penalización por parar muy lejos: -  0.1269187839171555\n",
      "Penalización por duración del episodio: -  0.48376974460103306\n",
      "steer input from model: 0.25 , throttle:  0.0\n",
      "reward: 0.2774154533824117\n",
      "Recompensa por acortar distancias: +  0.8881039819006002\n",
      "Penalización por parar muy lejos: -  0.1269187839171555\n",
      "Penalización por duración del episodio: -  0.4841740799579142\n",
      "Recompensa por acortar distancias: +  0.8881039819006002\n",
      "Penalización por duración del episodio: -  0.4845666872346609\n",
      "Recompensa por acortar distancias: +  0.8878949916401307\n",
      "Penalización por duración del episodio: -  0.48496684672979506\n",
      "Recompensa por acortar distancias: +  0.8878949916401307\n",
      "Penalización por parar muy lejos: -  0.12668611761867538\n",
      "Penalización por duración del episodio: -  0.48535286366825015\n",
      "Recompensa por acortar distancias: +  0.8876875334938481\n",
      "Penalización por parar muy lejos: -  0.12645589139606253\n",
      "Penalización por duración del episodio: -  0.48545247937954633\n",
      "Recompensa por acortar distancias: +  0.8875862241325714\n",
      "Penalización por duración del episodio: -  0.48575401940385776\n",
      "Recompensa por acortar distancias: +  0.8874342152441008\n",
      "Penalización por parar muy lejos: -  0.12617575914563217\n",
      "Penalización por duración del episodio: -  0.4859183545213562\n",
      "Step: 9180, Mean Reward (últimos 10 pasos): 0.27534011006355286\n",
      "Recompensa por acortar distancias: +  0.8874342152441008\n",
      "Penalización por parar muy lejos: -  0.12617575914563217\n",
      "Penalización por duración del episodio: -  0.48603752961328783\n",
      "Recompensa por acortar distancias: +  0.8873035617989432\n",
      "Penalización por parar muy lejos: -  0.12603169824869895\n",
      "Penalización por duración del episodio: -  0.48616984500795457\n",
      "Recompensa por acortar distancias: +  0.8873035617989432\n",
      "Penalización por parar muy lejos: -  0.12603169824869895\n",
      "Penalización por duración del episodio: -  0.4865408756112996\n",
      "Recompensa por acortar distancias: +  0.8873035617989432\n",
      "Penalización por parar muy lejos: -  0.12603169824869895\n",
      "Penalización por duración del episodio: -  0.48693846271667923\n",
      "Recompensa por acortar distancias: +  0.8873035617989432\n",
      "Penalización por parar muy lejos: -  0.12603169824869895\n",
      "Penalización por duración del episodio: -  0.48734217786708783\n",
      "Recompensa por acortar distancias: +  0.8872426530273704\n",
      "Penalización por parar muy lejos: -  0.1259646370118043\n",
      "Penalización por duración del episodio: -  0.48774948366434845\n",
      "Recompensa por acortar distancias: +  0.8872426530273704\n",
      "Penalización por parar muy lejos: -  0.1259646370118043\n",
      "Penalización por duración del episodio: -  0.48813172032660695\n",
      "Recompensa por acortar distancias: +  0.8872410835470008\n",
      "Penalización por parar muy lejos: -  0.1259629098179483\n",
      "Penalización por duración del episodio: -  0.4885336240825823\n",
      "Recompensa por acortar distancias: +  0.8872258504870059\n",
      "Penalización por parar muy lejos: -  0.1259461481657827\n",
      "Penalización por duración del episodio: -  0.4889320932454655\n",
      "Recompensa por acortar distancias: +  0.8872258504870059\n",
      "Penalización por parar muy lejos: -  0.1259461481657827\n",
      "Penalización por duración del episodio: -  0.4893240050775804\n",
      "Step: 9190, Mean Reward (últimos 10 pasos): 0.2719556987285614\n",
      "Recompensa por acortar distancias: +  0.8872258504870059\n",
      "Penalización por parar muy lejos: -  0.1259461481657827\n",
      "Penalización por duración del episodio: -  0.489708428986533\n",
      "Recompensa por acortar distancias: +  0.8871766325198019\n",
      "Penalización por duración del episodio: -  0.4898376037513597\n",
      "Recompensa por acortar distancias: +  0.8871575587400835\n",
      "Penalización por duración del episodio: -  0.4901131763305916\n",
      "steer input from model: -0.05 , throttle:  1.0\n",
      "reward: 0.3970443824094919\n",
      "Recompensa por acortar distancias: +  0.8871575587400835\n",
      "Penalización por duración del episodio: -  0.49050719974761436\n",
      "Recompensa por acortar distancias: +  0.8870928463529968\n",
      "Penalización por parar muy lejos: -  0.125799962360505\n",
      "Penalización por duración del episodio: -  0.4908867260425265\n",
      "Recompensa por acortar distancias: +  0.8870723701948048\n",
      "Penalización por parar muy lejos: -  0.12577748311733075\n",
      "Penalización por duración del episodio: -  0.49102921201571026\n",
      "Recompensa por acortar distancias: +  0.8870718352015865\n",
      "Penalización por duración del episodio: -  0.4912891798129735\n",
      "Recompensa por acortar distancias: +  0.8870718352015865\n",
      "Penalización por duración del episodio: -  0.49166513411320584\n",
      "Recompensa por acortar distancias: +  0.8870718352015865\n",
      "Penalización por parar muy lejos: -  0.12577689588205798\n",
      "Penalización por duración del episodio: -  0.4920591713593945\n",
      "Recompensa por acortar distancias: +  0.8870460573721416\n",
      "Penalización por parar muy lejos: -  0.12574860650615421\n",
      "Penalización por duración del episodio: -  0.49244678859704044\n",
      "Step: 9200, Mean Reward (últimos 10 pasos): 0.2688506543636322\n",
      "Recompensa por acortar distancias: +  0.8870459331522312\n",
      "Penalización por duración del episodio: -  0.49283500488055765\n",
      "Recompensa por acortar distancias: +  0.8870459331522312\n",
      "Penalización por parar muy lejos: -  0.12574847021026672\n",
      "Penalización por duración del episodio: -  0.4929598752504634\n",
      "Recompensa por acortar distancias: +  0.8870460382613938\n",
      "Penalización por duración del episodio: -  0.493221036756977\n",
      "Recompensa por acortar distancias: +  0.8870506725350875\n",
      "Penalización por duración del episodio: -  0.49361013393534\n",
      "Recompensa por acortar distancias: +  0.8870409260350548\n",
      "Penalización por parar muy lejos: -  0.1257429765428663\n",
      "Penalización por duración del episodio: -  0.49400748099101677\n",
      "Recompensa por acortar distancias: +  0.8870409260350548\n",
      "Penalización por parar muy lejos: -  0.1257429765428663\n",
      "Penalización por duración del episodio: -  0.4943908064449718\n",
      "Recompensa por acortar distancias: +  0.8870545231558777\n",
      "Penalización por duración del episodio: -  0.49476931700499144\n",
      "Recompensa por acortar distancias: +  0.8870546187033241\n",
      "Penalización por duración del episodio: -  0.4951611777875924\n",
      "Recompensa por acortar distancias: +  0.8870546187033241\n",
      "Penalización por parar muy lejos: -  0.12575800074286625\n",
      "Penalización por duración del episodio: -  0.4952608812501756\n",
      "Recompensa por acortar distancias: +  0.8870547715790916\n",
      "Penalización por duración del episodio: -  0.4955537656741997\n",
      "Step: 9210, Mean Reward (últimos 10 pasos): 0.3915010094642639\n",
      "Recompensa por acortar distancias: +  0.8870546903638628\n",
      "Penalización por parar muy lejos: -  0.1257580793801959\n",
      "Penalización por duración del episodio: -  0.49568227533735965\n",
      "Recompensa por acortar distancias: +  0.8870549101225998\n",
      "Penalización por parar muy lejos: -  0.125758320534936\n",
      "Penalización por duración del episodio: -  0.4958144033191937\n",
      "Recompensa por acortar distancias: +  0.8870548671263545\n",
      "Penalización por duración del episodio: -  0.4963312986261832\n",
      "steer input from model: 0.9 , throttle:  0.7\n",
      "reward: 0.3907235685001713\n",
      "Recompensa por acortar distancias: +  0.887054953118831\n",
      "Penalización por duración del episodio: -  0.4967320549915805\n",
      "Recompensa por acortar distancias: +  0.887054953118831\n",
      "Penalización por parar muy lejos: -  0.12575836771743143\n",
      "Penalización por duración del episodio: -  0.4968536196226567\n",
      "Recompensa por acortar distancias: +  0.887054953118831\n",
      "Penalización por duración del episodio: -  0.49696247142224853\n",
      "Recompensa por acortar distancias: +  0.887054953118831\n",
      "Penalización por duración del episodio: -  0.4971002188599223\n",
      "Recompensa por acortar distancias: +  0.8870387950848296\n",
      "Penalización por duración del episodio: -  0.4972183514520346\n",
      "Recompensa por acortar distancias: +  0.8870387950848296\n",
      "Penalización por duración del episodio: -  0.49736390172123407\n",
      "Recompensa por acortar distancias: +  0.8870297214309885\n",
      "Penalización por duración del episodio: -  0.49744450887002284\n",
      "Step: 9220, Mean Reward (últimos 10 pasos): 0.3895852267742157\n",
      "Recompensa por acortar distancias: +  0.8870297214309885\n",
      "Penalización por duración del episodio: -  0.4979338346310966\n",
      "Recompensa por acortar distancias: +  0.8870297214309885\n",
      "Penalización por duración del episodio: -  0.49834021939548134\n",
      "Recompensa por acortar distancias: +  0.8870218178988354\n",
      "Penalización por parar muy lejos: -  0.1257220154767586\n",
      "Penalización por duración del episodio: -  0.4984713125177\n",
      "Recompensa por acortar distancias: +  0.8870218178988354\n",
      "Penalización por parar muy lejos: -  0.1257220154767586\n",
      "Penalización por duración del episodio: -  0.4985594848911387\n",
      "Recompensa por acortar distancias: +  0.8870065828854796\n",
      "Penalización por duración del episodio: -  0.49872106592628823\n",
      "Recompensa por acortar distancias: +  0.8870065828854796\n",
      "Penalización por parar muy lejos: -  0.12570530747273956\n",
      "Penalización por duración del episodio: -  0.49912622063894846\n",
      "Recompensa por acortar distancias: +  0.8870065828854796\n",
      "Penalización por parar muy lejos: -  0.12570530747273956\n",
      "Penalización por duración del episodio: -  0.49925438816979617\n",
      "Recompensa por acortar distancias: +  0.8870065828854796\n",
      "Penalización por parar muy lejos: -  0.12570530747273956\n",
      "Penalización por duración del episodio: -  0.49939478665345255\n",
      "Recompensa por acortar distancias: +  0.8870065828854796\n",
      "Penalización por parar muy lejos: -  0.12570530747273956\n",
      "Penalización por duración del episodio: -  0.4995321811610638\n",
      "Recompensa por acortar distancias: +  0.8870065828854796\n",
      "Penalización por duración del episodio: -  0.49965902572195503\n",
      "Step: 9230, Mean Reward (últimos 10 pasos): 0.387347549200058\n",
      "Recompensa por acortar distancias: +  0.8870065828854796\n",
      "Penalización por duración del episodio: -  0.4997856259477367\n",
      "Penalización por duración del episodio\n",
      "Recompensa por acortar distancias: +  0.9156964880280614\n",
      "Penalización por parar muy lejos: -  0.16593176585835873\n",
      "Penalización por duración del episodio: -  0.2690618017395577\n",
      "Recompensa por acortar distancias: +  0.9156964880280614\n",
      "Penalización por parar muy lejos: -  0.16593176585835873\n",
      "Penalización por duración del episodio: -  0.26919442034536695\n",
      "Recompensa por acortar distancias: +  0.9156964880280614\n",
      "Penalización por parar muy lejos: -  0.16593176585835873\n",
      "Penalización por duración del episodio: -  0.2693950610163759\n",
      "Recompensa por acortar distancias: +  0.9156964880280614\n",
      "Penalización por duración del episodio: -  0.2697122287107993\n",
      "Recompensa por acortar distancias: +  0.9156959137883166\n",
      "Penalización por duración del episodio: -  0.2700174319336174\n",
      "Recompensa por acortar distancias: +  0.9156958254434252\n",
      "Penalización por duración del episodio: -  0.27032340760802637\n",
      "Recompensa por acortar distancias: +  0.9156958254434252\n",
      "Penalización por parar muy lejos: -  0.16593057797864097\n",
      "Penalización por duración del episodio: -  0.27041689483247955\n",
      "Recompensa por acortar distancias: +  0.9156958254434252\n",
      "Penalización por parar muy lejos: -  0.16593057797864097\n",
      "Penalización por duración del episodio: -  0.2706269989833214\n",
      "Step: 9240, Mean Reward (últimos 10 pasos): 0.47913825511932373\n",
      "Recompensa por acortar distancias: +  0.9156958254434252\n",
      "Penalización por duración del episodio: -  0.2709342755701966\n",
      "Recompensa por acortar distancias: +  0.9156959947710598\n",
      "Penalización por duración del episodio: -  0.27125189925252324\n",
      "Recompensa por acortar distancias: +  0.9156959947710598\n",
      "Penalización por duración del episodio: -  0.2715548389175333\n",
      "Recompensa por acortar distancias: +  0.915695950598663\n",
      "Penalización por parar muy lejos: -  0.16593080235539917\n",
      "Penalización por duración del episodio: -  0.27186014280744547\n",
      "Recompensa por acortar distancias: +  0.9156960536675559\n",
      "Penalización por duración del episodio: -  0.27216799480263626\n",
      "Recompensa por acortar distancias: +  0.9156960536675559\n",
      "Penalización por duración del episodio: -  0.272253549017524\n",
      "Recompensa por acortar distancias: +  0.9156960536675559\n",
      "Penalización por duración del episodio: -  0.27247818231482046\n",
      "Recompensa por acortar distancias: +  0.9156960536675559\n",
      "Penalización por parar muy lejos: -  0.16593098713644133\n",
      "Penalización por duración del episodio: -  0.2727944035993437\n",
      "Recompensa por acortar distancias: +  0.9156964144077797\n",
      "Penalización por parar muy lejos: -  0.16593163387138704\n",
      "Penalización por duración del episodio: -  0.27310917385094774\n",
      "Recompensa por acortar distancias: +  0.9156964144077797\n",
      "Penalización por parar muy lejos: -  0.16593163387138704\n",
      "Penalización por duración del episodio: -  0.2734164929386782\n",
      "Step: 9250, Mean Reward (últimos 10 pasos): 0.47634828090667725\n",
      "Recompensa por acortar distancias: +  0.9156964070457484\n",
      "Penalización por duración del episodio: -  0.27373001869255176\n",
      "Recompensa por acortar distancias: +  0.9156965910963577\n",
      "Penalización por duración del episodio: -  0.2738491983294654\n",
      "steer input from model: 0.9 , throttle:  1.0\n",
      "reward: 0.6418473927668923\n",
      "Recompensa por acortar distancias: +  0.9156965910963577\n",
      "Penalización por duración del episodio: -  0.2739340530999662\n",
      "Recompensa por acortar distancias: +  0.9156965910963577\n",
      "Penalización por duración del episodio: -  0.27401342248686966\n",
      "Recompensa por acortar distancias: +  0.9156965910963577\n",
      "Penalización por parar muy lejos: -  0.16593195064026042\n",
      "Penalización por duración del episodio: -  0.27414712510573663\n",
      "Recompensa por acortar distancias: +  0.9156965910963577\n",
      "Penalización por parar muy lejos: -  0.16593195064026042\n",
      "Penalización por duración del episodio: -  0.27424140923183105\n",
      "Recompensa por acortar distancias: +  0.9156965910963577\n",
      "Penalización por duración del episodio: -  0.2746644292656777\n",
      "Recompensa por acortar distancias: +  0.9156964806660359\n",
      "Penalización por duración del episodio: -  0.27498263755824476\n",
      "Recompensa por acortar distancias: +  0.9156966647164992\n",
      "Penalización por parar muy lejos: -  0.16593208262743395\n",
      "Penalización por duración del episodio: -  0.2750782364142173\n",
      "Recompensa por acortar distancias: +  0.9156966647164992\n",
      "Penalización por duración del episodio: -  0.27530575044224836\n",
      "Step: 9260, Mean Reward (últimos 10 pasos): 0.640390932559967\n",
      "Recompensa por acortar distancias: +  0.9156966647164992\n",
      "Penalización por duración del episodio: -  0.27538827818446976\n",
      "Recompensa por acortar distancias: +  0.9156966647164992\n",
      "Penalización por duración del episodio: -  0.27548816163436335\n",
      "Recompensa por acortar distancias: +  0.9156966426304628\n",
      "Penalización por parar muy lejos: -  0.1659320430312731\n",
      "Penalización por duración del episodio: -  0.2755895716240185\n",
      "Recompensa por acortar distancias: +  0.9156966426304628\n",
      "Penalización por parar muy lejos: -  0.1659320430312731\n",
      "Penalización por duración del episodio: -  0.2757199898756368\n",
      "Recompensa por acortar distancias: +  0.9156968561285941\n",
      "Penalización por parar muy lejos: -  0.16593242579447878\n",
      "Penalización por duración del episodio: -  0.2758394877876428\n",
      "Recompensa por acortar distancias: +  0.9156968561285941\n",
      "Penalización por parar muy lejos: -  0.16593242579447878\n",
      "Penalización por duración del episodio: -  0.275949280784121\n",
      "Recompensa por acortar distancias: +  0.9156969960064137\n",
      "Penalización por parar muy lejos: -  0.16593267657075564\n",
      "Penalización por duración del episodio: -  0.27624417091533654\n",
      "Recompensa por acortar distancias: +  0.9156969960064137\n",
      "Penalización por duración del episodio: -  0.2765522540619633\n",
      "Recompensa por acortar distancias: +  0.9156969960064137\n",
      "Penalización por parar muy lejos: -  0.16593267657075564\n",
      "Penalización por duración del episodio: -  0.27665617248531243\n",
      "Recompensa por acortar distancias: +  0.9156969960064137\n",
      "Penalización por duración del episodio: -  0.27685737509901154\n",
      "Step: 9270, Mean Reward (últimos 10 pasos): 0.638839602470398\n",
      "Recompensa por acortar distancias: +  0.9156969960064137\n",
      "Penalización por parar muy lejos: -  0.16593267657075564\n",
      "Penalización por duración del episodio: -  0.277155027935423\n",
      "Recompensa por acortar distancias: +  0.915697025454349\n",
      "Penalización por duración del episodio: -  0.2774633407628207\n",
      "steer input from model: -0.1 , throttle:  0.7\n",
      "reward: 0.6382336846915282\n",
      "Recompensa por acortar distancias: +  0.915697025454349\n",
      "Penalización por duración del episodio: -  0.27756008382098235\n",
      "Recompensa por acortar distancias: +  0.915697025454349\n",
      "Penalización por duración del episodio: -  0.2777792641692757\n",
      "Recompensa por acortar distancias: +  0.915697025454349\n",
      "Penalización por parar muy lejos: -  0.16593272936580003\n",
      "Penalización por duración del episodio: -  0.2778772806197047\n",
      "Recompensa por acortar distancias: +  0.9156967751466021\n",
      "Penalización por duración del episodio: -  0.27797741425839506\n",
      "Recompensa por acortar distancias: +  0.9156967751466021\n",
      "Penalización por duración del episodio: -  0.2780923311623637\n",
      "Recompensa por acortar distancias: +  0.9156968487665976\n",
      "Penalización por duración del episodio: -  0.2782125628486166\n",
      "Recompensa por acortar distancias: +  0.9156968487665976\n",
      "Penalización por duración del episodio: -  0.2783102231335949\n",
      "Recompensa por acortar distancias: +  0.9156968487665976\n",
      "Penalización por parar muy lejos: -  0.16593241259573577\n",
      "Penalización por duración del episodio: -  0.2787235921872629\n",
      "Step: 9280, Mean Reward (últimos 10 pasos): 0.47104084491729736\n",
      "Recompensa por acortar distancias: +  0.9156968487665976\n",
      "Penalización por parar muy lejos: -  0.16593241259573577\n",
      "Penalización por duración del episodio: -  0.2788350739552782\n",
      "Recompensa por acortar distancias: +  0.9156968487665976\n",
      "Penalización por duración del episodio: -  0.2789462186149332\n",
      "Recompensa por acortar distancias: +  0.9156968487665976\n",
      "Penalización por duración del episodio: -  0.2790968874257229\n",
      "Recompensa por acortar distancias: +  0.9156968487665976\n",
      "Penalización por duración del episodio: -  0.2792173518554133\n",
      "Recompensa por acortar distancias: +  0.9156965616482846\n",
      "Penalización por parar muy lejos: -  0.16593189784541454\n",
      "Penalización por duración del episodio: -  0.2793081638089\n",
      "Recompensa por acortar distancias: +  0.9156965616482846\n",
      "Penalización por duración del episodio: -  0.2794188815321551\n",
      "Recompensa por acortar distancias: +  0.9156966131824062\n",
      "Penalización por duración del episodio: -  0.2795173678548573\n",
      "Recompensa por acortar distancias: +  0.9156966131824062\n",
      "Penalización por duración del episodio: -  0.2796134645793274\n",
      "Recompensa por acortar distancias: +  0.9156966131824062\n",
      "Penalización por parar muy lejos: -  0.16593199023640365\n",
      "Penalización por duración del episodio: -  0.2800140594654871\n",
      "Recompensa por acortar distancias: +  0.9156966131824062\n",
      "Penalización por duración del episodio: -  0.28010470773081697\n",
      "Step: 9290, Mean Reward (últimos 10 pasos): 0.6355919241905212\n",
      "Recompensa por acortar distancias: +  0.9156967309745766\n",
      "Penalización por duración del episodio: -  0.2801968164936523\n",
      "Recompensa por acortar distancias: +  0.9156967309745766\n",
      "Penalización por parar muy lejos: -  0.16593220141596207\n",
      "Penalización por duración del episodio: -  0.2802957733609566\n",
      "steer input from model: 0.1 , throttle:  0.0\n",
      "reward: 0.4694687561976579\n",
      "Recompensa por acortar distancias: +  0.9156968561285941\n",
      "Penalización por duración del episodio: -  0.2803866889741847\n",
      "Recompensa por acortar distancias: +  0.9156968561285941\n",
      "Penalización por parar muy lejos: -  0.16593242579447878\n",
      "Penalización por duración del episodio: -  0.28048233308991694\n",
      "Recompensa por acortar distancias: +  0.9156968561285941\n",
      "Penalización por duración del episodio: -  0.28056324199524607\n",
      "Recompensa por acortar distancias: +  0.9156968561285941\n",
      "Penalización por parar muy lejos: -  0.16593242579447878\n",
      "Penalización por duración del episodio: -  0.28065025877186217\n",
      "Recompensa por acortar distancias: +  0.9156968561285941\n",
      "Penalización por parar muy lejos: -  0.16593242579447878\n",
      "Penalización por duración del episodio: -  0.280769375219049\n",
      "Recompensa por acortar distancias: +  0.9156968561285941\n",
      "Penalización por parar muy lejos: -  0.16593242579447878\n",
      "Penalización por duración del episodio: -  0.2809823297646281\n",
      "Recompensa por acortar distancias: +  0.9156968561285941\n",
      "Penalización por duración del episodio: -  0.2810479248019264\n",
      "Recompensa por acortar distancias: +  0.9156968561285941\n",
      "Penalización por parar muy lejos: -  0.16593242579447878\n",
      "Penalización por duración del episodio: -  0.2812907272813913\n",
      "Step: 9300, Mean Reward (últimos 10 pasos): 0.4684737026691437\n",
      "Recompensa por acortar distancias: +  0.9156968561285941\n",
      "Penalización por duración del episodio: -  0.2814118075555779\n",
      "Recompensa por acortar distancias: +  0.9156968561285941\n",
      "Penalización por duración del episodio: -  0.28151363458262685\n",
      "Recompensa por acortar distancias: +  0.9156968561285941\n",
      "Penalización por duración del episodio: -  0.281654907369128\n",
      "Recompensa por acortar distancias: +  0.9156967088885559\n",
      "Penalización por parar muy lejos: -  0.16593216181977846\n",
      "Penalización por duración del episodio: -  0.2817869491406471\n",
      "Recompensa por acortar distancias: +  0.9156967088885559\n",
      "Penalización por parar muy lejos: -  0.16593216181977846\n",
      "Penalización por duración del episodio: -  0.28193856685525076\n",
      "Recompensa por acortar distancias: +  0.9156967088885559\n",
      "Penalización por parar muy lejos: -  0.16593216181977846\n",
      "Penalización por duración del episodio: -  0.2820249257179556\n",
      "Recompensa por acortar distancias: +  0.9156968855765736\n",
      "Penalización por duración del episodio: -  0.28211640928555526\n",
      "Recompensa por acortar distancias: +  0.9156968855765736\n",
      "Penalización por duración del episodio: -  0.28222456350002656\n",
      "Recompensa por acortar distancias: +  0.9156968855765736\n",
      "Penalización por parar muy lejos: -  0.1659324785894592\n",
      "Penalización por duración del episodio: -  0.2825645465825032\n",
      "Recompensa por acortar distancias: +  0.9156968855765736\n",
      "Penalización por duración del episodio: -  0.28266955625318185\n",
      "Step: 9310, Mean Reward (últimos 10 pasos): 0.6330273151397705\n",
      "Recompensa por acortar distancias: +  0.9156969812824427\n",
      "Penalización por duración del episodio: -  0.28278152847747556\n",
      "Recompensa por acortar distancias: +  0.9156969812824427\n",
      "Penalización por duración del episodio: -  0.28287739270108897\n",
      "steer input from model: 0.0 , throttle:  1.0\n",
      "reward: 0.6328195885813537\n",
      "Recompensa por acortar distancias: +  0.9156969812824427\n",
      "Penalización por parar muy lejos: -  0.16593265017323852\n",
      "Penalización por duración del episodio: -  0.2831933329670687\n",
      "Recompensa por acortar distancias: +  0.9156969812824427\n",
      "Penalización por parar muy lejos: -  0.16593265017323852\n",
      "Penalización por duración del episodio: -  0.28329916660275656\n",
      "Recompensa por acortar distancias: +  0.9156969812824427\n",
      "Penalización por parar muy lejos: -  0.16593265017323852\n",
      "Penalización por duración del episodio: -  0.2834110863284168\n",
      "Recompensa por acortar distancias: +  0.9156969812824427\n",
      "Penalización por duración del episodio: -  0.2835339542773878\n",
      "Recompensa por acortar distancias: +  0.9156969812824427\n",
      "Penalización por parar muy lejos: -  0.16593265017323852\n",
      "Penalización por duración del episodio: -  0.28362619902262204\n",
      "Recompensa por acortar distancias: +  0.9156969812824427\n",
      "Penalización por duración del episodio: -  0.28372390792761165\n",
      "Recompensa por acortar distancias: +  0.9156969812824427\n",
      "Penalización por duración del episodio: -  0.2838146828241638\n",
      "Recompensa por acortar distancias: +  0.9156969812824427\n",
      "Penalización por parar muy lejos: -  0.16593265017323852\n",
      "Penalización por duración del episodio: -  0.28414515389156475\n",
      "Step: 9320, Mean Reward (últimos 10 pasos): 0.46561917662620544\n",
      "Recompensa por acortar distancias: +  0.9156968634905899\n",
      "Penalización por parar muy lejos: -  0.16593243899322263\n",
      "Penalización por duración del episodio: -  0.2842669332120468\n",
      "Recompensa por acortar distancias: +  0.9156968634905899\n",
      "Penalización por parar muy lejos: -  0.16593243899322263\n",
      "Penalización por duración del episodio: -  0.28438182494775954\n",
      "Recompensa por acortar distancias: +  0.9156968634905899\n",
      "Penalización por parar muy lejos: -  0.16593243899322263\n",
      "Penalización por duración del episodio: -  0.28449232826168824\n",
      "Recompensa por acortar distancias: +  0.9156969886444285\n",
      "Penalización por duración del episodio: -  0.2845839017787643\n",
      "Recompensa por acortar distancias: +  0.9156969886444285\n",
      "Penalización por duración del episodio: -  0.2846755998554055\n",
      "Recompensa por acortar distancias: +  0.9156969886444285\n",
      "Penalización por duración del episodio: -  0.2847882600569191\n",
      "Recompensa por acortar distancias: +  0.9156969886444285\n",
      "Penalización por duración del episodio: -  0.2848993441604334\n",
      "Recompensa por acortar distancias: +  0.9156969886444285\n",
      "Penalización por duración del episodio: -  0.28501271838452535\n",
      "Recompensa por acortar distancias: +  0.9156969886444285\n",
      "Penalización por duración del episodio: -  0.28514511655578517\n",
      "Recompensa por acortar distancias: +  0.9156971358840228\n",
      "Penalización por parar muy lejos: -  0.16593292734733617\n",
      "Penalización por duración del episodio: -  0.2852318827423922\n",
      "Step: 9330, Mean Reward (últimos 10 pasos): 0.4645323157310486\n",
      "Recompensa por acortar distancias: +  0.9156971358840228\n",
      "Penalización por parar muy lejos: -  0.16593292734733617\n",
      "Penalización por duración del episodio: -  0.2853539227087335\n",
      "Recompensa por acortar distancias: +  0.9156971358840228\n",
      "Penalización por parar muy lejos: -  0.16593292734733617\n",
      "Penalización por duración del episodio: -  0.28544092157776363\n",
      "steer input from model: 0.9 , throttle:  0.0\n",
      "reward: 0.46432328695892305\n",
      "Recompensa por acortar distancias: +  0.9156971358840228\n",
      "Penalización por duración del episodio: -  0.285563691366891\n",
      "Recompensa por acortar distancias: +  0.9156971358840228\n",
      "Penalización por duración del episodio: -  0.2856821042768188\n",
      "Recompensa por acortar distancias: +  0.9156971358840228\n",
      "Penalización por duración del episodio: -  0.2857752363057171\n",
      "Recompensa por acortar distancias: +  0.9156971358840228\n",
      "Penalización por parar muy lejos: -  0.16593292734733617\n",
      "Penalización por duración del episodio: -  0.2859043861542695\n",
      "Recompensa por acortar distancias: +  0.9156971358840228\n",
      "Penalización por parar muy lejos: -  0.16593292734733617\n",
      "Penalización por duración del episodio: -  0.28600241563074347\n",
      "Recompensa por acortar distancias: +  0.9156971358840228\n",
      "Penalización por duración del episodio: -  0.2860923768694976\n",
      "Recompensa por acortar distancias: +  0.915696870852585\n",
      "Penalización por parar muy lejos: -  0.1659324521919673\n",
      "Penalización por duración del episodio: -  0.28638535035165025\n",
      "Recompensa por acortar distancias: +  0.9156969444725047\n",
      "Penalización por duración del episodio: -  0.2864600472169911\n",
      "Step: 9340, Mean Reward (últimos 10 pasos): 0.6292368769645691\n",
      "Recompensa por acortar distancias: +  0.9156969444725047\n",
      "Penalización por parar muy lejos: -  0.1659325841794604\n",
      "Penalización por duración del episodio: -  0.28670082400645036\n",
      "Recompensa por acortar distancias: +  0.9156969444725047\n",
      "Penalización por parar muy lejos: -  0.1659325841794604\n",
      "Penalización por duración del episodio: -  0.28701998411081764\n",
      "Recompensa por acortar distancias: +  0.9156969444725047\n",
      "Penalización por parar muy lejos: -  0.1659325841794604\n",
      "Penalización por duración del episodio: -  0.2873323357942438\n",
      "Recompensa por acortar distancias: +  0.9156967898706059\n",
      "Penalización por duración del episodio: -  0.28741408955408837\n",
      "Recompensa por acortar distancias: +  0.9156967898706059\n",
      "Penalización por duración del episodio: -  0.2874972295449175\n",
      "Recompensa por acortar distancias: +  0.9156967898706059\n",
      "Penalización por duración del episodio: -  0.28761286314377404\n",
      "Recompensa por acortar distancias: +  0.9156967898706059\n",
      "Penalización por duración del episodio: -  0.28795478269512437\n",
      "Recompensa por acortar distancias: +  0.9156967456985874\n",
      "Penalización por duración del episodio: -  0.28827031337042097\n",
      "Recompensa por acortar distancias: +  0.9156967751466021\n",
      "Penalización por duración del episodio: -  0.28858607413869003\n",
      "Recompensa por acortar distancias: +  0.9156967751466021\n",
      "Penalización por parar muy lejos: -  0.16593228060835197\n",
      "Penalización por duración del episodio: -  0.2889137859671007\n",
      "Step: 9350, Mean Reward (últimos 10 pasos): 0.46085071563720703\n",
      "Recompensa por acortar distancias: +  0.9156965837343402\n",
      "Penalización por parar muy lejos: -  0.1659319374415477\n",
      "Penalización por duración del episodio: -  0.28900334678159395\n",
      "Recompensa por acortar distancias: +  0.9156965837343402\n",
      "Penalización por parar muy lejos: -  0.1659319374415477\n",
      "Penalización por duración del episodio: -  0.2890979024323173\n",
      "steer input from model: -0.9 , throttle:  0.0\n",
      "reward: 0.4606667438604752\n",
      "Recompensa por acortar distancias: +  0.9156967530605918\n",
      "Penalización por duración del episodio: -  0.28921296768371546\n",
      "Recompensa por acortar distancias: +  0.9156967530605918\n",
      "Penalización por parar muy lejos: -  0.16593224101215326\n",
      "Penalización por duración del episodio: -  0.28932721199668715\n",
      "Recompensa por acortar distancias: +  0.9156967530605918\n",
      "Penalización por parar muy lejos: -  0.16593224101215326\n",
      "Penalización por duración del episodio: -  0.28954898316089506\n",
      "Recompensa por acortar distancias: +  0.9156967530605918\n",
      "Penalización por parar muy lejos: -  0.16593224101215326\n",
      "Penalización por duración del episodio: -  0.2898704327519819\n",
      "Recompensa por acortar distancias: +  0.9156968340426032\n",
      "Penalización por duración del episodio: -  0.2899731968962432\n",
      "Recompensa por acortar distancias: +  0.9156969739204561\n",
      "Penalización por duración del episodio: -  0.2901930805464284\n",
      "Recompensa por acortar distancias: +  0.9156969739204561\n",
      "Penalización por parar muy lejos: -  0.16593263697448127\n",
      "Penalización por duración del episodio: -  0.29031714243649914\n",
      "Recompensa por acortar distancias: +  0.9156969739204561\n",
      "Penalización por duración del episodio: -  0.2905148839991251\n",
      "Step: 9360, Mean Reward (últimos 10 pasos): 0.6251820921897888\n",
      "Recompensa por acortar distancias: +  0.9156969739204561\n",
      "Penalización por parar muy lejos: -  0.16593263697448127\n",
      "Penalización por duración del episodio: -  0.29083674565054424\n",
      "Recompensa por acortar distancias: +  0.9156969739204561\n",
      "Penalización por parar muy lejos: -  0.16593263697448127\n",
      "Penalización por duración del episodio: -  0.2909275144678139\n",
      "Recompensa por acortar distancias: +  0.9156969444725047\n",
      "Penalización por duración del episodio: -  0.29115948183770335\n",
      "Recompensa por acortar distancias: +  0.9156969150245438\n",
      "Penalización por duración del episodio: -  0.2914871607815673\n",
      "Recompensa por acortar distancias: +  0.9156969150245438\n",
      "Penalización por duración del episodio: -  0.2915756212177046\n",
      "Recompensa por acortar distancias: +  0.9156969812824427\n",
      "Penalización por parar muy lejos: -  0.16593265017323852\n",
      "Penalización por duración del episodio: -  0.29180420232549364\n",
      "Recompensa por acortar distancias: +  0.9156969297485253\n",
      "Penalización por duración del episodio: -  0.2921221416839991\n",
      "Recompensa por acortar distancias: +  0.9156971432459964\n",
      "Penalización por duración del episodio: -  0.29243930761119497\n",
      "Recompensa por acortar distancias: +  0.9156971432459964\n",
      "Penalización por duración del episodio: -  0.29276761973483917\n",
      "Recompensa por acortar distancias: +  0.9156971432459964\n",
      "Penalización por duración del episodio: -  0.2928514595949745\n",
      "Step: 9370, Mean Reward (últimos 10 pasos): 0.6228457093238831\n",
      "Recompensa por acortar distancias: +  0.9156971432459964\n",
      "Penalización por parar muy lejos: -  0.16593294054611193\n",
      "Penalización por duración del episodio: -  0.29309056086510915\n",
      "Recompensa por acortar distancias: +  0.9156970917121691\n",
      "Penalización por duración del episodio: -  0.2934074625883174\n",
      "steer input from model: 0.25 , throttle:  1.0\n",
      "reward: 0.6222896291238517\n",
      "Recompensa por acortar distancias: +  0.9156970917121691\n",
      "Penalización por duración del episodio: -  0.29373951163341694\n",
      "Recompensa por acortar distancias: +  0.9156970917121691\n",
      "Penalización por parar muy lejos: -  0.16593284815469897\n",
      "Penalización por duración del episodio: -  0.29408331728666853\n",
      "Recompensa por acortar distancias: +  0.9156971211600738\n",
      "Penalización por duración del episodio: -  0.2944050006715273\n",
      "Recompensa por acortar distancias: +  0.9156971211600738\n",
      "Penalización por duración del episodio: -  0.29473711301842903\n",
      "Recompensa por acortar distancias: +  0.9156971211600738\n",
      "Penalización por parar muy lejos: -  0.16593290094978708\n",
      "Penalización por duración del episodio: -  0.29506920034156736\n",
      "Recompensa por acortar distancias: +  0.9156972242276673\n",
      "Penalización por duración del episodio: -  0.29538672720703807\n",
      "Recompensa por acortar distancias: +  0.9156971726938848\n",
      "Penalización por parar muy lejos: -  0.1659329933412236\n",
      "Penalización por duración del episodio: -  0.2954827466001298\n",
      "Recompensa por acortar distancias: +  0.9156971726938848\n",
      "Penalización por parar muy lejos: -  0.1659329933412236\n",
      "Penalización por duración del episodio: -  0.2957219358519155\n",
      "Step: 9380, Mean Reward (últimos 10 pasos): 0.4540422558784485\n",
      "Recompensa por acortar distancias: +  0.9156972536755301\n",
      "Penalización por parar muy lejos: -  0.16593313852784994\n",
      "Penalización por duración del episodio: -  0.2958156643514746\n",
      "Recompensa por acortar distancias: +  0.9156972536755301\n",
      "Penalización por parar muy lejos: -  0.16593313852784994\n",
      "Penalización por duración del episodio: -  0.29591543554426447\n",
      "Recompensa por acortar distancias: +  0.9156972463135653\n",
      "Penalización por duración del episodio: -  0.29601179805064276\n",
      "Recompensa por acortar distancias: +  0.9156972463135653\n",
      "Penalización por parar muy lejos: -  0.16593312532906154\n",
      "Penalización por duración del episodio: -  0.296360170110362\n",
      "Recompensa por acortar distancias: +  0.9156972757614211\n",
      "Penalización por duración del episodio: -  0.2964255827911648\n",
      "Recompensa por acortar distancias: +  0.9156972757614211\n",
      "Penalización por duración del episodio: -  0.2966962371789081\n",
      "Recompensa por acortar distancias: +  0.9156972757614211\n",
      "Penalización por duración del episodio: -  0.29701900861444164\n",
      "Recompensa por acortar distancias: +  0.9156971726938848\n",
      "Penalización por parar muy lejos: -  0.1659329933412236\n",
      "Penalización por duración del episodio: -  0.29711297478644705\n",
      "Recompensa por acortar distancias: +  0.9156971726938848\n",
      "Penalización por parar muy lejos: -  0.1659329933412236\n",
      "Penalización por duración del episodio: -  0.29734054314853575\n",
      "Recompensa por acortar distancias: +  0.9156971726938848\n",
      "Penalización por duración del episodio: -  0.2976582908947614\n",
      "Step: 9390, Mean Reward (últimos 10 pasos): 0.6180388927459717\n",
      "Recompensa por acortar distancias: +  0.9156972536755301\n",
      "Penalización por parar muy lejos: -  0.16593313852784994\n",
      "Penalización por duración del episodio: -  0.2979845482513346\n",
      "Recompensa por acortar distancias: +  0.9156973346571048\n",
      "Penalización por parar muy lejos: -  0.16593328371457805\n",
      "Penalización por duración del episodio: -  0.29831539809299273\n",
      "steer input from model: 0.05 , throttle:  0.0\n",
      "reward: 0.451448652849534\n",
      "Recompensa por acortar distancias: +  0.91569745244836\n",
      "Penalización por duración del episodio: -  0.2986478373045542\n",
      "Recompensa por acortar distancias: +  0.91569745244836\n",
      "Penalización por duración del episodio: -  0.2989757169768342\n",
      "Recompensa por acortar distancias: +  0.91569745244836\n",
      "Penalización por parar muy lejos: -  0.1659334948954552\n",
      "Penalización por duración del episodio: -  0.29931170328216805\n",
      "Recompensa por acortar distancias: +  0.9156972168657003\n",
      "Penalización por duración del episodio: -  0.29964014551125084\n",
      "Recompensa por acortar distancias: +  0.9156972168657003\n",
      "Penalización por duración del episodio: -  0.29995837544791537\n",
      "Recompensa por acortar distancias: +  0.9156973125712279\n",
      "Penalización por duración del episodio: -  0.30029389590881245\n",
      "Recompensa por acortar distancias: +  0.9156974671722563\n",
      "Penalización por duración del episodio: -  0.3006086925095036\n",
      "Recompensa por acortar distancias: +  0.9156974671722563\n",
      "Penalización por parar muy lejos: -  0.16593352129307995\n",
      "Penalización por duración del episodio: -  0.3009381924705352\n",
      "Step: 9400, Mean Reward (últimos 10 pasos): 0.44882574677467346\n",
      "Recompensa por acortar distancias: +  0.9156974671722563\n",
      "Penalización por duración del episodio: -  0.3012759784233876\n",
      "Recompensa por acortar distancias: +  0.9156973199331874\n",
      "Penalización por duración del episodio: -  0.3015992904390974\n",
      "Recompensa por acortar distancias: +  0.9156973199331874\n",
      "Penalización por parar muy lejos: -  0.16593325731698358\n",
      "Penalización por duración del episodio: -  0.3019173574015453\n",
      "Recompensa por acortar distancias: +  0.9156973272951463\n",
      "Penalización por parar muy lejos: -  0.1659332705157804\n",
      "Penalización por duración del episodio: -  0.30226132840595316\n",
      "Recompensa por acortar distancias: +  0.9156974450864109\n",
      "Penalización por parar muy lejos: -  0.16593348169664404\n",
      "Penalización por duración del episodio: -  0.3023556463003749\n",
      "Recompensa por acortar distancias: +  0.9156974450864109\n",
      "Penalización por parar muy lejos: -  0.16593348169664404\n",
      "Penalización por duración del episodio: -  0.30258972784773297\n",
      "Recompensa por acortar distancias: +  0.9156973420190626\n",
      "Penalización por duración del episodio: -  0.3029277033552871\n",
      "Recompensa por acortar distancias: +  0.9156973420190626\n",
      "Penalización por duración del episodio: -  0.3032512025289226\n",
      "Recompensa por acortar distancias: +  0.9156969076625522\n",
      "Penalización por parar muy lejos: -  0.16593251818570337\n",
      "Penalización por duración del episodio: -  0.30356403942286625\n",
      "Recompensa por acortar distancias: +  0.9156968634905899\n",
      "Penalización por duración del episodio: -  0.30388454780057567\n",
      "Step: 9410, Mean Reward (últimos 10 pasos): 0.6118122935295105\n",
      "Recompensa por acortar distancias: +  0.9156969297485253\n",
      "Penalización por parar muy lejos: -  0.16593255778195506\n",
      "Penalización por duración del episodio: -  0.30397301762975404\n",
      "Recompensa por acortar distancias: +  0.9156969297485253\n",
      "Penalización por parar muy lejos: -  0.16593255778195506\n",
      "Penalización por duración del episodio: -  0.3040518759419391\n",
      "steer input from model: -0.9 , throttle:  0.0\n",
      "reward: 0.4457124960246312\n",
      "Recompensa por acortar distancias: +  0.9156969371105153\n",
      "Penalización por parar muy lejos: -  0.16593257098070735\n",
      "Penalización por duración del episodio: -  0.30416345349072704\n",
      "Recompensa por acortar distancias: +  0.9156969371105153\n",
      "Penalización por parar muy lejos: -  0.16593257098070735\n",
      "Penalización por duración del episodio: -  0.30454197147043854\n",
      "Recompensa por acortar distancias: +  0.915697062264255\n",
      "Penalización por duración del episodio: -  0.3046306954003846\n",
      "Recompensa por acortar distancias: +  0.915697062264255\n",
      "Penalización por parar muy lejos: -  0.16593279535962438\n",
      "Penalización por duración del episodio: -  0.3048728423137743\n",
      "Recompensa por acortar distancias: +  0.915697062264255\n",
      "Penalización por parar muy lejos: -  0.16593279535962438\n",
      "Penalización por duración del episodio: -  0.30521462816414185\n",
      "Recompensa por acortar distancias: +  0.915697062264255\n",
      "Penalización por duración del episodio: -  0.30555169620596423\n",
      "Recompensa por acortar distancias: +  0.9156968193186064\n",
      "Penalización por duración del episodio: -  0.305874727973092\n",
      "Recompensa por acortar distancias: +  0.9156968193186064\n",
      "Penalización por duración del episodio: -  0.3059392114422565\n",
      "Step: 9420, Mean Reward (últimos 10 pasos): 0.6097576022148132\n",
      "Recompensa por acortar distancias: +  0.9156968193186064\n",
      "Penalización por duración del episodio: -  0.3061981583360968\n",
      "Recompensa por acortar distancias: +  0.9156969223865349\n",
      "Penalización por duración del episodio: -  0.30630416858003007\n",
      "Recompensa por acortar distancias: +  0.9156969812824427\n",
      "Penalización por duración del episodio: -  0.3065401057649296\n",
      "Recompensa por acortar distancias: +  0.9156969812824427\n",
      "Penalización por duración del episodio: -  0.3066393844234881\n",
      "Recompensa por acortar distancias: +  0.9156970328163313\n",
      "Penalización por parar muy lejos: -  0.1659327425645632\n",
      "Penalización por duración del episodio: -  0.3067629667175315\n",
      "Recompensa por acortar distancias: +  0.9156970549022747\n",
      "Penalización por duración del episodio: -  0.30719409194793934\n",
      "Recompensa por acortar distancias: +  0.9156970549022747\n",
      "Penalización por duración del episodio: -  0.30753098725837075\n",
      "Recompensa por acortar distancias: +  0.9156969297485253\n",
      "Penalización por parar muy lejos: -  0.16593255778195506\n",
      "Penalización por duración del episodio: -  0.3078569569178644\n",
      "Recompensa por acortar distancias: +  0.9156969297485253\n",
      "Penalización por duración del episodio: -  0.30819403213078134\n",
      "Recompensa por acortar distancias: +  0.9156970696262342\n",
      "Penalización por parar muy lejos: -  0.16593280855839176\n",
      "Penalización por duración del episodio: -  0.30853161707929555\n",
      "Step: 9430, Mean Reward (últimos 10 pasos): 0.4412326514720917\n",
      "Recompensa por acortar distancias: +  0.9156971432459964\n",
      "Penalización por duración del episodio: -  0.30886543691629065\n",
      "Recompensa por acortar distancias: +  0.9156972757614211\n",
      "Penalización por duración del episodio: -  0.308941982605673\n",
      "steer input from model: 0.1 , throttle:  1.0\n",
      "reward: 0.606755293155748\n",
      "Recompensa por acortar distancias: +  0.9156972757614211\n",
      "Penalización por duración del episodio: -  0.3091916140239875\n",
      "Recompensa por acortar distancias: +  0.9156972757614211\n",
      "Penalización por parar muy lejos: -  0.16593317812422026\n",
      "Penalización por duración del episodio: -  0.3095335989489809\n",
      "Recompensa por acortar distancias: +  0.9156972757614211\n",
      "Penalización por duración del episodio: -  0.30984996329970055\n",
      "Recompensa por acortar distancias: +  0.9156970401783131\n",
      "Penalización por duración del episodio: -  0.31018000899839265\n",
      "Recompensa por acortar distancias: +  0.9156970401783131\n",
      "Penalización por duración del episodio: -  0.31052173818176715\n",
      "Recompensa por acortar distancias: +  0.9156968782145795\n",
      "Penalización por parar muy lejos: -  0.16593246539071285\n",
      "Penalización por duración del episodio: -  0.31062678821900114\n",
      "Recompensa por acortar distancias: +  0.9156969297485253\n",
      "Penalización por parar muy lejos: -  0.16593255778195506\n",
      "Penalización por duración del episodio: -  0.31085813249281097\n",
      "Recompensa por acortar distancias: +  0.915697062264255\n",
      "Penalización por duración del episodio: -  0.3111851291878895\n",
      "Step: 9440, Mean Reward (últimos 10 pasos): 0.6045119166374207\n",
      "Recompensa por acortar distancias: +  0.915697062264255\n",
      "Penalización por duración del episodio: -  0.31152290947567807\n",
      "Recompensa por acortar distancias: +  0.915697062264255\n",
      "Penalización por duración del episodio: -  0.31185299051280735\n",
      "Recompensa por acortar distancias: +  0.9156971432459964\n",
      "Penalización por duración del episodio: -  0.3121865493961757\n",
      "Recompensa por acortar distancias: +  0.9156971432459964\n",
      "Penalización por parar muy lejos: -  0.16593294054611193\n",
      "Penalización por duración del episodio: -  0.3125307170733682\n",
      "Recompensa por acortar distancias: +  0.9156972904853456\n",
      "Penalización por duración del episodio: -  0.3128759578125218\n",
      "Recompensa por acortar distancias: +  0.9156973641049325\n",
      "Penalización por parar muy lejos: -  0.16593333650977715\n",
      "Penalización por duración del episodio: -  0.3129874357474176\n",
      "Recompensa por acortar distancias: +  0.9156973861907973\n",
      "Penalización por duración del episodio: -  0.3132099487382596\n",
      "Recompensa por acortar distancias: +  0.9156973272951463\n",
      "Penalización por parar muy lejos: -  0.1659332705157804\n",
      "Penalización por duración del episodio: -  0.31328653935780765\n",
      "Recompensa por acortar distancias: +  0.9156973272951463\n",
      "Penalización por parar muy lejos: -  0.1659332705157804\n",
      "Penalización por duración del episodio: -  0.3133978916485907\n",
      "Recompensa por acortar distancias: +  0.9156973272951463\n",
      "Penalización por duración del episodio: -  0.31355145118932415\n",
      "Step: 9450, Mean Reward (últimos 10 pasos): 0.6021458506584167\n",
      "Recompensa por acortar distancias: +  0.9156973272951463\n",
      "Penalización por parar muy lejos: -  0.1659332705157804\n",
      "Penalización por duración del episodio: -  0.31389482458506357\n",
      "Recompensa por acortar distancias: +  0.9156973272951463\n",
      "Penalización por parar muy lejos: -  0.1659332705157804\n",
      "Penalización por duración del episodio: -  0.31402372500407794\n",
      "steer input from model: 0.1 , throttle:  0.0\n",
      "reward: 0.4357403317752879\n",
      "Recompensa por acortar distancias: +  0.9156971653319136\n",
      "Penalización por parar muy lejos: -  0.16593298014244443\n",
      "Penalización por duración del episodio: -  0.31423653173888544\n",
      "Recompensa por acortar distancias: +  0.9156971874178257\n",
      "Penalización por parar muy lejos: -  0.16593301973878447\n",
      "Penalización por duración del episodio: -  0.31458367877413246\n",
      "Recompensa por acortar distancias: +  0.9156970696262342\n",
      "Penalización por duración del episodio: -  0.31494197944730695\n",
      "Recompensa por acortar distancias: +  0.9156972021417641\n",
      "Penalización por duración del episodio: -  0.31503478910570243\n",
      "Recompensa por acortar distancias: +  0.9156972757614211\n",
      "Penalización por duración del episodio: -  0.3151365515125353\n",
      "Recompensa por acortar distancias: +  0.9156973346571048\n",
      "Penalización por duración del episodio: -  0.31526912959682346\n",
      "Recompensa por acortar distancias: +  0.9156973935527511\n",
      "Penalización por parar muy lejos: -  0.16593338930498974\n",
      "Penalización por duración del episodio: -  0.31559671535916795\n",
      "Recompensa por acortar distancias: +  0.9156973935527511\n",
      "Penalización por duración del episodio: -  0.3159239125176069\n",
      "Step: 9460, Mean Reward (últimos 10 pasos): 0.5997734665870667\n",
      "Recompensa por acortar distancias: +  0.9156973935527511\n",
      "Penalización por duración del episodio: -  0.3162639541400746\n",
      "Recompensa por acortar distancias: +  0.9156972831233836\n",
      "Penalización por duración del episodio: -  0.31660219085006946\n",
      "Recompensa por acortar distancias: +  0.9156972831233836\n",
      "Penalización por parar muy lejos: -  0.16593319132301204\n",
      "Penalización por duración del episodio: -  0.3167072024672993\n",
      "Recompensa por acortar distancias: +  0.915697378828843\n",
      "Penalización por duración del episodio: -  0.3169424487921717\n",
      "Recompensa por acortar distancias: +  0.9156973199331874\n",
      "Penalización por duración del episodio: -  0.317082993091527\n",
      "Recompensa por acortar distancias: +  0.9156972904853456\n",
      "Penalización por duración del episodio: -  0.31719170990566337\n",
      "Recompensa por acortar distancias: +  0.9156972904853456\n",
      "Penalización por duración del episodio: -  0.3172997132970202\n",
      "Recompensa por acortar distancias: +  0.9156974156386088\n",
      "Penalización por parar muy lejos: -  0.16593342890140797\n",
      "Penalización por duración del episodio: -  0.3176243685994477\n",
      "Recompensa por acortar distancias: +  0.9156973493810199\n",
      "Penalización por parar muy lejos: -  0.16593331011217594\n",
      "Penalización por duración del episodio: -  0.31795827529957954\n",
      "Recompensa por acortar distancias: +  0.9156973493810199\n",
      "Penalización por duración del episodio: -  0.3183138697534684\n",
      "Step: 9470, Mean Reward (últimos 10 pasos): 0.5973834991455078\n",
      "Recompensa por acortar distancias: +  0.9156972978473069\n",
      "Penalización por duración del episodio: -  0.3184046551504238\n",
      "Recompensa por acortar distancias: +  0.9156973493810199\n",
      "Penalización por parar muy lejos: -  0.16593331011217594\n",
      "Penalización por duración del episodio: -  0.31851390875109475\n",
      "steer input from model: -0.1 , throttle:  0.0\n",
      "reward: 0.4312501305177492\n",
      "Recompensa por acortar distancias: +  0.9156973493810199\n",
      "Penalización por duración del episodio: -  0.3186480385874148\n",
      "Recompensa por acortar distancias: +  0.9156973493810199\n",
      "Penalización por duración del episodio: -  0.31899522834592825\n",
      "Recompensa por acortar distancias: +  0.9156965101141344\n",
      "Penalización por duración del episodio: -  0.3193291192599199\n",
      "Recompensa por acortar distancias: +  0.9155554350371512\n",
      "Penalización por duración del episodio: -  0.319662283033388\n",
      "Recompensa por acortar distancias: +  0.9152950848099567\n",
      "Penalización por parar muy lejos: -  0.1652149214497416\n",
      "Penalización por duración del episodio: -  0.3199955687372694\n",
      "Recompensa por acortar distancias: +  0.9152950848099567\n",
      "Penalización por duración del episodio: -  0.3203296404536579\n",
      "Recompensa por acortar distancias: +  0.9152950848099567\n",
      "Penalización por duración del episodio: -  0.3204372659865365\n",
      "Recompensa por acortar distancias: +  0.9152950848099567\n",
      "Penalización por parar muy lejos: -  0.1652149214497416\n",
      "Penalización por duración del episodio: -  0.32053888717229945\n",
      "Step: 9480, Mean Reward (últimos 10 pasos): 0.42954128980636597\n",
      "Recompensa por acortar distancias: +  0.9145050656640128\n",
      "Penalización por parar muy lejos: -  0.16382020783867993\n",
      "Penalización por duración del episodio: -  0.3206664933155644\n",
      "Recompensa por acortar distancias: +  0.9144177113180346\n",
      "Penalización por parar muy lejos: -  0.1636672889755416\n",
      "Penalización por duración del episodio: -  0.3207712644367956\n",
      "Recompensa por acortar distancias: +  0.9144177113180346\n",
      "Penalización por parar muy lejos: -  0.1636672889755416\n",
      "Penalización por duración del episodio: -  0.32085485119885937\n",
      "Recompensa por acortar distancias: +  0.9144177113180346\n",
      "Penalización por parar muy lejos: -  0.1636672889755416\n",
      "Penalización por duración del episodio: -  0.32097477592468254\n",
      "Recompensa por acortar distancias: +  0.9144177113180346\n",
      "Penalización por duración del episodio: -  0.321334452673716\n",
      "Recompensa por acortar distancias: +  0.9143486583827632\n",
      "Penalización por parar muy lejos: -  0.16354658905338648\n",
      "Penalización por duración del episodio: -  0.3214545030137341\n",
      "Recompensa por acortar distancias: +  0.9143486583827632\n",
      "Penalización por duración del episodio: -  0.32158579657007635\n",
      "Recompensa por acortar distancias: +  0.914303387109345\n",
      "Penalización por duración del episodio: -  0.3220086092652896\n",
      "Recompensa por acortar distancias: +  0.9142476348242553\n",
      "Penalización por duración del episodio: -  0.32235381178373895\n",
      "Recompensa por acortar distancias: +  0.9142476348242553\n",
      "Penalización por duración del episodio: -  0.32270243904815377\n",
      "Step: 9490, Mean Reward (últimos 10 pasos): 0.5915452241897583\n",
      "Recompensa por acortar distancias: +  0.9137130648087596\n",
      "Penalización por parar muy lejos: -  0.16244307352836296\n",
      "Penalización por duración del episodio: -  0.32303686283175503\n",
      "Recompensa por acortar distancias: +  0.9135547731902606\n",
      "Penalización por duración del episodio: -  0.3233806960492573\n",
      "steer input from model: 0.0 , throttle:  0.3\n",
      "reward: 0.5901740771410033\n",
      "Recompensa por acortar distancias: +  0.9130283365608949\n",
      "Penalización por parar muy lejos: -  0.16126911036632596\n",
      "Penalización por duración del episodio: -  0.3237219381735738\n",
      "Recompensa por acortar distancias: +  0.9128151582491177\n",
      "Penalización por duración del episodio: -  0.32381341846420064\n",
      "Recompensa por acortar distancias: +  0.9126838507910932\n",
      "Penalización por duración del episodio: -  0.32394544004059894\n",
      "Recompensa por acortar distancias: +  0.9126838507910932\n",
      "Penalización por duración del episodio: -  0.3240797092502663\n",
      "Recompensa por acortar distancias: +  0.9126010434311217\n",
      "Penalización por parar muy lejos: -  0.16054419979964923\n",
      "Penalización por duración del episodio: -  0.3244329568814419\n",
      "Recompensa por acortar distancias: +  0.9126010434311217\n",
      "Penalización por parar muy lejos: -  0.16054419979964923\n",
      "Penalización por duración del episodio: -  0.3245314300271391\n",
      "Recompensa por acortar distancias: +  0.9126010434311217\n",
      "Penalización por duración del episodio: -  0.32478030287956683\n",
      "Recompensa por acortar distancias: +  0.9126010434311217\n",
      "Penalización por duración del episodio: -  0.32489146485989967\n",
      "Step: 9500, Mean Reward (últimos 10 pasos): 0.5877096056938171\n",
      "Recompensa por acortar distancias: +  0.9126010434311217\n",
      "Penalización por duración del episodio: -  0.3251104110869003\n",
      "Recompensa por acortar distancias: +  0.9119055758641073\n",
      "Penalización por duración del episodio: -  0.32546193818819685\n",
      "Recompensa por acortar distancias: +  0.9119055758641073\n",
      "Penalización por parar muy lejos: -  0.1593767357273981\n",
      "Penalización por duración del episodio: -  0.3258107081780926\n",
      "Recompensa por acortar distancias: +  0.9117550852943302\n",
      "Penalización por parar muy lejos: -  0.15912611007379895\n",
      "Penalización por duración del episodio: -  0.3259033899484439\n",
      "Recompensa por acortar distancias: +  0.9117550852943302\n",
      "Penalización por duración del episodio: -  0.3260129381231196\n",
      "Recompensa por acortar distancias: +  0.9117528370651216\n",
      "Penalización por parar muy lejos: -  0.15912237124237524\n",
      "Penalización por duración del episodio: -  0.32609851866917283\n",
      "Recompensa por acortar distancias: +  0.9117528370651216\n",
      "Penalización por duración del episodio: -  0.32619712224735153\n",
      "Recompensa por acortar distancias: +  0.9117507115585347\n",
      "Penalización por duración del episodio: -  0.326319106370745\n",
      "Recompensa por acortar distancias: +  0.9117507115585347\n",
      "Penalización por parar muy lejos: -  0.15911883664471682\n",
      "Penalización por duración del episodio: -  0.32640682516154834\n",
      "Recompensa por acortar distancias: +  0.9117507115585347\n",
      "Penalización por parar muy lejos: -  0.15911883664471682\n",
      "Penalización por duración del episodio: -  0.3268472326999355\n",
      "Step: 9510, Mean Reward (últimos 10 pasos): 0.4257846474647522\n",
      "Recompensa por acortar distancias: +  0.9117507115585347\n",
      "Penalización por parar muy lejos: -  0.15911883664471682\n",
      "Penalización por duración del episodio: -  0.3271818509780374\n",
      "Recompensa por acortar distancias: +  0.911557934858219\n",
      "Penalización por duración del episodio: -  0.3275057543468363\n",
      "steer input from model: 0.1 , throttle:  0.7\n",
      "reward: 0.5840521805113827\n",
      "Recompensa por acortar distancias: +  0.9114864439075913\n",
      "Penalización por duración del episodio: -  0.327858492382974\n",
      "Recompensa por acortar distancias: +  0.9113204640794973\n",
      "Penalización por parar muy lejos: -  0.15840624141191637\n",
      "Penalización por duración del episodio: -  0.327951757070322\n",
      "Recompensa por acortar distancias: +  0.9112796847187948\n",
      "Penalización por duración del episodio: -  0.328040153002353\n",
      "Recompensa por acortar distancias: +  0.9112796847187948\n",
      "Penalización por duración del episodio: -  0.32815268219541416\n",
      "Recompensa por acortar distancias: +  0.911253897881326\n",
      "Penalización por parar muy lejos: -  0.15829650146003496\n",
      "Penalización por duración del episodio: -  0.32853776956633335\n",
      "Recompensa por acortar distancias: +  0.9112146802904698\n",
      "Penalización por parar muy lejos: -  0.15823191163270864\n",
      "Penalización por duración del episodio: -  0.328874609633325\n",
      "Recompensa por acortar distancias: +  0.9112146802904698\n",
      "Penalización por parar muy lejos: -  0.15823191163270864\n",
      "Penalización por duración del episodio: -  0.32922672074455184\n",
      "Recompensa por acortar distancias: +  0.9112101434939813\n",
      "Penalización por parar muy lejos: -  0.1582244427502991\n",
      "Penalización por duración del episodio: -  0.3293016008081832\n",
      "Step: 9520, Mean Reward (últimos 10 pasos): 0.42368409037590027\n",
      "Recompensa por acortar distancias: +  0.9112100046091557\n",
      "Penalización por duración del episodio: -  0.3295790711238229\n",
      "Recompensa por acortar distancias: +  0.9112100046091557\n",
      "Penalización por duración del episodio: -  0.32992081317487204\n",
      "Recompensa por acortar distancias: +  0.911210907357018\n",
      "Penalización por duración del episodio: -  0.33026841994365325\n",
      "Recompensa por acortar distancias: +  0.9111823240366865\n",
      "Penalización por parar muy lejos: -  0.15817865764581207\n",
      "Penalización por duración del episodio: -  0.33061443937548446\n",
      "Recompensa por acortar distancias: +  0.9111874795256849\n",
      "Penalización por duración del episodio: -  0.33097002338749587\n",
      "Recompensa por acortar distancias: +  0.9111874795256849\n",
      "Penalización por parar muy lejos: -  0.15818714073091703\n",
      "Penalización por duración del episodio: -  0.3313150937321148\n",
      "Recompensa por acortar distancias: +  0.9111874795256849\n",
      "Penalización por duración del episodio: -  0.3316623220262261\n",
      "Recompensa por acortar distancias: +  0.9111346384011704\n",
      "Penalización por parar muy lejos: -  0.15810023200937898\n",
      "Penalización por duración del episodio: -  0.33201587250953934\n",
      "Recompensa por acortar distancias: +  0.9111346384011704\n",
      "Penalización por duración del episodio: -  0.3323540215010662\n",
      "Recompensa por acortar distancias: +  0.9110834067796288\n",
      "Penalización por parar muy lejos: -  0.1580160519846114\n",
      "Penalización por duración del episodio: -  0.3327018074669514\n",
      "Step: 9530, Mean Reward (últimos 10 pasos): 0.4203655421733856\n",
      "Recompensa por acortar distancias: +  0.9110428227490179\n",
      "Penalización por duración del episodio: -  0.33303959711192616\n",
      "Recompensa por acortar distancias: +  0.9110428227490179\n",
      "Penalización por parar muy lejos: -  0.15794942419125002\n",
      "Penalización por duración del episodio: -  0.3333945245216112\n",
      "steer input from model: -0.25 , throttle:  0.0\n",
      "reward: 0.4196988740361567\n",
      "Recompensa por acortar distancias: +  0.9110428227490179\n",
      "Penalización por duración del episodio: -  0.3337417629301366\n",
      "Recompensa por acortar distancias: +  0.9110428227490179\n",
      "Penalización por parar muy lejos: -  0.15794942419125002\n",
      "Penalización por duración del episodio: -  0.33383764090820806\n",
      "Recompensa por acortar distancias: +  0.9110428227490179\n",
      "Penalización por duración del episodio: -  0.3339770606695992\n",
      "Recompensa por acortar distancias: +  0.9110254465633219\n",
      "Penalización por duración del episodio: -  0.33442842761180336\n",
      "Recompensa por acortar distancias: +  0.9110253074178036\n",
      "Penalización por duración del episodio: -  0.33450676681126273\n",
      "Recompensa por acortar distancias: +  0.9110253074178036\n",
      "Penalización por duración del episodio: -  0.33477986569695967\n",
      "Recompensa por acortar distancias: +  0.9110268302775135\n",
      "Penalización por duración del episodio: -  0.33487620532049406\n",
      "Recompensa por acortar distancias: +  0.9110268302775135\n",
      "Penalización por parar muy lejos: -  0.15792318276172998\n",
      "Penalización por duración del episodio: -  0.33501160744088215\n",
      "Step: 9540, Mean Reward (últimos 10 pasos): 0.4180920422077179\n",
      "Recompensa por acortar distancias: +  0.9110171593322924\n",
      "Penalización por parar muy lejos: -  0.157907317864198\n",
      "Penalización por duración del episodio: -  0.33509299455404656\n",
      "Recompensa por acortar distancias: +  0.9110171593322924\n",
      "Penalización por duración del episodio: -  0.33548089981616086\n",
      "Recompensa por acortar distancias: +  0.910996492335506\n",
      "Penalización por parar muy lejos: -  0.15787342382540398\n",
      "Penalización por duración del episodio: -  0.3356193735666139\n",
      "Recompensa por acortar distancias: +  0.910996492335506\n",
      "Penalización por duración del episodio: -  0.3357114942051143\n",
      "Recompensa por acortar distancias: +  0.910996492335506\n",
      "Penalización por parar muy lejos: -  0.15787342382540398\n",
      "Penalización por duración del episodio: -  0.33581282167497417\n",
      "Recompensa por acortar distancias: +  0.910996492335506\n",
      "Penalización por duración del episodio: -  0.33618000504464396\n",
      "Recompensa por acortar distancias: +  0.9109617747164444\n",
      "Penalización por parar muy lejos: -  0.15781651593562113\n",
      "Penalización por duración del episodio: -  0.33652390496526485\n",
      "Recompensa por acortar distancias: +  0.9109437885227265\n",
      "Penalización por parar muy lejos: -  0.1577870480304072\n",
      "Penalización por duración del episodio: -  0.33688785501623986\n",
      "Recompensa por acortar distancias: +  0.9109437885227265\n",
      "Penalización por parar muy lejos: -  0.1577870480304072\n",
      "Penalización por duración del episodio: -  0.33724752761272236\n",
      "Recompensa por acortar distancias: +  0.9109427672727504\n",
      "Penalización por duración del episodio: -  0.3373392926329842\n",
      "Step: 9550, Mean Reward (últimos 10 pasos): 0.5736034512519836\n",
      "Recompensa por acortar distancias: +  0.9109427672727504\n",
      "Penalización por duración del episodio: -  0.3376151197448182\n",
      "Recompensa por acortar distancias: +  0.9109427672727504\n",
      "Penalización por parar muy lejos: -  0.15778537514799915\n",
      "Penalización por duración del episodio: -  0.33796409324428034\n",
      "steer input from model: 0.0 , throttle:  0.0\n",
      "reward: 0.41519329888047085\n",
      "Recompensa por acortar distancias: +  0.9109427672727504\n",
      "Penalización por duración del episodio: -  0.33805408113866026\n",
      "Recompensa por acortar distancias: +  0.9109427672727504\n",
      "Penalización por parar muy lejos: -  0.15778537514799915\n",
      "Penalización por duración del episodio: -  0.33816946929697816\n",
      "Recompensa por acortar distancias: +  0.9109428523773185\n",
      "Penalización por duración del episodio: -  0.33831764107009693\n",
      "Recompensa por acortar distancias: +  0.9109428523773185\n",
      "Penalización por duración del episodio: -  0.33841033860156217\n",
      "Recompensa por acortar distancias: +  0.9109427982198746\n",
      "Penalización por parar muy lejos: -  0.1577854258411937\n",
      "Penalización por duración del episodio: -  0.33867137488529\n",
      "Recompensa por acortar distancias: +  0.9109427982198746\n",
      "Penalización por duración del episodio: -  0.33902331227303983\n",
      "Recompensa por acortar distancias: +  0.9109429529553501\n",
      "Penalización por duración del episodio: -  0.3393720708404452\n",
      "Recompensa por acortar distancias: +  0.9109431773213588\n",
      "Penalización por parar muy lejos: -  0.15778604683390088\n",
      "Penalización por duración del episodio: -  0.33971739925220495\n",
      "Step: 9560, Mean Reward (últimos 10 pasos): 0.41343972086906433\n",
      "Recompensa por acortar distancias: +  0.9109445621899165\n",
      "Penalización por parar muy lejos: -  0.1577883153751605\n",
      "Penalización por duración del episodio: -  0.34006299983440286\n",
      "Recompensa por acortar distancias: +  0.9109445621899165\n",
      "Penalización por duración del episodio: -  0.3404105319563147\n",
      "Recompensa por acortar distancias: +  0.910888610419639\n",
      "Penalización por duración del episodio: -  0.3405119510625386\n",
      "Recompensa por acortar distancias: +  0.910888610419639\n",
      "Penalización por duración del episodio: -  0.340645792677353\n",
      "Recompensa por acortar distancias: +  0.9108675448395811\n",
      "Penalización por duración del episodio: -  0.34076773725641285\n",
      "Recompensa por acortar distancias: +  0.9108675448395811\n",
      "Penalización por parar muy lejos: -  0.15766224244000002\n",
      "Penalización por duración del episodio: -  0.3411191432852533\n",
      "Recompensa por acortar distancias: +  0.9108675448395811\n",
      "Penalización por parar muy lejos: -  0.15766224244000002\n",
      "Penalización por duración del episodio: -  0.34146769486799905\n",
      "Recompensa por acortar distancias: +  0.9108502539273464\n",
      "Penalización por parar muy lejos: -  0.1576339629797852\n",
      "Penalización por duración del episodio: -  0.3415820919168032\n",
      "Recompensa por acortar distancias: +  0.9108502539273464\n",
      "Penalización por parar muy lejos: -  0.1576339629797852\n",
      "Penalización por duración del episodio: -  0.34183067520308114\n",
      "Recompensa por acortar distancias: +  0.910850122278702\n",
      "Penalización por duración del episodio: -  0.3421766568065508\n",
      "Step: 9570, Mean Reward (últimos 10 pasos): 0.5686734914779663\n",
      "Recompensa por acortar distancias: +  0.910850122278702\n",
      "Penalización por duración del episodio: -  0.3425363476240955\n",
      "Recompensa por acortar distancias: +  0.910850122278702\n",
      "Penalización por parar muy lejos: -  0.15763374770190447\n",
      "Penalización por duración del episodio: -  0.34261251534669346\n",
      "steer input from model: -0.9 , throttle:  0.0\n",
      "reward: 0.410603859230104\n",
      "Recompensa por acortar distancias: +  0.9108254854072297\n",
      "Penalización por duración del episodio: -  0.34271296066957174\n",
      "Recompensa por acortar distancias: +  0.9108254854072297\n",
      "Penalización por duración del episodio: -  0.34288210195282276\n",
      "Recompensa por acortar distancias: +  0.9108256403265812\n",
      "Penalización por duración del episodio: -  0.3432397503257106\n",
      "Recompensa por acortar distancias: +  0.9108256403265812\n",
      "Penalización por duración del episodio: -  0.34332234623949026\n",
      "Recompensa por acortar distancias: +  0.9108256403265812\n",
      "Penalización por duración del episodio: -  0.3434167570211695\n",
      "Recompensa por acortar distancias: +  0.9108256403265812\n",
      "Penalización por duración del episodio: -  0.34358509081606886\n",
      "Recompensa por acortar distancias: +  0.9108256403265812\n",
      "Penalización por duración del episodio: -  0.343936460738973\n",
      "Recompensa por acortar distancias: +  0.9107425687362259\n",
      "Penalización por duración del episodio: -  0.34404191204255824\n",
      "Step: 9580, Mean Reward (últimos 10 pasos): 0.5667006373405457\n",
      "Recompensa por acortar distancias: +  0.9107214875244904\n",
      "Penalización por parar muy lejos: -  0.1574236492169505\n",
      "Penalización por duración del episodio: -  0.3441226249547219\n",
      "Recompensa por acortar distancias: +  0.9107214875244904\n",
      "Penalización por duración del episodio: -  0.3442902998086339\n",
      "Recompensa por acortar distancias: +  0.9107214875244904\n",
      "Penalización por parar muy lejos: -  0.1574236492169505\n",
      "Penalización por duración del episodio: -  0.34437495385650113\n",
      "Recompensa por acortar distancias: +  0.9107214875244904\n",
      "Penalización por duración del episodio: -  0.34447428841435473\n",
      "Recompensa por acortar distancias: +  0.9107214875244904\n",
      "Penalización por duración del episodio: -  0.344566270596197\n",
      "Recompensa por acortar distancias: +  0.9107214875244904\n",
      "Penalización por parar muy lejos: -  0.1574236492169505\n",
      "Penalización por duración del episodio: -  0.3449848061292057\n",
      "Recompensa por acortar distancias: +  0.9105421507901499\n",
      "Penalización por duración del episodio: -  0.3451329465189867\n",
      "Recompensa por acortar distancias: +  0.9105421507901499\n",
      "Penalización por duración del episodio: -  0.3453477965012603\n",
      "Recompensa por acortar distancias: +  0.9104809886966337\n",
      "Penalización por parar muy lejos: -  0.1570321840960617\n",
      "Penalización por duración del episodio: -  0.3456992269633786\n",
      "Recompensa por acortar distancias: +  0.9104809886966337\n",
      "Penalización por parar muy lejos: -  0.1570321840960617\n",
      "Penalización por duración del episodio: -  0.34579741522187457\n",
      "Step: 9590, Mean Reward (últimos 10 pasos): 0.4076513946056366\n",
      "Recompensa por acortar distancias: +  0.9104305604974746\n",
      "Penalización por parar muy lejos: -  0.15695032167982906\n",
      "Penalización por duración del episodio: -  0.3460414326681882\n",
      "Recompensa por acortar distancias: +  0.9104299305662061\n",
      "Penalización por duración del episodio: -  0.346143206525173\n",
      "steer input from model: -0.9 , throttle:  1.0\n",
      "reward: 0.5642867240410332\n",
      "Recompensa por acortar distancias: +  0.9104299305662061\n",
      "Penalización por duración del episodio: -  0.3463845480900831\n",
      "Recompensa por acortar distancias: +  0.910429051766529\n",
      "Penalización por parar muy lejos: -  0.1569478736627839\n",
      "Penalización por duración del episodio: -  0.346733472146365\n",
      "Recompensa por acortar distancias: +  0.910429051766529\n",
      "Penalización por duración del episodio: -  0.3470903683485626\n",
      "Recompensa por acortar distancias: +  0.910429051766529\n",
      "Penalización por parar muy lejos: -  0.1569478736627839\n",
      "Penalización por duración del episodio: -  0.34720224610335504\n",
      "Recompensa por acortar distancias: +  0.910429051766529\n",
      "Penalización por parar muy lejos: -  0.1569478736627839\n",
      "Penalización por duración del episodio: -  0.3473068985546739\n",
      "Recompensa por acortar distancias: +  0.9104278307664629\n",
      "Penalización por duración del episodio: -  0.34744263635840034\n",
      "Recompensa por acortar distancias: +  0.9104278307664629\n",
      "Penalización por parar muy lejos: -  0.15694589255833732\n",
      "Penalización por duración del episodio: -  0.3475493987271716\n",
      "Recompensa por acortar distancias: +  0.9104277296638739\n",
      "Penalización por parar muy lejos: -  0.1569457285187541\n",
      "Penalización por duración del episodio: -  0.34766438448883064\n",
      "Step: 9600, Mean Reward (últimos 10 pasos): 0.4058176279067993\n",
      "Recompensa por acortar distancias: +  0.9104277296638739\n",
      "Penalización por parar muy lejos: -  0.1569457285187541\n",
      "Penalización por duración del episodio: -  0.3477918157534086\n",
      "Recompensa por acortar distancias: +  0.9104277296638739\n",
      "Penalización por duración del episodio: -  0.3481413915116454\n",
      "Recompensa por acortar distancias: +  0.9104286629146332\n",
      "Penalización por parar muy lejos: -  0.15694724273559227\n",
      "Penalización por duración del episodio: -  0.34849763214630153\n",
      "Recompensa por acortar distancias: +  0.9104071103629126\n",
      "Penalización por duración del episodio: -  0.34884955796053485\n",
      "Recompensa por acortar distancias: +  0.9104071103629126\n",
      "Penalización por duración del episodio: -  0.3491912781271224\n",
      "Recompensa por acortar distancias: +  0.9104071103629126\n",
      "Penalización por duración del episodio: -  0.349283398960335\n",
      "Recompensa por acortar distancias: +  0.9104071103629126\n",
      "Penalización por parar muy lejos: -  0.1569122799776249\n",
      "Penalización por duración del episodio: -  0.3495294239284235\n",
      "Recompensa por acortar distancias: +  0.9103921896189887\n",
      "Penalización por duración del episodio: -  0.34963492259231216\n",
      "Recompensa por acortar distancias: +  0.9103854675509585\n",
      "Penalización por parar muy lejos: -  0.1568771848055351\n",
      "Penalización por duración del episodio: -  0.34973002007158915\n",
      "Recompensa por acortar distancias: +  0.9103854675509585\n",
      "Penalización por parar muy lejos: -  0.1568771848055351\n",
      "Penalización por duración del episodio: -  0.34986641418579806\n",
      "Step: 9610, Mean Reward (últimos 10 pasos): 0.40364187955856323\n",
      "Recompensa por acortar distancias: +  0.9103854675509585\n",
      "Penalización por parar muy lejos: -  0.1568771848055351\n",
      "Penalización por duración del episodio: -  0.350211117575794\n",
      "Recompensa por acortar distancias: +  0.9103854675509585\n",
      "Penalización por parar muy lejos: -  0.1568771848055351\n",
      "Penalización por duración del episodio: -  0.35058052866232947\n",
      "steer input from model: 0.0 , throttle:  0.0\n",
      "reward: 0.4029277540830939\n",
      "Recompensa por acortar distancias: +  0.9103294092808314\n",
      "Penalización por parar muy lejos: -  0.15678634801917155\n",
      "Penalización por duración del episodio: -  0.3507056853265197\n",
      "Recompensa por acortar distancias: +  0.9103132388911575\n",
      "Penalización por duración del episodio: -  0.3508544343064474\n",
      "Recompensa por acortar distancias: +  0.9103132388911575\n",
      "Penalización por duración del episodio: -  0.351294530739642\n",
      "Recompensa por acortar distancias: +  0.9102863265331349\n",
      "Penalización por parar muy lejos: -  0.15671660062675458\n",
      "Penalización por duración del episodio: -  0.35138424424759584\n",
      "Recompensa por acortar distancias: +  0.9102863265331349\n",
      "Penalización por parar muy lejos: -  0.15671660062675458\n",
      "Penalización por duración del episodio: -  0.35145769205782607\n",
      "Recompensa por acortar distancias: +  0.9102863265331349\n",
      "Penalización por duración del episodio: -  0.35157950289155787\n",
      "Recompensa por acortar distancias: +  0.9102863265331349\n",
      "Penalización por parar muy lejos: -  0.15671660062675458\n",
      "Penalización por duración del episodio: -  0.3520037822421408\n",
      "Recompensa por acortar distancias: +  0.9102668697235554\n",
      "Penalización por duración del episodio: -  0.35236877576765663\n",
      "Step: 9620, Mean Reward (últimos 10 pasos): 0.5578981041908264\n",
      "Recompensa por acortar distancias: +  0.9102667139291074\n",
      "Penalización por parar muy lejos: -  0.15668486781431398\n",
      "Penalización por duración del episodio: -  0.3527208831367485\n",
      "Recompensa por acortar distancias: +  0.9102664412882369\n",
      "Penalización por parar muy lejos: -  0.15668442676760866\n",
      "Penalización por duración del episodio: -  0.35308657993935333\n",
      "Recompensa por acortar distancias: +  0.9102665347651909\n",
      "Penalización por parar muy lejos: -  0.15668457798350802\n",
      "Penalización por duración del episodio: -  0.3534356569661874\n",
      "Recompensa por acortar distancias: +  0.9102665347651909\n",
      "Penalización por parar muy lejos: -  0.15668457798350802\n",
      "Penalización por duración del episodio: -  0.35378594781691086\n",
      "Recompensa por acortar distancias: +  0.9102665347651909\n",
      "Penalización por duración del episodio: -  0.3538937276733521\n",
      "Recompensa por acortar distancias: +  0.9102665347651909\n",
      "Penalización por parar muy lejos: -  0.15668457798350802\n",
      "Penalización por duración del episodio: -  0.3541468713556545\n",
      "Recompensa por acortar distancias: +  0.9102716291264359\n",
      "Penalización por duración del episodio: -  0.3542623256507138\n",
      "Recompensa por acortar distancias: +  0.9102716291264359\n",
      "Penalización por duración del episodio: -  0.3543604887945037\n",
      "Recompensa por acortar distancias: +  0.9102716291264359\n",
      "Penalización por parar muy lejos: -  0.15669281942973107\n",
      "Penalización por duración del episodio: -  0.35449603485690223\n",
      "Recompensa por acortar distancias: +  0.9102716291264359\n",
      "Penalización por duración del episodio: -  0.35466833923951047\n",
      "Step: 9630, Mean Reward (últimos 10 pasos): 0.5556032657623291\n",
      "Recompensa por acortar distancias: +  0.9102716291264359\n",
      "Penalización por parar muy lejos: -  0.15669281942973107\n",
      "Penalización por duración del episodio: -  0.3548499328456804\n",
      "Recompensa por acortar distancias: +  0.9102716291264359\n",
      "Penalización por duración del episodio: -  0.35522069933206196\n",
      "steer input from model: 0.05 , throttle:  0.3\n",
      "reward: 0.555050929794374\n",
      "Recompensa por acortar distancias: +  0.9103211258852634\n",
      "Penalización por parar muy lejos: -  0.15677293358176309\n",
      "Penalización por duración del episodio: -  0.35559537111463424\n",
      "Recompensa por acortar distancias: +  0.9103378554541608\n",
      "Penalización por duración del episodio: -  0.3559487611727663\n",
      "Recompensa por acortar distancias: +  0.9103378554541608\n",
      "Penalización por parar muy lejos: -  0.15680002817743854\n",
      "Penalización por duración del episodio: -  0.35629765486081666\n",
      "Recompensa por acortar distancias: +  0.9103378554541608\n",
      "Penalización por parar muy lejos: -  0.15680002817743854\n",
      "Penalización por duración del episodio: -  0.3564315913261386\n",
      "Recompensa por acortar distancias: +  0.9103394278422597\n",
      "Penalización por parar muy lejos: -  0.15680257518976776\n",
      "Penalización por duración del episodio: -  0.35652796160020667\n",
      "Recompensa por acortar distancias: +  0.9103394278422597\n",
      "Penalización por parar muy lejos: -  0.15680257518976776\n",
      "Penalización por duración del episodio: -  0.3566636489752889\n",
      "Recompensa por acortar distancias: +  0.9103397469873045\n",
      "Penalización por duración del episodio: -  0.3570280974344239\n",
      "Recompensa por acortar distancias: +  0.9103397469873045\n",
      "Penalización por duración del episodio: -  0.35712251967330005\n",
      "Step: 9640, Mean Reward (últimos 10 pasos): 0.5532172322273254\n",
      "Recompensa por acortar distancias: +  0.9103397469873045\n",
      "Penalización por duración del episodio: -  0.3572322157838614\n",
      "Recompensa por acortar distancias: +  0.9103399960754082\n",
      "Penalización por duración del episodio: -  0.35737574272094286\n",
      "Recompensa por acortar distancias: +  0.9103399960754082\n",
      "Penalización por parar muy lejos: -  0.1568034956530032\n",
      "Penalización por duración del episodio: -  0.3574837866848836\n",
      "Recompensa por acortar distancias: +  0.9103402140269873\n",
      "Penalización por parar muy lejos: -  0.15680384870856195\n",
      "Penalización por duración del episodio: -  0.35773718360720247\n",
      "Recompensa por acortar distancias: +  0.9103401906750552\n",
      "Penalización por duración del episodio: -  0.3580844607416859\n",
      "Recompensa por acortar distancias: +  0.9103401906750552\n",
      "Penalización por duración del episodio: -  0.35844700811268204\n",
      "Recompensa por acortar distancias: +  0.9103401906750552\n",
      "Penalización por parar muy lejos: -  0.15680381088114975\n",
      "Penalización por duración del episodio: -  0.3587995588738167\n",
      "Recompensa por acortar distancias: +  0.9103404397620476\n",
      "Penalización por parar muy lejos: -  0.15680421437393005\n",
      "Penalización por duración del episodio: -  0.35891238454755264\n",
      "Recompensa por acortar distancias: +  0.9103404397620476\n",
      "Penalización por parar muy lejos: -  0.15680421437393005\n",
      "Penalización por duración del episodio: -  0.35917630330621186\n",
      "Recompensa por acortar distancias: +  0.9103404397620476\n",
      "Penalización por duración del episodio: -  0.35929601964944846\n",
      "Step: 9650, Mean Reward (últimos 10 pasos): 0.5510444045066833\n",
      "Recompensa por acortar distancias: +  0.9103404397620476\n",
      "Penalización por duración del episodio: -  0.3594085187082266\n",
      "Recompensa por acortar distancias: +  0.9103404397620476\n",
      "Penalización por parar muy lejos: -  0.15680421437393005\n",
      "Penalización por duración del episodio: -  0.35954903799606314\n",
      "steer input from model: -0.1 , throttle:  0.0\n",
      "reward: 0.39398718739205435\n",
      "Recompensa por acortar distancias: +  0.9103405098176518\n",
      "Penalización por duración del episodio: -  0.3599067607152128\n",
      "Recompensa por acortar distancias: +  0.91034056430531\n",
      "Penalización por parar muy lejos: -  0.1568044161206371\n",
      "Penalización por duración del episodio: -  0.36000494026037616\n",
      "Recompensa por acortar distancias: +  0.91034056430531\n",
      "Penalización por parar muy lejos: -  0.1568044161206371\n",
      "Penalización por duración del episodio: -  0.3600871720345393\n",
      "Recompensa por acortar distancias: +  0.91034056430531\n",
      "Penalización por parar muy lejos: -  0.1568044161206371\n",
      "Penalización por duración del episodio: -  0.36026042453718704\n",
      "Recompensa por acortar distancias: +  0.91034056430531\n",
      "Penalización por duración del episodio: -  0.36062020464194827\n",
      "Recompensa por acortar distancias: +  0.91034056430531\n",
      "Penalización por duración del episodio: -  0.3609839415984504\n",
      "Recompensa por acortar distancias: +  0.9103202227666023\n",
      "Penalización por duración del episodio: -  0.3610909838475469\n",
      "Recompensa por acortar distancias: +  0.9103202227666023\n",
      "Penalización por duración del episodio: -  0.36118592650164455\n",
      "Step: 9660, Mean Reward (últimos 10 pasos): 0.5491343140602112\n",
      "Recompensa por acortar distancias: +  0.9103202227666023\n",
      "Penalización por parar muy lejos: -  0.15677147116199036\n",
      "Penalización por duración del episodio: -  0.3613503910785729\n",
      "Recompensa por acortar distancias: +  0.9103202227666023\n",
      "Penalización por parar muy lejos: -  0.15677147116199036\n",
      "Penalización por duración del episodio: -  0.3617024921024774\n",
      "Recompensa por acortar distancias: +  0.9103309350942546\n",
      "Penalización por parar muy lejos: -  0.15678881920166074\n",
      "Penalización por duración del episodio: -  0.3618050079602926\n",
      "Recompensa por acortar distancias: +  0.9103309584483598\n",
      "Penalización por duración del episodio: -  0.361920678874835\n",
      "Recompensa por acortar distancias: +  0.9103309584483598\n",
      "Penalización por parar muy lejos: -  0.15678885702612888\n",
      "Penalización por duración del episodio: -  0.3620626605031722\n",
      "Recompensa por acortar distancias: +  0.9103309584483598\n",
      "Penalización por duración del episodio: -  0.36219645417451\n",
      "Recompensa por acortar distancias: +  0.9103310207259468\n",
      "Penalización por parar muy lejos: -  0.1567889578914136\n",
      "Penalización por duración del episodio: -  0.36230261653551343\n",
      "Recompensa por acortar distancias: +  0.9103310207259468\n",
      "Penalización por duración del episodio: -  0.36240889149629985\n",
      "Recompensa por acortar distancias: +  0.9103311141422543\n",
      "Penalización por duración del episodio: -  0.36278906725987103\n",
      "Recompensa por acortar distancias: +  0.9103311141422543\n",
      "Penalización por parar muy lejos: -  0.15678910918943967\n",
      "Penalización por duración del episodio: -  0.36315761461980817\n",
      "Step: 9670, Mean Reward (últimos 10 pasos): 0.39038437604904175\n",
      "Recompensa por acortar distancias: +  0.9103311141422543\n",
      "Penalización por parar muy lejos: -  0.15678910918943967\n",
      "Penalización por duración del episodio: -  0.3632582456996587\n",
      "Recompensa por acortar distancias: +  0.9103311141422543\n",
      "Penalización por duración del episodio: -  0.36352432584729066\n",
      "steer input from model: 0.25 , throttle:  1.0\n",
      "reward: 0.5468067882949637\n",
      "Recompensa por acortar distancias: +  0.9103125692853697\n",
      "Penalización por parar muy lejos: -  0.1567590788609264\n",
      "Penalización por duración del episodio: -  0.3638934143377959\n",
      "Recompensa por acortar distancias: +  0.9103041598987766\n",
      "Penalización por duración del episodio: -  0.3642648991829168\n",
      "Recompensa por acortar distancias: +  0.9102825569759838\n",
      "Penalización por parar muy lejos: -  0.15671050066488065\n",
      "Penalización por duración del episodio: -  0.3643803774079359\n",
      "Recompensa por acortar distancias: +  0.9102732103506813\n",
      "Penalización por duración del episodio: -  0.3644846657768013\n",
      "Recompensa por acortar distancias: +  0.9102732103506813\n",
      "Penalización por duración del episodio: -  0.3645913198006205\n",
      "Recompensa por acortar distancias: +  0.9102738568538526\n",
      "Penalización por duración del episodio: -  0.36496753444174124\n",
      "Recompensa por acortar distancias: +  0.9102738568538526\n",
      "Penalización por parar muy lejos: -  0.1566964235981738\n",
      "Penalización por duración del episodio: -  0.365318860835261\n",
      "Recompensa por acortar distancias: +  0.9102738568538526\n",
      "Penalización por parar muy lejos: -  0.1566964235981738\n",
      "Penalización por duración del episodio: -  0.3656737207317539\n",
      "Step: 9680, Mean Reward (últimos 10 pasos): 0.38790372014045715\n",
      "Recompensa por acortar distancias: +  0.9102442302340078\n",
      "Penalización por parar muy lejos: -  0.15664850375774872\n",
      "Penalización por duración del episodio: -  0.3660163613888168\n",
      "Recompensa por acortar distancias: +  0.9102442302340078\n",
      "Penalización por duración del episodio: -  0.3661164051910878\n",
      "Recompensa por acortar distancias: +  0.9102442302340078\n",
      "Penalización por parar muy lejos: -  0.15664850375774872\n",
      "Penalización por duración del episodio: -  0.36636848575209807\n",
      "Recompensa por acortar distancias: +  0.9102438406588536\n",
      "Penalización por duración del episodio: -  0.3667240363426181\n",
      "Recompensa por acortar distancias: +  0.9102292304902687\n",
      "Penalización por duración del episodio: -  0.3670768406133242\n",
      "Recompensa por acortar distancias: +  0.9102189046785071\n",
      "Penalización por parar muy lejos: -  0.15660756147059268\n",
      "Penalización por duración del episodio: -  0.3674363706318135\n",
      "Recompensa por acortar distancias: +  0.9102189046785071\n",
      "Penalización por parar muy lejos: -  0.15660756147059268\n",
      "Penalización por duración del episodio: -  0.3678066866969195\n",
      "Recompensa por acortar distancias: +  0.9102189046785071\n",
      "Penalización por duración del episodio: -  0.36816848460355306\n",
      "Recompensa por acortar distancias: +  0.9101824635445883\n",
      "Penalización por duración del episodio: -  0.3682662955633287\n",
      "Recompensa por acortar distancias: +  0.9101824635445883\n",
      "Penalización por duración del episodio: -  0.3685270242404834\n",
      "Step: 9690, Mean Reward (últimos 10 pasos): 0.541655421257019\n",
      "Recompensa por acortar distancias: +  0.9101824635445883\n",
      "Penalización por parar muy lejos: -  0.15654868284821\n",
      "Penalización por duración del episodio: -  0.3688908712595929\n",
      "Recompensa por acortar distancias: +  0.9101516009296204\n",
      "Penalización por duración del episodio: -  0.3690162966541301\n",
      "steer input from model: 0.1 , throttle:  1.0\n",
      "reward: 0.5411353042754903\n",
      "Recompensa por acortar distancias: +  0.9101361972379303\n",
      "Penalización por parar muy lejos: -  0.15647398648217323\n",
      "Penalización por duración del episodio: -  0.36915291084543767\n",
      "Recompensa por acortar distancias: +  0.9101361972379303\n",
      "Penalización por parar muy lejos: -  0.15647398648217323\n",
      "Penalización por duración del episodio: -  0.3693001136646885\n",
      "Recompensa por acortar distancias: +  0.9101242314119123\n",
      "Penalización por duración del episodio: -  0.3694410091503632\n",
      "Recompensa por acortar distancias: +  0.9101253937356808\n",
      "Penalización por parar muy lejos: -  0.15645655353630128\n",
      "Penalización por duración del episodio: -  0.36962783966092455\n",
      "Recompensa por acortar distancias: +  0.9101253937356808\n",
      "Penalización por duración del episodio: -  0.36997630913088364\n",
      "Recompensa por acortar distancias: +  0.9101253937356808\n",
      "Penalización por duración del episodio: -  0.37033430981237164\n",
      "Recompensa por acortar distancias: +  0.9101253937356808\n",
      "Penalización por parar muy lejos: -  0.15645655353630128\n",
      "Penalización por duración del episodio: -  0.3704088227487694\n",
      "Recompensa por acortar distancias: +  0.9101015360811829\n",
      "Penalización por duración del episodio: -  0.37069273673750464\n",
      "Step: 9700, Mean Reward (últimos 10 pasos): 0.539408802986145\n",
      "Recompensa por acortar distancias: +  0.9101013800280326\n",
      "Penalización por duración del episodio: -  0.371055184276923\n",
      "Recompensa por acortar distancias: +  0.9101013800280326\n",
      "Penalización por parar muy lejos: -  0.15641781652411166\n",
      "Penalización por duración del episodio: -  0.37142641038116064\n",
      "Recompensa por acortar distancias: +  0.9101011849612514\n",
      "Penalización por parar muy lejos: -  0.15641750192799486\n",
      "Penalización por duración del episodio: -  0.37178927397665695\n",
      "Recompensa por acortar distancias: +  0.9101012863960252\n",
      "Penalización por duración del episodio: -  0.37216427055889845\n",
      "Recompensa por acortar distancias: +  0.9101012863960252\n",
      "Penalización por duración del episodio: -  0.372537972063756\n",
      "Recompensa por acortar distancias: +  0.9101113981450242\n",
      "Penalización por parar muy lejos: -  0.15643397487370425\n",
      "Penalización por duración del episodio: -  0.3729098801243187\n",
      "Recompensa por acortar distancias: +  0.9100990001872399\n",
      "Penalización por parar muy lejos: -  0.1564139784866995\n",
      "Penalización por duración del episodio: -  0.37327590361714363\n",
      "Recompensa por acortar distancias: +  0.9100985476209263\n",
      "Penalización por duración del episodio: -  0.37364708298391475\n",
      "Recompensa por acortar distancias: +  0.9100985242122681\n",
      "Penalización por duración del episodio: -  0.37376378127216703\n",
      "Recompensa por acortar distancias: +  0.9100985476209263\n",
      "Penalización por duración del episodio: -  0.37389533486843407\n",
      "Step: 9710, Mean Reward (últimos 10 pasos): 0.5362032055854797\n",
      "Recompensa por acortar distancias: +  0.9100985476209263\n",
      "Penalización por duración del episodio: -  0.37405448315893\n",
      "Recompensa por acortar distancias: +  0.9100981496729889\n",
      "Penalización por duración del episodio: -  0.37415169245436153\n",
      "steer input from model: -0.05 , throttle:  0.7\n",
      "reward: 0.5359464572186273\n",
      "Recompensa por acortar distancias: +  0.9100981496729889\n",
      "Penalización por parar muy lejos: -  0.15641260687882114\n",
      "Penalización por duración del episodio: -  0.37439018936664376\n",
      "Recompensa por acortar distancias: +  0.9100981496729889\n",
      "Penalización por duración del episodio: -  0.37476143431141073\n",
      "Recompensa por acortar distancias: +  0.9100981496729889\n",
      "Penalización por duración del episodio: -  0.3751330837252309\n",
      "Recompensa por acortar distancias: +  0.9101229286570905\n",
      "Penalización por parar muy lejos: -  0.15645257627716597\n",
      "Penalización por duración del episodio: -  0.3755014139754979\n",
      "Recompensa por acortar distancias: +  0.9101229286570905\n",
      "Penalización por duración del episodio: -  0.3755949826368301\n",
      "Recompensa por acortar distancias: +  0.9101229286570905\n",
      "Penalización por duración del episodio: -  0.37587180677245474\n",
      "Recompensa por acortar distancias: +  0.9101366418335237\n",
      "Penalización por parar muy lejos: -  0.1564747039730463\n",
      "Penalización por duración del episodio: -  0.3762448067448428\n",
      "Recompensa por acortar distancias: +  0.9101486217683091\n",
      "Penalización por duración del episodio: -  0.3766066969678118\n",
      "Step: 9720, Mean Reward (últimos 10 pasos): 0.5335419178009033\n",
      "Recompensa por acortar distancias: +  0.9101486217683091\n",
      "Penalización por parar muy lejos: -  0.15649403947299553\n",
      "Penalización por duración del episodio: -  0.37698022651026053\n",
      "Recompensa por acortar distancias: +  0.9101486217683091\n",
      "Penalización por duración del episodio: -  0.37735383504990655\n",
      "Recompensa por acortar distancias: +  0.9100923987579124\n",
      "Penalización por parar muy lejos: -  0.15640333305327783\n",
      "Penalización por duración del episodio: -  0.37746032621655845\n",
      "Recompensa por acortar distancias: +  0.9100923987579124\n",
      "Penalización por duración del episodio: -  0.3775665546613188\n",
      "Recompensa por acortar distancias: +  0.9100923987579124\n",
      "Penalización por duración del episodio: -  0.3777189928474536\n",
      "Recompensa por acortar distancias: +  0.9100923987579124\n",
      "Penalización por duración del episodio: -  0.3780931471022649\n",
      "Recompensa por acortar distancias: +  0.9100923987579124\n",
      "Penalización por duración del episodio: -  0.378201660120561\n",
      "Recompensa por acortar distancias: +  0.9099725295319322\n",
      "Penalización por duración del episodio: -  0.37846310013409246\n",
      "Recompensa por acortar distancias: +  0.9099263533796466\n",
      "Penalización por duración del episodio: -  0.3785834671540662\n",
      "Recompensa por acortar distancias: +  0.9099263533796466\n",
      "Penalización por duración del episodio: -  0.3788253232445446\n",
      "Step: 9730, Mean Reward (últimos 10 pasos): 0.5311010479927063\n",
      "Recompensa por acortar distancias: +  0.9098874829258523\n",
      "Penalización por duración del episodio: -  0.3791844712001545\n",
      "Recompensa por acortar distancias: +  0.9098874829258523\n",
      "Penalización por duración del episodio: -  0.37926134808859174\n",
      "steer input from model: -0.05 , throttle:  0.7\n",
      "reward: 0.5306261348372605\n",
      "Recompensa por acortar distancias: +  0.9098874829258523\n",
      "Penalización por duración del episodio: -  0.3795436056264522\n",
      "Recompensa por acortar distancias: +  0.9098874829258523\n",
      "Penalización por parar muy lejos: -  0.15607352935672567\n",
      "Penalización por duración del episodio: -  0.37989537955194974\n",
      "Recompensa por acortar distancias: +  0.9096041456232326\n",
      "Penalización por parar muy lejos: -  0.1556195511856508\n",
      "Penalización por duración del episodio: -  0.38025778083772194\n",
      "Recompensa por acortar distancias: +  0.9096041456232326\n",
      "Penalización por duración del episodio: -  0.38036590016836436\n",
      "Recompensa por acortar distancias: +  0.9095527782775854\n",
      "Penalización por duración del episodio: -  0.3804511195103641\n",
      "Recompensa por acortar distancias: +  0.9095527782775854\n",
      "Penalización por parar muy lejos: -  0.15553750016466963\n",
      "Penalización por duración del episodio: -  0.3805815055911733\n",
      "Recompensa por acortar distancias: +  0.9095518054250588\n",
      "Penalización por parar muy lejos: -  0.15553594693568612\n",
      "Penalización por duración del episodio: -  0.38097606202377104\n",
      "Recompensa por acortar distancias: +  0.9095360187912681\n",
      "Penalización por duración del episodio: -  0.38133433795830635\n",
      "Step: 9740, Mean Reward (últimos 10 pasos): 0.528201699256897\n",
      "Recompensa por acortar distancias: +  0.9095360187912681\n",
      "Penalización por parar muy lejos: -  0.1555107463112117\n",
      "Penalización por duración del episodio: -  0.3817036477890247\n",
      "Recompensa por acortar distancias: +  0.9095360187912681\n",
      "Penalización por duración del episodio: -  0.38180972462739815\n",
      "Recompensa por acortar distancias: +  0.9095360187912681\n",
      "Penalización por duración del episodio: -  0.3820806258978826\n",
      "Recompensa por acortar distancias: +  0.9093643950272967\n",
      "Penalización por parar muy lejos: -  0.15523724850703646\n",
      "Penalización por duración del episodio: -  0.3821663358664645\n",
      "Recompensa por acortar distancias: +  0.9093643950272967\n",
      "Penalización por parar muy lejos: -  0.15523724850703646\n",
      "Penalización por duración del episodio: -  0.38227938110963067\n",
      "Recompensa por acortar distancias: +  0.9093132117329268\n",
      "Penalización por parar muy lejos: -  0.15515584955641465\n",
      "Penalización por duración del episodio: -  0.3824243487505716\n",
      "Recompensa por acortar distancias: +  0.9093132117329268\n",
      "Penalización por parar muy lejos: -  0.15515584955641465\n",
      "Penalización por duración del episodio: -  0.3825080720712264\n",
      "Recompensa por acortar distancias: +  0.9093132117329268\n",
      "Penalización por duración del episodio: -  0.38283591469093287\n",
      "Recompensa por acortar distancias: +  0.9093132117329268\n",
      "Penalización por parar muy lejos: -  0.15515584955641465\n",
      "Penalización por duración del episodio: -  0.3832030674438173\n",
      "Recompensa por acortar distancias: +  0.9091105192651943\n",
      "Penalización por parar muy lejos: -  0.15483424623047745\n",
      "Penalización por duración del episodio: -  0.3835781498403989\n",
      "Step: 9750, Mean Reward (últimos 10 pasos): 0.37069812417030334\n",
      "Recompensa por acortar distancias: +  0.9090683599424916\n",
      "Penalización por duración del episodio: -  0.3839555138022445\n",
      "Recompensa por acortar distancias: +  0.9090683599424916\n",
      "Penalización por duración del episodio: -  0.38406275831732267\n",
      "steer input from model: 0.0 , throttle:  1.0\n",
      "reward: 0.525005601625169\n",
      "Recompensa por acortar distancias: +  0.9090683599424916\n",
      "Penalización por duración del episodio: -  0.3841764331167208\n",
      "Recompensa por acortar distancias: +  0.9090683599424916\n",
      "Penalización por parar muy lejos: -  0.15476750332196906\n",
      "Penalización por duración del episodio: -  0.38469899547368325\n",
      "Recompensa por acortar distancias: +  0.9085541251433678\n",
      "Penalización por parar muy lejos: -  0.15395752621492065\n",
      "Penalización por duración del episodio: -  0.3847958989952751\n",
      "Recompensa por acortar distancias: +  0.9085541251433678\n",
      "Penalización por parar muy lejos: -  0.15395752621492065\n",
      "Penalización por duración del episodio: -  0.38506866626123526\n",
      "Recompensa por acortar distancias: +  0.9085541251433678\n",
      "Penalización por duración del episodio: -  0.3854428579146625\n",
      "Recompensa por acortar distancias: +  0.908156312431242\n",
      "Penalización por parar muy lejos: -  0.15333609865863998\n",
      "Penalización por duración del episodio: -  0.38557797378857295\n",
      "Recompensa por acortar distancias: +  0.9080956895216105\n",
      "Penalización por duración del episodio: -  0.38571983534508364\n",
      "Recompensa por acortar distancias: +  0.9080956895216105\n",
      "Penalización por parar muy lejos: -  0.1532417916185591\n",
      "Penalización por duración del episodio: -  0.3858224844062698\n",
      "Step: 9760, Mean Reward (últimos 10 pasos): 0.3690313994884491\n",
      "Recompensa por acortar distancias: +  0.9080080215424945\n",
      "Penalización por duración del episodio: -  0.3861831641657309\n",
      "Recompensa por acortar distancias: +  0.9080080215424945\n",
      "Penalización por duración del episodio: -  0.3865589679102875\n",
      "Recompensa por acortar distancias: +  0.9080080215424945\n",
      "Penalización por duración del episodio: -  0.3866879298917753\n",
      "Recompensa por acortar distancias: +  0.9080080215424945\n",
      "Penalización por duración del episodio: -  0.3868356883251642\n",
      "Recompensa por acortar distancias: +  0.9076459580036038\n",
      "Penalización por duración del episodio: -  0.3873050342917483\n",
      "Recompensa por acortar distancias: +  0.9075637852609045\n",
      "Penalización por parar muy lejos: -  0.15241875670167515\n",
      "Penalización por duración del episodio: -  0.38767599937727604\n",
      "Recompensa por acortar distancias: +  0.907307337009375\n",
      "Penalización por duración del episodio: -  0.38804184641005907\n",
      "Recompensa por acortar distancias: +  0.9071262686918099\n",
      "Penalización por parar muy lejos: -  0.15174765562420459\n",
      "Penalización por duración del episodio: -  0.3881453514549596\n",
      "Recompensa por acortar distancias: +  0.9071262686918099\n",
      "Penalización por duración del episodio: -  0.3882502652852638\n",
      "Recompensa por acortar distancias: +  0.9071262686918099\n",
      "Penalización por duración del episodio: -  0.38840777438517593\n",
      "Step: 9770, Mean Reward (últimos 10 pasos): 0.5187184810638428\n",
      "Recompensa por acortar distancias: +  0.9071262686918099\n",
      "Penalización por parar muy lejos: -  0.15174765562420459\n",
      "Penalización por duración del episodio: -  0.38878339163544084\n",
      "Recompensa por acortar distancias: +  0.9071262686918099\n",
      "Penalización por duración del episodio: -  0.38915143315599715\n",
      "steer input from model: -0.25 , throttle:  1.0\n",
      "reward: 0.5179748355358127\n",
      "Recompensa por acortar distancias: +  0.9066085545788879\n",
      "Penalización por duración del episodio: -  0.3892751223558926\n",
      "Recompensa por acortar distancias: +  0.9066085545788879\n",
      "Penalización por parar muy lejos: -  0.15096031049302092\n",
      "Penalización por duración del episodio: -  0.38936268204447094\n",
      "Recompensa por acortar distancias: +  0.9064783613966853\n",
      "Penalización por parar muy lejos: -  0.15076345489143803\n",
      "Penalización por duración del episodio: -  0.3895267729300463\n",
      "Recompensa por acortar distancias: +  0.9064783613966853\n",
      "Penalización por duración del episodio: -  0.3896256987448047\n",
      "Recompensa por acortar distancias: +  0.9064783613966853\n",
      "Penalización por parar muy lejos: -  0.15076345489143803\n",
      "Penalización por duración del episodio: -  0.38990975269331846\n",
      "Recompensa por acortar distancias: +  0.9064783613966853\n",
      "Penalización por parar muy lejos: -  0.15076345489143803\n",
      "Penalización por duración del episodio: -  0.3902903492284342\n",
      "Recompensa por acortar distancias: +  0.9063298510495464\n",
      "Penalización por parar muy lejos: -  0.15053946039320962\n",
      "Penalización por duración del episodio: -  0.3906617659410533\n",
      "Recompensa por acortar distancias: +  0.9063298510495464\n",
      "Penalización por duración del episodio: -  0.39104108177343305\n",
      "Step: 9780, Mean Reward (últimos 10 pasos): 0.515288770198822\n",
      "Recompensa por acortar distancias: +  0.9063298510495464\n",
      "Penalización por duración del episodio: -  0.3914097271915719\n",
      "Recompensa por acortar distancias: +  0.9062366937829004\n",
      "Penalización por duración del episodio: -  0.39177403679697936\n",
      "Recompensa por acortar distancias: +  0.9062366937829004\n",
      "Penalización por duración del episodio: -  0.3918735987891636\n",
      "Recompensa por acortar distancias: +  0.9061310310956805\n",
      "Penalización por duración del episodio: -  0.39215642001545586\n",
      "Recompensa por acortar distancias: +  0.9060870279210151\n",
      "Penalización por parar muy lejos: -  0.15017448944160794\n",
      "Penalización por duración del episodio: -  0.3922674805748677\n",
      "Recompensa por acortar distancias: +  0.9060480883414931\n",
      "Penalización por parar muy lejos: -  0.15011610844754494\n",
      "Penalización por duración del episodio: -  0.39252476261568986\n",
      "Recompensa por acortar distancias: +  0.9060086835655028\n",
      "Penalización por duración del episodio: -  0.3926148348182009\n",
      "Recompensa por acortar distancias: +  0.9060086835655028\n",
      "Penalización por duración del episodio: -  0.39277830015528803\n",
      "Recompensa por acortar distancias: +  0.9059650636554089\n",
      "Penalización por parar muy lejos: -  0.14999176663646568\n",
      "Penalización por duración del episodio: -  0.39287849844878914\n",
      "Recompensa por acortar distancias: +  0.9059234575733708\n",
      "Penalización por parar muy lejos: -  0.1499295242298786\n",
      "Penalización por duración del episodio: -  0.393300083912287\n",
      "Step: 9790, Mean Reward (últimos 10 pasos): 0.3626938462257385\n",
      "Recompensa por acortar distancias: +  0.9059234575733708\n",
      "Penalización por duración del episodio: -  0.3936744959291017\n",
      "Recompensa por acortar distancias: +  0.9059234575733708\n",
      "Penalización por duración del episodio: -  0.39404733072307063\n",
      "steer input from model: -0.9 , throttle:  0.7\n",
      "reward: 0.5118761268503002\n",
      "Recompensa por acortar distancias: +  0.9056941377002244\n",
      "Penalización por duración del episodio: -  0.3941314850787044\n",
      "Recompensa por acortar distancias: +  0.9056355752873808\n",
      "Penalización por duración del episodio: -  0.3942392291262512\n",
      "Recompensa por acortar distancias: +  0.9056355752873808\n",
      "Penalización por duración del episodio: -  0.3943454232119606\n",
      "Recompensa por acortar distancias: +  0.9056355752873808\n",
      "Penalización por duración del episodio: -  0.3947851500068377\n",
      "Recompensa por acortar distancias: +  0.9054340881259018\n",
      "Penalización por duración del episodio: -  0.3951601803238189\n",
      "Recompensa por acortar distancias: +  0.9052965582666621\n",
      "Penalización por duración del episodio: -  0.39554028192514085\n",
      "Recompensa por acortar distancias: +  0.9052965582666621\n",
      "Penalización por parar muy lejos: -  0.14899721783192804\n",
      "Penalización por duración del episodio: -  0.39592515141254553\n",
      "Recompensa por acortar distancias: +  0.9052965582666621\n",
      "Penalización por parar muy lejos: -  0.14899721783192804\n",
      "Penalización por duración del episodio: -  0.3960150846365916\n",
      "Step: 9800, Mean Reward (últimos 10 pasos): 0.3602842688560486\n",
      "Recompensa por acortar distancias: +  0.9052965582666621\n",
      "Penalización por duración del episodio: -  0.3961585327290351\n",
      "Recompensa por acortar distancias: +  0.905224120089399\n",
      "Penalización por duración del episodio: -  0.39631605934720554\n",
      "Recompensa por acortar distancias: +  0.905223412352908\n",
      "Penalización por duración del episodio: -  0.39668241550952615\n",
      "Recompensa por acortar distancias: +  0.905223412352908\n",
      "Penalización por parar muy lejos: -  0.14888910868530827\n",
      "Penalización por duración del episodio: -  0.39675695491531326\n",
      "Recompensa por acortar distancias: +  0.905223412352908\n",
      "Penalización por parar muy lejos: -  0.14888910868530827\n",
      "Penalización por duración del episodio: -  0.3968566488053019\n",
      "Recompensa por acortar distancias: +  0.905223412352908\n",
      "Penalización por parar muy lejos: -  0.14888910868530827\n",
      "Penalización por duración del episodio: -  0.39704517184230614\n",
      "Recompensa por acortar distancias: +  0.905222385512939\n",
      "Penalización por parar muy lejos: -  0.148887592015416\n",
      "Penalización por duración del episodio: -  0.3971659597695468\n",
      "Recompensa por acortar distancias: +  0.9052221850529784\n",
      "Penalización por parar muy lejos: -  0.1488872959339361\n",
      "Penalización por duración del episodio: -  0.39729775568691095\n",
      "Recompensa por acortar distancias: +  0.9052221850529784\n",
      "Penalización por duración del episodio: -  0.3974171766714577\n",
      "Recompensa por acortar distancias: +  0.9052222750554566\n",
      "Penalización por duración del episodio: -  0.39755083966785665\n",
      "Step: 9810, Mean Reward (últimos 10 pasos): 0.5076714158058167\n",
      "Recompensa por acortar distancias: +  0.905222168688883\n",
      "Penalización por duración del episodio: -  0.39768514043613695\n",
      "Recompensa por acortar distancias: +  0.905222168688883\n",
      "Penalización por duración del episodio: -  0.3978146303777197\n",
      "steer input from model: 0.05 , throttle:  0.3\n",
      "reward: 0.5074075383111634\n",
      "Recompensa por acortar distancias: +  0.905222168688883\n",
      "Penalización por parar muy lejos: -  0.14888727176404082\n",
      "Penalización por duración del episodio: -  0.3979341555559669\n",
      "Recompensa por acortar distancias: +  0.905222168688883\n",
      "Penalización por parar muy lejos: -  0.14888727176404082\n",
      "Penalización por duración del episodio: -  0.3981748935522258\n",
      "Recompensa por acortar distancias: +  0.905222168688883\n",
      "Penalización por duración del episodio: -  0.3982722058818715\n",
      "Recompensa por acortar distancias: +  0.905222168688883\n",
      "Penalización por duración del episodio: -  0.39853819315069045\n",
      "Recompensa por acortar distancias: +  0.905222168688883\n",
      "Penalización por parar muy lejos: -  0.14888727176404082\n",
      "Penalización por duración del episodio: -  0.3989076757527424\n",
      "Recompensa por acortar distancias: +  0.9051900370012514\n",
      "Penalización por duración del episodio: -  0.3992883733327195\n",
      "Recompensa por acortar distancias: +  0.9051900370012514\n",
      "Penalización por duración del episodio: -  0.39967021662289137\n",
      "Recompensa por acortar distancias: +  0.9051173743683273\n",
      "Penalización por duración del episodio: -  0.3997535782279272\n",
      "Step: 9820, Mean Reward (últimos 10 pasos): 0.5053638219833374\n",
      "Recompensa por acortar distancias: +  0.9051111455787272\n",
      "Penalización por duración del episodio: -  0.4000478272315255\n",
      "Recompensa por acortar distancias: +  0.9050921743868058\n",
      "Penalización por parar muy lejos: -  0.14869548898014537\n",
      "Penalización por duración del episodio: -  0.4004204736766225\n",
      "Recompensa por acortar distancias: +  0.9050921743868058\n",
      "Penalización por duración del episodio: -  0.40047197402427104\n",
      "Recompensa por acortar distancias: +  0.9050921743868058\n",
      "Penalización por parar muy lejos: -  0.14869548898014537\n",
      "Penalización por duración del episodio: -  0.40060326205869523\n",
      "Recompensa por acortar distancias: +  0.9050921743868058\n",
      "Penalización por parar muy lejos: -  0.14869548898014537\n",
      "Penalización por duración del episodio: -  0.4007850245631528\n",
      "Recompensa por acortar distancias: +  0.9050921743868058\n",
      "Penalización por duración del episodio: -  0.40115329361776886\n",
      "Recompensa por acortar distancias: +  0.9050159400414705\n",
      "Penalización por parar muy lejos: -  0.1485832232686332\n",
      "Penalización por duración del episodio: -  0.4012613193223567\n",
      "Recompensa por acortar distancias: +  0.9050159400414705\n",
      "Penalización por duración del episodio: -  0.40133459439101155\n",
      "Recompensa por acortar distancias: +  0.9050159400414705\n",
      "Penalización por duración del episodio: -  0.4014564944174632\n",
      "Recompensa por acortar distancias: +  0.9050159400414705\n",
      "Penalización por duración del episodio: -  0.40159954298925093\n",
      "Step: 9830, Mean Reward (últimos 10 pasos): 0.5034164190292358\n",
      "Recompensa por acortar distancias: +  0.9050159400414705\n",
      "Penalización por parar muy lejos: -  0.1485832232686332\n",
      "Penalización por duración del episodio: -  0.40191876989489783\n",
      "Recompensa por acortar distancias: +  0.9050159400414705\n",
      "Penalización por duración del episodio: -  0.4020285083222731\n",
      "steer input from model: -0.25 , throttle:  0.3\n",
      "reward: 0.5029874317191974\n",
      "Recompensa por acortar distancias: +  0.9049359836965366\n",
      "Penalización por duración del episodio: -  0.40229711569837256\n",
      "Recompensa por acortar distancias: +  0.9048992596334239\n",
      "Penalización por parar muy lejos: -  0.1484116864777157\n",
      "Penalización por duración del episodio: -  0.4026743391850869\n",
      "Recompensa por acortar distancias: +  0.9048556551279272\n",
      "Penalización por parar muy lejos: -  0.14834767194334442\n",
      "Penalización por duración del episodio: -  0.4030447253962841\n",
      "Recompensa por acortar distancias: +  0.9048556551279272\n",
      "Penalización por duración del episodio: -  0.4034035453222242\n",
      "Recompensa por acortar distancias: +  0.9046644323573472\n",
      "Penalización por parar muy lejos: -  0.14806752153807734\n",
      "Penalización por duración del episodio: -  0.4037687707818775\n",
      "Recompensa por acortar distancias: +  0.9046084374443796\n",
      "Penalización por duración del episodio: -  0.404134493324762\n",
      "Recompensa por acortar distancias: +  0.9046084374443796\n",
      "Penalización por duración del episodio: -  0.4042206050901959\n",
      "Recompensa por acortar distancias: +  0.9046084374443796\n",
      "Penalización por parar muy lejos: -  0.14798566416483203\n",
      "Penalización por duración del episodio: -  0.404325189611167\n",
      "Step: 9840, Mean Reward (últimos 10 pasos): 0.3522975742816925\n",
      "Recompensa por acortar distancias: +  0.904448073196423\n",
      "Penalización por parar muy lejos: -  0.14775167633452035\n",
      "Penalización por duración del episodio: -  0.40444972738096036\n",
      "Recompensa por acortar distancias: +  0.904448073196423\n",
      "Penalización por duración del episodio: -  0.4045577137186181\n",
      "Recompensa por acortar distancias: +  0.9043648643562652\n",
      "Penalización por duración del episodio: -  0.4048920112940319\n",
      "Recompensa por acortar distancias: +  0.9042964480833183\n",
      "Penalización por parar muy lejos: -  0.14753104335330453\n",
      "Penalización por duración del episodio: -  0.40525934117171225\n",
      "Recompensa por acortar distancias: +  0.9042964480833183\n",
      "Penalización por duración del episodio: -  0.4053332773373661\n",
      "Recompensa por acortar distancias: +  0.9042964480833183\n",
      "Penalización por duración del episodio: -  0.4056458093287473\n",
      "Recompensa por acortar distancias: +  0.9042964480833183\n",
      "Penalización por duración del episodio: -  0.40601256302418165\n",
      "Recompensa por acortar distancias: +  0.9037862545320017\n",
      "Penalización por duración del episodio: -  0.40639912061197675\n",
      "Recompensa por acortar distancias: +  0.9037862545320017\n",
      "Penalización por duración del episodio: -  0.40678620267471677\n",
      "Recompensa por acortar distancias: +  0.9032417022033682\n",
      "Penalización por parar muy lejos: -  0.146012301989178\n",
      "Penalización por duración del episodio: -  0.4068782185838434\n",
      "Step: 9850, Mean Reward (últimos 10 pasos): 0.3503511846065521\n",
      "Recompensa por acortar distancias: +  0.9032417022033682\n",
      "Penalización por duración del episodio: -  0.40701125707380725\n",
      "Recompensa por acortar distancias: +  0.9031356615822419\n",
      "Penalización por duración del episodio: -  0.4070971084061916\n",
      "steer input from model: -0.1 , throttle:  0.7\n",
      "reward: 0.4960385531760503\n",
      "Recompensa por acortar distancias: +  0.9029829709753612\n",
      "Penalización por parar muy lejos: -  0.14564398205093282\n",
      "Penalización por duración del episodio: -  0.4075490391148045\n",
      "Recompensa por acortar distancias: +  0.9029829709753612\n",
      "Penalización por duración del episodio: -  0.40793502991137887\n",
      "Recompensa por acortar distancias: +  0.9029829709753612\n",
      "Penalización por parar muy lejos: -  0.14564398205093282\n",
      "Penalización por duración del episodio: -  0.40830345677917135\n",
      "Recompensa por acortar distancias: +  0.9028027333368331\n",
      "Penalización por parar muy lejos: -  0.14538837477202007\n",
      "Penalización por duración del episodio: -  0.4086690079692216\n",
      "Recompensa por acortar distancias: +  0.9028009884930844\n",
      "Penalización por duración del episodio: -  0.4087902546858275\n",
      "Recompensa por acortar distancias: +  0.9028009884930844\n",
      "Penalización por parar muy lejos: -  0.1453859041769996\n",
      "Penalización por duración del episodio: -  0.4088625943004897\n",
      "Recompensa por acortar distancias: +  0.9028009884930844\n",
      "Penalización por parar muy lejos: -  0.1453859041769996\n",
      "Penalización por duración del episodio: -  0.4090438524966082\n",
      "Recompensa por acortar distancias: +  0.9028009884930844\n",
      "Penalización por duración del episodio: -  0.40941633544323797\n",
      "Step: 9860, Mean Reward (últimos 10 pasos): 0.4933846592903137\n",
      "Recompensa por acortar distancias: +  0.9027974024794552\n",
      "Penalización por duración del episodio: -  0.4095494117023549\n",
      "Recompensa por acortar distancias: +  0.9027972099946385\n",
      "Penalización por parar muy lejos: -  0.14538055430287825\n",
      "Penalización por duración del episodio: -  0.40968764447531963\n",
      "Recompensa por acortar distancias: +  0.9027972099946385\n",
      "Penalización por parar muy lejos: -  0.14538055430287825\n",
      "Penalización por duración del episodio: -  0.41020900392730664\n",
      "Recompensa por acortar distancias: +  0.9027968668686869\n",
      "Penalización por parar muy lejos: -  0.145380068497373\n",
      "Penalización por duración del episodio: -  0.41058531301372914\n",
      "Recompensa por acortar distancias: +  0.9027968668686869\n",
      "Penalización por duración del episodio: -  0.4106971315379354\n",
      "Recompensa por acortar distancias: +  0.9027971639656102\n",
      "Penalización por duración del episodio: -  0.4109695182514644\n",
      "Recompensa por acortar distancias: +  0.9027690742625074\n",
      "Penalización por parar muy lejos: -  0.14534072864852038\n",
      "Penalización por duración del episodio: -  0.41135316819172\n",
      "Recompensa por acortar distancias: +  0.9027690742625074\n",
      "Penalización por duración del episodio: -  0.4117419153049484\n",
      "Recompensa por acortar distancias: +  0.9027147366349134\n",
      "Penalización por duración del episodio: -  0.41212144953635554\n",
      "Recompensa por acortar distancias: +  0.9026458913100601\n",
      "Penalización por parar muy lejos: -  0.1451665926862312\n",
      "Penalización por duración del episodio: -  0.41224829229543947\n",
      "Step: 9870, Mean Reward (últimos 10 pasos): 0.34523099660873413\n",
      "Recompensa por acortar distancias: +  0.9026458913100601\n",
      "Penalización por duración del episodio: -  0.4124897000402962\n",
      "Recompensa por acortar distancias: +  0.9026458913100601\n",
      "Penalización por duración del episodio: -  0.41285818721339135\n",
      "steer input from model: -0.9 , throttle:  0.7\n",
      "reward: 0.4897877040966688\n",
      "Recompensa por acortar distancias: +  0.9026458913100601\n",
      "Penalización por parar muy lejos: -  0.1451665926862312\n",
      "Penalización por duración del episodio: -  0.4129779823389459\n",
      "Recompensa por acortar distancias: +  0.9026458913100601\n",
      "Penalización por parar muy lejos: -  0.1451665926862312\n",
      "Penalización por duración del episodio: -  0.4132430859585403\n",
      "Recompensa por acortar distancias: +  0.9022813255798675\n",
      "Penalización por parar muy lejos: -  0.1446533890942923\n",
      "Penalización por duración del episodio: -  0.4134039345385415\n",
      "Recompensa por acortar distancias: +  0.9022813255798675\n",
      "Penalización por parar muy lejos: -  0.1446533890942923\n",
      "Penalización por duración del episodio: -  0.4135362371250903\n",
      "Recompensa por acortar distancias: +  0.9022813255798675\n",
      "Penalización por parar muy lejos: -  0.1446533890942923\n",
      "Penalización por duración del episodio: -  0.4136776427348634\n",
      "Recompensa por acortar distancias: +  0.9022813255798675\n",
      "Penalización por parar muy lejos: -  0.1446533890942923\n",
      "Penalización por duración del episodio: -  0.4139754482717176\n",
      "Recompensa por acortar distancias: +  0.9022813255798675\n",
      "Penalización por duración del episodio: -  0.4143379799248827\n",
      "Recompensa por acortar distancias: +  0.9022327850531916\n",
      "Penalización por duración del episodio: -  0.41470501408764515\n",
      "Step: 9880, Mean Reward (últimos 10 pasos): 0.4875277578830719\n",
      "Recompensa por acortar distancias: +  0.902232482211938\n",
      "Penalización por duración del episodio: -  0.41509472985640006\n",
      "Recompensa por acortar distancias: +  0.902232482211938\n",
      "Penalización por duración del episodio: -  0.4154866421306179\n",
      "Recompensa por acortar distancias: +  0.9021671583206384\n",
      "Penalización por parar muy lejos: -  0.1444933349408849\n",
      "Penalización por duración del episodio: -  0.4158606548966063\n",
      "Recompensa por acortar distancias: +  0.9021619436918487\n",
      "Penalización por parar muy lejos: -  0.14448603190410367\n",
      "Penalización por duración del episodio: -  0.4159685462992848\n",
      "Recompensa por acortar distancias: +  0.9021619436918487\n",
      "Penalización por parar muy lejos: -  0.14448603190410367\n",
      "Penalización por duración del episodio: -  0.4162364909580915\n",
      "Recompensa por acortar distancias: +  0.9021311096083632\n",
      "Penalización por parar muy lejos: -  0.14444286242988916\n",
      "Penalización por duración del episodio: -  0.4163502271690266\n",
      "Recompensa por acortar distancias: +  0.9021309412073347\n",
      "Penalización por parar muy lejos: -  0.14444262672157976\n",
      "Penalización por duración del episodio: -  0.41647142350494365\n",
      "Recompensa por acortar distancias: +  0.9021309412073347\n",
      "Penalización por parar muy lejos: -  0.14444262672157976\n",
      "Penalización por duración del episodio: -  0.41659698748579327\n",
      "Recompensa por acortar distancias: +  0.9021307391257597\n",
      "Penalización por parar muy lejos: -  0.1444423438720305\n",
      "Penalización por duración del episodio: -  0.41700065590150054\n",
      "Recompensa por acortar distancias: +  0.90211726197112\n",
      "Penalización por parar muy lejos: -  0.14442348238172806\n",
      "Penalización por duración del episodio: -  0.41739486924740565\n",
      "Step: 9890, Mean Reward (últimos 10 pasos): 0.34029892086982727\n",
      "Recompensa por acortar distancias: +  0.90211726197112\n",
      "Penalización por duración del episodio: -  0.4177838470307235\n",
      "Recompensa por acortar distancias: +  0.90211726197112\n",
      "Penalización por parar muy lejos: -  0.14442348238172806\n",
      "Penalización por duración del episodio: -  0.41791219702656224\n",
      "steer input from model: -0.1 , throttle:  0.0\n",
      "reward: 0.33978158256282964\n",
      "Recompensa por acortar distancias: +  0.90211726197112\n",
      "Penalización por parar muy lejos: -  0.14442348238172806\n",
      "Penalización por duración del episodio: -  0.4180549255796931\n",
      "Recompensa por acortar distancias: +  0.902020608306432\n",
      "Penalización por duración del episodio: -  0.41818903030703\n",
      "Recompensa por acortar distancias: +  0.9019974695859212\n",
      "Penalización por parar muy lejos: -  0.14425602257182718\n",
      "Penalización por duración del episodio: -  0.41853342836569823\n",
      "Recompensa por acortar distancias: +  0.9019974695859212\n",
      "Penalización por parar muy lejos: -  0.14425602257182718\n",
      "Penalización por duración del episodio: -  0.4189038248029534\n",
      "Recompensa por acortar distancias: +  0.9019695575570091\n",
      "Penalización por parar muy lejos: -  0.1442170532627368\n",
      "Penalización por duración del episodio: -  0.419275427253237\n",
      "Recompensa por acortar distancias: +  0.9019693973406543\n",
      "Penalización por parar muy lejos: -  0.1442168296308885\n",
      "Penalización por duración del episodio: -  0.4193842013335305\n",
      "Recompensa por acortar distancias: +  0.9019693973406543\n",
      "Penalización por parar muy lejos: -  0.1442168296308885\n",
      "Penalización por duración del episodio: -  0.4196484393720894\n",
      "Recompensa por acortar distancias: +  0.9019693973406543\n",
      "Penalización por duración del episodio: -  0.4197467355413342\n",
      "Step: 9900, Mean Reward (últimos 10 pasos): 0.48222267627716064\n",
      "Recompensa por acortar distancias: +  0.9019693973406543\n",
      "Penalización por parar muy lejos: -  0.1442168296308885\n",
      "Penalización por duración del episodio: -  0.42002628843396883\n",
      "Recompensa por acortar distancias: +  0.9019693973406543\n",
      "Penalización por duración del episodio: -  0.4204115627589428\n",
      "Recompensa por acortar distancias: +  0.9019449320945817\n",
      "Penalización por duración del episodio: -  0.42080297161423774\n",
      "Recompensa por acortar distancias: +  0.9019442320436654\n",
      "Penalización por duración del episodio: -  0.421177484695458\n",
      "Recompensa por acortar distancias: +  0.9018962721703059\n",
      "Penalización por duración del episodio: -  0.4213020771183067\n",
      "Recompensa por acortar distancias: +  0.9018984997934498\n",
      "Penalización por parar muy lejos: -  0.144117930236726\n",
      "Penalización por duración del episodio: -  0.42141180347576224\n",
      "Recompensa por acortar distancias: +  0.9018984997934498\n",
      "Penalización por duración del episodio: -  0.4215275140136485\n",
      "Recompensa por acortar distancias: +  0.9018756096613934\n",
      "Penalización por parar muy lejos: -  0.14408602501287926\n",
      "Penalización por duración del episodio: -  0.4216553846457346\n",
      "Recompensa por acortar distancias: +  0.9018756096613934\n",
      "Penalización por parar muy lejos: -  0.14408602501287926\n",
      "Penalización por duración del episodio: -  0.4217770790589315\n",
      "Recompensa por acortar distancias: +  0.9018549854802339\n",
      "Penalización por duración del episodio: -  0.4222887644982278\n",
      "Step: 9910, Mean Reward (últimos 10 pasos): 0.47956621646881104\n",
      "Recompensa por acortar distancias: +  0.9018549854802339\n",
      "Penalización por duración del episodio: -  0.4226633324277683\n",
      "Recompensa por acortar distancias: +  0.9018549854802339\n",
      "Penalización por duración del episodio: -  0.4227606858032544\n",
      "steer input from model: 0.0 , throttle:  0.3\n",
      "reward: 0.47909429967697953\n",
      "Recompensa por acortar distancias: +  0.9017495718024066\n",
      "Penalización por duración del episodio: -  0.422877717934902\n",
      "Recompensa por acortar distancias: +  0.9017495718024066\n",
      "Penalización por duración del episodio: -  0.4230079157335894\n",
      "Recompensa por acortar distancias: +  0.901719610756629\n",
      "Penalización por parar muy lejos: -  0.1438689198440034\n",
      "Penalización por duración del episodio: -  0.42308468944244776\n",
      "Recompensa por acortar distancias: +  0.901719610756629\n",
      "Penalización por duración del episodio: -  0.4234147079236306\n",
      "Recompensa por acortar distancias: +  0.901719610756629\n",
      "Penalización por parar muy lejos: -  0.1438689198440034\n",
      "Penalización por duración del episodio: -  0.4235444956727043\n",
      "Recompensa por acortar distancias: +  0.901719610756629\n",
      "Penalización por duración del episodio: -  0.4237885405600121\n",
      "Recompensa por acortar distancias: +  0.9015739656231707\n",
      "Penalización por parar muy lejos: -  0.1436667463263687\n",
      "Penalización por duración del episodio: -  0.4241677072880198\n",
      "Recompensa por acortar distancias: +  0.9015336248011594\n",
      "Penalización por duración del episodio: -  0.4243176075714512\n",
      "Step: 9920, Mean Reward (últimos 10 pasos): 0.4772160053253174\n",
      "Recompensa por acortar distancias: +  0.9015328205435993\n",
      "Penalización por parar muy lejos: -  0.14360972293659563\n",
      "Penalización por duración del episodio: -  0.42455222887170685\n",
      "Recompensa por acortar distancias: +  0.9015328205435993\n",
      "Penalización por parar muy lejos: -  0.14360972293659563\n",
      "Penalización por duración del episodio: -  0.42493724380311015\n",
      "Recompensa por acortar distancias: +  0.9015328205435993\n",
      "Penalización por parar muy lejos: -  0.14360972293659563\n",
      "Penalización por duración del episodio: -  0.42504718657772056\n",
      "Recompensa por acortar distancias: +  0.9015328205435993\n",
      "Penalización por duración del episodio: -  0.42530966922449703\n",
      "Recompensa por acortar distancias: +  0.9014678722529633\n",
      "Penalización por duración del episodio: -  0.42541491069306137\n",
      "Recompensa por acortar distancias: +  0.9014313440520915\n",
      "Penalización por parar muy lejos: -  0.14346925672594898\n",
      "Penalización por duración del episodio: -  0.4255327362418044\n",
      "Recompensa por acortar distancias: +  0.9014313440520915\n",
      "Penalización por parar muy lejos: -  0.14346925672594898\n",
      "Penalización por duración del episodio: -  0.4256402185630004\n",
      "Recompensa por acortar distancias: +  0.9014313440520915\n",
      "Penalización por parar muy lejos: -  0.14346925672594898\n",
      "Penalización por duración del episodio: -  0.42575131024742435\n",
      "Recompensa por acortar distancias: +  0.9014313440520915\n",
      "Penalización por parar muy lejos: -  0.14346925672594898\n",
      "Penalización por duración del episodio: -  0.4260599686535501\n",
      "Recompensa por acortar distancias: +  0.9014313440520915\n",
      "Penalización por parar muy lejos: -  0.14346925672594898\n",
      "Penalización por duración del episodio: -  0.42644227027939274\n",
      "Step: 9930, Mean Reward (últimos 10 pasos): 0.33151981234550476\n",
      "Recompensa por acortar distancias: +  0.9013777647784817\n",
      "Penalización por duración del episodio: -  0.4265520278540558\n",
      "Recompensa por acortar distancias: +  0.9013774129503556\n",
      "Penalización por duración del episodio: -  0.42666412555788613\n",
      "steer input from model: -0.25 , throttle:  1.0\n",
      "reward: 0.47471328739246943\n",
      "Recompensa por acortar distancias: +  0.9013774129503556\n",
      "Penalización por duración del episodio: -  0.42678004534164937\n",
      "Recompensa por acortar distancias: +  0.9013771586160741\n",
      "Penalización por parar muy lejos: -  0.14339435148784302\n",
      "Penalización por duración del episodio: -  0.42690868926435405\n",
      "Recompensa por acortar distancias: +  0.9013771586160741\n",
      "Penalización por parar muy lejos: -  0.14339435148784302\n",
      "Penalización por duración del episodio: -  0.42720640178125535\n",
      "Recompensa por acortar distancias: +  0.9013771586160741\n",
      "Penalización por parar muy lejos: -  0.14339435148784302\n",
      "Penalización por duración del episodio: -  0.4275861296884728\n",
      "Recompensa por acortar distancias: +  0.9013771586160741\n",
      "Penalización por parar muy lejos: -  0.14339435148784302\n",
      "Penalización por duración del episodio: -  0.4279786379188263\n",
      "Recompensa por acortar distancias: +  0.9013765990785992\n",
      "Penalización por duración del episodio: -  0.42836683486580024\n",
      "Recompensa por acortar distancias: +  0.9013765694060784\n",
      "Penalización por parar muy lejos: -  0.14339353735206098\n",
      "Penalización por duración del episodio: -  0.42848850570849284\n",
      "Recompensa por acortar distancias: +  0.9013765694060784\n",
      "Penalización por parar muy lejos: -  0.14339353735206098\n",
      "Penalización por duración del episodio: -  0.4287453447948411\n",
      "Step: 9940, Mean Reward (últimos 10 pasos): 0.329237699508667\n",
      "Recompensa por acortar distancias: +  0.9013765694060784\n",
      "Penalización por duración del episodio: -  0.4291251296069198\n",
      "Recompensa por acortar distancias: +  0.9013768661309285\n",
      "Penalización por duración del episodio: -  0.42949979269870037\n",
      "Recompensa por acortar distancias: +  0.9013768661309285\n",
      "Penalización por duración del episodio: -  0.42957758018679304\n",
      "Recompensa por acortar distancias: +  0.9013768661309285\n",
      "Penalización por duración del episodio: -  0.4296959360070644\n",
      "Recompensa por acortar distancias: +  0.9013768661309285\n",
      "Penalización por parar muy lejos: -  0.14339394734801691\n",
      "Penalización por duración del episodio: -  0.42980039937922776\n",
      "Recompensa por acortar distancias: +  0.9013768661309285\n",
      "Penalización por parar muy lejos: -  0.14339394734801691\n",
      "Penalización por duración del episodio: -  0.42990178957569397\n",
      "Recompensa por acortar distancias: +  0.9013768661309285\n",
      "Penalización por parar muy lejos: -  0.14339394734801691\n",
      "Penalización por duración del episodio: -  0.4300426891725602\n",
      "Recompensa por acortar distancias: +  0.9013768661309285\n",
      "Penalización por duración del episodio: -  0.43025772430775167\n",
      "Recompensa por acortar distancias: +  0.9013542237407591\n",
      "Penalización por parar muy lejos: -  0.143362667460349\n",
      "Penalización por duración del episodio: -  0.4306506586815796\n",
      "Recompensa por acortar distancias: +  0.9013565301611137\n",
      "Penalización por parar muy lejos: -  0.14336585316917463\n",
      "Penalización por duración del episodio: -  0.4307276437117333\n",
      "Step: 9950, Mean Reward (últimos 10 pasos): 0.3272630274295807\n",
      "Recompensa por acortar distancias: +  0.9013565301611137\n",
      "Penalización por parar muy lejos: -  0.14336585316917463\n",
      "Penalización por duración del episodio: -  0.4308575127507572\n",
      "Recompensa por acortar distancias: +  0.9013565301611137\n",
      "Penalización por parar muy lejos: -  0.14336585316917463\n",
      "Penalización por duración del episodio: -  0.4310262795381563\n",
      "steer input from model: 0.0 , throttle:  0.0\n",
      "reward: 0.3269643974537828\n",
      "Recompensa por acortar distancias: +  0.9013565301611137\n",
      "Penalización por duración del episodio: -  0.43141434891264935\n",
      "Recompensa por acortar distancias: +  0.9013567421458688\n",
      "Penalización por parar muy lejos: -  0.14336614597625238\n",
      "Penalización por duración del episodio: -  0.43178732292889566\n",
      "Recompensa por acortar distancias: +  0.9013567082283354\n",
      "Penalización por parar muy lejos: -  0.1433660991270865\n",
      "Penalización por duración del episodio: -  0.43216634792768005\n",
      "Recompensa por acortar distancias: +  0.9013567082283354\n",
      "Penalización por duración del episodio: -  0.4325534227806786\n",
      "Recompensa por acortar distancias: +  0.9013567082283354\n",
      "Penalización por duración del episodio: -  0.43263939079182817\n",
      "Recompensa por acortar distancias: +  0.9013185444243648\n",
      "Penalización por duración del episodio: -  0.4329353003695042\n",
      "Recompensa por acortar distancias: +  0.9013202620780357\n",
      "Penalización por parar muy lejos: -  0.1433157729178742\n",
      "Penalización por duración del episodio: -  0.4333073812190636\n",
      "Recompensa por acortar distancias: +  0.9013202620780357\n",
      "Penalización por parar muy lejos: -  0.1433157729178742\n",
      "Penalización por duración del episodio: -  0.43342474847869067\n",
      "Step: 9960, Mean Reward (últimos 10 pasos): 0.32457974553108215\n",
      "Recompensa por acortar distancias: +  0.9013202620780357\n",
      "Penalización por parar muy lejos: -  0.1433157729178742\n",
      "Penalización por duración del episodio: -  0.4335710186648903\n",
      "Recompensa por acortar distancias: +  0.9012704690118503\n",
      "Penalización por duración del episodio: -  0.43368195565115014\n",
      "Recompensa por acortar distancias: +  0.9012704690118503\n",
      "Penalización por parar muy lejos: -  0.143247067299616\n",
      "Penalización por duración del episodio: -  0.4338460955560289\n",
      "Recompensa por acortar distancias: +  0.9012420373146927\n",
      "Penalización por duración del episodio: -  0.433956621480439\n",
      "Recompensa por acortar distancias: +  0.9012420373146927\n",
      "Penalización por duración del episodio: -  0.4341338467834421\n",
      "Recompensa por acortar distancias: +  0.9012092469436819\n",
      "Penalización por parar muy lejos: -  0.14316267153012668\n",
      "Penalización por duración del episodio: -  0.4342405883539938\n",
      "Recompensa por acortar distancias: +  0.9012092469436819\n",
      "Penalización por parar muy lejos: -  0.14316267153012668\n",
      "Penalización por duración del episodio: -  0.4343148377893836\n",
      "Recompensa por acortar distancias: +  0.9012092469436819\n",
      "Penalización por duración del episodio: -  0.4344543885447644\n",
      "Recompensa por acortar distancias: +  0.9012092469436819\n",
      "Penalización por parar muy lejos: -  0.14316267153012668\n",
      "Penalización por duración del episodio: -  0.4348421660157584\n",
      "Recompensa por acortar distancias: +  0.9012092469436819\n",
      "Penalización por duración del episodio: -  0.4352169837964573\n",
      "Step: 9970, Mean Reward (últimos 10 pasos): 0.465992271900177\n",
      "Recompensa por acortar distancias: +  0.901076772895289\n",
      "Penalización por duración del episodio: -  0.4356048942114332\n",
      "Recompensa por acortar distancias: +  0.901065589520947\n",
      "Penalización por duración del episodio: -  0.4359953575659771\n",
      "steer input from model: -0.05 , throttle:  0.3\n",
      "reward: 0.4650702319549698\n",
      "Recompensa por acortar distancias: +  0.9009915834257135\n",
      "Penalización por duración del episodio: -  0.43637432483670097\n",
      "Recompensa por acortar distancias: +  0.9009260109269702\n",
      "Penalización por duración del episodio: -  0.43676883274043515\n",
      "Recompensa por acortar distancias: +  0.9009260109269702\n",
      "Penalización por parar muy lejos: -  0.142773367734009\n",
      "Penalización por duración del episodio: -  0.4371490599541198\n",
      "Recompensa por acortar distancias: +  0.9009260109269702\n",
      "Penalización por duración del episodio: -  0.4375302528894572\n",
      "Recompensa por acortar distancias: +  0.9006321908677805\n",
      "Penalización por duración del episodio: -  0.4379119421454565\n",
      "Recompensa por acortar distancias: +  0.9006321908677805\n",
      "Penalización por duración del episodio: -  0.43829642257704055\n",
      "Recompensa por acortar distancias: +  0.9003762211097197\n",
      "Penalización por parar muy lejos: -  0.1420230116665987\n",
      "Penalización por duración del episodio: -  0.4384134030688862\n",
      "Recompensa por acortar distancias: +  0.9003762211097197\n",
      "Penalización por parar muy lejos: -  0.1420230116665987\n",
      "Penalización por duración del episodio: -  0.43851550318468424\n",
      "Step: 9980, Mean Reward (últimos 10 pasos): 0.3198377192020416\n",
      "Recompensa por acortar distancias: +  0.9002993039233866\n",
      "Penalización por duración del episodio: -  0.4386906933503541\n",
      "Recompensa por acortar distancias: +  0.9002467917688712\n",
      "Penalización por duración del episodio: -  0.43885309927987426\n",
      "Recompensa por acortar distancias: +  0.9002467917688712\n",
      "Penalización por duración del episodio: -  0.4389639058987402\n",
      "Recompensa por acortar distancias: +  0.9001702313779191\n",
      "Penalización por parar muy lejos: -  0.14174366903231042\n",
      "Penalización por duración del episodio: -  0.4390895688607727\n",
      "Recompensa por acortar distancias: +  0.9001702313779191\n",
      "Penalización por parar muy lejos: -  0.14174366903231042\n",
      "Penalización por duración del episodio: -  0.4392264441543441\n",
      "Recompensa por acortar distancias: +  0.9001702313779191\n",
      "Penalización por duración del episodio: -  0.4394763715417336\n",
      "Recompensa por acortar distancias: +  0.9001702313779191\n",
      "Penalización por duración del episodio: -  0.43986746546665706\n",
      "Recompensa por acortar distancias: +  0.9001702313779191\n",
      "Penalización por duración del episodio: -  0.43998199312535\n",
      "Recompensa por acortar distancias: +  0.9001702313779191\n",
      "Penalización por parar muy lejos: -  0.14174366903231042\n",
      "Penalización por duración del episodio: -  0.4401034537045583\n",
      "Recompensa por acortar distancias: +  0.9001052170886377\n",
      "Penalización por duración del episodio: -  0.4402629583444485\n",
      "Step: 9990, Mean Reward (últimos 10 pasos): 0.4598422646522522\n",
      "Recompensa por acortar distancias: +  0.9001052170886377\n",
      "Penalización por duración del episodio: -  0.4406435420291049\n",
      "Recompensa por acortar distancias: +  0.9001046254092948\n",
      "Penalización por parar muy lejos: -  0.14165490461109395\n",
      "Penalización por duración del episodio: -  0.4407508137925079\n",
      "steer input from model: -0.9 , throttle:  0.0\n",
      "reward: 0.3176989070056929\n",
      "Recompensa por acortar distancias: +  0.9001046254092948\n",
      "Penalización por duración del episodio: -  0.44086586059090654\n",
      "Recompensa por acortar distancias: +  0.9001046254092948\n",
      "Penalización por duración del episodio: -  0.44097746369888\n",
      "Recompensa por acortar distancias: +  0.9001046254092948\n",
      "Penalización por parar muy lejos: -  0.14165490461109395\n",
      "Penalización por duración del episodio: -  0.44142388275875494\n",
      "Recompensa por acortar distancias: +  0.9001032233740658\n",
      "Penalización por parar muy lejos: -  0.14165300873931036\n",
      "Penalización por duración del episodio: -  0.4418206531429768\n",
      "Recompensa por acortar distancias: +  0.9001030990337056\n",
      "Penalización por parar muy lejos: -  0.14165284060491504\n",
      "Penalización por duración del episodio: -  0.4422157806079726\n",
      "Recompensa por acortar distancias: +  0.9001030990337056\n",
      "Penalización por parar muy lejos: -  0.14165284060491504\n",
      "Penalización por duración del episodio: -  0.4423301957286227\n",
      "Recompensa por acortar distancias: +  0.9001030990337056\n",
      "Penalización por parar muy lejos: -  0.14165284060491504\n",
      "Penalización por duración del episodio: -  0.4426071285682077\n",
      "Recompensa por acortar distancias: +  0.9001029275295346\n",
      "Penalización por duración del episodio: -  0.44270077682733355\n",
      "Step: 10000, Mean Reward (últimos 10 pasos): 0.45740213990211487\n",
      "Recompensa por acortar distancias: +  0.9001031247593085\n",
      "Penalización por parar muy lejos: -  0.14165287539132798\n",
      "Penalización por duración del episodio: -  0.44281818847652255\n",
      "Recompensa por acortar distancias: +  0.9001031247593085\n",
      "Penalización por parar muy lejos: -  0.14165287539132798\n",
      "Penalización por duración del episodio: -  0.4430081606401508\n",
      "Recompensa por acortar distancias: +  0.9001031247593085\n",
      "Penalización por parar muy lejos: -  0.14165287539132798\n",
      "Penalización por duración del episodio: -  0.44308540024557685\n",
      "Recompensa por acortar distancias: +  0.9001031247593085\n",
      "Penalización por parar muy lejos: -  0.14165287539132798\n",
      "Penalización por duración del episodio: -  0.4433986285714366\n",
      "Recompensa por acortar distancias: +  0.9001033520018797\n",
      "Penalización por parar muy lejos: -  0.14165318267161883\n",
      "Penalización por duración del episodio: -  0.4437672738661241\n",
      "Recompensa por acortar distancias: +  0.9001036607080329\n",
      "Penalización por duración del episodio: -  0.4439240872507005\n",
      "Recompensa por acortar distancias: +  0.9001036607080329\n",
      "Penalización por duración del episodio: -  0.4441461286794766\n",
      "Recompensa por acortar distancias: +  0.9001036607080329\n",
      "Penalización por duración del episodio: -  0.44423322681094035\n",
      "Recompensa por acortar distancias: +  0.9001036607080329\n",
      "Penalización por parar muy lejos: -  0.14165360010988667\n",
      "Penalización por duración del episodio: -  0.44453354353824376\n",
      "Recompensa por acortar distancias: +  0.9001036607080329\n",
      "Penalización por parar muy lejos: -  0.14165360010988667\n",
      "Penalización por duración del episodio: -  0.4449432772131551\n",
      "Step: 10010, Mean Reward (últimos 10 pasos): 0.3135067820549011\n",
      "Recompensa por acortar distancias: +  0.9001041494910407\n",
      "Penalización por duración del episodio: -  0.44532146650610693\n",
      "Recompensa por acortar distancias: +  0.9000853169455267\n",
      "Penalización por duración del episodio: -  0.44542356958617335\n",
      "steer input from model: -0.1 , throttle:  0.3\n",
      "reward: 0.4546617473593534\n",
      "Recompensa por acortar distancias: +  0.9000853169455267\n",
      "Penalización por duración del episodio: -  0.4455195401983903\n",
      "Recompensa por acortar distancias: +  0.9000853169455267\n",
      "Penalización por parar muy lejos: -  0.1416287991019824\n",
      "Penalización por duración del episodio: -  0.44562386683501554\n",
      "Recompensa por acortar distancias: +  0.9000853169455267\n",
      "Penalización por parar muy lejos: -  0.1416287991019824\n",
      "Penalización por duración del episodio: -  0.4457379760825727\n",
      "Recompensa por acortar distancias: +  0.9000917448926633\n",
      "Penalización por parar muy lejos: -  0.14163748889754965\n",
      "Penalización por duración del episodio: -  0.4461072313480854\n",
      "Recompensa por acortar distancias: +  0.9000916805721313\n",
      "Penalización por duración del episodio: -  0.44624309862775774\n",
      "Recompensa por acortar distancias: +  0.9000918006370944\n",
      "Penalización por parar muy lejos: -  0.14163756426129961\n",
      "Penalización por duración del episodio: -  0.44638278011913046\n",
      "Recompensa por acortar distancias: +  0.9000918006370944\n",
      "Penalización por parar muy lejos: -  0.14163756426129961\n",
      "Penalización por duración del episodio: -  0.4469051345906712\n",
      "Recompensa por acortar distancias: +  0.9000848752518712\n",
      "Penalización por duración del episodio: -  0.44728116030552295\n",
      "Step: 10020, Mean Reward (últimos 10 pasos): 0.45280370116233826\n",
      "Recompensa por acortar distancias: +  0.9000848752518712\n",
      "Penalización por parar muy lejos: -  0.14162820202096757\n",
      "Penalización por duración del episodio: -  0.4473837275454448\n",
      "Recompensa por acortar distancias: +  0.9000848752518712\n",
      "Penalización por duración del episodio: -  0.447516450929023\n",
      "Recompensa por acortar distancias: +  0.9000849867475208\n",
      "Penalización por parar muy lejos: -  0.14162835274024874\n",
      "Penalización por duración del episodio: -  0.44766783403534377\n",
      "Recompensa por acortar distancias: +  0.9000847980625103\n",
      "Penalización por duración del episodio: -  0.44806093299925853\n",
      "Recompensa por acortar distancias: +  0.9000847980625103\n",
      "Penalización por parar muy lejos: -  0.14162809767692827\n",
      "Penalización por duración del episodio: -  0.44843511413716414\n",
      "Recompensa por acortar distancias: +  0.9000849953241046\n",
      "Penalización por parar muy lejos: -  0.14162836433404513\n",
      "Penalización por duración del episodio: -  0.44855975785477414\n",
      "Recompensa por acortar distancias: +  0.9000851411259301\n",
      "Penalización por duración del episodio: -  0.44881610096940716\n",
      "Recompensa por acortar distancias: +  0.9000852268916214\n",
      "Penalización por parar muy lejos: -  0.14162867736684762\n",
      "Penalización por duración del episodio: -  0.4491996431244891\n",
      "Recompensa por acortar distancias: +  0.9000852268916214\n",
      "Penalización por duración del episodio: -  0.44957699775039583\n",
      "Recompensa por acortar distancias: +  0.9000852268916214\n",
      "Penalización por duración del episodio: -  0.4499610782735932\n",
      "Step: 10030, Mean Reward (últimos 10 pasos): 0.4501241445541382\n",
      "Recompensa por acortar distancias: +  0.9000713663065956\n",
      "Penalización por parar muy lejos: -  0.14160994279138553\n",
      "Penalización por duración del episodio: -  0.45006789036199596\n",
      "Recompensa por acortar distancias: +  0.9000713663065956\n",
      "Penalización por parar muy lejos: -  0.14160994279138553\n",
      "Penalización por duración del episodio: -  0.4503320872530294\n",
      "steer input from model: 0.1 , throttle:  0.0\n",
      "reward: 0.30812933626218064\n",
      "Recompensa por acortar distancias: +  0.9000592068676206\n",
      "Penalización por duración del episodio: -  0.450708015164028\n",
      "Recompensa por acortar distancias: +  0.9000592068676206\n",
      "Penalización por duración del episodio: -  0.45108532172422383\n",
      "Recompensa por acortar distancias: +  0.9000592068676206\n",
      "Penalización por duración del episodio: -  0.45147197791820365\n",
      "Recompensa por acortar distancias: +  0.9000216265330959\n",
      "Penalización por parar muy lejos: -  0.14154274837111333\n",
      "Penalización por duración del episodio: -  0.45185560429126426\n",
      "Recompensa por acortar distancias: +  0.9000317478611676\n",
      "Penalización por duración del episodio: -  0.45224835373364347\n",
      "Recompensa por acortar distancias: +  0.9000317478611676\n",
      "Penalización por parar muy lejos: -  0.14155641690207715\n",
      "Penalización por duración del episodio: -  0.4526270508914474\n",
      "Recompensa por acortar distancias: +  0.9000059729359531\n",
      "Penalización por duración del episodio: -  0.45273184834351843\n",
      "Recompensa por acortar distancias: +  0.9000059729359531\n",
      "Penalización por parar muy lejos: -  0.14152161327932247\n",
      "Penalización por duración del episodio: -  0.45283194767525264\n",
      "Step: 10040, Mean Reward (últimos 10 pasos): 0.3056524097919464\n",
      "Recompensa por acortar distancias: +  0.8999945961069796\n",
      "Penalización por duración del episodio: -  0.45300974932070753\n",
      "Recompensa por acortar distancias: +  0.8999945961069796\n",
      "Penalización por duración del episodio: -  0.45338733912958334\n",
      "Recompensa por acortar distancias: +  0.8999945961069796\n",
      "Penalización por parar muy lejos: -  0.1415062560710213\n",
      "Penalización por duración del episodio: -  0.45350677360155534\n",
      "Recompensa por acortar distancias: +  0.8999945961069796\n",
      "Penalización por parar muy lejos: -  0.1415062560710213\n",
      "Penalización por duración del episodio: -  0.45362243154556325\n",
      "Recompensa por acortar distancias: +  0.8999941325980438\n",
      "Penalización por parar muy lejos: -  0.1415056304579413\n",
      "Penalización por duración del episodio: -  0.4537835561957127\n",
      "Recompensa por acortar distancias: +  0.8999941325980438\n",
      "Penalización por duración del episodio: -  0.45390004165131864\n",
      "Recompensa por acortar distancias: +  0.8999943514775013\n",
      "Penalización por duración del episodio: -  0.45418030464682807\n",
      "Recompensa por acortar distancias: +  0.8999943514775013\n",
      "Penalización por parar muy lejos: -  0.14150592588605232\n",
      "Penalización por duración del episodio: -  0.45455183480830375\n",
      "Recompensa por acortar distancias: +  0.8999943514775013\n",
      "Penalización por parar muy lejos: -  0.14150592588605232\n",
      "Penalización por duración del episodio: -  0.4546850178040589\n",
      "Recompensa por acortar distancias: +  0.8999943514775013\n",
      "Penalización por duración del episodio: -  0.45492748305509434\n",
      "Step: 10050, Mean Reward (últimos 10 pasos): 0.4450668692588806\n",
      "Recompensa por acortar distancias: +  0.8999943514775013\n",
      "Penalización por duración del episodio: -  0.45504365096339666\n",
      "Recompensa por acortar distancias: +  0.8999448395432907\n",
      "Penalización por parar muy lejos: -  0.14143912590541868\n",
      "Penalización por duración del episodio: -  0.4553111412925393\n",
      "steer input from model: -0.25 , throttle:  0.0\n",
      "reward: 0.3031945723453328\n",
      "Recompensa por acortar distancias: +  0.8999398588124667\n",
      "Penalización por duración del episodio: -  0.4554069902459846\n",
      "Recompensa por acortar distancias: +  0.8999398588124667\n",
      "Penalización por parar muy lejos: -  0.1414324091408849\n",
      "Penalización por duración del episodio: -  0.4556940719808422\n",
      "Recompensa por acortar distancias: +  0.8999398588124667\n",
      "Penalización por duración del episodio: -  0.4560825969244828\n",
      "Recompensa por acortar distancias: +  0.8998986605798229\n",
      "Penalización por duración del episodio: -  0.4564688920220601\n",
      "Recompensa por acortar distancias: +  0.8998990944143597\n",
      "Penalización por parar muy lejos: -  0.14137745748724806\n",
      "Penalización por duración del episodio: -  0.45686193058899777\n",
      "Recompensa por acortar distancias: +  0.8998990944143597\n",
      "Penalización por parar muy lejos: -  0.14137745748724806\n",
      "Penalización por duración del episodio: -  0.45724192879949405\n",
      "Recompensa por acortar distancias: +  0.899866045183752\n",
      "Penalización por parar muy lejos: -  0.1413329337980172\n",
      "Penalización por duración del episodio: -  0.4576285276165537\n",
      "Recompensa por acortar distancias: +  0.8998659248776687\n",
      "Penalización por parar muy lejos: -  0.14133277176776995\n",
      "Penalización por duración del episodio: -  0.4580144850119235\n",
      "Step: 10060, Mean Reward (últimos 10 pasos): 0.300518661737442\n",
      "Recompensa por acortar distancias: +  0.8998659248776687\n",
      "Penalización por duración del episodio: -  0.4581031030880889\n",
      "Recompensa por acortar distancias: +  0.89986565848517\n",
      "Penalización por parar muy lejos: -  0.1413324129870605\n",
      "Penalización por duración del episodio: -  0.4584023218386391\n",
      "Recompensa por acortar distancias: +  0.8998583453354448\n",
      "Penalización por duración del episodio: -  0.4587948325810153\n",
      "Recompensa por acortar distancias: +  0.8998684985405022\n",
      "Penalización por parar muy lejos: -  0.14133623809155202\n",
      "Penalización por duración del episodio: -  0.4591733741553656\n",
      "Recompensa por acortar distancias: +  0.8998536873592877\n",
      "Penalización por parar muy lejos: -  0.1413162917875369\n",
      "Penalización por duración del episodio: -  0.45931266830728085\n",
      "Recompensa por acortar distancias: +  0.8998536873592877\n",
      "Penalización por parar muy lejos: -  0.1413162917875369\n",
      "Penalización por duración del episodio: -  0.4595650078513355\n",
      "Recompensa por acortar distancias: +  0.8998536873592877\n",
      "Penalización por duración del episodio: -  0.45993977763802985\n",
      "Recompensa por acortar distancias: +  0.8998536873592877\n",
      "Penalización por parar muy lejos: -  0.1413162917875369\n",
      "Penalización por duración del episodio: -  0.46006075874985997\n",
      "Recompensa por acortar distancias: +  0.899856007777382\n",
      "Penalización por duración del episodio: -  0.46032878407039596\n",
      "Recompensa por acortar distancias: +  0.8998432964566936\n",
      "Penalización por parar muy lejos: -  0.14130230126669716\n",
      "Penalización por duración del episodio: -  0.46072411201671043\n",
      "Step: 10070, Mean Reward (últimos 10 pasos): 0.2978168725967407\n",
      "Recompensa por acortar distancias: +  0.8998432964566936\n",
      "Penalización por duración del episodio: -  0.46112089939264095\n",
      "Recompensa por acortar distancias: +  0.8998344475341317\n",
      "Penalización por parar muy lejos: -  0.14129038882805145\n",
      "Penalización por duración del episodio: -  0.4615110880218482\n",
      "steer input from model: 0.0 , throttle:  0.0\n",
      "reward: 0.297032970684232\n",
      "Recompensa por acortar distancias: +  0.8998427678615987\n",
      "Penalización por duración del episodio: -  0.46190007938491573\n",
      "Recompensa por acortar distancias: +  0.8998427678615987\n",
      "Penalización por parar muy lejos: -  0.14130158962100836\n",
      "Penalización por duración del episodio: -  0.46229353835913956\n",
      "Recompensa por acortar distancias: +  0.8998429182750894\n",
      "Penalización por duración del episodio: -  0.4624179867526178\n",
      "Recompensa por acortar distancias: +  0.8998429182750894\n",
      "Penalización por parar muy lejos: -  0.1413017921215093\n",
      "Penalización por duración del episodio: -  0.46252013655524893\n",
      "Recompensa por acortar distancias: +  0.8998431288536393\n",
      "Penalización por parar muy lejos: -  0.14130207562261796\n",
      "Penalización por duración del episodio: -  0.46269795642760325\n",
      "Recompensa por acortar distancias: +  0.8998431288536393\n",
      "Penalización por parar muy lejos: -  0.14130207562261796\n",
      "Penalización por duración del episodio: -  0.46308788814441804\n",
      "Recompensa por acortar distancias: +  0.8998431288536393\n",
      "Penalización por duración del episodio: -  0.4631870647062114\n",
      "Recompensa por acortar distancias: +  0.8998431288536393\n",
      "Penalización por duración del episodio: -  0.46329876483257715\n",
      "Step: 10080, Mean Reward (últimos 10 pasos): 0.43654435873031616\n",
      "Recompensa por acortar distancias: +  0.8998431288536393\n",
      "Penalización por parar muy lejos: -  0.14130207562261796\n",
      "Penalización por duración del episodio: -  0.4634106168558877\n",
      "Recompensa por acortar distancias: +  0.8998439238915558\n",
      "Penalización por parar muy lejos: -  0.14130314598823057\n",
      "Penalización por duración del episodio: -  0.4635471954976937\n",
      "Recompensa por acortar distancias: +  0.899828533539528\n",
      "Penalización por parar muy lejos: -  0.14128242838485866\n",
      "Penalización por duración del episodio: -  0.46367132275981887\n",
      "Recompensa por acortar distancias: +  0.899828533539528\n",
      "Penalización por duración del episodio: -  0.46386759601921823\n",
      "Recompensa por acortar distancias: +  0.899828533539528\n",
      "Penalización por duración del episodio: -  0.464258574959127\n",
      "Recompensa por acortar distancias: +  0.899828533539528\n",
      "Penalización por duración del episodio: -  0.4646441712779307\n",
      "Recompensa por acortar distancias: +  0.8997588617293237\n",
      "Penalización por duración del episodio: -  0.46480720299912626\n",
      "Recompensa por acortar distancias: +  0.8997588617293237\n",
      "Penalización por parar muy lejos: -  0.14118870731408156\n",
      "Penalización por duración del episodio: -  0.4649181369568041\n",
      "Recompensa por acortar distancias: +  0.8997405477331\n",
      "Penalización por duración del episodio: -  0.4654397460868219\n",
      "Recompensa por acortar distancias: +  0.8997405477331\n",
      "Penalización por parar muy lejos: -  0.14116408993479698\n",
      "Penalización por duración del episodio: -  0.46555827507820613\n",
      "Step: 10090, Mean Reward (últimos 10 pasos): 0.2930181920528412\n",
      "Recompensa por acortar distancias: +  0.8997405477331\n",
      "Penalización por duración del episodio: -  0.46582971819229413\n",
      "Recompensa por acortar distancias: +  0.8997396788411908\n",
      "Penalización por parar muy lejos: -  0.14116292217266707\n",
      "Penalización por duración del episodio: -  0.4659424339064372\n",
      "steer input from model: -0.1 , throttle:  0.0\n",
      "reward: 0.29263432276208656\n",
      "Recompensa por acortar distancias: +  0.8997396788411908\n",
      "Penalización por duración del episodio: -  0.4660899383992002\n",
      "Recompensa por acortar distancias: +  0.8997396616353429\n",
      "Penalización por duración del episodio: -  0.4662287743666305\n",
      "Recompensa por acortar distancias: +  0.8997416876059033\n",
      "Penalización por duración del episodio: -  0.466627048952582\n",
      "Recompensa por acortar distancias: +  0.8997416876059033\n",
      "Penalización por duración del episodio: -  0.46702254124197085\n",
      "Recompensa por acortar distancias: +  0.8997416876059033\n",
      "Penalización por duración del episodio: -  0.46740160496318867\n",
      "Recompensa por acortar distancias: +  0.8996841031793414\n",
      "Penalización por duración del episodio: -  0.46780221147445356\n",
      "Recompensa por acortar distancias: +  0.8996841031793414\n",
      "Penalización por parar muy lejos: -  0.14108826574828143\n",
      "Penalización por duración del episodio: -  0.46817903696433477\n",
      "Recompensa por acortar distancias: +  0.8996906315217158\n",
      "Penalización por parar muy lejos: -  0.14109703184742703\n",
      "Penalización por duración del episodio: -  0.468272202723177\n",
      "Step: 10100, Mean Reward (últimos 10 pasos): 0.290321409702301\n",
      "Recompensa por acortar distancias: +  0.8996906960716673\n",
      "Penalización por duración del episodio: -  0.4685654274746533\n",
      "Recompensa por acortar distancias: +  0.8996924087835662\n",
      "Penalización por parar muy lejos: -  0.14109941847796761\n",
      "Penalización por duración del episodio: -  0.46895047818708324\n",
      "Recompensa por acortar distancias: +  0.8996924087835662\n",
      "Penalización por parar muy lejos: -  0.14109941847796761\n",
      "Penalización por duración del episodio: -  0.4693306966792202\n",
      "Recompensa por acortar distancias: +  0.8996924087835662\n",
      "Penalización por parar muy lejos: -  0.14109941847796761\n",
      "Penalización por duración del episodio: -  0.4694460209640518\n",
      "Recompensa por acortar distancias: +  0.899667933470884\n",
      "Penalización por parar muy lejos: -  0.14106655759933878\n",
      "Penalización por duración del episodio: -  0.46971773859406857\n",
      "Recompensa por acortar distancias: +  0.8996679851212303\n",
      "Penalización por duración del episodio: -  0.47009945388170893\n",
      "Recompensa por acortar distancias: +  0.8996679851212303\n",
      "Penalización por duración del episodio: -  0.47051321326018586\n",
      "Recompensa por acortar distancias: +  0.8996713939918451\n",
      "Penalización por parar muy lejos: -  0.14107120291998426\n",
      "Penalización por duración del episodio: -  0.47065151036296754\n",
      "Recompensa por acortar distancias: +  0.8996713939918451\n",
      "Penalización por parar muy lejos: -  0.14107120291998426\n",
      "Penalización por duración del episodio: -  0.47081277654456344\n",
      "Recompensa por acortar distancias: +  0.899647981757815\n",
      "Penalización por parar muy lejos: -  0.14103978016533492\n",
      "Penalización por duración del episodio: -  0.4709274943332612\n",
      "Step: 10110, Mean Reward (últimos 10 pasos): 0.2876807153224945\n",
      "Recompensa por acortar distancias: +  0.8996470303583233\n",
      "Penalización por parar muy lejos: -  0.1410385035049112\n",
      "Penalización por duración del episodio: -  0.4710159999710208\n",
      "Recompensa por acortar distancias: +  0.8996470303583233\n",
      "Penalización por duración del episodio: -  0.47115971338745277\n",
      "steer input from model: -0.05 , throttle:  0.7\n",
      "reward: 0.4284873169708705\n",
      "Recompensa por acortar distancias: +  0.8996480764668281\n",
      "Penalización por duración del episodio: -  0.4712976927463537\n",
      "Recompensa por acortar distancias: +  0.8996480764668281\n",
      "Penalización por duración del episodio: -  0.47168628741309576\n",
      "Recompensa por acortar distancias: +  0.8996480764668281\n",
      "Penalización por duración del episodio: -  0.4720679644119495\n",
      "Recompensa por acortar distancias: +  0.8996026931440376\n",
      "Penalización por duración del episodio: -  0.47218251905925773\n",
      "Recompensa por acortar distancias: +  0.8995829581998198\n",
      "Penalización por parar muy lejos: -  0.14095257354417917\n",
      "Penalización por duración del episodio: -  0.47228163891268415\n",
      "Recompensa por acortar distancias: +  0.8995829581998198\n",
      "Penalización por parar muy lejos: -  0.14095257354417917\n",
      "Penalización por duración del episodio: -  0.4723633501123718\n",
      "Recompensa por acortar distancias: +  0.8995829581998198\n",
      "Penalización por parar muy lejos: -  0.14095257354417917\n",
      "Penalización por duración del episodio: -  0.4728883608333545\n",
      "Recompensa por acortar distancias: +  0.8995839230611445\n",
      "Penalización por parar muy lejos: -  0.14095386687588915\n",
      "Penalización por duración del episodio: -  0.4729726681487052\n",
      "Step: 10120, Mean Reward (últimos 10 pasos): 0.2856573760509491\n",
      "Recompensa por acortar distancias: +  0.8995839058315503\n",
      "Penalización por parar muy lejos: -  0.14095384378059306\n",
      "Penalización por duración del episodio: -  0.47310140826070907\n",
      "Recompensa por acortar distancias: +  0.8995838972167522\n",
      "Penalización por duración del episodio: -  0.4732705076666377\n",
      "Recompensa por acortar distancias: +  0.8995838541427517\n",
      "Penalización por parar muy lejos: -  0.14095377449472374\n",
      "Penalización por duración del episodio: -  0.47366752779609467\n",
      "Recompensa por acortar distancias: +  0.8995838799871541\n",
      "Penalización por parar muy lejos: -  0.14095380913765485\n",
      "Penalización por duración del episodio: -  0.4737851121280474\n",
      "Recompensa por acortar distancias: +  0.8995838799871541\n",
      "Penalización por duración del episodio: -  0.47405065939725727\n",
      "Recompensa por acortar distancias: +  0.8995838799871541\n",
      "Penalización por parar muy lejos: -  0.14095380913765485\n",
      "Penalización por duración del episodio: -  0.47442971364509073\n",
      "Recompensa por acortar distancias: +  0.8995838799871541\n",
      "Penalización por parar muy lejos: -  0.14095380913765485\n",
      "Penalización por duración del episodio: -  0.47481562261295857\n",
      "Recompensa por acortar distancias: +  0.8995832898718292\n",
      "Penalización por duración del episodio: -  0.4752059675059796\n",
      "Recompensa por acortar distancias: +  0.8995832898718292\n",
      "Penalización por duración del episodio: -  0.4755999758682697\n",
      "Recompensa por acortar distancias: +  0.8995833674054055\n",
      "Penalización por duración del episodio: -  0.4757416714955889\n",
      "Step: 10130, Mean Reward (últimos 10 pasos): 0.4238416850566864\n",
      "Recompensa por acortar distancias: +  0.8995833674054055\n",
      "Penalización por parar muy lejos: -  0.14095312205418403\n",
      "Penalización por duración del episodio: -  0.4759998542955771\n",
      "Recompensa por acortar distancias: +  0.8995769233222737\n",
      "Penalización por duración del episodio: -  0.476216290078709\n",
      "steer input from model: -0.25 , throttle:  0.7\n",
      "reward: 0.42336063324356465\n",
      "Recompensa por acortar distancias: +  0.8995769233222737\n",
      "Penalización por duración del episodio: -  0.47634333095837544\n",
      "Recompensa por acortar distancias: +  0.8995769233222737\n",
      "Penalización por parar muy lejos: -  0.14094448467223514\n",
      "Penalización por duración del episodio: -  0.4764559409078887\n",
      "Recompensa por acortar distancias: +  0.8995769233222737\n",
      "Penalización por duración del episodio: -  0.4767884322141708\n",
      "Recompensa por acortar distancias: +  0.8995769233222737\n",
      "Penalización por parar muy lejos: -  0.14094448467223514\n",
      "Penalización por duración del episodio: -  0.476873222139267\n",
      "Recompensa por acortar distancias: +  0.8995769233222737\n",
      "Penalización por duración del episodio: -  0.47698598005359927\n",
      "Recompensa por acortar distancias: +  0.8995769233222737\n",
      "Penalización por parar muy lejos: -  0.14094448467223514\n",
      "Penalización por duración del episodio: -  0.4770900027673013\n",
      "Recompensa por acortar distancias: +  0.8995769233222737\n",
      "Penalización por duración del episodio: -  0.4775699698596065\n",
      "Recompensa por acortar distancias: +  0.8995887903163646\n",
      "Penalización por duración del episodio: -  0.47795154744993157\n",
      "Step: 10140, Mean Reward (últimos 10 pasos): 0.42163723707199097\n",
      "Recompensa por acortar distancias: +  0.8995936272128016\n",
      "Penalización por duración del episodio: -  0.4783442521263163\n",
      "Recompensa por acortar distancias: +  0.8995693631174303\n",
      "Penalización por parar muy lejos: -  0.14093435247864916\n",
      "Penalización por duración del episodio: -  0.47845985380836087\n",
      "Recompensa por acortar distancias: +  0.8995693631174303\n",
      "Penalización por duración del episodio: -  0.47873410392528026\n",
      "Recompensa por acortar distancias: +  0.8995760273244063\n",
      "Penalización por duración del episodio: -  0.47913488217501254\n",
      "Recompensa por acortar distancias: +  0.8995760273244063\n",
      "Penalización por parar muy lejos: -  0.1409432837878552\n",
      "Penalización por duración del episodio: -  0.47951621734590805\n",
      "Recompensa por acortar distancias: +  0.899608657742513\n",
      "Penalización por duración del episodio: -  0.4798871921984764\n",
      "Recompensa por acortar distancias: +  0.8995877436588167\n",
      "Penalización por duración del episodio: -  0.4802863859495902\n",
      "Recompensa por acortar distancias: +  0.8995877436588167\n",
      "Penalización por parar muy lejos: -  0.140958988335923\n",
      "Penalización por duración del episodio: -  0.4804403750889258\n",
      "Recompensa por acortar distancias: +  0.8995863653295643\n",
      "Penalización por parar muy lejos: -  0.14095714066611478\n",
      "Penalización por duración del episodio: -  0.48058109614411554\n",
      "Recompensa por acortar distancias: +  0.8995863653295643\n",
      "Penalización por parar muy lejos: -  0.14095714066611478\n",
      "Penalización por duración del episodio: -  0.48068509898976425\n",
      "Step: 10150, Mean Reward (últimos 10 pasos): 0.2779441177845001\n",
      "Recompensa por acortar distancias: +  0.8995790512887463\n",
      "Penalización por duración del episodio: -  0.4808138208228616\n",
      "Recompensa por acortar distancias: +  0.8995802574058017\n",
      "Penalización por duración del episodio: -  0.48106711767280247\n",
      "steer input from model: -0.05 , throttle:  0.3\n",
      "reward: 0.41851313973299925\n",
      "Recompensa por acortar distancias: +  0.8995647233567623\n",
      "Penalización por parar muy lejos: -  0.14092813490407183\n",
      "Penalización por duración del episodio: -  0.4814821162356885\n",
      "Recompensa por acortar distancias: +  0.8995647233567623\n",
      "Penalización por duración del episodio: -  0.481588413045871\n",
      "Recompensa por acortar distancias: +  0.8995647233567623\n",
      "Penalización por duración del episodio: -  0.48169048526633274\n",
      "Recompensa por acortar distancias: +  0.8995647233567623\n",
      "Penalización por duración del episodio: -  0.4817826480086592\n",
      "Recompensa por acortar distancias: +  0.8995647233567623\n",
      "Penalización por parar muy lejos: -  0.14092813490407183\n",
      "Penalización por duración del episodio: -  0.4822730783048036\n",
      "Recompensa por acortar distancias: +  0.8995721158659303\n",
      "Penalización por duración del episodio: -  0.4826714623957214\n",
      "Recompensa por acortar distancias: +  0.8995721761757887\n",
      "Penalización por duración del episodio: -  0.4830505668705317\n",
      "Recompensa por acortar distancias: +  0.8995761737860818\n",
      "Penalización por parar muy lejos: -  0.14094348008567867\n",
      "Penalización por duración del episodio: -  0.4831449679954723\n",
      "Step: 10160, Mean Reward (últimos 10 pasos): 0.2754877209663391\n",
      "Recompensa por acortar distancias: +  0.8995761737860818\n",
      "Penalización por duración del episodio: -  0.48328523233054893\n",
      "Recompensa por acortar distancias: +  0.8995702117810006\n",
      "Penalización por duración del episodio: -  0.4834342872827457\n",
      "Recompensa por acortar distancias: +  0.8995702117810006\n",
      "Penalización por duración del episodio: -  0.4838284709419541\n",
      "Recompensa por acortar distancias: +  0.8995577655129227\n",
      "Penalización por duración del episodio: -  0.4839434301025922\n",
      "Recompensa por acortar distancias: +  0.8995577655129227\n",
      "Penalización por parar muy lejos: -  0.14091881185846\n",
      "Penalización por duración del episodio: -  0.48422777775876497\n",
      "Recompensa por acortar distancias: +  0.8995577655129227\n",
      "Penalización por parar muy lejos: -  0.14091881185846\n",
      "Penalización por duración del episodio: -  0.4846171482454588\n",
      "Recompensa por acortar distancias: +  0.8995577655129227\n",
      "Penalización por parar muy lejos: -  0.14091881185846\n",
      "Penalización por duración del episodio: -  0.48476420392036595\n",
      "Recompensa por acortar distancias: +  0.8994951256473842\n",
      "Penalización por duración del episodio: -  0.4850043280646379\n",
      "Recompensa por acortar distancias: +  0.8994591205821595\n",
      "Penalización por duración del episodio: -  0.48538235460983326\n",
      "Recompensa por acortar distancias: +  0.8994591205821595\n",
      "Penalización por parar muy lejos: -  0.14078675134742283\n",
      "Penalización por duración del episodio: -  0.48551180151105067\n",
      "Step: 10170, Mean Reward (últimos 10 pasos): 0.27316057682037354\n",
      "Recompensa por acortar distancias: +  0.8994591205821595\n",
      "Penalización por parar muy lejos: -  0.14078675134742283\n",
      "Penalización por duración del episodio: -  0.48564108955628227\n",
      "Recompensa por acortar distancias: +  0.8994494868215627\n",
      "Penalización por duración del episodio: -  0.4857789675558975\n",
      "steer input from model: 0.1 , throttle:  1.0\n",
      "reward: 0.41367051926566517\n",
      "Recompensa por acortar distancias: +  0.8994494868215627\n",
      "Penalización por parar muy lejos: -  0.14077386590323884\n",
      "Penalización por duración del episodio: -  0.48589126191601023\n",
      "Recompensa por acortar distancias: +  0.8994491073191326\n",
      "Penalización por duración del episodio: -  0.48602910213691997\n",
      "Recompensa por acortar distancias: +  0.8994526780416661\n",
      "Penalización por parar muy lejos: -  0.14077813402529984\n",
      "Penalización por duración del episodio: -  0.4861335378891819\n",
      "Recompensa por acortar distancias: +  0.8994526780416661\n",
      "Penalización por duración del episodio: -  0.4862800894652095\n",
      "Recompensa por acortar distancias: +  0.8994526780416661\n",
      "Penalización por parar muy lejos: -  0.14077813402529984\n",
      "Penalización por duración del episodio: -  0.4863964759454552\n",
      "Recompensa por acortar distancias: +  0.8994526780416661\n",
      "Penalización por duración del episodio: -  0.4865586130297556\n",
      "Recompensa por acortar distancias: +  0.8994526780416661\n",
      "Penalización por parar muy lejos: -  0.14077813402529984\n",
      "Penalización por duración del episodio: -  0.4869553133785378\n",
      "Recompensa por acortar distancias: +  0.8994526780416661\n",
      "Penalización por parar muy lejos: -  0.14077813402529984\n",
      "Penalización por duración del episodio: -  0.4870601348091002\n",
      "Step: 10180, Mean Reward (últimos 10 pasos): 0.2716144025325775\n",
      "Recompensa por acortar distancias: +  0.8994526780416661\n",
      "Penalización por parar muy lejos: -  0.14077813402529984\n",
      "Penalización por duración del episodio: -  0.48716392094050504\n",
      "Recompensa por acortar distancias: +  0.8994526780416661\n",
      "Penalización por parar muy lejos: -  0.14077813402529984\n",
      "Penalización por duración del episodio: -  0.4873105064390156\n",
      "Recompensa por acortar distancias: +  0.8994260674138225\n",
      "Penalización por parar muy lejos: -  0.1407425504255479\n",
      "Penalización por duración del episodio: -  0.4877239048262188\n",
      "Recompensa por acortar distancias: +  0.8994261450552211\n",
      "Penalización por duración del episodio: -  0.4881095777861376\n",
      "Recompensa por acortar distancias: +  0.8994261019211175\n",
      "Penalización por duración del episodio: -  0.48850354556596004\n",
      "Recompensa por acortar distancias: +  0.8994291773415339\n",
      "Penalización por parar muy lejos: -  0.14074670818579535\n",
      "Penalización por duración del episodio: -  0.4889035030286014\n",
      "Recompensa por acortar distancias: +  0.8994291773415339\n",
      "Penalización por parar muy lejos: -  0.14074670818579535\n",
      "Penalización por duración del episodio: -  0.48929146390844086\n",
      "Recompensa por acortar distancias: +  0.8994291773415339\n",
      "Penalización por parar muy lejos: -  0.14074670818579535\n",
      "Penalización por duración del episodio: -  0.48968435893591095\n",
      "Recompensa por acortar distancias: +  0.8994117373508221\n",
      "Penalización por duración del episodio: -  0.4900819199985658\n",
      "Recompensa por acortar distancias: +  0.8994117373508221\n",
      "Penalización por parar muy lejos: -  0.14072339491521407\n",
      "Penalización por duración del episodio: -  0.4904748401731845\n",
      "Step: 10190, Mean Reward (últimos 10 pasos): 0.26821351051330566\n",
      "Recompensa por acortar distancias: +  0.8994117589206119\n",
      "Penalización por duración del episodio: -  0.49057869377508695\n",
      "Recompensa por acortar distancias: +  0.8994116942112304\n",
      "Penalización por parar muy lejos: -  0.14072333725592168\n",
      "Penalización por duración del episodio: -  0.4908535730756244\n",
      "steer input from model: -0.05 , throttle:  0.0\n",
      "reward: 0.2678347838796843\n",
      "Recompensa por acortar distancias: +  0.8994117589206119\n",
      "Penalización por parar muy lejos: -  0.14072342374486768\n",
      "Penalización por duración del episodio: -  0.4912601194800752\n",
      "Recompensa por acortar distancias: +  0.8994118236299565\n",
      "Penalización por parar muy lejos: -  0.1407235102338581\n",
      "Penalización por duración del episodio: -  0.4913473959940509\n",
      "Recompensa por acortar distancias: +  0.8994118236299565\n",
      "Penalización por duración del episodio: -  0.4916493194446317\n",
      "Recompensa por acortar distancias: +  0.8994118236299565\n",
      "Penalización por parar muy lejos: -  0.1407235102338581\n",
      "Penalización por duración del episodio: -  0.49179272465416235\n",
      "Recompensa por acortar distancias: +  0.8994118236299565\n",
      "Penalización por duración del episodio: -  0.4920326003743626\n",
      "Recompensa por acortar distancias: +  0.8994118236299565\n",
      "Penalización por parar muy lejos: -  0.1407235102338581\n",
      "Penalización por duración del episodio: -  0.49211253990517995\n",
      "Recompensa por acortar distancias: +  0.8994118236299565\n",
      "Penalización por parar muy lejos: -  0.1407235102338581\n",
      "Penalización por duración del episodio: -  0.49241366792867536\n",
      "Recompensa por acortar distancias: +  0.8994112153606573\n",
      "Penalización por duración del episodio: -  0.49280193112716336\n",
      "Step: 10200, Mean Reward (últimos 10 pasos): 0.40660929679870605\n",
      "Recompensa por acortar distancias: +  0.8994112153606573\n",
      "Penalización por duración del episodio: -  0.4929016591125602\n",
      "Recompensa por acortar distancias: +  0.8994198084793051\n",
      "Penalización por parar muy lejos: -  0.1407341833164624\n",
      "Penalización por duración del episodio: -  0.4931929681511341\n",
      "Recompensa por acortar distancias: +  0.899432024079817\n",
      "Penalización por duración del episodio: -  0.49357820300864175\n",
      "Recompensa por acortar distancias: +  0.8994384419181034\n",
      "Penalización por duración del episodio: -  0.49395103165774007\n",
      "Recompensa por acortar distancias: +  0.8994384419181034\n",
      "Penalización por parar muy lejos: -  0.14075909557546332\n",
      "Penalización por duración del episodio: -  0.49434308110379366\n",
      "Recompensa por acortar distancias: +  0.8994384419181034\n",
      "Penalización por duración del episodio: -  0.4947210187361832\n",
      "Recompensa por acortar distancias: +  0.8994701979621398\n",
      "Penalización por duración del episodio: -  0.4951118834502817\n",
      "Recompensa por acortar distancias: +  0.8994701979621398\n",
      "Penalización por parar muy lejos: -  0.14080157025052822\n",
      "Penalización por duración del episodio: -  0.49550291505882926\n",
      "Recompensa por acortar distancias: +  0.8994737249034561\n",
      "Penalización por parar muy lejos: -  0.14080628903837575\n",
      "Penalización por duración del episodio: -  0.49589047745269266\n",
      "Recompensa por acortar distancias: +  0.8994738240701441\n",
      "Penalización por parar muy lejos: -  0.14080642172014082\n",
      "Penalización por duración del episodio: -  0.49627573225311755\n",
      "Step: 10210, Mean Reward (últimos 10 pasos): 0.2623916566371918\n",
      "Recompensa por acortar distancias: +  0.899473949106279\n",
      "Penalización por duración del episodio: -  0.49665966831184244\n",
      "Recompensa por acortar distancias: +  0.899473949106279\n",
      "Penalización por duración del episodio: -  0.49705304339633494\n",
      "steer input from model: 0.9 , throttle:  0.7\n",
      "reward: 0.40242090570994404\n",
      "Recompensa por acortar distancias: +  0.899455209391468\n",
      "Penalización por parar muy lejos: -  0.14078151976124378\n",
      "Penalización por duración del episodio: -  0.4971854507185292\n",
      "Recompensa por acortar distancias: +  0.8994584866938369\n",
      "Penalización por duración del episodio: -  0.4974371717304686\n",
      "Recompensa por acortar distancias: +  0.8994584866938369\n",
      "Penalización por duración del episodio: -  0.4978226382086702\n",
      "Recompensa por acortar distancias: +  0.8994328737741927\n",
      "Penalización por parar muy lejos: -  0.14075165034509313\n",
      "Penalización por duración del episodio: -  0.4979015175532372\n",
      "Recompensa por acortar distancias: +  0.8994354832018315\n",
      "Penalización por parar muy lejos: -  0.14075513935473064\n",
      "Penalización por duración del episodio: -  0.49802283483139476\n",
      "Recompensa por acortar distancias: +  0.8994354832018315\n",
      "Penalización por parar muy lejos: -  0.14075513935473064\n",
      "Penalización por duración del episodio: -  0.49822130953561267\n",
      "Recompensa por acortar distancias: +  0.8994343531760878\n",
      "Penalización por duración del episodio: -  0.49860744240336374\n",
      "Recompensa por acortar distancias: +  0.8994635663249936\n",
      "Penalización por parar muy lejos: -  0.14079269836440303\n",
      "Penalización por duración del episodio: -  0.49899552003572406\n",
      "Step: 10220, Mean Reward (últimos 10 pasos): 0.25967535376548767\n",
      "Recompensa por acortar distancias: +  0.8994635663249936\n",
      "Penalización por duración del episodio: -  0.4993900778934681\n",
      "Recompensa por acortar distancias: +  0.8994635663249936\n",
      "Penalización por duración del episodio: -  0.4995111943848471\n",
      "Recompensa por acortar distancias: +  0.8994986130160332\n",
      "Penalización por duración del episodio: -  0.49962354905565953\n",
      "Recompensa por acortar distancias: +  0.8994986130160332\n",
      "Penalización por duración del episodio: -  0.4997466147162865\n",
      "Recompensa por acortar distancias: +  0.8995068460557405\n",
      "Penalización por parar muy lejos: -  0.14085061633185275\n",
      "Penalización por duración del episodio: -  0.499862509969362\n",
      "Penalización por duración del episodio\n",
      "Recompensa por acortar distancias: +  0.9156963187013263\n",
      "Penalización por duración del episodio: -  0.2690501639997843\n",
      "Recompensa por acortar distancias: +  0.9156963187013263\n",
      "Penalización por duración del episodio: -  0.2692923854917801\n",
      "Recompensa por acortar distancias: +  0.9156963187013263\n",
      "Penalización por parar muy lejos: -  0.16593146228844954\n",
      "Penalización por duración del episodio: -  0.26961260375541235\n",
      "Recompensa por acortar distancias: +  0.9156958548917316\n",
      "Penalización por duración del episodio: -  0.2697087771116917\n",
      "Step: 10230, Mean Reward (últimos 10 pasos): 0.6459870934486389\n",
      "Recompensa por acortar distancias: +  0.9156958548917316\n",
      "Penalización por duración del episodio: -  0.269914287352224\n",
      "Recompensa por acortar distancias: +  0.9156958548917316\n",
      "Penalización por duración del episodio: -  0.2702230151095815\n",
      "Recompensa por acortar distancias: +  0.9156958548917316\n",
      "Penalización por duración del episodio: -  0.27052793292507493\n",
      "Recompensa por acortar distancias: +  0.9156957297363646\n",
      "Penalización por duración del episodio: -  0.27083398053926677\n",
      "Recompensa por acortar distancias: +  0.9156957002880186\n",
      "Penalización por parar muy lejos: -  0.16593035360212585\n",
      "Penalización por duración del episodio: -  0.27090224304171845\n",
      "Recompensa por acortar distancias: +  0.9156957002880186\n",
      "Penalización por parar muy lejos: -  0.16593035360212585\n",
      "Penalización por duración del episodio: -  0.27115151623691525\n",
      "Recompensa por acortar distancias: +  0.9156957959951093\n",
      "Penalización por parar muy lejos: -  0.16593052518414497\n",
      "Penalización por duración del episodio: -  0.2712506974588995\n",
      "Recompensa por acortar distancias: +  0.9156957959951093\n",
      "Penalización por parar muy lejos: -  0.16593052518414497\n",
      "Penalización por duración del episodio: -  0.27135924939890904\n",
      "Recompensa por acortar distancias: +  0.9156959358745261\n",
      "Penalización por parar muy lejos: -  0.16593077595812086\n",
      "Penalización por duración del episodio: -  0.2714642544327986\n",
      "Recompensa por acortar distancias: +  0.9156959358745261\n",
      "Penalización por duración del episodio: -  0.2715479957293288\n",
      "Step: 10240, Mean Reward (últimos 10 pasos): 0.6441479325294495\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 852           |\n",
      "|    ep_rew_mean          | 287           |\n",
      "| time/                   |               |\n",
      "|    fps                  | 58            |\n",
      "|    iterations           | 5             |\n",
      "|    time_elapsed         | 175           |\n",
      "|    total_timesteps      | 10240         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00048121778 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.5           |\n",
      "|    entropy_loss         | -3.98         |\n",
      "|    explained_variance   | 0.0194        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 11.3          |\n",
      "|    n_updates            | 90            |\n",
      "|    policy_gradient_loss | -0.00089      |\n",
      "|    value_loss           | 57.8          |\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ],
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-22T08:32:00.176864Z",
     "start_time": "2024-10-22T08:32:00.164343Z"
    }
   },
   "cell_type": "code",
   "source": [
    "TIMESTEPS = 5  # how long is each training iteration - individual steps\n",
    "iters = 0\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "num_episodes = 10\n",
    "rewards_per_episode = []"
   ],
   "id": "7cc0b992a68ebb26",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-22T08:32:00.254414Z",
     "start_time": "2024-10-22T08:32:00.247543Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# while iters < 5:  # how many training iterations you want\n",
    "#     iters += 1\n",
    "#     print('Iteration ', iters, ' is to commence...')\n",
    "#     model.learn(total_timesteps=TIMESTEPS, reset_num_timesteps=False, tb_log_name=f\"PPO\")\n",
    "#     print('Iteration ', iters, ' has been trained')\n",
    "#     model.save(f\"{models_dir}/{TIMESTEPS * iters}\")"
   ],
   "id": "11f10709e9ebca8d",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-22T08:32:00.316306Z",
     "start_time": "2024-10-22T08:32:00.297810Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# # Evaluar el modelo después de cada iteración\n",
    "# for _ in range(num_episodes):\n",
    "#     obs = env.reset()\n",
    "#     done = False\n",
    "#     episode_reward = 0\n",
    "#     while not done:\n",
    "#         action, _states = model.predict(obs)\n",
    "#         obs, reward, done, info = env.step(action)\n",
    "#         episode_reward += reward\n",
    "#     rewards_per_episode.append(episode_reward)\n",
    "# \n",
    "# \n"
   ],
   "id": "690d02e353d8920d",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-22T08:32:00.348596Z",
     "start_time": "2024-10-22T08:32:00.334850Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# # --- Generar gráfico de recompensas ---\n",
    "# plt.plot(rewards_per_episode)\n",
    "# plt.title('Recompensas por Episodio')\n",
    "# plt.xlabel('Episodio')\n",
    "# plt.ylabel('Recompensa Total')\n",
    "# plt.grid(True)\n",
    "# plt.show()"
   ],
   "id": "39a84ac34cc299c4",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-22T08:32:00.425968Z",
     "start_time": "2024-10-22T08:32:00.380800Z"
    }
   },
   "cell_type": "code",
   "source": [
    "spectator = env.world.get_spectator()\n",
    "\n",
    "transform = spectator.get_transform()\n",
    "location = transform.location\n",
    "rotation = transform.rotation\n",
    "\n",
    "print(location, rotation)"
   ],
   "id": "5338de9af92e1a32",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Location(x=18.633802, y=-19.904999, z=7.794066) Rotation(pitch=-29.543756, yaw=-117.807945, roll=0.000025)\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-22T08:32:00.458208Z",
     "start_time": "2024-10-22T08:32:00.444296Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "print(\"GPU disponible:\", tf.config.list_physical_devices())"
   ],
   "id": "8e632c53a0881df7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU disponible: [PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-22T08:32:00.660063Z",
     "start_time": "2024-10-22T08:32:00.495222Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# v es el valor que se quiere penalizar\n",
    "# k controla la inclinación de la curva (qué tan rápido crece la penalización)\n",
    "# m controla la penalización maxima\n",
    "# p controla la magnitud de la penalización\n",
    "\n",
    "mm=60\n",
    "\n",
    "def punish_logistic(v, k=0.1, m=mm, p=1):\n",
    "    logistic = 2 / (1 + np.exp(-k * (v - m)))\n",
    "    return logistic * p\n",
    "\n",
    "# Generar valores de tiempo entre 0 y 60\n",
    "tiempos = np.linspace(0, mm, 100)\n",
    "penalizaciones = punish_logistic(tiempos)\n",
    "\n",
    "# Graficar\n",
    "plt.plot(tiempos, penalizaciones)\n",
    "plt.title(\"Penalización respecto al tiempo\")\n",
    "plt.xlabel(\"Tiempo (segundos)\")\n",
    "plt.ylabel(\"Penalización\")\n",
    "plt.show()"
   ],
   "id": "1d9813293ca76f50",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ],
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "tensorboard --logdir='E:\\UADY\\CARLA\\CARLA_Latest\\WindowsNoEditor\\PythonAPI\\examples\\Ruben\\Parking training\\logs'",
   "id": "b53e55c9d397c579"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
